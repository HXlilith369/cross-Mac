{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This IPYNB file provides the sentiment binary classification experimental results using test data that does not contain zeros. The training and validation datasets will be made available later.\n",
    "本ipnyb文件提供不包含0的测试数据的情感二分类实验结果。训练集、验证集数据将在后续公开。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0:\n",
      "  video_id: -6rXp3zJ3kc\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the answer to the question, can I contribute stock to an IRA is absolutely correct but always be mindful of the security that your using it, make sure it's safe.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1104, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 1:\n",
      "  video_id: -6rXp3zJ3kc\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Many people are not until they get to be a older age and they realize that gosh they wasted a lot of time and money in placing bets on stock that's ultimately lost value.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 828, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s so nice, by giving a good example and not directly comparing it to a lady\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 609, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: is, you can say, hey I really like baby skin, they are so soft, they don’t have any hair on their face\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 5:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And lastly, hey or hey bitch\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 729, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 6:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You are hinting that you want her to remove her mustache\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 8:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The better way to use this or the better word to say is, Excuse me Ms, Excuse me Mam\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 9:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So even if you’re a lady, never call another women or a lady, hey\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 10:\n",
      "  video_id: -9y-fZ3swSY\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That’s a more decent and more polite way to call a lady\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 11:\n",
      "  video_id: -AUZQgSxyPQ\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The perfect soul mate to the Clarisonic Spot Therapy Brush, this gentle, Ph balanced and hydrating exfoliant containing jojoba and acai fruit oils and bamboo and prickly bear extracts deliver intense healing, while smooth granules buff away dead, dry skin cells.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1364, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 12:\n",
      "  video_id: -HeZS2-Prhc\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the major index-tracking exchange traded funds were smartly higher at the opening bell on the stock market today.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 849, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 13:\n",
      "  video_id: -HeZS2-Prhc\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: She pledged to fight “excessive unjustified costs” of drugs.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 14:\n",
      "  video_id: -HeZS2-Prhc\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The August jobs report is out and it was seen overall as solid but not great.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 791, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 15:\n",
      "  video_id: -HeZS2-Prhc\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So a look at the gold and silver exchange traded funds: SPDR Gold Shares (GLD) popped nearly 1% in early trade on the stock market today.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 16:\n",
      "  video_id: -MeTTeMJBNc\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Okay, what happens at this point after we've taken this brief walk down memory lane, is the presentation of the gift.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 17:\n",
      "  video_id: -MeTTeMJBNc\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It just needs to be a simple statement, and then you present the gift.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 19:\n",
      "  video_id: -MeTTeMJBNc\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Maybe you could find a picture of the couple from their wedding or sometime in their life, or maybe even a current picture and have it put in a beautiful frame.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 868, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 20:\n",
      "  video_id: -RfYyzHpjk4\n",
      "  clip_id: 11\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So get your friends lined up, get your business colleagues lined up and have a good time.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 21:\n",
      "  video_id: -RfYyzHpjk4\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's pretty, pretty easy to do but you got to set up those numbers ahead of time.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 582, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 22:\n",
      "  video_id: -RfYyzHpjk4\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can make a conference call but it takes quite a bit of planning, well not a lot of planning it's pretty easy to do.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 24:\n",
      "  video_id: -UUCSKoHeMA\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Three pitches, two pitches, always better than one which will leave you monotone.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 25:\n",
      "  video_id: -UUCSKoHeMA\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now, the big problem with being monotone, obviously, you'll put your audience to sleep.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 686, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 29:\n",
      "  video_id: -cEhr0cQcDM\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I think that feeling of empowerment is much more valuable than the feeling you get on television.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 30:\n",
      "  video_id: -ri04Z7vwnc\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think finances for some reason has been a very delicate issue between couples\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 32:\n",
      "  video_id: -ri04Z7vwnc\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: most people think it'll sort itself out, \"we'll discuss it later,\" it's not something too important\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 33:\n",
      "  video_id: -ri04Z7vwnc\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" So I think it's important to discuss finances\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 34:\n",
      "  video_id: -ri04Z7vwnc\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: what do they really want You know, maybe a fancy car, maybe a bigger house maybe a trip abroad\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 545, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 35:\n",
      "  video_id: -ri04Z7vwnc\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think first it's important for individuals Who are in a relationship or in a marriage to acknowledged to themselves what really are their financial goals\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 800, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 36:\n",
      "  video_id: -rxZxtG0xmY\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I am a mother of two children who have finished their   studies, have done their masters but are now unemployed.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 38:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the hardest thing in life to learn, is to lose\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 39:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: they have doubt, they have fear, they lose in a Ferrari race, or they lose in a race, and then they just give up\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 343, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 40:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's your ability to take a loss, get up the next day, dust yourself off, and keep going\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 41:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Winning's easy, you win, you're happy, you get a high five, your friends are happy\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 42:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I have been beat up and put down and everything that can go wrong, has gone wrong for me\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 44:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I used to work for Warren Avis, the guy who started Avis Rent a Car, and he said to me one day, \"Robert, \"what's the purpose of business\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 46:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" And he said, \"No, the purpose of business \"is to create a customer because \"everything else takes care of itself\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 47:\n",
      "  video_id: -s9qJ7ATP7w\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" And I said, \"Oh, make a profit, and all these other things\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 50:\n",
      "  video_id: -yRb-Jum7EQ\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Yesterday Eliav Gelman lost his life in another terrorist attack, not by the students of terrorism, but by those who teach terrorism, a Palestinian teacher.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 53:\n",
      "  video_id: 0Fqav67TDEw\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So a very good way of helping yourself to remember your dreams better on a consistent basis, is to keep a dream journal.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 771, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 54:\n",
      "  video_id: 0JaYazphxfM\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However I feel it tastes better without onions because onions release water, which makes the bhindi (ladyfinger) sticky.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 891, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 56:\n",
      "  video_id: 0K7dCp80n9c\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's really designed for well water because that's the kind of water that typically will have an iron problem.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 625, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 57:\n",
      "  video_id: 0K7dCp80n9c\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, it helps keep your resin doing what it's supposed to do.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 365, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 60:\n",
      "  video_id: 0K7dCp80n9c\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's commonly the culprit behind those nasty iron stains in your toilet bowls, or in your tub or even in your laundry sometimes.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 63:\n",
      "  video_id: 0K7dCp80n9c\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, do it right away, don't wait until the problem arises, use Rust Out.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 64:\n",
      "  video_id: 0PlQc98SccA\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Joe Echevarria, CEO of Deloitte, recently stated that White House discussions over the fiscal cliff are encouraging.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 65:\n",
      "  video_id: 0PlQc98SccA\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Echevarria was one of fourteen CEO\"s of large organizations who met with the president earlier this week.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 741, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 66:\n",
      "  video_id: 0PlQc98SccA\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He also said that the president is getting a better sense of what steps need to be taken to prevent the crisis from erupting.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 426, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 67:\n",
      "  video_id: 0YiAKqU36KE\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So every nook and corner, every commons--and the Ganga is the ultimate commons-- becomes a place to throw your garbage into\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 68:\n",
      "  video_id: 0YiAKqU36KE\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The filth that you see in India with this throw away culture is a result of the fact that there is no industrially organized system to pick it up\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 69:\n",
      "  video_id: 0YiAKqU36KE\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And this information had been brought to me, so I filed a case\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 71:\n",
      "  video_id: 0YiAKqU36KE\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Shiva, \"that we are being treated like a waste dump\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 333, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 73:\n",
      "  video_id: 0YiAKqU36KE\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" And it led to a huge series of investigations and a new alertness\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 74:\n",
      "  video_id: 0YiAKqU36KE\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" I said, \"Yes, we are\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 406, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 76:\n",
      "  video_id: 0bxhZ-LIfZY\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think what will hold us back will be our weakness in implementation, our deadlocked democracy, if not educated, will turn back on us, which is something we need to clearly focus on.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1148, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 77:\n",
      "  video_id: 0bxhZ-LIfZY\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Education, health care, all these critical if not dealt with and kept to the last, will turn India into less of a superpower than it can be.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 910, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 78:\n",
      "  video_id: 0eTibWQdO5M\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Something else for you to consider is, if you have to go to great lengths to work in this funny story or joke, or antidote, don't do it.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 824, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 79:\n",
      "  video_id: 0uftSGdwo0Q\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Informational interviews work well for the candidates and for the company.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 81:\n",
      "  video_id: 0uftSGdwo0Q\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A couple of things to remember; one, it could be in a group format; the other is it could be in a one on one.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 82:\n",
      "  video_id: 0uftSGdwo0Q\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You could have it on a CD, where you could actually just give it to that individual and have them take a look at it.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 83:\n",
      "  video_id: 100178\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Not all that funny and not all that original and I didn't think the acting was all that great either\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 85:\n",
      "  video_id: 100178\n",
      "  clip_id: 13\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This was pretty popular (umm) and it's a good choice for like I said kids or families\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 86:\n",
      "  video_id: 100178\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But who knows? I (umm) am probably tougher on movies than a lot of people\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 88:\n",
      "  video_id: 100178\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) So if you're looking for something it's sort of lighthearted\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 89:\n",
      "  video_id: 100178\n",
      "  clip_id: 17\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But for me it only gets two stars out of five\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 238, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 90:\n",
      "  video_id: 100178\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Cheaper by the Dozen is a good place to look\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 548, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 95:\n",
      "  video_id: 100178\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) All names that should be familiar with kids and some adults and so this kind of makes the movie have wide appeal\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 600, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 97:\n",
      "  video_id: 100178\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think Steve Martin's done other better things\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 437, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 98:\n",
      "  video_id: 100178\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn't really like the movie, I thought it was cheesy\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 99:\n",
      "  video_id: 100178\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The humor seemed kind of contrived, kind of, you know, slapstick\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 100:\n",
      "  video_id: 100178\n",
      "  clip_id: 8\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Ebert and Roper apparently said two thumbs up here on the cover but for me it's probably two thumbs down\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 101:\n",
      "  video_id: 10219\n",
      "  clip_id: 11\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And (uhh) It's just a great story so you have to continue the whole thing\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 402, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 102:\n",
      "  video_id: 10219\n",
      "  clip_id: 10\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Overall I would give it a five out of five stars because I have the previous two DVDs\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 103:\n",
      "  video_id: 10219\n",
      "  clip_id: 13\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They're just (uhh) great DVDs\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 287, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 107:\n",
      "  video_id: 10219\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It continues the story\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 345, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 108:\n",
      "  video_id: 10219\n",
      "  clip_id: 2\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's very good\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 109:\n",
      "  video_id: 10219\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And (uhh) it introduces (umm) a couple new characters (umm) new situations and it really adds a lot to the story\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 434, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 110:\n",
      "  video_id: 10219\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It keeps the (uhh) It keeps up the expectations that (uhh) came to be expected from the first two DVDs of the series\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 111:\n",
      "  video_id: 10219\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's a really great (uhh) collection of the episodes on the third DVD\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 113:\n",
      "  video_id: 10219\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because (uhh) great story\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 262, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 114:\n",
      "  video_id: 10219\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And if you enjoyed the previous two DVDs, you have to continue the story\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 115:\n",
      "  video_id: 102213\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The story sucks, the characters were really wooden and plain and I liked some of the actors and actresses, so I'm not sure what was going on there\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 116:\n",
      "  video_id: 102213\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's definitely better ways to go about humor than making you know really unfunny jokes, and there's a lot of moments like that\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 117:\n",
      "  video_id: 102213\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Unfortunately, it seems like it'll be a good bomb\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 118:\n",
      "  video_id: 102213\n",
      "  clip_id: 12\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It just seems like a really lousy effort by everybody and (uhh) I guess the box office is reflecting that\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 378, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 119:\n",
      "  video_id: 102213\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was a huge fan of the original film Bruce Almighty but I did think it was funny\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 633, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 121:\n",
      "  video_id: 102213\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then I heard that it was gonna have like a, it was going way over budget, it was going to be two-hundred and fifty million\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 353, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 122:\n",
      "  video_id: 102213\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Like Jim Carey, Morgan Freeman and I like Steve Carell too so I figured okay you know the sequel will be pretty good\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 123:\n",
      "  video_id: 102213\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I'm afraid it wasn't\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 124:\n",
      "  video_id: 102213\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Then I was thinking I don't know how a comedy can really be two-hundred fifty million but you know, I guess with all this hype it's worth seeing\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 125:\n",
      "  video_id: 102213\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There seems to be a ton of CG but there also seems to be a ton of real animals and I'm not sure why they would have blown all that money when they could have just you know CG's it all, because the animals really weren't that impressive\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 747, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 126:\n",
      "  video_id: 102213\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) All the money they seem to have spent on a giant arc and a bunch of live animals\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 127:\n",
      "  video_id: 102213\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like, I mean there's a lot of animal poop jokes in there that really didn't need to be there\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 129:\n",
      "  video_id: 102389\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Just some untasteful things in the movie\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 130:\n",
      "  video_id: 102389\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: People or (uhh) the penguins were passing gas\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 236, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 131:\n",
      "  video_id: 102389\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I've had my fill of it\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 132:\n",
      "  video_id: 102389\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And in my opinion, (umm) too, I think we've had enough (stutter) penguin movies made in the last year\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 133:\n",
      "  video_id: 102389\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, I would highly recommend that you save your money\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 230, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 134:\n",
      "  video_id: 102389\n",
      "  clip_id: 1\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I was very disappointed in it\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 415, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 138:\n",
      "  video_id: 102389\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It did not hold the attention of my five year old\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 140:\n",
      "  video_id: 102389\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) We were at the drive in and it was the first movie and there was another movie coming, so there was no way we could leave\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 703, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 141:\n",
      "  video_id: 102389\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: She was ready to leave when it was half over\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 142:\n",
      "  video_id: 102389\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) even though they're not considered curse words, (umm) they were using the word (uhh) poop and crap (umm) things like that\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 530, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 143:\n",
      "  video_id: 102389\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It used (uhh) words that I don't like my children to use\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 146:\n",
      "  video_id: 104741\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I give it probably about a two, (umm) because of some of the language it contains\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 147:\n",
      "  video_id: 104741\n",
      "  clip_id: 2\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm), I don't like this movie\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 149:\n",
      "  video_id: 104741\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And, it's the story about four friends, (umm), Stan, Kyle, Kenny, and Cartman, who sneak into an, X-rated or R-Rated movie, and it kind of warps their mind and then, for some reason their parents start a war against Canada or something\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1258, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 150:\n",
      "  video_id: 104741\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's, (umm) as I said I don't like it, I'd give it about a two\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 426, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 151:\n",
      "  video_id: 104741\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's an animated film, probably about an hour and a half, maybe two hours long\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 628, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 152:\n",
      "  video_id: 104741\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But, if you're interested in owning this, you can find it on amazon dot com\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 153:\n",
      "  video_id: 104741\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's not appropriate for kids because there's a lot of cursing and things in it\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 625, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 154:\n",
      "  video_id: 107585\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You don't connect with any of the characters\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 155:\n",
      "  video_id: 107585\n",
      "  clip_id: 10\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They're you don't like any of the characters\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 156:\n",
      "  video_id: 107585\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It it's (stutter) not even romantic you know in a way that, the way it's written it's like how can someone you know go that hard\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 673, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 157:\n",
      "  video_id: 107585\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And It felt like the you know there's like just a little bit just way too typical of a boring film that tries really hard to be funny but it's just not funny at all and it's not it's not (stutter) witty\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1065, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 158:\n",
      "  video_id: 107585\n",
      "  clip_id: 15\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You don't believe that someone can actually you know believe in the priest and just wanted get married that badly in that church\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 159:\n",
      "  video_id: 107585\n",
      "  clip_id: 14\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just like at the end when you're done with the movie you don't even believe in the original premise of the movie\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 160:\n",
      "  video_id: 107585\n",
      "  clip_id: 17\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't know if it's the acting or the way the characters are characterized\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 659, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 161:\n",
      "  video_id: 107585\n",
      "  clip_id: 16\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And be you know believe everything in the priest, it's just kind of like, the movie's stressful\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 162:\n",
      "  video_id: 107585\n",
      "  clip_id: 19\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So (umm) For those who are interested, I definitely do not recommend this movie at all\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 163:\n",
      "  video_id: 107585\n",
      "  clip_id: 18\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just really boring, bland film that even the plot it didn't really have anything going on for that\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 164:\n",
      "  video_id: 107585\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) This is a movie I though was going to be pretty funny because the trailer looked pretty funny and it's got you know Robin Williams, which I personally like and thought you know he's gonna bring some entertainment to this movie\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1116, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 165:\n",
      "  video_id: 107585\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, this is my movie review of the movie (stutter) License to Wed starring Mandy Moore\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 166:\n",
      "  video_id: 107585\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was boring\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 484, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 167:\n",
      "  video_id: 107585\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I didn't really like this movie at all\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 436, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 168:\n",
      "  video_id: 107585\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was just they are trying to you know create all these things to make you laugh but I don't think it was funny at all\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 169:\n",
      "  video_id: 107585\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (stutter) The plot It was like it didn't have a plot\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 287, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 170:\n",
      "  video_id: 107585\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It looked funny in the clip for the trailer but didn't seem funny at all\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 171:\n",
      "  video_id: 107585\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Even the robotic baby part was supposed to be funny, it didn't turn out to be funny in the film\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 172:\n",
      "  video_id: 107585\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it wasn't and I feel like the characters were underdeveloped\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 173:\n",
      "  video_id: 107585\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) you know Mandy Moore's character is kind of like, you feel like her character's unrealistic because what type of girl would go that hard core to you know to get married in this church and it just seemed unrealistic and she gets all in a hissy fit and it's just really really tiring and stressful movie\n",
      "  text_feature_shape: (1, 69, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1421, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 174:\n",
      "  video_id: 108146\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you don't see it, you're not missing anything\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 175:\n",
      "  video_id: 108146\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you're going to go see a movie, I would not recommend that\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 176:\n",
      "  video_id: 108146\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I saw Ocean's Eleven and Ocean's Twelve and I really like those\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 178:\n",
      "  video_id: 108146\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Ocean's Thirteen not good at all\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 179:\n",
      "  video_id: 108146\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All of the movies have George Clooney, Matt Damon, Brad Pitt and so you know, they're nice to look at but Ocean's Eleven and Twelve were good\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 180:\n",
      "  video_id: 108146\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I thought the other two were pretty exciting\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 181:\n",
      "  video_id: 108146\n",
      "  clip_id: 4\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't like it\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 182:\n",
      "  video_id: 108146\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Ocean's Thirteen, not exciting at all\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 459, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 183:\n",
      "  video_id: 108146\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And (uhh) not a lot of people liked Ocean's Twelve but I still liked it\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 184:\n",
      "  video_id: 108146\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was just not exciting, at all\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 185:\n",
      "  video_id: 108146\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They had some complications that were pretty small and were resolved pretty quickly without any drama or anything\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1014, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 186:\n",
      "  video_id: 110565\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I expected more, I'd seen the previews and I thought it looked like a pretty good story\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 187:\n",
      "  video_id: 110565\n",
      "  clip_id: 0\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I recently viewed the movie Click with Adam Sandler, and I was very disappointed\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 422, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 188:\n",
      "  video_id: 110565\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) There's (uhh) a dog that keeps (uhh) humping the stuffed animal, there's farting, I just I just (stutter) thought it was a rude movie\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 729, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 189:\n",
      "  video_id: 110565\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's PG-thirteen, but in this day and age, PG-thirteen it's harder to tell what, what that really means, you know, well in this one there's lots of cussing, (umm) there's some bedroom scenes, even though they don't show any skin you obviously know what they're doing\n",
      "  text_feature_shape: (1, 74, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1042, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 190:\n",
      "  video_id: 110565\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know, I love the fact of what the story about, in fact in even made me cry in the end\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 671, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 191:\n",
      "  video_id: 110565\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I loved the storyline\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 402, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 192:\n",
      "  video_id: 110565\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I don't know why they do that to movies, and my husband was very leery of it too, because he said I've never seen an Adam Sandler movie that's actually been clean and (umm) and actually okay for children to watch\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 193:\n",
      "  video_id: 110565\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But we could've done without all the other garbage that they added to this movie\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 194:\n",
      "  video_id: 110565\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I'm gonna give this a two just because you know, it could (stutter) it had so much potential, and they just like, trashed it up in my opinion\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 780, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 195:\n",
      "  video_id: 111881\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It didn't\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 196:\n",
      "  video_id: 111881\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I was left watching this by myself, and I went ahead and watched it all the way through to the end so I could do this review and I was hoping that it would get better in the end\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 713, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 198:\n",
      "  video_id: 111881\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Very Disappointing\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 199:\n",
      "  video_id: 111881\n",
      "  clip_id: 15\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm glad I didn't pay money to go see this at the movies\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 332, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 200:\n",
      "  video_id: 111881\n",
      "  clip_id: 14\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Rent it if you must (umm) I would\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 201:\n",
      "  video_id: 111881\n",
      "  clip_id: 17\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So anyway, if you don't have anything better to do, then you might watch this movie\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 202:\n",
      "  video_id: 111881\n",
      "  clip_id: 16\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I would've really been upset had I paid (uhh) you know, seven eight bucks a ticket for us to go see this\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 665, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 203:\n",
      "  video_id: 111881\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was looking very forward to seeing it when I had remembered seeing the previews for it\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 205:\n",
      "  video_id: 111881\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think it could have been (umm) so much more\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 206:\n",
      "  video_id: 111881\n",
      "  clip_id: 2\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was very disappointed in it\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 198, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 208:\n",
      "  video_id: 111881\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean there was a few funny parts and I expected more from you know, considering all the stars it has in it\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 209:\n",
      "  video_id: 111881\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I guess I just expected a few more, a a (stutter) better movie from these (umm) actors\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 210:\n",
      "  video_id: 111881\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: , Andy Dick, George Carlin and Sigourney Weaver just to name a few\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 582, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 211:\n",
      "  video_id: 111881\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: However, I started watching it with my kids and they got so bored they got up and left, went outside to play\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 633, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 212:\n",
      "  video_id: 111881\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is rated PG so you can watch this with your kids\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 607, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 213:\n",
      "  video_id: 112425\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it's a great movie that anyone should see\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 254, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 214:\n",
      "  video_id: 112425\n",
      "  clip_id: 10\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I think that (uhh) a lot of the more recent videos from Disney such as The Emperor's New Groove, (umm) Over the Hedge, and stuff like that, they've had a lot of real high brow (umm) you know adult comedy but, I think Ratatouille does a very good job in (umm) sticking to it's target audience which is kids and you know, hyping that to how Disney movies used to be, you know, with with kids jokes and not these kinds of inane sexual references so I would highly recommend Ratatouille\n",
      "  text_feature_shape: (1, 124, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1791, 1024])\n",
      "  vision_feature_shape: (35, 2048)\n",
      "Item 215:\n",
      "  video_id: 112425\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Okay\n",
      "  text_feature_shape: (1, 3, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 216:\n",
      "  video_id: 112425\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Jordan and today I will be reviewing the movie Ratatouille\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 218:\n",
      "  video_id: 112425\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I saw the previews in theaters six months ago, (uhh) I looked at my friend and said look, we're seeing this\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 219:\n",
      "  video_id: 112425\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) First of all let's say that I had an incredible build up to this movie\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 220:\n",
      "  video_id: 112425\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I know that (umm) in Finding Nemo they had, in fact, (uhh) made the scenes look too real so they had to, you know, kind of fake it down and I'm pretty sure they did the same thing in Ratatouille\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 793, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 221:\n",
      "  video_id: 112425\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I personally love Disney movies and I think that (umm) Disney Pixar, you know, the animations has just added a real, you know, incredible life-like (uhh) aspect to (umm) Disney movies which is especially true in Ratatouille which looks incredible\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 933, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 222:\n",
      "  video_id: 112425\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I I (stutter) love the storyline, it's so incredible, it's like anyone can cook\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 669, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 223:\n",
      "  video_id: 112425\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I cook a lot {laughter} and so I can appreciate, you know, a lot of the (uhh) a lot of the food references that are made\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 224:\n",
      "  video_id: 112425\n",
      "  clip_id: 9\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think I think (stutter) it's incredible\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 225:\n",
      "  video_id: 112425\n",
      "  clip_id: 8\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It's a story about a rat who decides to become a chef in Paris and how he goes about doing that but, really I I (stutter) love this movie\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 739, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 226:\n",
      "  video_id: 112509\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Land of the Dead was (umm) and not as good as (uhh) the other Romero zombie movies\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 756, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 227:\n",
      "  video_id: 112509\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is a review of John Lamaro's Land of the Dead\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 228:\n",
      "  video_id: 112509\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Which was you know, and important and interesting but if you like overall it really is, wasn't that new of a plot going on here\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 748, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 229:\n",
      "  video_id: 112509\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Yes it continued the motif of having zombies represent either (uhh) some sort of disenfranchised group\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 571, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 230:\n",
      "  video_id: 112509\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As for the acting, the acting was pretty good (uhh) John Leguizamo was okay, better than I expected and (umm) Dennis Hopper was awesome as always\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 702, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 231:\n",
      "  video_id: 112509\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Felt pretty rehashed\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 232:\n",
      "  video_id: 116213\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The process of the movie takes you through how he changed the world and how it comes from his small town to change people's lives all the way across the country\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 234:\n",
      "  video_id: 116213\n",
      "  clip_id: 12\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This movie truly teaches you that one person can make a difference\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 351, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 235:\n",
      "  video_id: 116213\n",
      "  clip_id: 1\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Summer here and if you're looking for a fantastic DVD at a value price that everyone in your family can watch, well why not try Pay It Forward, with Haley Joel Osment, Helen Hunt, and Kevin Spacey? This movie takes you through the journey of a child who learns life's lessons and it might just leave you crying in the end\n",
      "  text_feature_shape: (1, 72, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1116, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 236:\n",
      "  video_id: 116213\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey there\n",
      "  text_feature_shape: (1, 4, 768)\n",
      "  audio_feature_shape: torch.Size([1, 104, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 237:\n",
      "  video_id: 116213\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But, word of caution\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 238:\n",
      "  video_id: 116213\n",
      "  clip_id: 2\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now I purchased this DVD for a little under ten dollars so it's a great value to add to your DVD collection\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 587, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 239:\n",
      "  video_id: 116213\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But let me tell you for your older kids you can learn a lesson from this like none other\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 242:\n",
      "  video_id: 116213\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: According to the movie it's a simple story line\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 449, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 243:\n",
      "  video_id: 116213\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's change the world\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 244:\n",
      "  video_id: 116213\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The teacher gives him a lesson\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 428, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 245:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A diverse faculty enriches a university by widening the spectrum of available viewpoints, thus increasing the possibility of innovation, as well as helping to ensure an institutional sensitivity to the needs of people from all kinds of backgrounds.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1229, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 246:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Participating in the Diversity Inclusion Initiative has been incredibly beneficial to me in my career in a number of ways.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 247:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the projects that I was able to develop myself involved putting together a study of instructional practices in graduate institutions that offer music degrees from around the country.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 876, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 248:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This helped give me the experience and qualifications I needed to make me competitive in the job market.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 713, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 249:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This has provided valuable insight into curricular practice.\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 235, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 250:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My conversations convinced me to apply for positions that I otherwise may not have considered.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 251:\n",
      "  video_id: 11UtTaDYgII\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As I was looking for a job, the advice, encouragement and assistance I received from the wonderful staff of the Association of Research Libraries and librarian colleagues in the Music Library Association were invaluable.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 901, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 252:\n",
      "  video_id: 121400\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So (uhh) Sean Connery, the (stutter) League of Extraordinary Gentlemen\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 269, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 253:\n",
      "  video_id: 121400\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Comic, you know one of those weird ones that they put out\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 254:\n",
      "  video_id: 121400\n",
      "  clip_id: 1\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I did not like this movie at all, I would not recommend it\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 257:\n",
      "  video_id: 121400\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I only watched half of it because I didn't like the rest of the movie\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 259:\n",
      "  video_id: 121400\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) It is a mind-blowing adventure\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 261:\n",
      "  video_id: 121400\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And little do you know that (uhh) the league extraordinary gentlemen has a woman in it and each of these (uhh) five people have different powers, and (uhh) they're all a little bit special at what they do, and (uhh) you've got a vampire in there, you've got an invisible man\n",
      "  text_feature_shape: (1, 71, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1190, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 262:\n",
      "  video_id: 121400\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Almost like a (umm) I don't know, really weird comic strip that you're gonna get\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 296, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 264:\n",
      "  video_id: 126872\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One out of five\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 266:\n",
      "  video_id: 126872\n",
      "  clip_id: 13\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I wouldn't\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 267:\n",
      "  video_id: 126872\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you want to see it, you can do it\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 268:\n",
      "  video_id: 126872\n",
      "  clip_id: 14\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I Know Who Killed Me, one out of five\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 269:\n",
      "  video_id: 126872\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Nah, not very good\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 271:\n",
      "  video_id: 126872\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) But it's a Lindsay Lohan movie, so (uhh) I don't know\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 272:\n",
      "  video_id: 126872\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One out of five at very most\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 273:\n",
      "  video_id: 126872\n",
      "  clip_id: 5\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was kind of (umm) more funny to me than it was scary\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 274:\n",
      "  video_id: 126872\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn't like it\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 153, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 275:\n",
      "  video_id: 126872\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But (uhh) it's definitely in the vein of, like, I don't know, I'd I'd (stutter) say it's pretty similar, in some aspects, to a movie like (umm) maybe even, maybe Saw\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 675, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 276:\n",
      "  video_id: 126872\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I kind of took the whole thing as a joke\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 277:\n",
      "  video_id: 126872\n",
      "  clip_id: 9\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But, I mean, if you're going to watch a movie like that, go see Saw again or something, because this movie is really not good at all\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 923, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 278:\n",
      "  video_id: 126872\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's almost (umm), I don't know, it's almost too similar, to the point of where you kind of know what's going to happen, kind of all all (stutter) those kind of movies kind of blend together\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 813, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 279:\n",
      "  video_id: 130366\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But it felt (uhh) at least like three hours and the fact that they kept rewinding the story where she keeps reliving the same week over and over, (uhh) it felt extremely long (uhh) and (uhh) it just really went on a long time\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 742, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 280:\n",
      "  video_id: 130366\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) But it, and that's a long movie to me\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 281:\n",
      "  video_id: 130366\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't have the box for it because I rented it (uhh) at (uhh) Red Box, one of their kiosks\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 282:\n",
      "  video_id: 130366\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm Bruce and today (umm) I'm reviewing the DVD (uhh) widescreen edition of Premonition, (uhh) starring Sandra Bullock and Julian McMahon, and here's a closer look at it\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 284:\n",
      "  video_id: 130366\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And this is a psychological thriller\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 209, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 286:\n",
      "  video_id: 130366\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) {clears throat} And so we keep seeing a lot of same events over and over again\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 359, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 287:\n",
      "  video_id: 130366\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was (uhh) rather disappointing\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 575, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 288:\n",
      "  video_id: 130366\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Unfortunately, I cannot recommend it\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 454, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 289:\n",
      "  video_id: 130366\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was two hours and twenty minutes\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 290:\n",
      "  video_id: 130366\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) and (umm) It was very long\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 293:\n",
      "  video_id: 132028\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I mean it has some entertaining action sequences, some cool gadgets and cars and stuff, but overall it just feels tired and old and not that engaging\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 872, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 294:\n",
      "  video_id: 132028\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And this is one of the more recent James Bond movies but I found that it's just really silly overall\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 296:\n",
      "  video_id: 132028\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) The DVD however is quite good\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 323, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 297:\n",
      "  video_id: 132028\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Trailers, DVD-rom features, (umm) great audio and video quality so it's got a lot of features and it's generally a great DVD set but the movie's not really that good so I (stutter) don't think I'll recommend it\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1336, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 298:\n",
      "  video_id: 132028\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Like audio commentary, (umm) lots of featurettes and documentaries, interactive things you can do\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 873, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 299:\n",
      "  video_id: 135623\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I gotta say I've seen the other two Spider Man movies and I wasn't really that impressed, you know\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 407, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 301:\n",
      "  video_id: 135623\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You know, it was probably worse than I thought it would be, actually\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 302:\n",
      "  video_id: 135623\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They're pretty entertaining I guess and I'm a fan of (uhh) Kirsten Dunst so I always like to watch movies that she's in but I didn't have high expectations for Spider Man Three because I didn't really like the first two, but it certainly did not exceed my incredibly low expectations\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1229, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 303:\n",
      "  video_id: 135623\n",
      "  clip_id: 5\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't know, I'm not really into that, and the action in it was really not that exciting\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 304:\n",
      "  video_id: 135623\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Granted I only paid two dollars to see it, (uhh) there's a really cheap movie theater where I live that I can go see movies that have come out (umm) recently for pretty cheap but two dollars didn't even really seem like a bargain considering that movie, you know? Just really cheesy (uhh) the graphics and stuff were just kind of annoying, like the CGI stuff\n",
      "  text_feature_shape: (1, 83, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1234, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 305:\n",
      "  video_id: 135623\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I feel like there's a lot of movies that have come out recently based on comic books that are way better than the Spider Man ones and it's just kind of a disappointment\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 306:\n",
      "  video_id: 135623\n",
      "  clip_id: 6\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The acting also horrible, you know, I realize it's based on a comic book and that's kind of the style that they're in, you know, kind of over the top, kind of cheesy, but I don't know\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 307:\n",
      "  video_id: 135623\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) So in a scale from like one to five I think I'd give it like a two, honestly\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 308:\n",
      "  video_id: 135623\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think that they could have done a much better job on that movie\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 309:\n",
      "  video_id: 136196\n",
      "  clip_id: 11\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I actually found it pretty hard to sit through\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 310:\n",
      "  video_id: 136196\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't think it was needed at all and I didn't really enjoy it\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 369, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 311:\n",
      "  video_id: 136196\n",
      "  clip_id: 13\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I would say you could skip it entirely even if you were a fan of the previous movies\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 312:\n",
      "  video_id: 136196\n",
      "  clip_id: 12\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So (uhh) I definitely will not recommend this movie\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 203, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 313:\n",
      "  video_id: 136196\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) So unfortunately (uhh) a great series that really just lived on longer than I think it needed to\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 315:\n",
      "  video_id: 136196\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, this is my review of Jurassic Park Three\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 246, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 316:\n",
      "  video_id: 136196\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) What I found most exciting about this movie when I first heard about that they were making a third is that it once again stars Sam Neill who was absent in the second movie\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 548, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 318:\n",
      "  video_id: 136196\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) The second movie I didn't think was nearly as good as the first, which is one of my all-time favorite movies, but (uhh) the second still had some good aspects to it and it was overall a pretty enjoyable movie\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 565, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 319:\n",
      "  video_id: 136196\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Unfortunately (uhh) when I ended up seeing it I was pretty disappointed all around\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 320:\n",
      "  video_id: 136196\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It seems like we've seen all this before, (uhh) and seen it better\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 321:\n",
      "  video_id: 136196\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) The third one just feels completely (uhh) unneeded\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 322:\n",
      "  video_id: 136196\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) the story's just kind of a rehash of the previous movie and it overall just feels very forced\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 654, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 323:\n",
      "  video_id: 136196\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's really not a whole lot original original (stutter) concept left in it\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 346, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 325:\n",
      "  video_id: 167521\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It wasn't just your typical like you know terrorist then you know cop comes in and saves the day\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 326:\n",
      "  video_id: 167521\n",
      "  clip_id: 13\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's one of the best action blockbuster I've seen this whole summer and I highly recommend you guys seeing it\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 327:\n",
      "  video_id: 167521\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The action scenes were my favorite parts though\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 328:\n",
      "  video_id: 167521\n",
      "  clip_id: 15\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The casting was really good, the effects were awesome\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 199, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 329:\n",
      "  video_id: 167521\n",
      "  clip_id: 14\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Bruce Willis does his role perfectly, everything is done perfect\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 499, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 330:\n",
      "  video_id: 167521\n",
      "  clip_id: 17\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You (uhh) you won't be disappointed\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 331:\n",
      "  video_id: 167521\n",
      "  clip_id: 16\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I definitely recommend you guys watching that movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 328, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 332:\n",
      "  video_id: 167521\n",
      "  clip_id: 1\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By far Live Free or Die Hard, or known as Die Hard Four, is probably my favorite as best movie in the Die Hard series\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 333:\n",
      "  video_id: 167521\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey guys, what's up? Right now I'm going to review the movie Live Free or Die Hard featuring Bruce Willis\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 334:\n",
      "  video_id: 167521\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Basically the terrorists have hacked into the FBI's like security measures and they're like taking over the world, or the United States at least\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 459, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 336:\n",
      "  video_id: 167521\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But basically this movie it was more xxx than your average action movie\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 439, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 337:\n",
      "  video_id: 167521\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And you know saving as always the cop goes in, save the days\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 226, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 338:\n",
      "  video_id: 167521\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They were done amazingly\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 219, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 339:\n",
      "  video_id: 167521\n",
      "  clip_id: 6\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The effects, like the shootout scenes, were amazing\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 340:\n",
      "  video_id: 167521\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The story it was actually done really well\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 341:\n",
      "  video_id: 167521\n",
      "  clip_id: 8\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you're in the theater and you're watching them shootout each other you actually feel like you're there\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 343:\n",
      "  video_id: 173CpFb3clw\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Review your draft again and then again make sure that it meets all the requirements for your products and services and the regulations and compliance that you working in.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 348:\n",
      "  video_id: 180971\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today I would like to review the Disney DVD, The Fox and the Hound\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 349:\n",
      "  video_id: 180971\n",
      "  clip_id: 5\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is not one of my favorite movies, it doesn't seem to hold my kids attention either so no matter what the price of it is, it's not one, that I would recommend buying\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 970, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 350:\n",
      "  video_id: 180971\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It follows the story of a hound dog named Copper and a fox cub named Todd and when they're young, they are friends but one winter, Copper goes away with his (umm) owner and he's taught to be an hound dog that hunts and when he comes back, he's suppose to be hunting Todd and that causes conflict in their relationship\n",
      "  text_feature_shape: (1, 73, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1601, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 351:\n",
      "  video_id: 180971\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It does have some special features on here, there is the trailer, there a (stutter) trivia game, there's a read along, which actually my kids actually enjoy better than the movie\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 615, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 352:\n",
      "  video_id: 190743\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (uhh) that this (stutter) to me was very, very similar to some news event that had actually occurred\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 354:\n",
      "  video_id: 190743\n",
      "  clip_id: 13\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: When I'm watching a movie of something you know with with (stutter) actors of this caliber I expect to watch something that's new and unique and I didn't find that with this movie\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 739, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 355:\n",
      "  video_id: 190743\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And then that's when it fell off for me\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 323, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 356:\n",
      "  video_id: 190743\n",
      "  clip_id: 15\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was a total waste of money\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 188, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 357:\n",
      "  video_id: 190743\n",
      "  clip_id: 14\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So for me Freedomland was a total waste of time\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 358:\n",
      "  video_id: 190743\n",
      "  clip_id: 17\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't think Samuel L Jackson should have been in it and I think that Julianna Moore lowered herself to play the person in this movie\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 602, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 359:\n",
      "  video_id: 190743\n",
      "  clip_id: 16\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I hated the movie\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 360:\n",
      "  video_id: 190743\n",
      "  clip_id: 18\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I hated the events that unfolded and I hated the ending\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 379, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 363:\n",
      "  video_id: 190743\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is rated R for some language and some violent content and it runs about two hours long\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 484, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 365:\n",
      "  video_id: 190743\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I do not like this movie\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 367:\n",
      "  video_id: 190743\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I understand that the movie was based on the bestselling novel, I understand that it was acted well, I understand that Julianne Moore totally was out of character by playing the person she played in this movie, but I didn't see the premise behind the movie\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 946, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 368:\n",
      "  video_id: 190743\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't see any sense in Freedomland ever being made\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 369:\n",
      "  video_id: 190743\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The entire town is trying to find her son\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 371:\n",
      "  video_id: 194299\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So he's lost his powers\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 375:\n",
      "  video_id: 194299\n",
      "  clip_id: 15\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I didn't find it too exciting\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 364, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 378:\n",
      "  video_id: 194299\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today I'm reviewing (umm) Zoom Academy for Superheroes\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 382:\n",
      "  video_id: 194299\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It seemed to be a little bit boring (umm) getting through it\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 383:\n",
      "  video_id: 194299\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) And I have to say that I was not overly impressed with this movie\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 384:\n",
      "  video_id: 194299\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I thought, Oh, this is going to be funny and good\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 343, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 385:\n",
      "  video_id: 194299\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) There's a few decent stars in there where, I guess, maybe that's where my disappointment came from\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 389:\n",
      "  video_id: 198112\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Definitely something to check into\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 176, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 390:\n",
      "  video_id: 198112\n",
      "  clip_id: 12\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) But it's really good, I really enjoy it\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 454, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 392:\n",
      "  video_id: 198112\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: {movie} Hey what's up Expo videos, I'm here to talk about Napoleon Dynamite\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 304, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 393:\n",
      "  video_id: 198112\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's like the the new teenage movie to watch\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 395:\n",
      "  video_id: 198112\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Napoleon Dynamite is definitely a classic comedy of our age I guess you could say\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 396:\n",
      "  video_id: 198112\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's like a big hit\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 397:\n",
      "  video_id: 198112\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But this is definitely something you're gonna show your kids cause it's hilarious, and it's hilarious in a different way and a lot of people don't (uhh) appreciate it as much as xxx it is because they just kinda think it's funny but I think this is creatively done because I'm into like a weird humor, I guess you could say, and there's like (umm) like hidden humor in here just that (uhh) with editing and continuity and (uhh) just the way things are produced that makes it humorous in that aspect as opposed to just (uhh) the way he is\n",
      "  text_feature_shape: (1, 128, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1584, 1024])\n",
      "  vision_feature_shape: (31, 2048)\n",
      "Item 399:\n",
      "  video_id: 198112\n",
      "  clip_id: 9\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the best comedies out there of our age as opposed to like, those other comedies that are actually really stupid with just bad bad (stutter) jokes and what not\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 400:\n",
      "  video_id: 198112\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it's (stutters) intelligently made I think\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 401:\n",
      "  video_id: 1Gp4l-ZTCVk\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Concepts about structuring data into tables, extracting data that we want, counting rows with aggregations and linking tables together using primary keys and joins.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 723, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 402:\n",
      "  video_id: 1Gp4l-ZTCVk\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In this lesson, you've learned a lot of concepts that we'll be applying in this course.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 251, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 403:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 10\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The best part about doing an interview over the phone is that you don’t have to get dressed up or worry about looking nice\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 512, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 404:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: 1) Be ready early - We’ve heard from employers who call job seekers during their scheduled time, only to be met with a voice mail\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 673, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 405:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe your clock is a few minutes fast, maybe they were running a little behind\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 417, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 406:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This will ensure you won’t miss their call and will also give you some time before the interview starts to go over any final points you want to remember\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 407:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Whatever the case may be, treat this as you would for an in-person interview – be ready around 10 minutes early\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 408:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Interviewee is reviewing his/her notes\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 214, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 409:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [BROLL] Interviewee is nicely dressed sitting at a table with a with pen, notepad, glass of water and phone\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 410:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You may be thinking, “Kim, seriously\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 285, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 411:\n",
      "  video_id: 1HS2HcN2LDo\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: 2) Clean up - I don’t know about you, but I am at my best when I’m showered, dressed and organized\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 412:\n",
      "  video_id: 1LkYxsqRPZM\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I personally love the to-do list with my next tasks, and there's a lot more! The pricing is also great\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 413:\n",
      "  video_id: 1LkYxsqRPZM\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've created a simple spreadsheet Just like the one you're currently using but packed with all the great features you get in Modern CRM systems You can set reminders and appointments and sync them with your Google calendar\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 414:\n",
      "  video_id: 1LkYxsqRPZM\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was very important for us to make it affordable for small businesses, so while pricing starts at $29 per user It's easy to reduce the price to five dollars by sharing it with friends\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 694, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 415:\n",
      "  video_id: 1S6ji_d4OLI\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we dug a little bit deeper into this and again developed a very sound economics OR type of model.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 416:\n",
      "  video_id: 1S6ji_d4OLI\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So what we started doing was ask the question why don't we see the effect of advertising on prices and profits as much as we would like to see or at least what the lab studies would suggest?\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1005, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 417:\n",
      "  video_id: 1jogeKX0wGw\n",
      "  clip_id: 2\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our nationwide registry includes thousands of the best and most qualified accountants, accounting firms and audit firms.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 418:\n",
      "  video_id: 1jogeKX0wGw\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Find the right accountant for your business by visiting GoodAccountants.com.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 419:\n",
      "  video_id: 1jogeKX0wGw\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Over 10 million business owners have already selected GoodAccountants.com.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 420:\n",
      "  video_id: 1pl2FVdQWj0\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey there we are talking about introductory speeches and we have just talked to the person that we are going to be introducing and we have got a real good sense of what it is that they want us to say.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 421:\n",
      "  video_id: 1pl2FVdQWj0\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Where are they from, where do they go to school, what was their life like growing up, what was their career like, what were the highs of their career, what were the lows of their career, do they have a family, do they like basketball, do they eat pizza with pepperonis?\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 824, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 422:\n",
      "  video_id: 1pl2FVdQWj0\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now you are saying to yourself, well why do I want to know everything if they're going to tell me what they want me to say anyway?\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 423:\n",
      "  video_id: 1zXAYdPdzy8\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I often visit my clients  in order to to inform them about new products that we have  and to let them know  that Mi-Bospo is supporting their business\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 869, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 424:\n",
      "  video_id: 200941\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The movie seemed to kinda drag on for me and it wasn't even that long\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 241, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 425:\n",
      "  video_id: 200941\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (stutter) I guess I didn't like the plot so once the plot got ruined, I really didn't care\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 470, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 426:\n",
      "  video_id: 200941\n",
      "  clip_id: 13\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But you're probably just gonna end up wasting about six bucks\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 427:\n",
      "  video_id: 200941\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was definitely a comedy and I guess if you're a true Simpsons fan you're gonna wanna see the movie\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 428:\n",
      "  video_id: 200941\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe rent it, that's probably gonna be cheaper and if you rent it, I wouldn't really expect too much cause really you can see a lot funnier stuff in the show, and the shows are free\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 753, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 429:\n",
      "  video_id: 200941\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you're thinking about seeing it, I wouldn't recommend it\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 540, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 430:\n",
      "  video_id: 200941\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you haven't seen this movie by now I don't really think you should\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 469, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 432:\n",
      "  video_id: 200941\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm pretty sure they'll be taking it out soon and in my opinion, this is pretty much just a big let down\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 433:\n",
      "  video_id: 200941\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's been out in theaters quite awhile\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 434:\n",
      "  video_id: 200941\n",
      "  clip_id: 5\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you own a TV and you saw the commercials, I wouldn't recommend seeing the movie, and even if you didn't see the commercials, I wouldn't really recommend the movie\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 435:\n",
      "  video_id: 200941\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There (stutter) wasn't that many funny parts in the movie and the only funny parts that there actually were I had already seen cause they were in the commercials\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 436:\n",
      "  video_id: 200941\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Some people don't like the current seasons, but I still think that they're pretty funny, and I was really let down by the movie\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 646, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 437:\n",
      "  video_id: 200941\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean, I love the Simpsons and pretty much they're always funny\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 340, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 439:\n",
      "  video_id: 200941\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I mean the whole plot was kind of stupid\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 440:\n",
      "  video_id: 201005\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Again, this is All of Me\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 442:\n",
      "  video_id: 201005\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, this is Brian\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 164, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 443:\n",
      "  video_id: 201005\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's actually kind of a short movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 445:\n",
      "  video_id: 201005\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) This is the Gold Reel Collection\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 448:\n",
      "  video_id: 201005\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm), It's kind of a slow movie\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 449:\n",
      "  video_id: 201005\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It wasn't one of my favorite movies, but (umm) I'd probably give it a two but, two out of five stars but (umm), if you haven't seen the movie maybe you want to rent it before you you (stutter) purchase it but you can probably get it for ten dollars because it's been out for a little bit\n",
      "  text_feature_shape: (1, 76, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1091, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 450:\n",
      "  video_id: 201005\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It's interesting that Steve Martin is an an (stutter) attorney or lawyer, but he wants to be a magician, and, (umm) Lily Tomlin, (umm) is a spinster and I don't want to give away too much of the plot but she ends up being inside of (umm) her spirit becomes inside of (umm) Steve Martin and that's where a lot of the interesting things in the movie come in\n",
      "  text_feature_shape: (1, 94, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1453, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 452:\n",
      "  video_id: 202826\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So (uhh) I give the movie two out of five stars\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 453:\n",
      "  video_id: 202826\n",
      "  clip_id: 13\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So save your money and go see something else\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 454:\n",
      "  video_id: 202826\n",
      "  clip_id: 12\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I don't know, it makes you think a little bit but most of the time you're just thinking I wish I didn't watch this movie\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 459:\n",
      "  video_id: 202826\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) If you're like most people including myself, you probably will not enjoy this movie because I most definitely did not\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 460:\n",
      "  video_id: 202826\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's just, it's far too long\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 462:\n",
      "  video_id: 202826\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) The movie stars John Grisham, I mean {laughter} the movie stars George Clooney as Michael Clayton and (uhh) he actually, he does a pretty decent job and (uhh) anyways, Michael Clayton is (uhh) the fixer of the law firm, (uhh) takes care of all the messy messy (stutter) corporate cases\n",
      "  text_feature_shape: (1, 81, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1471, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 463:\n",
      "  video_id: 202826\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you even look at the other Expo TV reviews about this movie, even the people that like the movie all seem to agree, the movie's way too long\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 801, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 464:\n",
      "  video_id: 202826\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hopefully you're not gonna see it anyway because it sucks\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 465:\n",
      "  video_id: 202826\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And also kind of complicating this is the fact that his personal life sort of unraveling with gambling and family problems and all sorts of things and basically he gets to the point where he just gets completely sick of fixing everyone's mistakes and it just kinda compounds and (uhh) I don't wanna ruin it for you, but\n",
      "  text_feature_shape: (1, 68, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1611, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 466:\n",
      "  video_id: 206585\n",
      "  clip_id: 1\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) You know I really didn't enjoy this movie at all (uhh) it was, kinda boring for me, (umm) it kinda felt as if there were parts in there they just put in there to kinda pass the time on\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 860, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 467:\n",
      "  video_id: 206585\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello my name is Sarah and I will be doing my video opinion on the movie Shall We Dance? (uhh) starring Jennifer Lopez, Richard Gere and Susan Sarandon\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 470:\n",
      "  video_id: 206585\n",
      "  clip_id: 5\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think the movie was horrible, it was kinda boring but (uhh) if you like to see some dancing, then hey pick it up if not\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 471:\n",
      "  video_id: 206585\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He gets into it, he enjoys it a lot but he's still keeping a secret from his family so he is trying to cope with having this this (stutter) you know, exciting moment added to his life and trying to keep it from his family so he's trying to figure out how to balance everything and you know I mean the dance scenes in here I felt were fantastic I thought Jennifer Lopez did a fantastic job and the girl really can dance (umm) as as (stutter) far as that goes, that's pretty much it\n",
      "  text_feature_shape: (1, 111, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1795, 1024])\n",
      "  vision_feature_shape: (35, 2048)\n",
      "Item 473:\n",
      "  video_id: 208322\n",
      "  clip_id: 10\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So definitely pass on Mr\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 420, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 475:\n",
      "  video_id: 208322\n",
      "  clip_id: 12\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Save your money and rent (uhh) the classic Willy Wonka and you'll enjoy (uhh) the experience a whole lot better\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 477:\n",
      "  video_id: 208322\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, my name is Mike, and this is my review for Mr\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 271, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 478:\n",
      "  video_id: 208322\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The main reason why was there wasn't much of a plot but it was pretty boring\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 517, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 479:\n",
      "  video_id: 208322\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's probably one of the worst films (uhh) I've seen probably in the last five or six years\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 606, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 480:\n",
      "  video_id: 208322\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) One of the things that was (uhh) kind of interesting is it seems to be a cross between Willy Wonka and (uhh) and some other Christmas style movies (uhh) in which they're just hoping to kind of show you some (uhh) interesting, colorful scenery (uhh) and have a toy store in which you walk by things and things pop out and weird stuff happens\n",
      "  text_feature_shape: (1, 88, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1189, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 481:\n",
      "  video_id: 208322\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Not, not (stutter) really a lot of interesting things (uhh) seemed to occur during the (uhh) during the show\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 482:\n",
      "  video_id: 208322\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Dustin Hoffman (uhh) is kind of bizarre (uhh) cast as this (uhh) particular person and Natalie Portman seems to just be sleepwalking through the role\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 483:\n",
      "  video_id: 208322\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But (uhh) that just after maybe a minute or two of that and it becomes, you become used to it, you're just really not interested in seeing any more of that\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 826, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 484:\n",
      "  video_id: 208322\n",
      "  clip_id: 9\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a horrible, terrible film and so I I (stutter) can't (uhh) recommend it whatsoever\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 485:\n",
      "  video_id: 208322\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) (stutter) Everybody involved in this movie (uhh) seems to just be cashing a paycheck\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 486:\n",
      "  video_id: 208592\n",
      "  clip_id: 10\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I just lost three hours of my time for nothing\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 244, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 488:\n",
      "  video_id: 208592\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, my name is Anaj, and today I'm reviewing the movie Saawariya which is currently running in theaters (uhh) nationwide\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 489:\n",
      "  video_id: 208592\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I do not have good words for this movie\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 492:\n",
      "  video_id: 208592\n",
      "  clip_id: 4\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I think it's like one of the worst movies I've ever seen\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 493:\n",
      "  video_id: 208592\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The only good thing about this movie are the songs and the dances\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 611, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 495:\n",
      "  video_id: 208592\n",
      "  clip_id: 9\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Was bad, bad (stutter) part of New York actually, you know, going to the movies\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 496:\n",
      "  video_id: 208592\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you're a fan of Indian songs and the dances that go along with it you may want to watch this movie but otherwise I'll just rate this movie one out of five\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 498:\n",
      "  video_id: 209758\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He's going through all these different things\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 226, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 500:\n",
      "  video_id: 209758\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) This is just really cool and this, what I like about this DVD is that it gives you an option\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 501:\n",
      "  video_id: 209758\n",
      "  clip_id: 15\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So again I really think you should pick it up\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 414, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 502:\n",
      "  video_id: 209758\n",
      "  clip_id: 14\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Which is great I think (umm) you know, someone who really doesn't, I don't really like widescreen so I'm great that it gives me an option\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 723, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 504:\n",
      "  video_id: 209758\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, my name is Sara and I will be doing my video opinion on the classic Elf, (umm) starring the wonderful comedian Will Ferrell\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 510:\n",
      "  video_id: 209758\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) This movie is is (stutter) definitely hilarious\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 511:\n",
      "  video_id: 209758\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Which I thought was you know, really cool\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 512:\n",
      "  video_id: 209758\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Experiencing you know, a whole new life change\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 513:\n",
      "  video_id: 20LfN8ENbhM\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Therefore he can add value and be a great fit for this organization\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 514:\n",
      "  video_id: 20LfN8ENbhM\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: interested in this opportunity and passionate about the industry that he wants to be able to join\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 515:\n",
      "  video_id: 20LfN8ENbhM\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now you want to make sure that you practice practice practice\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 516:\n",
      "  video_id: 20LfN8ENbhM\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Think about what they'll be interested in by really understanding the job description and the traits that they're looking for in the job description\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 517:\n",
      "  video_id: 20LfN8ENbhM\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is almost guaranteed that you're going to get a question similar to this one so you want to make sure that you're selling what the interviewer is buying\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 811, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 518:\n",
      "  video_id: 20LfN8ENbhM\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Make sure you focus on those strengths\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 519:\n",
      "  video_id: 210259\n",
      "  clip_id: 11\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's it's (stutter) not at all good, I'm sorry for the words but that's what the movie is\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 520:\n",
      "  video_id: 210259\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And you see go watch his new movie and it's it's (stutter), you know, crap\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 521:\n",
      "  video_id: 210259\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If I had a chance of putting it zero, so you know, it's D\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 627, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 522:\n",
      "  video_id: 210259\n",
      "  clip_id: 12\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (uhh) I rate this movie one out of five\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 523:\n",
      "  video_id: 210259\n",
      "  clip_id: 15\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But anyways I'll give it a one\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 524:\n",
      "  video_id: 210259\n",
      "  clip_id: 14\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If I get a chance of F I'll give a F, I'll give it a zero\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 376, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 525:\n",
      "  video_id: 210259\n",
      "  clip_id: 17\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean only if you have an additional two hours in your life that you have nothing to do go watch that movie\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 526:\n",
      "  video_id: 210259\n",
      "  clip_id: 16\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Do not go in theaters to watch this movie, this (uhh) movie's no good\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 527:\n",
      "  video_id: 210259\n",
      "  clip_id: 1\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now Lions for Lambs has a great star cast\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 214, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 530:\n",
      "  video_id: 210259\n",
      "  clip_id: 2\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It stars Robert Redford, Tom Cruise, Meryl (stutter) Streep, and you know that's about it, that's the only good thing about the movie, there's nothing else that is good about this movie and I'll tell you why\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 884, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 533:\n",
      "  video_id: 210259\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (stutter) Everyone that I've talked to, I saw the movie I hated it\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 534:\n",
      "  video_id: 210259\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (stutter) all the three of the, you know, all the three scenes are kind of related to each other because they're talking about why did the US go to war with Afghanistan and Iraq and what was the reason and what can be done now? And (stutter) you know whatever they talk about it's, they try to make a (stutter) drama out of it, a dramatic movie out of it, but really doesn't make sense, you know\n",
      "  text_feature_shape: (1, 99, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1508, 1024])\n",
      "  vision_feature_shape: (30, 2048)\n",
      "Item 536:\n",
      "  video_id: 210259\n",
      "  clip_id: 8\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Everyone I talks to said that it did not make any sense\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 539:\n",
      "  video_id: 210433\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Some of the comedy was good there was still a decent chemistry between (uhh) Will Smith and Tommy Lee Jones\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 540:\n",
      "  video_id: 210433\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And (uhh) this movie I thought was a very inferior sequel, it was good it had some good moments, some good elements to it\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 723, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 541:\n",
      "  video_id: 210433\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) well overall the movie just wasn't as good, the props were just as interesting the design was just as (uhh) good\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 661, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 543:\n",
      "  video_id: 210433\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It just wasn't as funny, wasn't as entertaining\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 544:\n",
      "  video_id: 210433\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The effects were (stutter) not quite as good I thought they could have been a bit better given the fact that it was a few years later and that (uhh) you know ILM standards are continually evolving\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 545:\n",
      "  video_id: 210433\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I have to give it two stars out of five\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 546:\n",
      "  video_id: 211875\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It has, it it (stutter) makes no sense it kind of shift around a little bit\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 625, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 547:\n",
      "  video_id: 211875\n",
      "  clip_id: 10\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Not my favorite show and I do not recommend it for anybody it was just retarded\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 552:\n",
      "  video_id: 211875\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It wasn't my favorite, I actually thought the plot stunk\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 553:\n",
      "  video_id: 211875\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well if you've seen the previews you've seen the best parts of the movie\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 554:\n",
      "  video_id: 211875\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's not one of my favorites that I've I've (stutter) watched, it was actually one of the worst ones I've seen in a long time\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 555:\n",
      "  video_id: 211875\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The acting was horrible\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 556:\n",
      "  video_id: 211875\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Okay, oh me, we've seen this plot millions and millions of times, you know blah blah blah, everybody knows you can pretty much tell what the whole movie's about just from the commercials\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 673, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 557:\n",
      "  video_id: 211875\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Just, it (stutter) oh my gosh it's so (stutter) my eleven year old son did, about halfway through he was ready to go home\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 575, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 558:\n",
      "  video_id: 213327\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The writing is bad and (umm) it just looks like a low budget film to me\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 561:\n",
      "  video_id: 213327\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think it's geared more toward (umm) the younger teenage, preteen audience even though it's definitely not appropriate for them\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 562:\n",
      "  video_id: 213327\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I really didn't find it that funny\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 230, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 565:\n",
      "  video_id: 213327\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) There are much better movies out there\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 566:\n",
      "  video_id: 213327\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I (umm) like I said definitely do not waste your eighty-eight minutes (umm) xxx (umm) watching this\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 703, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 567:\n",
      "  video_id: 213327\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The acting is bad\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 326, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 568:\n",
      "  video_id: 213327\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you're looking for comedy, then {laughter} rent or buy a comedy and if you're looking for something that's going to scare you, then I would definitely just rent or buy a horror movie because this movie just didn't do it for me\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1094, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 569:\n",
      "  video_id: 215318\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It does have a lot of special features, if you like Britney Spears it's got some music videos\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 457, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 571:\n",
      "  video_id: 215318\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Seven deleted scenes, a sing along with Britney, a karaoke version of some of her songs\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 703, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 573:\n",
      "  video_id: 215318\n",
      "  clip_id: 15\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Lots of special features but an awful movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 574:\n",
      "  video_id: 215318\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) A Crossroads through photo gallery\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 575:\n",
      "  video_id: 215318\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is Rachel\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 151, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 576:\n",
      "  video_id: 215318\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi Expo TV\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 119, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 577:\n",
      "  video_id: 215318\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you think Britney Spears is bad now you haven't seen this movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 579:\n",
      "  video_id: 215318\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's about three girls in high school\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 225, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 580:\n",
      "  video_id: 215318\n",
      "  clip_id: 4\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's awful\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 108, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 581:\n",
      "  video_id: 215318\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They were best friends when they were younger and now they've gone their separate ways and they've come back together and they're going on a road trip\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 582:\n",
      "  video_id: 215318\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) they're getting ready to graduate and go their separate ways\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 583:\n",
      "  video_id: 215318\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Obviously starring Britney Spears, (umm) Taryn Manning and Zoe Saldana\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 893, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 584:\n",
      "  video_id: 215318\n",
      "  clip_id: 8\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Awful awful acting\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 586:\n",
      "  video_id: 221137\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi\n",
      "  text_feature_shape: (1, 3, 768)\n",
      "  audio_feature_shape: torch.Size([1, 61, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 587:\n",
      "  video_id: 221137\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And but this one is just not even really that funny and really even that good at all\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 589:\n",
      "  video_id: 221137\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But (umm) it's not funny (umm) it's really really just a bad movie and (uhh) if you want to see a good stoner movie see Half Baked, it's really funny\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 938, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 590:\n",
      "  video_id: 221137\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Basically (uhh) the plot of the movie is this (umm) (uhh) pothead named Jane eats (umm) these these (stutter) (umm) (uhh) treats that are, that have THC in them and she doesn't know that she does it and it just follows her day and her hilarious, supposed to be hilarious, misadventures and mishaps\n",
      "  text_feature_shape: (1, 84, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1654, 1024])\n",
      "  vision_feature_shape: (33, 2048)\n",
      "Item 591:\n",
      "  video_id: 221137\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't see this one, just skip it\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 258, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 592:\n",
      "  video_id: 221137\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Or Harold and Kumar Go to White Castle\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 184, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 593:\n",
      "  video_id: 221137\n",
      "  clip_id: 8\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's not worth your money, and (umm) just don't go to see it\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 595:\n",
      "  video_id: 221153\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: 974} It's an okay movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 596:\n",
      "  video_id: 221153\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's not the greatest movie\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 340, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 597:\n",
      "  video_id: 221153\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'd probably only give it a two out of five stars\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 233, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 599:\n",
      "  video_id: 221153\n",
      "  clip_id: 16\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But two out of five stars\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 423, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 600:\n",
      "  video_id: 221153\n",
      "  clip_id: 19\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So anyways, two out of five stars\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 601:\n",
      "  video_id: 221153\n",
      "  clip_id: 18\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) If you're an Elvis fan, you like seeing a bunch of guys dressed up as Elvis, you might like it even more than I do\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 362, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 602:\n",
      "  video_id: 221153\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm going to be reviewing the DVD three thousand Miles to Graceland\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 358, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 603:\n",
      "  video_id: 221153\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What's up, Expo? This is Seth again\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 135, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 604:\n",
      "  video_id: 221153\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And what it is about (umm) two guys that are teamed up to (umm) go make a daring (umm) robbery of a casino in Las Vegas\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 992, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 606:\n",
      "  video_id: 221153\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And everybody is dressed up as Elvis\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 607:\n",
      "  video_id: 221153\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the twist is that it's during an Elvis (umm) (uhh) conference\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 803, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 608:\n",
      "  video_id: 221153\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's what (umm) the whole Graceland part is about\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 300, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 610:\n",
      "  video_id: 221153\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It is rated R for some strong violence (uhh) during the robbery\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 611:\n",
      "  video_id: 221153\n",
      "  clip_id: 20\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) three thousand Miles to Graceland, Kurt Russell and Kevin Costner\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 613:\n",
      "  video_id: 221274\n",
      "  clip_id: 1\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I have been an avid fan of The Simpsons most of my life, and (uhh) was quite disappointed that the movie wasn't anything more spectacular than in an overblown episode per se\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 614:\n",
      "  video_id: 221274\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey this is Dan with a review of The Simpsons the Movie\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 615:\n",
      "  video_id: 221274\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) When things happen that makes it such, (umm) the national government steps in and tries to seal it off in a bubble of sorts\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 616:\n",
      "  video_id: 221274\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) The Simpsons the Movie basically (umm) (uhh) it serves on the premise of (umm) basically the entire town (umm) being at the verge of a toxic waste dump and ready to be quarantined\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1114, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 617:\n",
      "  video_id: 221274\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So there was nothing too novel about it, I didn't find it particularly funny, particularly interesting and definitely not worth a ticket price (umm) let alone probably wanting to purchase this movie unless you get it at a really good deal\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 777, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 618:\n",
      "  video_id: 221274\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) The premise isn't anything too far fetched out of a wacky Simpsons episode, and the postmodern (uhh) references within it to (uhh) movies like Titanic and (umm) other references or nothing more than something you might expect from a halloween special to The Shining or something like that\n",
      "  text_feature_shape: (1, 68, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1383, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 619:\n",
      "  video_id: 221274\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Out of five it's definitely two\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 534, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 620:\n",
      "  video_id: 221274\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It is a overblown episode, would not highly recommend it out of five, (uhh) out of four stars I would probably give this two\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 753, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 621:\n",
      "  video_id: 221274\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It has cooler animation stressing more three D at the perspectives but nothing too revolutionary, so with that, The Simpsons the Movie, (umm) not something I'd really keep in my collection unless you can get it for a pretty good deal despite the donuts\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1328, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 622:\n",
      "  video_id: 221274\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But The Simpsons The Movie not worthwhile in my book\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 623:\n",
      "  video_id: 222247\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It just can't make up it's mind what it is and falls apart in every level and (umm) by the end, you're just not interested anymore\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 624:\n",
      "  video_id: 222247\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a fairly (uhh) promising premise at the beginning but the (uhh) execution was just poor and it can't make up it's mind if it's (uhh) a prison story or a action movie or (uhh) exactly or military inquest (uhh) type of a conspiracy movie\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1163, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 625:\n",
      "  video_id: 222247\n",
      "  clip_id: 13\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Really (umm) it's not, it's not worth your time\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 626:\n",
      "  video_id: 222247\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) As far as the DVD itself goes, special features (umm) on this includes pretty standard theatrical trailer, production notes, deleted scenes, commentary and (uhh) a little HBO movie called (uhh) Inside The Castle Walls about military prisons and things like that\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1148, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 627:\n",
      "  video_id: 222247\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Maybe if it's on TV, you might watch it then, but really, I wouldn't bother with The Last Castle on DVD\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 628:\n",
      "  video_id: 222247\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am Chris and this is a review of the DVD, The Last Castle starring Robert Redford and James Gandolfini\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 632:\n",
      "  video_id: 222247\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) This movie starts out okay but quickly devolves, (umm) it doesn't end up being very good\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 490, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 633:\n",
      "  video_id: 222247\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Robert Redford decides to do something about it and takes command and runs the military prison as sort of a military camp\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 883, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 634:\n",
      "  video_id: 222247\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I feel maybe he lost a bet (umm) towards the end of this movie, it just becomes (uhh) silly\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 635:\n",
      "  video_id: 222247\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I am not exactly sure (uhh) what Robert Redford is doing in this movie\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 636:\n",
      "  video_id: 222247\n",
      "  clip_id: 9\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) This movie, it doesn't turn out to be as good as it starts out\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 637:\n",
      "  video_id: 222247\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The ending was a little bit surprising but by then I I (stutter) really didn't care anymore\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 638:\n",
      "  video_id: 22373\n",
      "  clip_id: 10\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's, it (stutter), I wouldn't suggest this, it's (uhh) not a, not a very great movie, not all very well put together\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 601, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 642:\n",
      "  video_id: 22373\n",
      "  clip_id: 2\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I don't think is one of the best movies (uhh) ever it's about (umm) is about (uhh) two guys who go to Africa because they've been called upon because (uhh) a village over there in East Africa, this is set in 1996, has a problem because there's two man-eating lion, lions (stutter) who are (uhh) killing a lot of the people there\n",
      "  text_feature_shape: (1, 93, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1419, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 643:\n",
      "  video_id: 22373\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But it's a very drawn out long movie, (umm) not really interesting the ending's pretty lame and kind of flops in the end\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 851, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 644:\n",
      "  video_id: 22373\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So they have a lot of problems (umm) during that time and they set up traps which the lions (umm) actually (uhh) outsmart them with, so it's actually kind of interesting\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 646:\n",
      "  video_id: 22373\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Which is why I guess this movie this movie (stutter) didn't really (uhh) hit big or anything\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 697, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 647:\n",
      "  video_id: 22373\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Not the lions, not the people, not the hunters or the (umm) village people so there's nobody really to side with in here\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 590, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 648:\n",
      "  video_id: 22373\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) And then you don't feel sympathetic for anybody in this movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 649:\n",
      "  video_id: 224263\n",
      "  clip_id: 11\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, don't go out there and get this movie please, because it's really not worth it\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 650:\n",
      "  video_id: 224263\n",
      "  clip_id: 10\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But the story was so bad that I actually considered leaving halfway through the movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 808, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 651:\n",
      "  video_id: 224263\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Those are all great movies\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 499, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 652:\n",
      "  video_id: 224263\n",
      "  clip_id: 12\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you wanna see a good superhero, if you wanna see a good superhero movie, go see any of the Spider-Mans, go see any of the go see Batman Begins, that's a good one, or go see any of the X-Men\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 653:\n",
      "  video_id: 224263\n",
      "  clip_id: 15\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It just didn't do it any honor\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 289, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 654:\n",
      "  video_id: 224263\n",
      "  clip_id: 14\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This movie just jumped on the superhero bandwagon and just did not do a good job at retelling the true story of the Fantastic Four group\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 655:\n",
      "  video_id: 224263\n",
      "  clip_id: 17\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I don't suggest you go out there to watch it and waste your money on this DVD\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 656:\n",
      "  video_id: 224263\n",
      "  clip_id: 16\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I would be ashamed to have made this film if I was a director\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 570, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 659:\n",
      "  video_id: 224263\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The movie is just really not that great\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 406, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 660:\n",
      "  video_id: 224263\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: What can I say about this? It stars Jessica Alba and though she may be pretty, she's not the best actress\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 616, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 661:\n",
      "  video_id: 224263\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The special effects in it is the same and so is the script and story\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 662:\n",
      "  video_id: 224263\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) The acting in it is mediocre\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 164, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 663:\n",
      "  video_id: 224263\n",
      "  clip_id: 7\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The direction was was (stutter) horrible\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 209, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 664:\n",
      "  video_id: 224263\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: All of it's mediocre\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 519, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 666:\n",
      "  video_id: 224263\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was completely unsatisfied by this movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 667:\n",
      "  video_id: 224370\n",
      "  clip_id: 20\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Save yourself the money, get yourself another Nicholas Cage movie\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 669:\n",
      "  video_id: 224370\n",
      "  clip_id: 22\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's a good John Woo, Nicholas Cage movie\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 484, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 672:\n",
      "  video_id: 224370\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Do not go out there and watch it\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 673:\n",
      "  video_id: 224370\n",
      "  clip_id: 2\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm), I'm going to have to say do not get this movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 428, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 674:\n",
      "  video_id: 224370\n",
      "  clip_id: 5\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Usually I'm a big Nicholas Cage fan but this time he completely missed his mark\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 675:\n",
      "  video_id: 224370\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just no good\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 177, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 677:\n",
      "  video_id: 224370\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I feel like it was John Woo to blame\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 548, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 678:\n",
      "  video_id: 224370\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And martial arts really like to emphasize dramatic scenes every single second\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 850, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 680:\n",
      "  video_id: 224370\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Running across the room is very dramatic when everyone is shooting at you\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 681:\n",
      "  video_id: 224370\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You know what I mean, like throwing a, throwing a (stutter) suitcase across the grounds very dramatic\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 682:\n",
      "  video_id: 224370\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But he tries to make every single little tidbit of it very dramatic and very it becomes very awkward\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 462, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 683:\n",
      "  video_id: 224370\n",
      "  clip_id: 12\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But, war movies are supposed to be as a whole dramatic\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 684:\n",
      "  video_id: 224370\n",
      "  clip_id: 15\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) There's a scene where they mix actual real life cannon firing video with filmed video, and it's just very awkward to watch\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 943, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 685:\n",
      "  video_id: 224370\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Nicholas Cage does his best, but he can't just pull it off\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 249, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 686:\n",
      "  video_id: 224370\n",
      "  clip_id: 17\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The musical score was no good\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 225, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 687:\n",
      "  video_id: 224370\n",
      "  clip_id: 16\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn't enjoy it at all\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 158, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 688:\n",
      "  video_id: 224370\n",
      "  clip_id: 19\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I don't suggest going out there and finding Windtalkers\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 548, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 689:\n",
      "  video_id: 224370\n",
      "  clip_id: 18\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: A lot of the movie is just more awkward than it is entertaining\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 426, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 690:\n",
      "  video_id: 224631\n",
      "  clip_id: 11\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I give it a five out of five, and it's something you need to check out\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 691:\n",
      "  video_id: 224631\n",
      "  clip_id: 10\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) This, movie really makes you think, what if there is more to what our world really is, and it's just a fabulous movie if you haven't seen it you definitely have to watch it\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 692:\n",
      "  video_id: 224631\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm reviewing for you today, The Matrix, featuring Keanu Reeves and Lawrence Fish, Fishburn (stutter)\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 365, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 693:\n",
      "  video_id: 224631\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi Expo TV, this is Melissa and you can check out my reviews at PM three two one to see (uhh), what I've been reviewing lately\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 694:\n",
      "  video_id: 224631\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh), they just came out with these innovative new ways to film that just changed the whole film industry, and a lot of movies have started to film like the way they did The Matrix\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 711, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 695:\n",
      "  video_id: 224631\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Basically, this movie, changed (umm), the way movies are made now\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 696:\n",
      "  video_id: 224631\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You have behind-the-scenes documentaries, cast and crew commentary, music only audio track, follow the white rabbit and take the red pills for more mysteries, mind bending extras\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1109, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 697:\n",
      "  video_id: 224631\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) There's some good special features on this (uhh), DVD\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 449, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 698:\n",
      "  video_id: 224631\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) basically this is what it says on the back here and (uhh), I was trying to think of a way to describe this movie because it's just so complex, and the way they put it on the back just (umm), it's the right way to say it\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 955, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 702:\n",
      "  video_id: 226601\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Didn't get it\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 326, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 703:\n",
      "  video_id: 226601\n",
      "  clip_id: 10\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) But nothing really great\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 223, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 704:\n",
      "  video_id: 226601\n",
      "  clip_id: 13\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As far as it being a Ron Howard film I was actually fairly disappointed\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 705:\n",
      "  video_id: 226601\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Didn't understand it\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 708:\n",
      "  video_id: 226601\n",
      "  clip_id: 17\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Eleven deleted scenes and eleven behind the scenes featurettes (umm) and a lot of other stuff as well\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 709:\n",
      "  video_id: 226601\n",
      "  clip_id: 16\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe if they would've picked another one it would've been been better\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 710:\n",
      "  video_id: 226601\n",
      "  clip_id: 18\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I would not recommend this one, (uhh) even with all the bonus footage\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 364, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 711:\n",
      "  video_id: 226601\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) This is another Ron Howard film\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 712:\n",
      "  video_id: 226601\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, I'm reviewing the movie The Missing starring Tommy Lee Jones and Cate Blanchett\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 713:\n",
      "  video_id: 226601\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Essentially what happens is (uhh) Cate Blanchett (uhh) is living on the prairie and (uhh) someone or something comes in and captures her daughter\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 715:\n",
      "  video_id: 226601\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He shows up (uhh) to help find the girl\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 716:\n",
      "  video_id: 226601\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Kidnaps one of the two girls and takes off with her and Tommy Lee Jones is actually Cate Blanchett's father\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 800, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 717:\n",
      "  video_id: 226601\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I gotta say I honestly didn't get this one\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 718:\n",
      "  video_id: 226601\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He's an indian tracker (umm) so he has the ability (uhh) to help find the girl\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 719:\n",
      "  video_id: 226601\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Thought Cate Blanchett did a great, did a good job\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 720:\n",
      "  video_id: 226601\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn't think Tommy Lee Jones (uhh) pulled off this role at all\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 722:\n",
      "  video_id: 226640\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi this is Dan with my review of The Namesake available on DVD\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 238, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 723:\n",
      "  video_id: 226640\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The (uhh) generation divide and also with cultural issues are illustrated in this movie\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 687, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 725:\n",
      "  video_id: 226640\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (uhh) unless you have great interest in this subject, I frankly lost a bit of interest rather quickly so (uhh) it wasn't the best movie to me\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 726:\n",
      "  video_id: 226640\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) unfortunately this serious theme drags on for quite a long time\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 536, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 727:\n",
      "  video_id: 226640\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Namesake does tackle a serious topic and (umm) it does a good job portraying life although kind of depressingly as our main character (umm) struggles in life to find out who he is and how he fits in\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1031, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 728:\n",
      "  video_id: 226640\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In my opinion I, I (stutter) only give it two out of five stars\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 730:\n",
      "  video_id: 226640\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Namesake (umm) is rated PG-thirteen and (umm) generally pretty benign of a movie (uhh) so available on DVD\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 724, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 731:\n",
      "  video_id: 22689\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: With an all-star cast like this, apparently good director, you know and excellent story, you'd think they'd be able to do it but I don't think it was worth it\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 732:\n",
      "  video_id: 22689\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean I was really really disappointed\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 230, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 733:\n",
      "  video_id: 22689\n",
      "  clip_id: 1\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But unfortunately, I don't think an all-star cast really makes up or really makes the film\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 652, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 735:\n",
      "  video_id: 22689\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I really really wish he could have done a better job\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 428, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 736:\n",
      "  video_id: 22689\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) This is for, this is (stutter) Robert De Niro's return to directing for since the last thirteen years\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 737:\n",
      "  video_id: 22689\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And there are parts of it that are boring, but the really bad part about the movie is all these things all these parts having to do with his family\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 740:\n",
      "  video_id: 22689\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean I understand that's kind of an important part of a movie but it made up about a third of the movie and I really wanted to sleep through all of it\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 741:\n",
      "  video_id: 22689\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was bored through most of it\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 742:\n",
      "  video_id: 22689\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I mean it's a really really long movie\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 378, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 743:\n",
      "  video_id: 233939\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It tries to be Lord of the Rings\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 366, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 744:\n",
      "  video_id: 233939\n",
      "  clip_id: 10\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This one doesn't even offer that it's just boring more than anything\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 612, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 745:\n",
      "  video_id: 233939\n",
      "  clip_id: 13\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Basically stole everything out of Lord of the Rings but made a million times worse\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 746:\n",
      "  video_id: 233939\n",
      "  clip_id: 12\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It has a many of orge like creatures, a wizard, a medieval time setting\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 747:\n",
      "  video_id: 233939\n",
      "  clip_id: 15\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was a horrible movie\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 285, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 748:\n",
      "  video_id: 233939\n",
      "  clip_id: 14\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umhh) It's just everyone stay away from this film\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 224, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 751:\n",
      "  video_id: 233939\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm here to review In the Name of the King\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 752:\n",
      "  video_id: 233939\n",
      "  clip_id: 3\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This one was horrible\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 755:\n",
      "  video_id: 233939\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm giving it a one out of five\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 756:\n",
      "  video_id: 233939\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There was no saving grace for this film\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 500, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 757:\n",
      "  video_id: 233939\n",
      "  clip_id: 6\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: {laughter} This movie had horrible plot, horrible acting, horrible dialogue, horrible special effects, horrible action\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 826, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 758:\n",
      "  video_id: 233939\n",
      "  clip_id: 9\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's directed by Uwe Boll who is known for making pretty bad movies however this film see (uhh) most of his films are bad enough that they're funny, you can laugh at them\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 826, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 759:\n",
      "  video_id: 233939\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It starred Jason Statham so I thought it would be good cause he tends to be in pretty good movies but no, this was a let down\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 481, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 760:\n",
      "  video_id: 234046\n",
      "  clip_id: 11\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This movie just didn't do it for me\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 761:\n",
      "  video_id: 234046\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's not bad but (umm), I don't know\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 327, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 762:\n",
      "  video_id: 234046\n",
      "  clip_id: 13\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I I (stutter) slogged my way through it but it it (stutter) really wasn't that interesting\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 414, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 763:\n",
      "  video_id: 234046\n",
      "  clip_id: 12\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I really didn't enjoy it\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 136, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 764:\n",
      "  video_id: 234046\n",
      "  clip_id: 15\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) As far as the DVD goes there are eighteen minutes of additional footage which usually (umm) these scenes are cut out of the movie for a pretty good reason\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 753, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 765:\n",
      "  video_id: 234046\n",
      "  clip_id: 14\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I really wouldn't recommend this, I've seen this sort of (uhh) theme done better\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 766:\n",
      "  video_id: 234046\n",
      "  clip_id: 17\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's an alternate ending which isn't any better or any worse than the original ending, then there's you know theatrical content, (uhh) theatrical trailer and different languages and stuff like that\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1018, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 767:\n",
      "  video_id: 234046\n",
      "  clip_id: 16\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They really don't add anything to the movie\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 769:\n",
      "  video_id: 234046\n",
      "  clip_id: 18\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Maybe rent this but I definitely wouldn't buy it\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 771:\n",
      "  video_id: 234046\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm Chris, and this is a review of the DVD of the movie Constantine starring Keanu Reeves and Rachel Weiss\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 772:\n",
      "  video_id: 234046\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He has (uhh) some fairly strange weapons that he uses this, that he uses to do this\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 773:\n",
      "  video_id: 234046\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) His character is John Constantine, hence the title, and this is based on a series of (uhh) graphic novels and he he (stutter) can see demons and he can see (umm) otherworld spirits and he basically fights them\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1293, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 774:\n",
      "  video_id: 234046\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a fairly strange movie\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 217, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 776:\n",
      "  video_id: 234046\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) This movie's a little stranger than most, it really was very odd\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 777:\n",
      "  video_id: 234046\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I know it's based on a graphic novel and those movies can tend to (uhh) run on the strange side\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 778:\n",
      "  video_id: 234046\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's a big sort of (uhh) conspiracy to unleash a bunch of demons from hell and (umm) Keanu Reeves is trying to stop this and (umm) Rachel Weiss plays a cop who sort of reluctantly agrees to help him, basically reluctantly because she doesn't really believe him and he has an assistant who (uhh) the assistant has some pretty funny parts\n",
      "  text_feature_shape: (1, 77, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1368, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 780:\n",
      "  video_id: 236442\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's The Ladykillers\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 114, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 781:\n",
      "  video_id: 236442\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So (umm) I'd probably give this one a two and if you wanna check it out (umm) you might like it better than I did\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 782:\n",
      "  video_id: 236442\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is my review on the movie The Ladykillers\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 323, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 783:\n",
      "  video_id: 236442\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi expo\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 94, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 784:\n",
      "  video_id: 236442\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It seemed like there was a lot of drag time in this movie\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 785:\n",
      "  video_id: 236442\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I'm a big Tom Hanks fan but I really wasn't all that impressed with this movie\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 724, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 786:\n",
      "  video_id: 236442\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) for a Tom Hanks movie I was really let down\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 787:\n",
      "  video_id: 236442\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Yeah there were (stutter) some funny scenes but (uhh) very few\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 265, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 788:\n",
      "  video_id: 236442\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's several different actors in this movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 585, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 790:\n",
      "  video_id: 236442\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And again I think this is another movie where my expectations were a lot higher than they should have been\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 791:\n",
      "  video_id: 236442\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) And however, you know, (stutter) it's just not as great as I expected it to be\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 793:\n",
      "  video_id: 23656\n",
      "  clip_id: 21\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you're a younger kid then maybe watch it\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 795:\n",
      "  video_id: 23656\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, I'm doing a movie review of the movie Eragon\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 223, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 796:\n",
      "  video_id: 23656\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I also have seen all of the Lord of the Rings movies\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 797:\n",
      "  video_id: 23656\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now I'm a fan of Harry Potter, I've seen all the Harry Potter movies\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 798:\n",
      "  video_id: 23656\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Though they were still good\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 799:\n",
      "  video_id: 23656\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now the Lord of the Rings movies got a little long for me\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 572, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 800:\n",
      "  video_id: 23656\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And actually, while I was at Eragon I wanted to be Eragone out of the theater and away from that movie\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1054, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 801:\n",
      "  video_id: 23656\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I found Eragon's plot to be a little thin\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 802:\n",
      "  video_id: 23656\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It wanted me to go to, go to (stutter) sleep to be honest\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 459, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 803:\n",
      "  video_id: 23656\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Because I found it boring\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 805:\n",
      "  video_id: 23656\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: {noise} So I (uhh) tried to struggle through it\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 806:\n",
      "  video_id: 23656\n",
      "  clip_id: 13\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's probably a movie for younger boys\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 807:\n",
      "  video_id: 23656\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Ate it, wondered if I'd like the movie if I were eating and not paying full attention to it but I didn't really like it any more\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 764, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 808:\n",
      "  video_id: 23656\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's for younger boys who maybe have read the book too because then they'll like seeing everything they read in the book come to life\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 508, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 809:\n",
      "  video_id: 23656\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Younger boys who can't quite grasp a full plot\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 198, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 811:\n",
      "  video_id: 23656\n",
      "  clip_id: 16\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One thing I found cheesy and awkward about the movie was how the dragon and the main boy Eragon talked with their minds\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 812:\n",
      "  video_id: 23656\n",
      "  clip_id: 19\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hard to watch\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 194, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 813:\n",
      "  video_id: 23656\n",
      "  clip_id: 18\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That is what they looked like when they talked and it was awful\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 814:\n",
      "  video_id: 237363\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Figured this was gonna sweet movie, I didn't think he'd, well I mean I really wasn't probably thinking at all, because if you think about it, The Nightmare Before Christmas is sort of like a musical\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 816:\n",
      "  video_id: 237363\n",
      "  clip_id: 13\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't think it's fair of me to give it a one out of five, but that's what I'm gonna give it\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 817:\n",
      "  video_id: 237363\n",
      "  clip_id: 12\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, I don't know, I made a bad choice with this movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 818:\n",
      "  video_id: 237363\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) This movie, when I saw it, this movie looked sweet\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 819:\n",
      "  video_id: 237363\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Alright Expo TV, this is my video review of the movie Sweeney Todd\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 820:\n",
      "  video_id: 237363\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I obviously did not do enough research before I saw the movie, which you are a good person if you're watching this video because you're trying to do some research before you go out there and spend the (umm) looks like six fifty on the movie\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1108, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 821:\n",
      "  video_id: 237363\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean it had everything, it looked I mean it was about this serial killer like barber guy and it had Johnny Depp and he was dressed up looking all sweet and so I was like yes I'm gonna go see this movie\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 831, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 822:\n",
      "  video_id: 237363\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, if you don't like musicals, don't go see this movie\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 824:\n",
      "  video_id: 237363\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, if you can get past the fact that there's Johnny Depp singing in this movie, (uhh) more power to you I guess\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 825:\n",
      "  video_id: 237363\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As soon as they started singing, I was just like, what did I get myself into, you know? I mean, I couldn't, I could not (stutter) get past that\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 826:\n",
      "  video_id: 237363\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I did not\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 827:\n",
      "  video_id: 237363\n",
      "  clip_id: 8\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You're gonna enjoy this one\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 828:\n",
      "  video_id: 238063\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The monster possibly were wearing these huge face masks so this movie didn't portray it like that\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 830:\n",
      "  video_id: 238063\n",
      "  clip_id: 13\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So of her good looks because they didn't try to, you know, make her look evil, they just had her made her look like (stutter) Angelina Jolie with extra gloss\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 619, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 831:\n",
      "  video_id: 238063\n",
      "  clip_id: 12\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They actually had Grendel as some really ugly monster and Angelina Jolie as a gorgeous mother who would make Grendel look like a sweet heart because she was so evil\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 832:\n",
      "  video_id: 238063\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So (umm) I am disappointed in the way it was presented\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 833:\n",
      "  video_id: 238063\n",
      "  clip_id: 14\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean, we don't need that, she has lips we know we see them she doesn't need that\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 834:\n",
      "  video_id: 238063\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: John Malkovich was okay he didn't help though\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 241, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 835:\n",
      "  video_id: 238063\n",
      "  clip_id: 16\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is an epic tale, it's a good story, it's a great history about people, (umm) animation of the the (stutter) new age (uhh) type deal was terrible, and like I said she didn't fit the character\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 944, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 836:\n",
      "  video_id: 238063\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I like to tell you about a movie I saw recently\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 211, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 837:\n",
      "  video_id: 238063\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello\n",
      "  text_feature_shape: (1, 3, 768)\n",
      "  audio_feature_shape: torch.Size([1, 96, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 838:\n",
      "  video_id: 238063\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This movie could have been really great if they had taken into the direction of three-hundred or possibly Lord of the Rings, they didn't do that\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 840:\n",
      "  video_id: 238063\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It's (uhh) a great story really about a lifestyle of people\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 596, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 842:\n",
      "  video_id: 238063\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Grendel is a really bad guy, he's a monster\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 843:\n",
      "  video_id: 238063\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Beowulf is a good guy\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 844:\n",
      "  video_id: 238063\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Actually I this in college a very long time, for so long that you began to hate it but, then I look back and I kind of understand why it was important to learn about it\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 783, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 845:\n",
      "  video_id: 238063\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Beowulf and the community around him have to protect themselves from Grendel\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 846:\n",
      "  video_id: 24196\n",
      "  clip_id: 11\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You all know it's the same thing over and over that happens with Rocky movies\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 847:\n",
      "  video_id: 24196\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know the acting was okay\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 250, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 848:\n",
      "  video_id: 24196\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) (uhh) You know, scene wise, there are a couple of good scenes in it\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 596, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 849:\n",
      "  video_id: 24196\n",
      "  clip_id: 12\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If they would have stopped Rocky one, I think it would have been great but, you know\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 850:\n",
      "  video_id: 24196\n",
      "  clip_id: 15\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But as I said before, if you if you (stutter) haven't been feeling the other Rocky movies as of late, I wouldn't waste my time seeing this\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 770, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 851:\n",
      "  video_id: 24196\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if you're a Rocky, I guess if you're a die hard Rocky fan, this is a great movie\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 852:\n",
      "  video_id: 24196\n",
      "  clip_id: 17\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But (ehh) it was a waste of time so keep that in mind before you go and waste ten dollars on this overrated and highly dragged out movie\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 855:\n",
      "  video_id: 24196\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm reviewing the movie Rocky Balboa, which is currently in theaters\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 249, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 856:\n",
      "  video_id: 24196\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I just thought this was too much\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 857:\n",
      "  video_id: 24196\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's it's (stutter) gotten great reviews around but, to tell you the truth, I thought they should have stopped at Rocky one\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 793, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 858:\n",
      "  video_id: 24196\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He goes out, we all know he's gonna fight, he's gonna win\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 273, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 859:\n",
      "  video_id: 24196\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Sylvester Stallone was a great actor but he's now pushing sixty and having him in this role, you know, same old thing, you know\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 860:\n",
      "  video_id: 24196\n",
      "  clip_id: 7\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you weren't liking Rockys three, four, five, then trust me, you do not want to see this movie\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 861:\n",
      "  video_id: 24196\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, it was a, it's a typical Rocky movie but I see where it got some good reviews but I'm pretty much a little tired of the whole Rocky scene\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 809, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 862:\n",
      "  video_id: 24196\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I don't know how some people loved it\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 863:\n",
      "  video_id: 24196\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't waste your money\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 864:\n",
      "  video_id: 24351\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I suggest going to pick this up tonight if you were looking for a hilarious comedy\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 866:\n",
      "  video_id: 24351\n",
      "  clip_id: 12\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Go out and rent it, it's great\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 868:\n",
      "  video_id: 24351\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What I have up for review here is the New Line platinum series widescreen edition of The Wedding Crashers, starring Vince Vaughn, Owen Wilson and Christopher Walken\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 872:\n",
      "  video_id: 24351\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) The two characters actually play wedding crasher where they try to charm their way into the hearts of bridesmaids and hope to go home with them later that evening\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 687, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 873:\n",
      "  video_id: 24351\n",
      "  clip_id: 7\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's hilarious\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 166, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 874:\n",
      "  video_id: 24351\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And most of the movie takes place at this estate\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 875:\n",
      "  video_id: 24351\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I can't even stop laughing\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 445, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 876:\n",
      "  video_id: 24351\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I was laughing (stutter) right through the movie\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 357, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 877:\n",
      "  video_id: 243981\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like, they also (umm) explain the riff of the materials they use so it's like, what the heck? I, the first twenty minutes when I watched it, it was kinda like three hundred, but a little bit different by adding comedy\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1308, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 878:\n",
      "  video_id: 243981\n",
      "  clip_id: 10\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like when (umm) xxx it was really offensive and it wasn't that funny and like they were they (stutter) like pretty they go to the extreme all the time\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 749, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 879:\n",
      "  video_id: 243981\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like, sure it has cheap cheap jokes\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 880:\n",
      "  video_id: 243981\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It wasn't that great, it wasn't (stutter) good and it wasn't that funny\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 882:\n",
      "  video_id: 243981\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But it wasn't that great\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 233, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 883:\n",
      "  video_id: 243981\n",
      "  clip_id: 17\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it's just like three hundred, but weirder and not, like they tried to be funny\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 885:\n",
      "  video_id: 243981\n",
      "  clip_id: 19\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But it's not that great, so I highly do not recommend you to watch Meet The Spartans\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 461, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 886:\n",
      "  video_id: 243981\n",
      "  clip_id: 18\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You have to admit that\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 891:\n",
      "  video_id: 243981\n",
      "  clip_id: 5\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It wasn't that great, it was really bad\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 892:\n",
      "  video_id: 243981\n",
      "  clip_id: 4\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And like (umm) Well Meet the Spartans is a very cheap knock off\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 713, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 893:\n",
      "  video_id: 243981\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Some (stutter) like people expected it to be great because of three hundred but it wasn't\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 730, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 894:\n",
      "  video_id: 243981\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (stutter) It was spent a whole bunch of money on it, but it wasn't that great\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 896:\n",
      "  video_id: 243981\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like it was pretty offensive\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 897:\n",
      "  video_id: 24504\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you can find it for cheap, buy it\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 898:\n",
      "  video_id: 24504\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the DVD has special edition stuff so if you wanna see (uhh) behind the scenes and things like that\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 425, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 899:\n",
      "  video_id: 24504\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is not a very good movie at all, but if you like the video game Tomb Raider it's based on that and that was one of my very favorite favorite video games ever, and so of course I had to get the movie\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 934, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 900:\n",
      "  video_id: 24504\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm going to review for you today the DVD of Lara Croft: Tomb Raider\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 901:\n",
      "  video_id: 24504\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The acting's not that great\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 386, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 902:\n",
      "  video_id: 24504\n",
      "  clip_id: 2\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The plot in it's really bad\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 903:\n",
      "  video_id: 24504\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's a lot of action and fighting and shooting, but the bad guy's not even that bad, I think\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 815, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 904:\n",
      "  video_id: 24504\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's fun to watch (umm) (uhh) Angeline Jolie be Tomb Raider, but I mean it's not really not that interesting\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 866, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 905:\n",
      "  video_id: 24504\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) If you can find it for cheap and you like Tomb Raider that would be a good thing to get it, but don't pay over five dollars for this\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 906:\n",
      "  video_id: 24504\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's just does a typical overacting sort of job\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 907:\n",
      "  video_id: 24504\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) If you can see it on TV for free that's good too\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 908:\n",
      "  video_id: 24504\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's not really worth it\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 909:\n",
      "  video_id: 245582\n",
      "  clip_id: 11\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And but there were some scenes that were, that went over the top with trying to make it humorous by, and, (stutter) it ended up just being disturbing or disgusting\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1460, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 910:\n",
      "  video_id: 245582\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Cuz like I was expecting like, I was gonna stare at wallpaper kind of movie\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 911:\n",
      "  video_id: 245582\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or whatever\n",
      "  text_feature_shape: (1, 4, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 913:\n",
      "  video_id: 245582\n",
      "  clip_id: 15\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Even if you haven't seen the movie you should know it's a bad movie\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 914:\n",
      "  video_id: 245582\n",
      "  clip_id: 14\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I give this movie a two out of five because it's a bad movie, that's no surprise\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 596, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 916:\n",
      "  video_id: 245582\n",
      "  clip_id: 16\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But it's not as bad as I thought it would be\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 628, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 917:\n",
      "  video_id: 245582\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I came into the movie with very low expectations\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 920:\n",
      "  video_id: 245582\n",
      "  clip_id: 2\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like, I knew it wasn't gonna be good\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 922:\n",
      "  video_id: 245582\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I heard that people thought it was gonna be like, really hilariously funny and they're not really smart\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 664, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 923:\n",
      "  video_id: 245582\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Anyway, (umm) the movie is a parody of three hundred and a parody of other (stutter) movies and celebrities like Shrek, little bit of Happy Feet, You Got Served\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1036, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 924:\n",
      "  video_id: 245582\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I watched it because I had nothing else better to do\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 925:\n",
      "  video_id: 245582\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And (umm) there were probably two or three things that were kind of entertaining for me which is a surprise cuz I expected much of my expectations were much lower than two or three laughs\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1196, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 926:\n",
      "  video_id: 245582\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Paris Hilton and other stuff\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 927:\n",
      "  video_id: 252097\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: These people seem to not have anything else to do with their time\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 229, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 928:\n",
      "  video_id: 252097\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I just don't know\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 929:\n",
      "  video_id: 252097\n",
      "  clip_id: 12\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I just don't like it and I hope they don't keep on making more like this\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 930:\n",
      "  video_id: 252097\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's me, Danny Ericson, and I'm here to talk to you today about the movie currently in theaters Meet the Spartans\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 931:\n",
      "  video_id: 252097\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello expotv land\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 154, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 932:\n",
      "  video_id: 252097\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like exactly what the Scary Movies have become, the last three-hundred they made, and things like The Comebacks\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 874, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 933:\n",
      "  video_id: 252097\n",
      "  clip_id: 2\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I don't know (stutter) why I did, but I went to this movie cause I knew I would hate it, cause I hate all movies like this\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 934:\n",
      "  video_id: 252097\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like, they just have, I just don't know how they come up with them, they're not funny\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 557, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 935:\n",
      "  video_id: 252097\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They're just all these lame attempts that just keep on referencing movies over and over and they're just not even funny\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 813, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 936:\n",
      "  video_id: 252097\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) They're talking about the Three-Hundred and really they just keep on bringing up things that aren't funny\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 937:\n",
      "  video_id: 252097\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Meet the Spartans was just the same way\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 226, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 938:\n",
      "  video_id: 252097\n",
      "  clip_id: 9\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't know why they keep on making these kinds movie and I just hope they don't make more movies like this, cause Three-Hundred just came out last year and they already made a parody of it\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 866, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 939:\n",
      "  video_id: 252097\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They're all trying to make this topical humor like Britney Spears, just all this ridiculous stuff that doesn't make sense and isn't, just not funny\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 732, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 940:\n",
      "  video_id: 252912\n",
      "  clip_id: 11\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Like I said it's cheap, I think it runs like five bucks which is why I picked it up, I should of known better\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 941:\n",
      "  video_id: 252912\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It made me sick to my stomach\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 942:\n",
      "  video_id: 252912\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Will Ferrel the parts that I watched you know he's kind of funny but the writing in it's terrible and they don't really give him much to work with and it seems like he kind of may have had a jerk director that wouldn't let him you know do his thing and experiment and play around and be as (uhh) (uhh) improvious as he would want to be\n",
      "  text_feature_shape: (1, 86, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1324, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 943:\n",
      "  video_id: 252912\n",
      "  clip_id: 12\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But (uhh) consider this a warning to avoid Men Seeking Women\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 944:\n",
      "  video_id: 252912\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Tonight I would like to share with you Men Seeking Women, starring Will Ferrel and a couple other horribly unfunny people\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 945:\n",
      "  video_id: 252912\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello Expo TV\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 131, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 946:\n",
      "  video_id: 252912\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's one of those things where a company has a movie with someone in it and they realize that person is now famous so they pull it out and put it on DVD to trick people into buying it because it has someone they love, being Will Ferrel\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 969, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 947:\n",
      "  video_id: 252912\n",
      "  clip_id: 2\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I highly advise you stay as far away (uhh) from this movie as you can\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 948:\n",
      "  video_id: 252912\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's all over the back, because no one else cares about the other people in this movie\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 606, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 950:\n",
      "  video_id: 252912\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's just not awesome\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 138, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 951:\n",
      "  video_id: 252912\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It has the little smarmy glasses wearing guy from Murphy Brown\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 952:\n",
      "  video_id: 252912\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I honestly can't even tell you that I watched the movie all the way through\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 226, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 953:\n",
      "  video_id: 252912\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's about these best friends and there's something about them trying to get married in a certain amount of time\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 954:\n",
      "  video_id: 254427\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What's up guys I am going to review a movie that I think and actually many people agree with me (uhh) critics and fans alike that is one of or maybe the best war movie (umm) ever made and it's called Saving Private Ryan it stars Tom Hank's of course (umm) Matt Damon and a cast of others including Vin Diesel if you're a fan of his and it's about (umm) you know a setting in World War Two and a mother who has lost three of her four sons in the war, so there is one squadron's mission to go and find the fourth son whose name is Private Ryan (umm) the movie goes through that it goes through the realities of war and World War Two what happened there and what happened to them (umm) It's seen through the eyes of these soldiers you know they question their orders they don't understand why they have to risk their life (umm) Ryan questions his orders he just wants to stay and fight for his country (umm) and really just goes through their struggles of your your (stutter) everyday you know American soldier in World War Two, and it's poignant and it's beautiful, and you know it won five academy awards including best director Steven Spielberg of course you know it's hailed by everybody Time Magazine, USA Today, New York Times, Entertainment Weekly, (umm) it won best picture award at the the (stutter) Toronto broadcast film critic special\n",
      "  text_feature_shape: (1, 293, 768)\n",
      "  audio_feature_shape: torch.Size([1, 4106, 1024])\n",
      "  vision_feature_shape: (82, 2048)\n",
      "Item 957:\n",
      "  video_id: 255408\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Supposed to be a comedy movie but it's not much comedy\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 508, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 960:\n",
      "  video_id: 255408\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I enjoyed Will Ferrell's last movie Blades of Glory but this movie's (umm) not up to that mark of comedy\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 962:\n",
      "  video_id: 255408\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The name of the team was the Tropics and then (umm) and there was a competition if their team xxx xxx xxx that then their team would be totally (umm) like moshed into some other team\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 903, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 963:\n",
      "  video_id: 255408\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, (umm) I'm probably gonna give this movie (umm) like two out of five\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 964:\n",
      "  video_id: 255408\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But (umm) mean, it it (stutter) was (umm) not that interesting movie\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 645, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 965:\n",
      "  video_id: 25640\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) This is not the full throttle version, this is the first one\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 454, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 967:\n",
      "  video_id: 25640\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I wouldn't go out and say, you know, go out of your way and buy it, but if you like (uhh) Drew Barrymore and Carmen Diaz's acting, and Lucy Liu, go out and buy it\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 711, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 968:\n",
      "  video_id: 25640\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it's pretty good\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 172, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 969:\n",
      "  video_id: 25640\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It was okay\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 102, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 970:\n",
      "  video_id: 25640\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Otherwise it's not really worth the price\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 390, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 971:\n",
      "  video_id: 25640\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean, the the (stutter) people elements are there, it's just not really the same, so (umm) I don't know, with special features and all I would say you know, don't go out and get it\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 774, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 972:\n",
      "  video_id: 25640\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It didn't really (umm) reflect the series as well as everyone thought it should have, if you're a fan of the Charlie's Angels TV series\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 607, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 973:\n",
      "  video_id: 25640\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) If you're going go out and get you know, you get this one and full throttle which is the second Charlie's Angels (umm) together for cheap, go ahead but don't bother\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 889, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 974:\n",
      "  video_id: 257277\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Wouldn't recommend seeing it in theaters (umm) just because the plot and stuff like that is all just regurgitated and (stutter) formulaic\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 567, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 975:\n",
      "  video_id: 257277\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's it's (stutter) that kind of movie where they just stretch it out with an unnecessary plot that's formulaic and (stutter) try to turn it into a movie and it it (stutter) ultimately fails in in (stutter) the sense of a movie\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 976:\n",
      "  video_id: 257277\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hopefully one day, when the DVD comes out or something, you'll be able to just easily watch it on youtube or (uhh) rent it even, just to see the dance scenes because the rest of the movie is just there kind of to fill up space and make it ninety minute, minute (stutter) (uhh) feature length\n",
      "  text_feature_shape: (1, 72, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1093, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 980:\n",
      "  video_id: 257277\n",
      "  clip_id: 16\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you have, if you hate dancing there's no point in even checking this out really cause the plot sucks and (uhh) the dancing is only there for people that enjoy dancing\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 758, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 981:\n",
      "  video_id: 257277\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's the king of movies here and today I'm going to (stutter) review Step Up Two the Streets which is a new movie in theaters\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 443, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 982:\n",
      "  video_id: 257277\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey y'all\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 144, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 983:\n",
      "  video_id: 257277\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) If you're interested at all in dancing (uhh) like (stutter) street, excuse me, street style dancing (uhh) like (uhh) (stutter) You Got Served and that kind of dancing you might enjoy this film\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1166, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 984:\n",
      "  video_id: 257277\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's a teen, teen kind of drama about (stutter) {burp} excuse me, dancing\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 351, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 985:\n",
      "  video_id: 257277\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Just like regurgitated stuff\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 183, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 987:\n",
      "  video_id: 257277\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're a fan of dancing in that sense, just like to watch people dance, see impressive dance moves then you might want to check out this movie solely for that\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 988:\n",
      "  video_id: 257277\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However I must admit that the choreographed dance scenes are (uhh) quite a sight to see and they're really top notch\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 526, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 990:\n",
      "  video_id: 257277\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The actual plot, however, is formulaic and not really worth seeing\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 991:\n",
      "  video_id: 257534\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) No value in watching this at all\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 992:\n",
      "  video_id: 257534\n",
      "  clip_id: 10\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) So a completely ridiculous story\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 359, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 994:\n",
      "  video_id: 257534\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You don't learn anything from this movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 156, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 995:\n",
      "  video_id: 257534\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like I said, there's really nothing that sticks out that would be even remotely good about this movie\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 996:\n",
      "  video_id: 257534\n",
      "  clip_id: 14\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) After watching it, I just felt a little bit sick, a little bit disgusted, like why did I just waste my time watching that? (umm) So I think most people would get that feeling after seeing this\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 744, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 997:\n",
      "  video_id: 257534\n",
      "  clip_id: 16\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Even the acting is poor\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 254, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1000:\n",
      "  video_id: 257534\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I should have known that going in, but I didn't listen\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1001:\n",
      "  video_id: 257534\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Watching this movie is probably one of the biggest wastes of my time (umm) in recent memory\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 539, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1005:\n",
      "  video_id: 257534\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (uhh), as you can tell, the movie is already completely ridiculous and not something you want to watch\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1008:\n",
      "  video_id: 259470\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Number one, you've got you know pyramids being built, you've got vultures on like mammoths and you've got people of different kinds of (umm) races sometimes, it's just like ten thousand B\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 971, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1009:\n",
      "  video_id: 259470\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's not true and (umm) the movie is really terrible\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1010:\n",
      "  video_id: 259470\n",
      "  clip_id: 12\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: , this is not probable\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 576, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1011:\n",
      "  video_id: 259470\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Throughout the duration of the movie I don't feel a sense to any of the characters\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 719, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1012:\n",
      "  video_id: 259470\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They don't develop into the characters at all\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 522, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1013:\n",
      "  video_id: 259470\n",
      "  clip_id: 17\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And If I could say this (umm) {laugh} just save your money\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1014:\n",
      "  video_id: 259470\n",
      "  clip_id: 16\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And also the acting is just some of the worst acting I've ever seen\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 490, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1015:\n",
      "  video_id: 259470\n",
      "  clip_id: 19\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Whatever the movie rate is in your city and do not go see ten thousand B\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1016:\n",
      "  video_id: 259470\n",
      "  clip_id: 18\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Save your eight, nine, ten dollars\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 351, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1017:\n",
      "  video_id: 259470\n",
      "  clip_id: 23\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So again, (umm) this is my review for ten thousand B\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1021:\n",
      "  video_id: 259470\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This movie though, this movie is absolutely awful\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 487, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1022:\n",
      "  video_id: 259470\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) A prehistoric culture (umm) and it kind of revolves around a young man who is hunting mammoths and (umm) trying to save his tribe\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 759, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1023:\n",
      "  video_id: 259470\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's all kinds of things going around that don't seem to actually make any sense,(umm) especially in regards to historical accuracy\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1024:\n",
      "  video_id: 259470\n",
      "  clip_id: 8\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I (umm) I couldn't recommend this to anybody\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 683, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1025:\n",
      "  video_id: 259470\n",
      "  clip_id: 21\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's probably a lot of other movies playing right now that you would enjoy more than ten thousand B\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1026:\n",
      "  video_id: 267466\n",
      "  clip_id: 28\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And even for myself, I still wonder if I got the whole thing right\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1027:\n",
      "  video_id: 267466\n",
      "  clip_id: 29\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's that messy\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 502, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1028:\n",
      "  video_id: 267466\n",
      "  clip_id: 24\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it would be enough to swallow (umm) the whole scandal thing\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 418, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1029:\n",
      "  video_id: 267466\n",
      "  clip_id: 25\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I can't, I can't (stutter) even go into all the detail around the scandal thing because it's so in-depth\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 664, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1030:\n",
      "  video_id: 267466\n",
      "  clip_id: 26\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And so (umm) convoluted and messy\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1031:\n",
      "  video_id: 267466\n",
      "  clip_id: 27\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You just kind of have to watch the movie and read the subtitles for yourself (umm) in order to figure it all out\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1032:\n",
      "  video_id: 267466\n",
      "  clip_id: 20\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So it's kind of, it's all out there\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 228, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1033:\n",
      "  video_id: 267466\n",
      "  clip_id: 21\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a little bit ridiculous with the extremist religious thing at the beginning and then the scandal and then falling in love with the girl\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1034:\n",
      "  video_id: 267466\n",
      "  clip_id: 22\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it kind of doesn't really fit together\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 273, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1035:\n",
      "  video_id: 267466\n",
      "  clip_id: 23\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I think any one of those three things could have been it's own separate movie and it would've been a better production, rather than trying to ravel all three of these things into one long, drawn-out and ridiculous film\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 975, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1036:\n",
      "  video_id: 267466\n",
      "  clip_id: 46\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just not worth it\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 175, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1037:\n",
      "  video_id: 267466\n",
      "  clip_id: 44\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't waste your time seeing it in a theater\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1038:\n",
      "  video_id: 267466\n",
      "  clip_id: 45\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't even waste your time renting this one\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 130, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1039:\n",
      "  video_id: 267466\n",
      "  clip_id: 42\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But this one was kind of fantastical and weird and out there and just not worth my time\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1040:\n",
      "  video_id: 267466\n",
      "  clip_id: 43\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Again, one out of five stars\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1041:\n",
      "  video_id: 267466\n",
      "  clip_id: 40\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I I've (stutter) seen some foreign film lately that I really enjoyed\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 604, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1042:\n",
      "  video_id: 267466\n",
      "  clip_id: 41\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I really got into the story line and really felt part of these characters\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 361, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1047:\n",
      "  video_id: 267466\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) If you don't mind subtitles and you're into foreign films, I would still say don't get your hopes up\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 732, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1048:\n",
      "  video_id: 267466\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you're not a fan of sub-titles, you're gonna want to steer clear of this one\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1049:\n",
      "  video_id: 267466\n",
      "  clip_id: 7\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Honestly, I was bored out of my mind and couldn't wait for this film to be over\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1050:\n",
      "  video_id: 267466\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just, it really isn't that good\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 402, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1051:\n",
      "  video_id: 267466\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It it (stutter) drew on and on\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 354, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1052:\n",
      "  video_id: 267466\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was long\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1054:\n",
      "  video_id: 267466\n",
      "  clip_id: 12\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But when it's, in terms of this movie it was just so pointless and didn't seem to go anywhere and was just kind of a big circle of ridiculousness actually\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 968, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1055:\n",
      "  video_id: 267466\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And, you know, generally I don't mind that\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1056:\n",
      "  video_id: 267466\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) In typical foreign film fashion, it was all about character development, and all about the background story and getting to know people\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1057:\n",
      "  video_id: 267466\n",
      "  clip_id: 39\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) But that would've been a better alternative to what they did here\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 380, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1061:\n",
      "  video_id: 267466\n",
      "  clip_id: 17\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's not gonna be making any more movies anytime soon in his homeland\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 265, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1062:\n",
      "  video_id: 267466\n",
      "  clip_id: 16\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's not looking very good\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 118, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1063:\n",
      "  video_id: 267466\n",
      "  clip_id: 33\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It would have took me another two or three viewings (uhh) just to to (stutter) figure this out\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1064:\n",
      "  video_id: 267466\n",
      "  clip_id: 18\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) So he leaves and in his new city, he ends up being there and he meets this guy who finds out he's a film director and says, well can you film my daughter's wedding And Franco says, sure, I'll do that\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1049, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1065:\n",
      "  video_id: 267466\n",
      "  clip_id: 31\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It, it (stutter) could have been simplified or done as it's own movie where you can spend the time getting into and really explaining and delving into the whole situation\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 881, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1066:\n",
      "  video_id: 267466\n",
      "  clip_id: 30\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) And that was my least favorite part about the movie was that scandal and the huge shebang that happened because of it\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1067:\n",
      "  video_id: 267466\n",
      "  clip_id: 37\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I can't think of anything (uhh) for the movie as a whole that would have increased that rating\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1068:\n",
      "  video_id: 267466\n",
      "  clip_id: 36\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm only gonna give it a one out of five rating\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1069:\n",
      "  video_id: 267466\n",
      "  clip_id: 35\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean entertainment value here is what I want and that's not what I was given in this film at all\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1070:\n",
      "  video_id: 267466\n",
      "  clip_id: 34\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I don't think any movie should be that complex or that complicated, foreign or not\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 415, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1072:\n",
      "  video_id: 267466\n",
      "  clip_id: 32\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) When you try to combine it into a whole other movie like it was done in this one, it's just to much to digest\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 364, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1073:\n",
      "  video_id: 267694\n",
      "  clip_id: 11\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Not that good of a movie as I said\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1074:\n",
      "  video_id: 267694\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) He goes off and fights crime against like this guy called the hourglass\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 374, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1075:\n",
      "  video_id: 267694\n",
      "  clip_id: 13\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's like one of the most stupid comedies, like you don't really laugh that much, but, but (stutter) you laugh at some parts but as soon as it ends you're like, I just wasted like, ninety minutes of my life and like like (stutter) ten dollars\n",
      "  text_feature_shape: (1, 67, 768)\n",
      "  audio_feature_shape: torch.Size([1, 918, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1076:\n",
      "  video_id: 267694\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It could have been a lot better\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1077:\n",
      "  video_id: 267694\n",
      "  clip_id: 15\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't see it in the theaters\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1078:\n",
      "  video_id: 267694\n",
      "  clip_id: 14\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) So I really don't recommend seeing it\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1079:\n",
      "  video_id: 267694\n",
      "  clip_id: 17\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Just completely ignore like this movie\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 289, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1080:\n",
      "  video_id: 267694\n",
      "  clip_id: 16\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Do not see it on dvd\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 509, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1081:\n",
      "  video_id: 267694\n",
      "  clip_id: 19\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like who wants to do this\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1082:\n",
      "  video_id: 267694\n",
      "  clip_id: 18\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't get how these movies get put in like like (stutter) theaters, or like production even\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 637, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1085:\n",
      "  video_id: 267694\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's about ninety minutes long and it's rated PG-thirteen for (uhh) crude and sexual content, comic violence, drug references, language\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 909, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1089:\n",
      "  video_id: 267694\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I thought it was kind of bad\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 146, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1090:\n",
      "  video_id: 267694\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It it's (stutter) not as good as the original Scary Movie, and it's not as good as pretty much any spoof movie\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 499, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1093:\n",
      "  video_id: 272838\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't even know why I saw it\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1094:\n",
      "  video_id: 272838\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Honestly that sounds pretty stupid\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 358, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1095:\n",
      "  video_id: 272838\n",
      "  clip_id: 13\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't see Death Race\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1096:\n",
      "  video_id: 272838\n",
      "  clip_id: 12\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) But at least now you guys are warned\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 214, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1097:\n",
      "  video_id: 272838\n",
      "  clip_id: 15\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's really pretty bad\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 481, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1098:\n",
      "  video_id: 272838\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I wouldn't even rent it\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 378, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1102:\n",
      "  video_id: 272838\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hello Expo TV\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 176, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1103:\n",
      "  video_id: 272838\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It really wasn't very good\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1104:\n",
      "  video_id: 272838\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) This means two out of five\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 247, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1108:\n",
      "  video_id: 272838\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Anyways, (umm) where do I start? (umm) The movie takes place in two thousand twelve\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1110:\n",
      "  video_id: 272838\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a like, for profit prison where they have this pay-per-view creation that's these death races and they have convicts racing in like cars with all kinds of crazy stuff like missiles and flamethrowers and machine guns and they kill each other and if you win, it's five races, you get your freedom\n",
      "  text_feature_shape: (1, 70, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1716, 1024])\n",
      "  vision_feature_shape: (34, 2048)\n",
      "Item 1111:\n",
      "  video_id: 273207\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But he has issues and the young guy has issues and there's a lot of sex in it and it's, it's just not a movie at all that I would recommend\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1114:\n",
      "  video_id: 273207\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I would not recommend this movie at all {laughter}\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 215, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1115:\n",
      "  video_id: 273207\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it is described as a cute romantic comedy on the back\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 359, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1116:\n",
      "  video_id: 273207\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And so I had these expectations that this movie would be along the lines of (umm) Roxanne or (umm) You've Got Mail, Sleepless in Seattle, Never Been Kissed, that kind of cute romantic comedy\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 869, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1117:\n",
      "  video_id: 273207\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is based on a short novel or novella written by Steve Martin\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1118:\n",
      "  video_id: 273207\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's actually a little odd\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1119:\n",
      "  video_id: 273207\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is, to me very dark\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1120:\n",
      "  video_id: 273207\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: A young guy that's not going anywhere and a rich older entrepreneur who's Steve Martin\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 309, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1122:\n",
      "  video_id: 273250\n",
      "  clip_id: 24\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The premise is barely there at all\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 186, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1123:\n",
      "  video_id: 273250\n",
      "  clip_id: 25\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's like a quarter of a movie but running the full length\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1124:\n",
      "  video_id: 273250\n",
      "  clip_id: 26\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Which is bad because the actors do a good job, but that cannot save it from being an atrocious pile of junk\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1125:\n",
      "  video_id: 273250\n",
      "  clip_id: 27\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, one out five for Traitor\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1126:\n",
      "  video_id: 273250\n",
      "  clip_id: 20\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I mean, not necessarily like spy like, James Bond, but counter, like you know, investigation spy movies\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1127:\n",
      "  video_id: 273250\n",
      "  clip_id: 21\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There are so many better ones to be doing\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1128:\n",
      "  video_id: 273250\n",
      "  clip_id: 22\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, I have to say, one out of five\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1129:\n",
      "  video_id: 273250\n",
      "  clip_id: 23\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This was horrible\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1131:\n",
      "  video_id: 273250\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, my name is Mike, and today I'll be talking to you about the movie Traitor, which I went and saw last night\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1132:\n",
      "  video_id: 273250\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, Traitor is a movie about (uhh), it's a basic spy movie\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1134:\n",
      "  video_id: 273250\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I will try to hack it together for you\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 336, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1135:\n",
      "  video_id: 273250\n",
      "  clip_id: 4\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The premise here is really not good in any way, shape, or form\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 633, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1136:\n",
      "  video_id: 273250\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it turns out that this other sort of counter intelligence dude for the US, (uhh) is always seems to be connected to all of it\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1139:\n",
      "  video_id: 273250\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, it's, he has to figure out what's going on and why this is happening and is person number two involved with this, and is he a good guy or a bad guy, is the people is coming to help him investigate and are they good or bad is there other interests in here\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 969, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1140:\n",
      "  video_id: 273250\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's the investigation element, but that's it\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 369, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1141:\n",
      "  video_id: 273250\n",
      "  clip_id: 10\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a really bad spy movie cause it really feels like there's no real story to it\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1142:\n",
      "  video_id: 273250\n",
      "  clip_id: 13\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There is none\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 145, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1143:\n",
      "  video_id: 273250\n",
      "  clip_id: 12\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You know, what's the story, what's the point\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1144:\n",
      "  video_id: 273250\n",
      "  clip_id: 15\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The script was written as sort of a, sub-element\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1145:\n",
      "  video_id: 273250\n",
      "  clip_id: 14\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That's the flaw of this movie\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 277, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1146:\n",
      "  video_id: 273250\n",
      "  clip_id: 17\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And, that's why I can't give this movie anything more than a one out of five, cause it was atrocious\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1147:\n",
      "  video_id: 273250\n",
      "  clip_id: 16\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You know, it's missing the greater story to which the script plugs in to\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 309, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1149:\n",
      "  video_id: 273250\n",
      "  clip_id: 18\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And this isn't worth seeing at all, cause I mean, come on, you can come up with better spy movies than this\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1150:\n",
      "  video_id: 275267\n",
      "  clip_id: 11\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I wouldn't see it at the theater and I wouldn't rent it either\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1151:\n",
      "  video_id: 275267\n",
      "  clip_id: 10\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean I wouldn't recommend you watch it, cause it was bad enough that I watched it one time\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1152:\n",
      "  video_id: 275267\n",
      "  clip_id: 13\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Kinda like it was a bad dream, you know\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 539, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1153:\n",
      "  video_id: 275267\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'd just try to forget about it\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 405, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1155:\n",
      "  video_id: 275267\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Just forget it had ever happened\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 218, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1156:\n",
      "  video_id: 275267\n",
      "  clip_id: 1\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I just returned from the theater and I saw this really really bad movie called (umm) Beer for My Horses and like I said, did I mention that it was bad? Well it was bad\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 783, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1158:\n",
      "  video_id: 275267\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's a former (umm) rock singer or whatever but he's not really an actor either\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 749, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1159:\n",
      "  video_id: 275267\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It has Tom Skerrit in it, (uhh) that's not a reflection on him cause he's actually a good actor, it's got Toby Keith, who he's a country music singer and if you're listening to country music that's fine but he really shouldn't be acting, and it's also got (uhh) Ted Nugent\n",
      "  text_feature_shape: (1, 74, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1164, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 1161:\n",
      "  video_id: 275267\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I mean you're you're (stutter) putting these people together to make this really bad movie and I guess that's what you're gonna get\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1164:\n",
      "  video_id: 275267\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: and like I said, you watch it for yourself and see what you think\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1166:\n",
      "  video_id: 27v7Blr0vjw\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Some Boards have provision for committee members to serve who are not full Board members, not voting members of the Board.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1168:\n",
      "  video_id: 27v7Blr0vjw\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So you may not have all of the skills and abilities that you need for the audit committee on your full voting Board members but you among your committee members that expertise.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 801, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1171:\n",
      "  video_id: 28006\n",
      "  clip_id: 20\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't get this movie\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 537, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1172:\n",
      "  video_id: 28006\n",
      "  clip_id: 21\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's from the director of Blade, that should have told me in the first place cause Blade sucked, this sucks\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 505, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1173:\n",
      "  video_id: 28006\n",
      "  clip_id: 22\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't rent it, don't buy it, don't waste your time\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 255, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1175:\n",
      "  video_id: 28006\n",
      "  clip_id: 0\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hi, my name is Logan and this piece of dog crap is The League of Extraordinary Gentlemen\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 358, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1176:\n",
      "  video_id: 28006\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's set in like the eighteen hundreds and it's like fantasy and (uhh) you know, the (stutter) first of all the main star, or the main guy in (stutter), there's like all these like Captain Nemo's in it and then other people, other famousishy people from around that time were in it\n",
      "  text_feature_shape: (1, 75, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1158, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 1177:\n",
      "  video_id: 28006\n",
      "  clip_id: 2\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just so stupid\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1178:\n",
      "  video_id: 28006\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I don't know what they were thinking when they decided that Sean Connery should star as Alan Quartermain\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1179:\n",
      "  video_id: 28006\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I have never heard of Alan Quartermain\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1180:\n",
      "  video_id: 28006\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It it's (stutter) pretty dumb\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 377, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1181:\n",
      "  video_id: 28006\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It doesn't make any sense but (uhh) I don't know\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1182:\n",
      "  video_id: 28006\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's really just a dull story line\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1183:\n",
      "  video_id: 28006\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's like a vampire in it, an invisible guy, Captain Nemo, a guy that can't die cause he's like he starts out as a good guy and then he goes to a bad guy\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 966, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1184:\n",
      "  video_id: 28006\n",
      "  clip_id: 11\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I can't do a very (stutter) good Sean Connery voice but this was really lame movie\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 652, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1185:\n",
      "  video_id: 28006\n",
      "  clip_id: 10\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was an excuse to get Sean Connery into a James Bondish role without being James Bond cause they didn't want to pay for that and he (stutter) shoots people and he acts like oh I'm Sean Connery {mumble} you gotta shoot people, this is how you do it\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1247, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 1186:\n",
      "  video_id: 28006\n",
      "  clip_id: 13\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's like he was really hurting for money so he picked the first script that came along\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 652, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1187:\n",
      "  video_id: 28006\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean, come on Sean, can't do you do better than that? (stutter) It's just {sigh}\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 415, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1188:\n",
      "  video_id: 28006\n",
      "  clip_id: 15\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It doesn't make a lot of sense\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1189:\n",
      "  video_id: 28006\n",
      "  clip_id: 14\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just a horrible, stupid movie\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 415, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1190:\n",
      "  video_id: 28006\n",
      "  clip_id: 17\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So they go up into the mountains or something after the bad guy\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 230, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1191:\n",
      "  video_id: 28006\n",
      "  clip_id: 16\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The action sequences are sometimes way too long and sometimes they're too short and it just, it jumps around, it's like oh he's going to his, you know, his (uhh) his castle of fortressness, we have to go get him\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 889, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1192:\n",
      "  video_id: 28006\n",
      "  clip_id: 19\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was a really dull story line, it doesn't make a lot of sense\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1193:\n",
      "  video_id: 28006\n",
      "  clip_id: 18\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's like how do they know he was there? Why did he go there? That's like the first place you would think he would go, why would you I don't know\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1194:\n",
      "  video_id: 283935\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ExpoTV I am DJ Mel here and I will be reviewing myself, no I am not so why did I tell you my name? Anyways, today I am reviewing (stutter) Denzel Washington's Deja Vu\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1195:\n",
      "  video_id: 283935\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey\n",
      "  text_feature_shape: (1, 3, 768)\n",
      "  audio_feature_shape: torch.Size([1, 98, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 1196:\n",
      "  video_id: 283935\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I would've, I watched this movie once, four years ago for something, didn't really like it, it's (stutter) suspenseful but, meaningless at the same time and it has a confusing plot so if you're looking for a good watch, like a classic watch like you're going to watch an old movie, (umm) and you're you're (stutter) looking for an action or a suspense movie, don't get Deja Vu, you'll get like Shanghai Knights\n",
      "  text_feature_shape: (1, 106, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1441, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 1197:\n",
      "  video_id: 283935\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This movie is, this movie is PG thirteen, thirteen, yes (umm) (uhh) This is starring touched, no (stutter) that's not him I'm sorry (uhh) it is (uhh) brought to you by Jerry Bruckheimer Films and Touchstone Pictures\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1338, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 1198:\n",
      "  video_id: 283935\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So {laughter} anyways, this this (stutter) not a great movie, so yeah, don't watch it\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1199:\n",
      "  video_id: 283935\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Just any Jackie Chan movie will do\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1201:\n",
      "  video_id: 286943\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So I don't give it a good review\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 380, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1203:\n",
      "  video_id: 286943\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi expo\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 61, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 1206:\n",
      "  video_id: 286943\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This movie (umm) if you saw previews for it it looks kind of funny, but this movie actually wasn't very funny\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1207:\n",
      "  video_id: 286943\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) And a small war between them begins (umm) because they both just (umm) don't want to make any compromises\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1208:\n",
      "  video_id: 286943\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) And you know I really do like to see fluffy chick flicks sometimes so I'm not against that but this one was pretty terrible\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1209:\n",
      "  video_id: 286943\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was very (umm) average, very predictable, and the acting wasn't that great\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1210:\n",
      "  video_id: 286943\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you're looking for a movie to see with your girlfriends on a Friday night or a fluffy chick flick I would not recommend seeing Bride Wars because it's not what you expect, it's not worth the money, and it's not that good\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1211:\n",
      "  video_id: 286943\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I definitely recommend that if you're considering going to see Bride Wars that you save your money because it's not that good\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1216:\n",
      "  video_id: 29751\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This movie is pretty bad\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1218:\n",
      "  video_id: 29751\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The only reason to see this is (umm) if you are a fan of Jaime Pressly or Nicholas Brandon, (umm) those are the two stars\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 701, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1219:\n",
      "  video_id: 29751\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is (umm) {laugh} it's less than a B movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1220:\n",
      "  video_id: 29751\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Only reason why the, to really to see this movie\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1223:\n",
      "  video_id: 29751\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The special features there aren't very many, there's a feature commentary and some other junk but who who (stutter) really cares because this movie is pretty bad\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 793, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1224:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 11\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This event has once again been seamlessly executed, serving as a needed antithesis to the current presidential campaign\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1225:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 10\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They make it look so easy, don't they? Chaired by Jaine Blome, guided by Craig Meador, and supported expertly by Jane Thompson and Scott Blome, as well as dozens of behind-the-scenes folks, you know who you are\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 934, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1226:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 13\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: &lt;&lt;Laughter&gt;&gt; As you head back out into the Year of Braille, I hope you'll feel like your trunk is straight and strong, your roots run deeper, and your branches reach a little farther to your colleagues and friends across this great country\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1118, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 1227:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 12\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: &lt;&lt;Laughter&gt;&gt; Now that's something to be thankful for\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 376, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1228:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Travel safely and we'll see you next year\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1229:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 1\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I guess the first thing I'd like to say it was really cool to celebrate my birthday with over 300 of my favorite people, so thank you very much for that\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1230:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know, for the last few days I've been trying to think of words to describe how it feels to be on the other side of APH's Annual Meeting from teacher, O&amp;M, CLVT, and user of products, to EOT in two different states and and now to APH employee\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 974, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1231:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" The depth of my feelings go way beyond that though to all of you\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1232:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 2\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But you know, I was wondering was I was I like a proud mama and I thought no, that would insinuate that I had a hand in shaping this amazing organization and event and I'm really much to new at APH to claim that, so I settled instead on Auntie as in \"Auntie Dorinda is so proud to be part of this organization and event and the deep roots and branches we build\n",
      "  text_feature_shape: (1, 87, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1420, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 1233:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 5\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And you left piles of work and you came here to participate in related meetings and in product sessions and our new roundtable discussions and I'm really glad to hear that you enjoyed those\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 748, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1234:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm so grateful to all of you who traveled to Louisville and I know that you left overflowing email boxes that continued to overflow while you were here\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1235:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then of course the many celebrations and then the hallway conversations that we all enjoy so much\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 709, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1236:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm hoping we're going to continue that in the future\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1237:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm thankful for the APH staff who have worked tirelessly to put on this event\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 703, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1238:\n",
      "  video_id: 2BuFtglEcaY\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm thankful for your day-to-day work making strides in improving the lives of the individuals that we serve\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1240:\n",
      "  video_id: 2ItiGjefTRA\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The test can only be used on urine, you're not going to be able to test blood or saliva or any other bodily fluids, so there's really no point in using anything but urine.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1242:\n",
      "  video_id: 2QXHdu2zlQY\n",
      "  clip_id: 0\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Scott Reed talking: Some people in the community as the game has become more, um, more regarded . . . have raised the concerns about how we as graduate students have absorbed a lot of cost in producing the game and um . . . trust me, it concerns us too.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1243:\n",
      "  video_id: 2QXHdu2zlQY\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There’s a lot of real labor; there’s a lot of real capital that goes into the game.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1244:\n",
      "  video_id: 2QXHdu2zlQY\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We just asked if they were interested, and they helped us defray some of the costs.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1245:\n",
      "  video_id: 2QXHdu2zlQY\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We were lucky early on thanks to Doug Eyman to get some funding through Cengage; there wasn’t a very formal process to it.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1246:\n",
      "  video_id: 2QXHdu2zlQY\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And our sponsor, and having Cengage sponsor us has been . . . has helped.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1248:\n",
      "  video_id: 2QXHdu2zlQY\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Um, this year we’re switching up how we approach funding, and we’re hopefully going to be able to arrange for some sustainable, more officially recognized sorts of funding.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1249:\n",
      "  video_id: 2W-U94hXuK0\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was a victim of a horrible crime when I was young, and went on after that to a career as a defense attorney, and understand that no matter what the crime is, there needs to be a just process.\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 884, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1250:\n",
      "  video_id: 2W-U94hXuK0\n",
      "  clip_id: 3\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Or I see what happened in the Rwandan genocide, with the slamming of babies against the walls of churches, you know, of families seeing their own children killed in front of their eyes, and other loved ones.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1006, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1251:\n",
      "  video_id: 2W-U94hXuK0\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But when I put myself in these situations and I see a Nazi camp guard killing Jewish people in the morning before breakfast, in my mind's eye.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 720, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1252:\n",
      "  video_id: 2W-U94hXuK0\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I see the brutality and the animus in the eyes of the people doing those crimes.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1253:\n",
      "  video_id: 2fbBrB1nJEQ\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We are now inside the main auditorium, where family and friends will witness the entire event - what a fanatic view their are treated too today\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1546, 1024])\n",
      "  vision_feature_shape: (30, 2048)\n",
      "Item 1255:\n",
      "  video_id: 2m58ShI1QSI\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That brings us to tonight, the Universal Design Grand Challenge\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1257:\n",
      "  video_id: 2o2ljA0QD7g\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But figure out a way where you have a little bit of legal advice for the film as the process develops.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 734, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1258:\n",
      "  video_id: 2o2ljA0QD7g\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But our next topic here is what is the next step that you take for a first time producer?\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 596, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1260:\n",
      "  video_id: 2vsgDSlJ9pU\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Get a special phone, special email, get your family aware of what's going on, take the entry level job if that's what it takes, and just have yourself a great interview processing.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1261:\n",
      "  video_id: 2vsgDSlJ9pU\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Professionally, give yourself the best opportunity to get the job once you've done a good job on your interview.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1262:\n",
      "  video_id: 2vsgDSlJ9pU\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The other thing that you get to do is you get to choose your name, so why not put your name.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 701, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1263:\n",
      "  video_id: 2ze94yo2aPo\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Arabic Textbooks are not just a direct translation of the English materials - they were carefully translated by a team of experts who understand both English and Arabic.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1264:\n",
      "  video_id: 2ze94yo2aPo\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For over 10 years HOCK international has offered high-quality CIA study materials in English, and now in partnership with Al-Joman Consultancy in Amman, Jordan, (Sarh Al-Joman Training) we are pleased to offer our high-quality CIA Textbooks in Arabic.\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 969, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1265:\n",
      "  video_id: 2ze94yo2aPo\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Shipping is free to all Arabic-speaking countries, and orders are fulfilled from Amman for delivery in just a few days.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 427, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1266:\n",
      "  video_id: 2ze94yo2aPo\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The CIA in Arabic materials are available to purchase on our web site at www.hockinternational.com or from Al-Joman Consultancy in Amman.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1267:\n",
      "  video_id: 34cU3HO_hEA\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, for example, they could say, \"I only experience difficulty when there's background noise\", \"I only experience difficulty in meetings at work\". So it can be very situation specific.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 923, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1268:\n",
      "  video_id: 35694\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Yeah\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 149, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1270:\n",
      "  video_id: 35694\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) He wasn't very good (umm) at you know trying to solve the big problems or anything like that\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 422, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1271:\n",
      "  video_id: 35694\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He's the guy (umm) who's the big hero in the movie, and (umm) I don't think that he could really be a hero in a movie\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1272:\n",
      "  video_id: 35694\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This was actually after Jurassic Park came out and (umm) in this movie, the effects look worse than Jurassic Park, so people went expecting, you know, (umm) you know, effects that would actually look better, but no, they didn't look nearly as good as Jurassic Park\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 918, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1273:\n",
      "  video_id: 35694\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The effects in this movie were not that great\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 582, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1274:\n",
      "  video_id: 35694\n",
      "  clip_id: 17\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Not a whole lot, but it has like how they created you know, some of the (umm) some of the character, you know, CGI stuff, and everything like that, and how they destroyed a lot of the buildings and stuff like that, but I mean, the movie kind of just isn't that great, so I mean you probably don't wanna pick this DVD up because (umm) the movie's not that great, so you won't be that interested in the special features, so (umm) I'd skip over this one and (uhh) look for another one\n",
      "  text_feature_shape: (1, 121, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1376, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 1275:\n",
      "  video_id: 35694\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It actually looked kind of similar, it looks like they kind of copied some of the stuff from Jurassic Park, but (umm) as far as special features go, I mean it has a little bit of special features\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 545, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1276:\n",
      "  video_id: 35694\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, this movie well if you saw it, then you probably don't need to watch any more of this review\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 729, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1278:\n",
      "  video_id: 35694\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's not really a great movie\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 183, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1279:\n",
      "  video_id: 35694\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) The movie kind of speaks for itself\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1281:\n",
      "  video_id: 35694\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Matthew Perry is actually Not Matthew Perry\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1282:\n",
      "  video_id: 35694\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think his name's Matthew Perry\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1284:\n",
      "  video_id: 35694\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think his name is Matthew Perry\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1285:\n",
      "  video_id: 35694\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's the guy from Ferris Bueller's Day Off\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 376, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1287:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I saw a big red cross on a page like engraving the cross on my heart\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1288:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But it totally went wrong\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 116, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1289:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Many people asked me what happened, but I always replied them nothing and they just left\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1290:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 2\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Since the moment, it was too hard to smile for me\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1291:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe I can say it was one of the worst days in my life, but it changed to one of the best days in my life later\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1293:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: She didn’t say anything but stayed until I left the school\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1294:\n",
      "  video_id: 3At-BKm9eYk\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One girl, who looks very chill, stayed beside me instead of saying something\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1295:\n",
      "  video_id: 3HyAaqre_Fk\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There are one or two dissenters here and there but generally whether it's the economy, the environment, or politics, people seem to agree that right now we are in a big crisis, and which is self evident of course, but also at this time it has really brought home to everyone that everything is interconnected.\n",
      "  text_feature_shape: (1, 65, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1191, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 1296:\n",
      "  video_id: 3HyAaqre_Fk\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The one thing that really stands out is no matter which conference I attend, there seems to be very close to a consensus on many issues.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 683, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1297:\n",
      "  video_id: 3HyAaqre_Fk\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I also had a chance to watch some kids yesterday, especially I think some of the young speakers from Malawi, really made an impact.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 946, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1298:\n",
      "  video_id: 3IUVpwx23cY\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: While both are two slightly different problems, there is one solution.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 376, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1299:\n",
      "  video_id: 3IUVpwx23cY\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that solution is to build a green economy that's strong enough to lift people out of poverty.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 254, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1300:\n",
      "  video_id: 3IUVpwx23cY\n",
      "  clip_id: 31\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The governments of the world need to get on the side of the problem solvers in the world.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1304:\n",
      "  video_id: 3OYY5Tsz_2k\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you have the other options, I would suggest using those to get the best signal out of your box and into your set to give you the best image possible.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1305:\n",
      "  video_id: 3OYY5Tsz_2k\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And in this clip I want to cover getting digital cable or high definition cable into your HD TV set.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 481, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1309:\n",
      "  video_id: 3REPHw7oLWo\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Moody's did some excellent county by county progressive deterioration of the economy across the United States.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1310:\n",
      "  video_id: 3REPHw7oLWo\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And so our ability to really blunt that, to get in the middle of that down at that very local level, in the store by store basis, were really critical for not just the retailer success, but everyone who puts stuff on a retail shelf.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 808, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1311:\n",
      "  video_id: 3REPHw7oLWo\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe some of the counties that went in early will come out early.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 241, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1312:\n",
      "  video_id: 3REPHw7oLWo\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But that's really, I think, where the local nature of the economy really comes to play for the marketer.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1314:\n",
      "  video_id: 3UOqbf_B_Yc\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Any great country out there saves, that is how the country is able to grow.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 306, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1315:\n",
      "  video_id: 3UOqbf_B_Yc\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Marketing has a big influence on us because they are pushing every product out there we have to have in the newest and most fast form possible and we buy into that but the bottom line you need to save for your retirement.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1089, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 1316:\n",
      "  video_id: 3UOqbf_B_Yc\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want to have a good retirement and be able to do whatever you want without working you have to save.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1317:\n",
      "  video_id: 3WZ6R9B0PcU\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And, of course, student loans are notorious for being subsidized by the government as well.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1318:\n",
      "  video_id: 3XShFTBsp_Q\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the more a brand allows the consumer in, takes that feedback, and uses that to push it back out, a consumer receptive brand, I think brands will be more successful.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 744, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1319:\n",
      "  video_id: 3hOlJf_JQDs\n",
      "  clip_id: 1\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s just an incredible … with this challenging environment, that the power and the motivations, and the leadership just generated from the speakers was just, it was very emotional.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1023, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1320:\n",
      "  video_id: 3hOlJf_JQDs\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I think that with the incredible members that we have in this organization, we’re ready.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1321:\n",
      "  video_id: 3odZe3AGilc\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want to be a Salvation Army officer because I really strongly believe that God has called me to officership.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1322:\n",
      "  video_id: 3odZe3AGilc\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's all about me displaying His glory to other people so that they can also see how great God is.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 745, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1323:\n",
      "  video_id: 3odZe3AGilc\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For me officership is not anything about me and what I can offer, but it's all about what God can do through somebody like me.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 693, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1324:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 24\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We believe that the right to read, the right to information is a fundamental right and by ratifying Marrakesh we will secure a major victory in our right to read campaign\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 727, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1325:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 25\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now that you have all the details I hope you're as excited as I am\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1326:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 26\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Last year was an election year and a lot of people were complaining\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1327:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 27\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They're part of the problem, but we're part of the process\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1329:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 21\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" This year we are going before the United States Senate and urging them to ratify the Marrakesh Treaty\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1330:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 22\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This would allow us to get books from all over the world in foreign languages and even in English that are already produced in Braille or other accessible formats\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 732, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1331:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 23\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It will allow the rest of the world to get access to the collections we have here in the United States\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 587, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1332:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm on Capitol Hill in Washington, DC\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 276, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1333:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi Federationists! Lauren McLarney here with the Government Affairs team\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1334:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: 500 Federationists are going to come here to DC and we're going to hike the hill together to tell our members of Congress about our legislative priorities and the things that we need to live the lives we want\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 602, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1335:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's freezing! But I'm really excited because in two weeks we're going to do one of the coolest things that we do as an organization\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 582, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1337:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our three legislative priorities this year are the Transitioning to Meaningful and Integrated Employment Act or the TIME Act, the Technology, Education and Accessibility in College and Higher Education Act or the TEACH Act and the Marrakesh Treaty\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 812, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1338:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm Rose Sloan and this year we are advocating for the Transitioning to Integrated and Meaningful Employment Act or the TIME Act\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1339:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We want them to transition their business model to ensure that all people with disabilities, especially those being paid subminimum wages have the opportunity to transition into integrated and meaningful employment that they strive for\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1340:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The title of the TIME Act explains exactly what we want nonprofits who hold Section 14(c) Certificates to do\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1341:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the TIME Act will give nonprofit entities three years to transition their business model and ensure that all people with disabilities are paid the fair wages we deserve\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 657, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1342:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Currently, over four-hundred thousand Americans with disabilities are being paid less than the minimum wage, some of them mere pennies per hour\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 537, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1344:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's time for people with disabilities to receive fair wages\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1345:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They offer the opportunity for blind students to use the exact same materials as their sighted peers and luckily the law actually requires that institutions of higher education provide equal access\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 693, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1347:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 17\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Schools have no idea what to ask for, manufacturers aren't really embracing accessibility solutions and blind students are the ones that pay the price\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 562, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1348:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 16\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The problem is that requirement has no specifics, no criteria, no guidelines telling schools this is what accessibility looks like and this is what you should demand from the market\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 693, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1349:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 19\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our goal is to improve access for blind students, reduce litigation and stimulate an accessible digital marketplace\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1350:\n",
      "  video_id: 3wHE78v9zr4\n",
      "  clip_id: 18\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The TEACH Act authorizes the creation of voluntary accessibility guidelines so this is what accessibility looks like, this is what you should demand from the market and then incentivizes schools to only use technology that conforms to those guidelines with a safe harbor from litigation\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 820, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1351:\n",
      "  video_id: 41381\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Not many special features either\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1352:\n",
      "  video_id: 41381\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It's a psychological thriller, if you haven't watched it it's a nice movie\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1353:\n",
      "  video_id: 41381\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, my name is Anaj and today I'm reviewing the movie Boxing Helena\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1354:\n",
      "  video_id: 41381\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He's really generous, you know, really rich, but he wants this girl who's kind of a seductress and (uhh) well the movie's R rated\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 824, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1356:\n",
      "  video_id: 41381\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (uhh) it's an alright movie, I didn't like the acting of the guy (uhh) Julian Sands and Sherilyn Fenn so the acting was just alright\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 680, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1359:\n",
      "  video_id: 41381\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) A onetime movie, definitely not my type though\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1360:\n",
      "  video_id: 41381\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: DVD (uhh) I'm not sure if you'd want it in your collection, I won't suggest it though\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1361:\n",
      "  video_id: 41381\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Watch this movie (umm) one time see, not bad\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1362:\n",
      "  video_id: 424SXFTCFsA\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's important to consider what other financing options you have available.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1363:\n",
      "  video_id: 424SXFTCFsA\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Angel investors, venture capitalists, accelerators, and incubators all provide different opportunities to get the resources that you need.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 485, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1364:\n",
      "  video_id: 424SXFTCFsA\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Spending on your business, you might want to start seeking investment.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1365:\n",
      "  video_id: 424SXFTCFsA\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's look into who these investors are, and how they can help your business.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 269, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1367:\n",
      "  video_id: 46495\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hi\n",
      "  text_feature_shape: (1, 3, 768)\n",
      "  audio_feature_shape: torch.Size([1, 39, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1372:\n",
      "  video_id: 46495\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) The twists and the turns weren't really inspired or creative or (stutter) even interesting\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 745, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1373:\n",
      "  video_id: 46495\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I did not care for this movie at all\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 351, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1374:\n",
      "  video_id: 46495\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It just, by the time you get to the end of the movie it felt like a waste of time to have watched any of it\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1375:\n",
      "  video_id: 46495\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It just seemed like they came up with random things to happen that (uhh) I don't know\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1376:\n",
      "  video_id: 46615\n",
      "  clip_id: 1\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Starring (uhh) Charlie Sheen (umm) I guess now he's trying to take himself seriously since the box says, Charles Sheen, but (uhh) this is not a movie I would pick if I was Charles Sheen to launch my serious movie career\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1062, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 1378:\n",
      "  video_id: 46615\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Which there are a million of in movies\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 159, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1380:\n",
      "  video_id: 46615\n",
      "  clip_id: 5\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's not (uhh) a very good movie\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1381:\n",
      "  video_id: 46615\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And he retires to become a novelist but he moves to a small town to get away from it all and it turns out that the small town has a serial killer so he has to help track him down\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1382:\n",
      "  video_id: 46615\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) So it's a pretty poor DVD\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1383:\n",
      "  video_id: 46615\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn't enjoy watching it, there's no special features\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 255, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1384:\n",
      "  video_id: 46615\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I actually think it went straight to DVD\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 377, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1385:\n",
      "  video_id: 46615\n",
      "  clip_id: 8\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) Overall I really can't say anything positive about this, I wouldn't recommend watching it\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 655, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1386:\n",
      "  video_id: 4EDblUpJieU\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As you are probably aware, even if you use the most advanced application-specific programs, the job of steel detailing is still labor-intensive.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 764, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1387:\n",
      "  video_id: 4EDblUpJieU\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You must have heard about how there are a few Asian firms that do faultless detailing jobs for rates up to 40% less than those of their Western counterparts.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 811, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1388:\n",
      "  video_id: 4EDblUpJieU\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Send us your detailing question through the form below, and if you don't get a reply in one business day, we will give you a 5% discount.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 829, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1389:\n",
      "  video_id: 4YfyP0uIqw0\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you would like to go to bed at eleven pm, go to bed at eleven pm every night of the week.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1390:\n",
      "  video_id: 4dAYMzRyndc\n",
      "  clip_id: 10\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Everybody needs a space where they can define themselves, and not be pre-defined by the information that exists about them.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1393:\n",
      "  video_id: 4dAYMzRyndc\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It used to be when I was younger and I would give a speech, I could go into that room and I could tell stories and I could paint who I am based on the stories I painted in that room.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1394:\n",
      "  video_id: 4dAYMzRyndc\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I’ve been defined by the digital content that exists about me before I even give that speech.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 433, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1397:\n",
      "  video_id: 4o4ilPK9rl8\n",
      "  clip_id: 1\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Kanabar has said that auditors and accountants are concerned that a conflict of interest amongst committee members would cause them to look at transactions unfairly.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1398:\n",
      "  video_id: 4t5k_yILGJM\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The major problem I believe is the competition between entire market of India and the other companies around the world.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 826, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1399:\n",
      "  video_id: 4wLP4elp1uM\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: MALE SPEAKER: I think of commercials and get annoyed, in general.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 251, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1400:\n",
      "  video_id: 4wLP4elp1uM\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: FEMALE SPEAKER: Annoying ads, things that I want to either fast forward or turn off.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 461, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1401:\n",
      "  video_id: 53609\n",
      "  clip_id: 11\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I wanted to see it just to see it\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 249, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1402:\n",
      "  video_id: 53609\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I knew it was going to be bad\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 166, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1403:\n",
      "  video_id: 53609\n",
      "  clip_id: 13\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It was still pretty bad, you know? Most of the people in the movie I didn't know\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 249, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1404:\n",
      "  video_id: 53609\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I knew going in it was going to be bad and it wasn't as bad as I thought it was gonna be\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1405:\n",
      "  video_id: 53609\n",
      "  clip_id: 15\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Like I said, nuclear testing and then the army goes in to to (stutter) do stuff and then most of them get killed\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 666, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1406:\n",
      "  video_id: 53609\n",
      "  clip_id: 14\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) A couple of the people I did, I knew who they were, but (umm) it (stutter) was a very bad movie\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1408:\n",
      "  video_id: 53609\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Hills Have Eyes Two\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 206, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1410:\n",
      "  video_id: 53609\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Going into the movie I knew the plot\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 361, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1413:\n",
      "  video_id: 53609\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you saw The Hills Have Eyes One you're probably thinking why not add soldiers? But (umm) it was it was a bad movie\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1415:\n",
      "  video_id: 53609\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) But it was, it was (stutter) bad\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1416:\n",
      "  video_id: 53609\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: it wasn't the worst movie, and on a scale of one to ten I'd say it was probably a three\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1417:\n",
      "  video_id: 53766\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is the Derek, this time with another DVD review and this one is one of (uhh) I mean come on if you were ever a teenage boy or (uhh) in the eighties or nineties or even nowadays, every party has a little (stutter) bit of a nerd, you will love Rush, the rock band Rush\n",
      "  text_feature_shape: (1, 73, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1018, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1419:\n",
      "  video_id: 53766\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's a double disk (uhh) Rush R30, so their thirtieth anniversary world tour, has a DVD one is one entire huge concert live that pretty well plays every one of their hits (uhh) including most of the twenty-one twelve (uhh) over (uhh) their (stutter) (uhh) to (umm) all some some (stutter) new ones like earthshine\n",
      "  text_feature_shape: (1, 89, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1490, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 1421:\n",
      "  video_id: 53766\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) The second disk has a bunch of interviews with them, it has a vault of other, you know, music videos and some more live performances\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 537, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1422:\n",
      "  video_id: 53766\n",
      "  clip_id: 4\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) spanning thirty years of their career of such a phenomenal band (uhh) that, that (stutter) really is more influential to rock (uhh) and than than (stutter) so many other bands out there, I mean there are still going today\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 946, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1423:\n",
      "  video_id: 53766\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They are not really autographed by they have their signatures on them from Geddy Lee and Alex Lifeson and also has a (uhh) great little booklet of photos with (uhh) other trinkets it thrown in like stickers, (uhh) (stutter) and a replica of a backstage pass so you can pretend that you were ever at one of these concerts\n",
      "  text_feature_shape: (1, 79, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1158, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 1424:\n",
      "  video_id: 53766\n",
      "  clip_id: 6\n",
      "  label_1: 3.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But one of the special things for this whole box set is really when you open it up, it has such a beautiful presentation to any fan that shows you (uhh) a retrospective of the the years, has a (uhh) a live CD over here so you can listen to the live concert in your car, has the two disks, it also has (umm) some (uhh) autographed (uhh) guitar picks\n",
      "  text_feature_shape: (1, 91, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1376, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 1425:\n",
      "  video_id: 53766\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I definitely pick it up if you are a fan, if you just are a kid today and want to know what a great rock band out there is still living and, and working and breathing sounds like you know, pick it up and check it out\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1426:\n",
      "  video_id: 53766\n",
      "  clip_id: 8\n",
      "  label_1: 3.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's a great (uhh) box set, amazingly good sound, (uhh) lots of easter eggs on here, they even say on the back good luck finding them, but I can't recommend it better if you are a fan to listen to one of their greater concerts that they have put on a long time in adobe five point one audio\n",
      "  text_feature_shape: (1, 75, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1300, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 1427:\n",
      "  video_id: 56989\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It was just, I was just waiting for this movie to be over it was so boring\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1428:\n",
      "  video_id: 56989\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) But other than that there weren't many positives in this movie\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 261, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1429:\n",
      "  video_id: 56989\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if you need an excuse to see that movie (uhh) fellas, that's one\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 603, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1430:\n",
      "  video_id: 56989\n",
      "  clip_id: 12\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Eva Mendes can't really act well, but she is extremely easy on the eyes\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 400, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1431:\n",
      "  video_id: 56989\n",
      "  clip_id: 1\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) This was probably the worst Marvel movie I have ever seen\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1433:\n",
      "  video_id: 56989\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I actually liked Daredevil a little bit, but this was just awful\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 534, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1434:\n",
      "  video_id: 56989\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It's even better than Dare (stutter), or even worse than Daredevil I mean\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1435:\n",
      "  video_id: 56989\n",
      "  clip_id: 5\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) The story was really boring\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 228, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1436:\n",
      "  video_id: 56989\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It stars Cage as the Ghost Rider, a supernatural (uhh) bounty hunter of the devil, who has to go and chase another bad guy called Black Heart (umm) before he can collect souls and become super powerful\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 896, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1437:\n",
      "  video_id: 56989\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) The special effects were pretty good, I'll give them that\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1438:\n",
      "  video_id: 56989\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) It didn't go anywhere for a long time\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1439:\n",
      "  video_id: 56989\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was cool to see that\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1440:\n",
      "  video_id: 56989\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) Watching (umm) Nicolas Cage transform into the Ghost Rider and back, seeing his flesh peel away, things like that\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 426, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1441:\n",
      "  video_id: 59673\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And this really wasn't\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 507, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1442:\n",
      "  video_id: 59673\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Even like the cover like makes you think it's gonna be like some xxx nation like wrong turn, I don't know some sort of horror movie or something\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1444:\n",
      "  video_id: 59673\n",
      "  clip_id: 12\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I wasn't too impressed I hardly watched any of it and (umm) I was kind of let down, (umm) I thought the original previews in two thousand really led me astray and then I rewatched (umm) one on the internet (umm) today right, (uhh) right as I was watching it and it {laugh} seemed a lot different so I don't know maybe there's another Gosford Park out there but this Gosford Park is sure not (umm) a horror movie, so (uhh) don't rent it\n",
      "  text_feature_shape: (1, 116, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1346, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 1447:\n",
      "  video_id: 59673\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For some reason I had thought that this was going to be like (uhh) like a horror movie and people were going to be like getting killed in this house and it was going to be really sweet\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 948, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1449:\n",
      "  video_id: 59673\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I rent movies online and I put, {laugh} put it in my list and sure enough I get it and it is nothing like that\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 759, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1450:\n",
      "  video_id: 59673\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I always like it had been a movie in the back of my head that I'd been wanting to rent or buy for a long time\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1451:\n",
      "  video_id: 59673\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) with like British accent people, English accents\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 459, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1452:\n",
      "  video_id: 59673\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's like an old stool like (umm) you know like a murder theme mystery in someone's house\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 709, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1453:\n",
      "  video_id: 59673\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I wasn't too impressed\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1454:\n",
      "  video_id: 59673\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) I don't know, I, it definitely seemed more like a B film to me\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1455:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thirdly, financing is still a major obstacle for buyers\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 225, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1457:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It�s not uncommon for approved buyers to get their loans denied right before their closing, although it�s getting better than it was just a couple of years ago as credit standards have begun loosening somewhat again\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 629, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1458:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Banks are still being strict, requiring money down and even changing their terms at the last minute\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1459:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you are trying to decide whether or not to sell your house, we can help you\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 305, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1460:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 14\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In general, the markets remain strong\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 272, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1461:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you need to sell a property in or near Washington DC, we can help\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 357, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1462:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 16\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There�s a lot of shakeup in the US economy still taking place with the markets moving fast and in lots of directions at once, but we�re investing in the Washington DC area because we believe in the community and the people here\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1463:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Is it still a buyer�s market today in Washington DC? As experts in the Washington DC real estate market, we get asked this question a lot, and the answer isn�t as simple as yes or no\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 685, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1464:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The market really depends on the property type and location because while single-family homes, in great locations that are priced well, have been flying off the shelves, there are other areas that are a bit slower\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 785, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1465:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I�m Brad Chandler from Express Homebuyers and I would like to talk with you about the real estate market in Washington DC\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1466:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: First of all, buyers are often looking for the same thing , which is good neighborhoods, access to transportation and shopping, good schools, and being close to work, to name a few\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1467:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To better explain - I would like to talk about some different factors that play a role in the market\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1468:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Secondly, investment properties are in demand\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1469:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Properties that deliver all these conditions are definitely a hot commodity and sellers with a highly desirable property are in control of the market\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 490, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1470:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Overall, those people in a position to pay cash for properties have been picking up the good deals in the marketplace\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1471:\n",
      "  video_id: 5eY4S1F62Z4\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The massive amounts of foreign cash flooding into the US to invest in real estate has impacted the Washington DC area in unique ways\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1472:\n",
      "  video_id: 5fKPJPFqPho\n",
      "  clip_id: 11\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They will not fairly represent all the second choices\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1476:\n",
      "  video_id: 5fKPJPFqPho\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The order you number candidates is important and will impact on which candidates are elected\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1477:\n",
      "  video_id: 5fKPJPFqPho\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the following examples, we show you how proportional representation works when 3 candidates are elected\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 565, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1479:\n",
      "  video_id: 5fKPJPFqPho\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Candidate 4 has more votes than the quota and is elected\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 571, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1480:\n",
      "  video_id: 5fKPJPFqPho\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For real Legislative Council elections, 5 members are elected\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1482:\n",
      "  video_id: 5fKPJPFqPho\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The votes over the quota are called surplus votes\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1483:\n",
      "  video_id: 5lrDS7LluCA\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We elected a president, we had a house and a senate, there were lobbyists involved\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1484:\n",
      "  video_id: 5lrDS7LluCA\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: my brother-in-law, Hunter, set up a mock government\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 166, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1485:\n",
      "  video_id: 5lrDS7LluCA\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Issac, as president, ended up vetoing it, and then we had a supermajority, and we overrode him\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 379, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1486:\n",
      "  video_id: 5lrDS7LluCA\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We were learning a ton, the kids were loving it, and ultimately, it ended up in a Supreme Court battle\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1487:\n",
      "  video_id: 5lrDS7LluCA\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was just a lot of fun\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 206, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1488:\n",
      "  video_id: 5lrDS7LluCA\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am gonna put on Facebook a longer version, so you can go check that out if you want to, but here's the Supreme Court battle\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1493:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Does he mean potentially that the government is now going to create its own lending facility to compete directly with the commercial banks?\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1495:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it's going to be very interesting to watch how the details unfold on what exactly he means by this new lending fund.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1496:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He specifically said again and again and again that his policies are going to be aimed to make sure that speculators don't benefit nor our people who have bought homes that they could not afford, they also are not going to benefit from the bailout.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1074, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 1497:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 17\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Does this mean that we are going to potentially change our bankruptcy laws?\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1499:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One of the things that we see the press constantly talking about is this issue of potential nationalization of the banks.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 640, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1500:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 27\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Until next time, I'm Mike Brandl from the University of Texas at Austin.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1501:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But if you look at President Obama's speech last night, he made it clear that that's really not the path he intends on taking.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 550, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1502:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If so, is that a way to try to force more competition in the banking system, to try to get those banks to start lending?\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1503:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The second issue that Obama brings up and I think one that needs to be looked at very, very carefully is he talks about creating a new lending fund that is going to ensure that more money will make its way to households to buy automobiles, to fund college education and also to entrepreneurs.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1219, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 1504:\n",
      "  video_id: 5vwXp27bCLw\n",
      "  clip_id: 21\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Bush administration had put forward a plan that was very, very murky, didn't have a correct alignment of incentives and so on.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1505:\n",
      "  video_id: 5xa0Ac2krGs\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The major indexes all pulled back today, all down around a half a percent, give or take, as both U.S.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1506:\n",
      "  video_id: 5xa0Ac2krGs\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So to find out what those are, check out the link in the description of this video and check back in about an hour for our Stock Market Today video.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 629, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1507:\n",
      "  video_id: 61531\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Of course it's rated G so the whole family can enjoy it\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1508:\n",
      "  video_id: 61531\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean you've got some great comedy, you know, great songs xxx\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 269, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1510:\n",
      "  video_id: 61531\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) You actually get two, two versions of the film\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 293, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1512:\n",
      "  video_id: 61531\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You get some extra music, you get a Celine Dion video, you get never before seen footage, you get a video game on there, you get all types of good stuff\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 988, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1513:\n",
      "  video_id: 61531\n",
      "  clip_id: 16\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) I would definitely recommend this, like I said, it's one of the classics\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 410, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1515:\n",
      "  video_id: 61531\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi\n",
      "  text_feature_shape: (1, 3, 768)\n",
      "  audio_feature_shape: torch.Size([1, 66, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 1519:\n",
      "  video_id: 61531\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The DVD I want to review is Beauty and the Beast by Disney\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 819, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1520:\n",
      "  video_id: 61531\n",
      "  clip_id: 7\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Actually, it's one of the greatest, one of the greatest cartoons ever made\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 617, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1521:\n",
      "  video_id: 61531\n",
      "  clip_id: 6\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) This is a great DVD\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 430, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1522:\n",
      "  video_id: 61531\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) It's a classic\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1523:\n",
      "  video_id: 61531\n",
      "  clip_id: 8\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's got a great score, it's got a great story\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 339, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1524:\n",
      "  video_id: 63951\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was falling asleep half the way and it was ridiculous because (uhh) ticket prices are so expensive so I don't recommend you see this\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 861, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1525:\n",
      "  video_id: 63951\n",
      "  clip_id: 10\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) I wanted the fricking bad guy to die the entire movie, I wanted the good guy to die, I wanted everybody to just die so it would be over and I wouldn't have to listen to it anymore or watch it\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 851, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1526:\n",
      "  video_id: 63951\n",
      "  clip_id: 13\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's terrible, I don't recommend it\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 351, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1527:\n",
      "  video_id: 63951\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you really, really want to see it rent it with like Netflix or something so you don't have to pay for it\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 693, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1529:\n",
      "  video_id: 63951\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's called Pathfinder, so avoid this\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1532:\n",
      "  video_id: 63951\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And for some reason they left, and they left behind one of their kids and the kid got picked up by Indians and he was raised by Indians\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 676, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1534:\n",
      "  video_id: 63951\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And they're very big monstrous creatures in the movie\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1536:\n",
      "  video_id: 63951\n",
      "  clip_id: 7\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I do not recommend you go see this because it's awful\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1537:\n",
      "  video_id: 63951\n",
      "  clip_id: 6\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a terrible, this is a terrible movie\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1538:\n",
      "  video_id: 63951\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it's just ridiculous\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1539:\n",
      "  video_id: 63951\n",
      "  clip_id: 8\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's full of cliches, it's got a stupid love story in it like everything in theaters now\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1540:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’re always looking for new things; and we’ve had some other programs like Care Credit, we still use some of them but Care Credit seems to be the one that we get the best approval rating, approval from for patients\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1068, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 1541:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The primary financing option we use is something called Care Credit, it gives some great interest free options so it’s a great way to break down some bigger expenses that way\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1542:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’re actually looking at an in-office discount plan of some kind especially for our patients without insurance\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1543:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’re always looking for new things that we can do to help patients in that area\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 652, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1544:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Just one more option for folks to kind of get a little bit of a savings, a little bit of a break on things and plus, it benefits us because folks keep coming to see us that way too\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1545:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That topic has come up before so that’s something we’re looking at and maybe something we can offer here in the near future\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1546:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 17\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There’s nothing like coming in and thinking you’ve got a hundred dollar thing you’re having done and walk out front and the ladies tell you it’s five hundred dollars\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 741, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1547:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The big thing with financial things in the office is we like patients to know what to expect\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 343, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1548:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 18\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Surprises like that are not good\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1549:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If they have dental insurance, we want to get as accurate information as we can so we can estimate things well for them\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 778, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1550:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: On patient financing here in the office; of course one of the things we try our best to do is get good accurate information on their insurance\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1551:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We want them to know what to expect, try to give them as good an estimate as we can with their insurance\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1553:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But we do file folk’s insurance, we estimate what their copay should be and have them pay that at the time of service, but then we have the insurance reimburse us\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1556:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s interesting when it comes to insurance, there are all the time, CE courses, continuing education courses out there of people giving their recommendations\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1558:\n",
      "  video_id: 67uKYi7mslE\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well, that’s not real customer service related and there are folks who tried that and found out real quickly that didn’t work so well\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 557, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1559:\n",
      "  video_id: 69824\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I just witnessed a terrible movie that was called TMNT, or Teenage Mutant Ninja Turtles as they used to call it when it was good\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1561:\n",
      "  video_id: 69824\n",
      "  clip_id: 3\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This Turtles movie is terrible and it has the worst plot and cliche, collecting orbs and stuff xxx I've ever seen in my life\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1562:\n",
      "  video_id: 69824\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is a computer animated version of our beloved turtles and it is nowhere near as good as those great, early nineties, real life Ninja Turtles cheese fests\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 939, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1563:\n",
      "  video_id: 69824\n",
      "  clip_id: 5\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I hated it and animation was pretty terrible\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1564:\n",
      "  video_id: 69824\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And there's (uhh) the chick is like has like a staff and she hits people with it\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 531, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1565:\n",
      "  video_id: 69824\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) All the catch phrases were there, Splinter was there, he was cool, but I didn't really like it\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 676, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1566:\n",
      "  video_id: 69824\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Looks like a video game cut scene, with the exception of one rain fight which was pretty cool\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 663, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1567:\n",
      "  video_id: 69824\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, don't see it\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 306, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1568:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By the start... At the start of the year, I wouldn't have been able to do that and that's like a massive tick.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1569:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 13\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've come back after my placement so much more motivated because I know what's out there and what I need to do to get there.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 619, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1570:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They've ...at first they'd asked me if I would consider not coming back to Uni and to stay with them but I've obviously made the decision to get my degree and it's in the back of my mind that I could go back there but I'm gonna see what's out there for the minute as well.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 769, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1571:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 14\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because you're in such a routine on your placement year, now that I've come back to Uni, I am applying that work ethic here, so I'm really glad that I did my placement year.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 517, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1572:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The office that I worked in was above the factory and it was my job to be part of the production planning team and we told the factory what to make to meet customer demand.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 757, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1573:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To begin with, it was just getting used to learning how the factory actually runs and what goes into just like the simple task of making bottled drinks.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 615, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1574:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What I got from this role was mainly confidence, like the change throughout the year, like when you started, one of the main roles is to go to a meeting every morning where you're talking to the leaders of each Department.\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 727, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1575:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: it had increased massively from the start, when you're a bit shy, when you walk in.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 295, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1576:\n",
      "  video_id: 6EDoVEm16fU\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By the end of my year, I was holding my own meetings and to come up with a template and actually stand in front of everyone and tell them what you're doing.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 547, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1577:\n",
      "  video_id: 6EJHA6IDLNk\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s going to take people, you know, at the grassroots level working together to accomplish our goals.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1578:\n",
      "  video_id: 6EJHA6IDLNk\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Lisa Migliore Black: Well, you know, the first step is, um, has been taken: The task force has been created.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1582:\n",
      "  video_id: 6RFVsOWK1m4\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is important to remember that as the health professional it's up to you to maintain the professional boundaries, even when the behaviour is instigated by the patient.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1021, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1584:\n",
      "  video_id: 6RFVsOWK1m4\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The first thing you need to do is identify what is wrong with the behaviour with the patient.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 664, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1585:\n",
      "  video_id: 6RFVsOWK1m4\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For example, the consequence may be that if they continue with the inappropriate comments you'll have to discontinue their treatment.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 724, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1586:\n",
      "  video_id: 6RFVsOWK1m4\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you need to discuss this, please contact me at the College at (416) 591-3828 extension 241.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 509, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1587:\n",
      "  video_id: 6RFVsOWK1m4\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So again that's three things, you need to identify the behaviour, you need to tell them what you expect, and then you also need to describe what the consequences will be if the behaviour doesn't change.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 921, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1588:\n",
      "  video_id: 6brtMLkjjYk\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you are searching for a good investment option, consider betterment.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 249, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1589:\n",
      "  video_id: 6brtMLkjjYk\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They've created a platform that helps to automate the process of investing by accessing risk versus reward and making the split second decisions that you simply don't have time to make.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1590:\n",
      "  video_id: 6brtMLkjjYk\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They boast about smarter investment for busy people and they really seem to be able to do that.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 454, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1591:\n",
      "  video_id: 6gtfeIqGasE\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It really is a burnt coral\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 141, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1592:\n",
      "  video_id: 6gtfeIqGasE\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: shook\" is kind of a burnt burnt coral they called it, and I like that it actually is the color that that they say\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1593:\n",
      "  video_id: 6gtfeIqGasE\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I like the description of the color\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 211, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1594:\n",
      "  video_id: 6gtfeIqGasE\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But it's a great color\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1595:\n",
      "  video_id: 6gtfeIqGasE\n",
      "  clip_id: 6\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But personally I love this one and I'm pretty happy with all the products\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1596:\n",
      "  video_id: 6uoM8-9d0zA\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: subsidiary will be one of the first real-time processing systems in the U.S.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 629, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1597:\n",
      "  video_id: 79356\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) So, the PG thirteen rating I think is primary there's some a little bit profanity in it and there's like I said some tense scenes\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1598:\n",
      "  video_id: 79356\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) The sexual amount in it is some xxx (uhh) but nothing overt (umm) that I can recall\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1599:\n",
      "  video_id: 79356\n",
      "  clip_id: 12\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But absolutely fantastic show, you gotta watch this if you haven't seen it\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 288, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1600:\n",
      "  video_id: 79356\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Absolutely fantastic movie made by Kevin Costner, it won seven academy awards back in nineteen ninety-one and if you haven't seen this movie, then where have you been because this movie is fantastic\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1011, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1601:\n",
      "  video_id: 79356\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Alright, this is the (uhh) movie Dances with Wolves and if I were asked to put a top ten list of movies, this would definitely be in that list\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1602:\n",
      "  video_id: 79356\n",
      "  clip_id: 3\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) The music is fantastic, the acting is great (uhh), one thing I should mentioned is almost four hours long, it's three hours and what fifty-six minutes long\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 522, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1603:\n",
      "  video_id: 79356\n",
      "  clip_id: 2\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All about captain John Dunbar and his growing up in the frontier and encountering (uhh) the native American xxx tribe and it's just a fantastic so (uhh) really beautifully filmed\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 863, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1606:\n",
      "  video_id: 79356\n",
      "  clip_id: 7\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Very long movie but, (stutter) the time flies by, absolutely fantastic\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1607:\n",
      "  video_id: 79356\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Lord of the Rings wasn't maybe more than maybe three and a half hours\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 369, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1608:\n",
      "  video_id: 79356\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) There's some tense scenes in it, some hunting scenes\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 469, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1610:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then around that time, because the industry was really in dire straits, what people were looking for is how do I raise some incremental revenue or ancillary revenue on top of the main airline ticket that I buy.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1611:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 20\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So there’s things included in the price of a ticket that we feel should be included.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1613:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we already still have free drinks onboard the plane, you know, free soft drinks, free snacks.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1614:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 32\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We-- our research supports that customers are choosing Southwest specifically because of the no bag fee and that we’ve given-- the number we’ve gone to Wall Street is that a shifted market share, one percentage point, which is a huge difference.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1159, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 1615:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 31\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This campaign has paid off economically for Southwest, is winning customers.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1616:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 23\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now picture that in an economy that’s already down, business is off, you’re losing-- you know?\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1618:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I mean we were seeing and hearing from customers that, “Hey, I normally go see my clients twice a month, well now I’m only allowed to go see them once a month.” Well, for that consumer, we just lost half their travel budget.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 739, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1619:\n",
      "  video_id: 7IxmlIwqigw\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And then on the leisure side, you know, we all learned a word that is not a friendly word in the airline language, which is a staycation.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 761, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1620:\n",
      "  video_id: 7deoh0NoMs4\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Mark Pearson, managing director of Accenture Operations Consulting Services commented: “We believe that being positioned in the Leaders quadrant of this Gartner report is a testament to the quality and breadth of services Accenture delivers to clients to help them create dynamic operations capable of responding to volatility in the business environment,” he said.\n",
      "  text_feature_shape: (1, 69, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1224, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 1621:\n",
      "  video_id: 7deoh0NoMs4\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Accenture has been positioned in the “Leaders” quadrant of Gartner, Inc.’s recently published “Magic Quadrant for Business Operations Consulting, Worldwide.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 611, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1622:\n",
      "  video_id: 7f3ndBCx_JE\n",
      "  clip_id: 11\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Audience analysis is a crucial part in picking a great speech topic.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1623:\n",
      "  video_id: 7f3ndBCx_JE\n",
      "  clip_id: 19\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Three body parts, a killer introduction, and a great conclusion, but it all starts with your topic.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1624:\n",
      "  video_id: 7f3ndBCx_JE\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Art of Voice and Movement Integration.\" And today I'm going to be teaching you how to pick a great speech topic.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1630:\n",
      "  video_id: 7mb8Y2AhXIY\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: LORRAINE TWOHILL: I think engaging with communities is absolutely imperative right now.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1631:\n",
      "  video_id: 7mb8Y2AhXIY\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It may just be community around friendship and who they know and who they trust.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1632:\n",
      "  video_id: 7mb8Y2AhXIY\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For example, if you're on a community site that's for moms, and someone is saying, don't buy that baby food product or that diaper, that's a disaster for your brand.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1633:\n",
      "  video_id: 7mb8Y2AhXIY\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think the other trend I think is important people are trusting their friends and families more than ever to recommend things to them.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1634:\n",
      "  video_id: 7npCA0zoQ8Q\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All kinds of things from communication to more specific research skills, data-handling, things like that (and statistics) are really well trained and if you want that training, it's there for you to take.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1635:\n",
      "  video_id: 7npCA0zoQ8Q\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think the University of Manchester has a lot to offer a prospective PhD student, there's an awful lot of support, like I mentioned earlier, the Speed PhD course was really good at introducing the PhD and on the whole the training that you're offered and support in that way is really good.\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1028, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1636:\n",
      "  video_id: 7npCA0zoQ8Q\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The support as well that I've received around me, from my colleagues and my supervisory team has been excellent and I've had a really good experience so far.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1637:\n",
      "  video_id: 83400\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But if you're looking for something to make fun of (uhh) I would definitely (umm) definitely pick this up just to sit around and poke fun of\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 758, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1639:\n",
      "  video_id: 83400\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's some films that are really comical and just rather funny without meaning to be\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1641:\n",
      "  video_id: 83400\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This film {clears throat} is about a dragon even though there's about eight seconds total of dragon in the entire film\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 783, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1644:\n",
      "  video_id: 83400\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He's developed a plan to destroy them and he is relying on the inhabitants of the castle to help carry it out\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1645:\n",
      "  video_id: 83400\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) {clears throat} The scene takes a twist with Matthew McConaughey, I'm sorry, Matthew Slab of Beef McConaughey enters the (uhh) scene as a (uhh) US (uhh) military man that is trying to combat the dragons\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1109, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 1646:\n",
      "  video_id: 83400\n",
      "  clip_id: 9\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As far as a serious film? Do not rent this\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1647:\n",
      "  video_id: 83400\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: {clears throat} The acting is over the top, shoddy, hilariously done even though it's not meant to be\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1649:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He led thousands of his black \"brothers and sisters\" in peaceful protests against the government.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1650:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 22\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: African-Americans, and all Americans, have a better life today because of Martin Luther King Jr.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 784, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1652:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 19\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Many people were angry when they saw police violence against him and his followers.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 711, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1653:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: People around the world read about King in the newspaper and saw him on TV.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 784, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1654:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Martin Luther King \"We must meet hate with love\" Martin Luther King Jr.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1655:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Presidents are the only other Americans who are remembered in this way.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1656:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He was not a president, but his birthday is a national day in the US.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1657:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the first half of the 1900's in the American South, African Americans suffered terribly under white men's laws.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1658:\n",
      "  video_id: 86c2OkQ3_U8\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: His dream was for black people and white people to live together peacefully.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 719, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1659:\n",
      "  video_id: 88791\n",
      "  clip_id: 11\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) I I (stutter) would never watch this again\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 531, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1660:\n",
      "  video_id: 88791\n",
      "  clip_id: 10\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Basically it was just terrible\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1661:\n",
      "  video_id: 88791\n",
      "  clip_id: 13\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's up there with Mars Attacks for its annoying factor and the fact that it never moves\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1662:\n",
      "  video_id: 88791\n",
      "  clip_id: 12\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's very few movies I would say I'd never watch again and this is one of them\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1663:\n",
      "  video_id: 88791\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Well any good one\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 326, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1665:\n",
      "  video_id: 88791\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is the movie\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1666:\n",
      "  video_id: 88791\n",
      "  clip_id: 0\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you ever wanna make an action movie with (uhh) five dollars for the plot and for (uhh) the props and everything\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1667:\n",
      "  video_id: 88791\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Has good names in it, I mean there's Colin Farrell, There's Forest Whitaker and Kiefer Sutherland (umm) good old Jack Bauer's son\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 461, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1669:\n",
      "  video_id: 88791\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You can change the angles all you want but, come on\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 604, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1670:\n",
      "  video_id: 88791\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But, the whole story takes place inside of a phone booth\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1671:\n",
      "  video_id: 88791\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) Action (stutter) movies usually have action in them\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1672:\n",
      "  video_id: 88791\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is really boring\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 336, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1674:\n",
      "  video_id: 88791\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So it makes no sense to have it stand in the same spot for too long (umm) how long is it, two hours\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1675:\n",
      "  video_id: 89ZmOPOilu4\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I want to talk to you about and ultra huge no no when it comes to using humor.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1676:\n",
      "  video_id: 89ZmOPOilu4\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's just too great of a risk and it is socially unacceptable.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 749, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1679:\n",
      "  video_id: 8NPaDkOiXw4\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But their very support of such characters could lead to a decline in women’s social status\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 679, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1680:\n",
      "  video_id: 8NPaDkOiXw4\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: “Female viewers find comfort in these characters\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 183, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 1681:\n",
      "  video_id: 8TDAP0KNIIw\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And a lot of times you'll get responses that have to do with trying to find out where the start of that movement is based in\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 541, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1683:\n",
      "  video_id: 8VhVf0TbjDA\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As the West Sub-Area Advisory Managing Partner of Ernst &amp; Young LLP, Blair’s leadership has resulted in her sub-area gaining the number one rankings for sales performance, revenue growth and profitability within Ernst &amp; Young LLP, and in her personally being voted “best in class” by her colleagues for her exemplary and strategic leadership.\n",
      "  text_feature_shape: (1, 75, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1448, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 1684:\n",
      "  video_id: 8VhVf0TbjDA\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Blair first joined Ernst &amp; Young LLP (then Ernst &amp; Whinney) in 1989. She was named a partner in 1994. For the complete article, please go to Big4.com\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 767, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1685:\n",
      "  video_id: 8XZszYrUSCQ\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today we're actually beginning recording of our first masonic podcast, the first in the southern hemisphere! It's going to be called Brought To Light\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1686:\n",
      "  video_id: 8XZszYrUSCQ\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, my name is Brother Jack Aquilina the president of the Blue Lounge Social Club\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1687:\n",
      "  video_id: 8XZszYrUSCQ\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is going to be a great resource for that\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1688:\n",
      "  video_id: 8XZszYrUSCQ\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Its all about providing information and education to young masons through an informal setting\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1690:\n",
      "  video_id: 8i7u3fl-hP8\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Men men men men, manly men men men\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 640, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1691:\n",
      "  video_id: 8i7u3fl-hP8\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Simpsons California here we come Right back where we started from California\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1264, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 1693:\n",
      "  video_id: 8jY_RhOS89o\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It will also help those who seek to extend their capabilities beyond the classroom and traditional E-learning tutorials to take advantage of the opportunities provided by computers, the Internet and mobile technology.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1694:\n",
      "  video_id: 8jY_RhOS89o\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The course is aimed at learning and development professionals who want to produce more-for-less learning solutions which are aligned to organisational goals and ensure learning is transferred into performance in the workplace.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 855, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1695:\n",
      "  video_id: 8jY_RhOS89o\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You will explore different learning methods and media that enable you to provide more flexible, accessible and cost effective learning solutions without compromising on quality and apply this to producing a blended solution for your workplace.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 809, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1696:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it's been a while since I've done one of these but today I wanted to share a story of my first experience with drama\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1697:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 0\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Yeah, I'm never going that high again\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 146, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1698:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This story takes place in the second grade and I still remember it because of how stupid and ridiculous the situation was\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 713, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1699:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is gonna get real heated, so get your popcorn, and enjoy\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1700:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And Madison had another friend, let's say her name was Jasmine, and I really did not like Jasmine\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 669, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1701:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So basically I had a friend, I'm not going to mention any real names here, but for the sake of clarification let's say her name was Madison\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1702:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But because I liked hanging out with Madison, I dealt with Jasmine\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1703:\n",
      "  video_id: 8lfS97s2AKc\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: She was really mean and just not a very good person in general and I didn't understand why Madison hung out with her all the time\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 723, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1705:\n",
      "  video_id: 8wNr-NQImFg\n",
      "  clip_id: 13\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: -During the primary, he criticized housing regulations to address segregation in public housing\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1706:\n",
      "  video_id: 8wNr-NQImFg\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: -He's never really done anything with housing policy, with urban development policy, and he's never run a major organization\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1708:\n",
      "  video_id: 8wNr-NQImFg\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: like the elderly and the disabled\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 98, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 1709:\n",
      "  video_id: 8wNr-NQImFg\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, regardless of what you think of his politics, Dr\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 410, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1710:\n",
      "  video_id: 8wNr-NQImFg\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [ Laughter ] This whole thing is gonna be about you\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1711:\n",
      "  video_id: 8wNr-NQImFg\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Carson's own story is remarkable\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 220, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1712:\n",
      "  video_id: 8wQhzezNcUY\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let me give you an example, my Princess Inaara Foundation recently announced a fund raising campaign in the German city of [inaudible] and in yet in four weeks we were able to collect more than half million euro for poor families, for women and their families in Southern India.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1418, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 1713:\n",
      "  video_id: 8wQhzezNcUY\n",
      "  clip_id: 13\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So in other words, what I want to say is it works, it is fantastic and all of us can do it.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 604, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1715:\n",
      "  video_id: 8wQhzezNcUY\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is Begum Aga Khan and I'm very happy to join you today.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1716:\n",
      "  video_id: 8wQhzezNcUY\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let me tell you what I believe is one of the most important things that all people should be doing in 2009 in order to fight poverty.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1717:\n",
      "  video_id: 8wQhzezNcUY\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now the good thing is that it takes a relatively small amount of money to lift these people out of poverty by granting them small loans called micro-loans.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 731, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1718:\n",
      "  video_id: 8wQhzezNcUY\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In other words, they have no clean water, they have no safe housing, no medical care, and no education.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 508, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1719:\n",
      "  video_id: 91844\n",
      "  clip_id: 11\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm sorry, on the scale of one to five I would give this a five\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1720:\n",
      "  video_id: 91844\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) on the scale of one to ten\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1721:\n",
      "  video_id: 91844\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So check this out\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 414, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1722:\n",
      "  video_id: 91844\n",
      "  clip_id: 12\n",
      "  label_1: 3.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) If it were a scale of one to ten I'd give it a ten {laugh} definitely\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 345, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1723:\n",
      "  video_id: 91844\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It probably cost me about ten to fifteen dollars\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1724:\n",
      "  video_id: 91844\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi I'm Marshal Hammer and right now I want to share with you this film, I've got it on DVD\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 364, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1725:\n",
      "  video_id: 91844\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is Bound uhh starring Jennifer Tilly, Gina Gershon, and Joe Pantoliano and Patoliano is incredible in this movie, I've never seen him play a part this well\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 948, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1727:\n",
      "  video_id: 91844\n",
      "  clip_id: 5\n",
      "  label_1: 3.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Bound keeps me in suspense every time I watched it and I've seen it about a million times now\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1729:\n",
      "  video_id: 91844\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But I've I've (stutter) watched it a lot\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1730:\n",
      "  video_id: 91844\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Maybe that's an exaggeration\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 374, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1731:\n",
      "  video_id: 91844\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) This isn't going to be a film that you can watch with your children, (umm) it's probably going to be something that you can watch on a date or (umm) with friends\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 959, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1732:\n",
      "  video_id: 91844\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've definitely (umm) made it so this film has paid for itself over and over again\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 764, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1733:\n",
      "  video_id: 92291\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Anyways, Ice Cube plays this guy named Nick Persons who has just married the woman of his dreams, Suzanne, and (umm) he wants to settle down so he buys a quiet suburban house to escape, you know, the hustle and bustle of, you know, the city life\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1339, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 1734:\n",
      "  video_id: 92291\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, my name is Mary and today I'll be reviewing a movie that I recently saw in theaters and it's called Are We Done Yet? And (umm) this is part of the series with Ice Cube\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1735:\n",
      "  video_id: 92291\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But sadly what happens is that (umm) his house actually becomes very, very expensive to fix up and he has to deal with this like really weird, crazy contractor and it's just a barrel of laughs\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 886, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1737:\n",
      "  video_id: 92291\n",
      "  clip_id: 5\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I just felt like all the jokes were not that funny, (umm) and there were some funny parts but really not, not (stutter) really\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1738:\n",
      "  video_id: 92291\n",
      "  clip_id: 4\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It's an hour and thirty-two minutes long so it's really not that long, but overall {laugh} it's just a really pointless movie\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 509, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1739:\n",
      "  video_id: 92291\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I just felt like we were going nowhere and basically I just really wanted it to end {laugh} so overall I would not recommend this movie\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 809, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1740:\n",
      "  video_id: 92291\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And (umm) the acting was okay, but overall the plot was pretty bad\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 386, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1741:\n",
      "  video_id: 92496\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was (uhh) it was a pain to sit through really it was it was kinda a mystery that it was was made you know\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 737, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1742:\n",
      "  video_id: 92496\n",
      "  clip_id: 0\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Hey, (uhh) this is a review of Are We Done Yet which is a (uhh) (uhh) abysmal movie starring (uhh) ice cube\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1743:\n",
      "  video_id: 92496\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (umm) It feels like about half a movie should've been cut which would be kinda a short film but (uhh) probably would've been easy to sit through\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 883, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1744:\n",
      "  video_id: 92496\n",
      "  clip_id: 2\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There was probably a lot better movies that get passed up but this somehow made it\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 738, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1745:\n",
      "  video_id: 92496\n",
      "  clip_id: 5\n",
      "  label_1: -3.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was it was terrible\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 446, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1747:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I actually studied a bit of Mad Men in my television class\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 343, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1748:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And breaking bad, again, I just did not care about all of these men, sorry\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 430, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1749:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Lorelai, close second, and a closer is Angela and Hodgins from Bones\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 265, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1750:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: pretty much all the core relationships on pretty little liars are my fav\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 213, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1751:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I love Josh and Donna from The West Wing and Charlie and Zoey from the West Wing\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 333, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1753:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Rory and books in Gilmore Girls\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 323, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1754:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I did watch a significant amount of both and just could not emotionally invest\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 510, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1755:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: the two big ones for me and these might be controversial are Mad Men and Breaking Bad\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 540, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1756:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was mad the entire time\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 213, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1757:\n",
      "  video_id: 93iGT5oueTA\n",
      "  clip_id: 8\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: mad man made me straight-up angry because it does a really good job of depicting the 1950's workplace setting and I just did not enjoy it\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 642, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1758:\n",
      "  video_id: 94481\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) Yeah very enjoyable see it buy it\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1759:\n",
      "  video_id: 94481\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: (uhh) But it gives you a little kind of a taste of history\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1760:\n",
      "  video_id: 94481\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And with good reason, it is (uhh) monumental\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1762:\n",
      "  video_id: 94481\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's (uhh) it's amazing\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1763:\n",
      "  video_id: 94481\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's epic\n",
      "  text_feature_shape: (1, 5, 768)\n",
      "  audio_feature_shape: torch.Size([1, 378, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1764:\n",
      "  video_id: 94481\n",
      "  clip_id: 5\n",
      "  label_1: 3.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (uhh) The CG is perfect it's pretty amazing what they can do nowadays\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 688, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1765:\n",
      "  video_id: 94481\n",
      "  clip_id: 4\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) The the (stutter) battles, is, they're perfect\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1766:\n",
      "  video_id: 94481\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: (umm) But yeah it's got a good story\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 276, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1767:\n",
      "  video_id: 94481\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's it's (stutter) inspirational will change your life\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1768:\n",
      "  video_id: 94481\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's got pretty much everything you ever need including you know gore with the story\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1769:\n",
      "  video_id: 94481\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's got good characters\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 372, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1770:\n",
      "  video_id: 97ENTofrmNo\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We'll fly you to Budapest, put you up in a four-star hotel, and show you a real good time\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 425, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1771:\n",
      "  video_id: 97ENTofrmNo\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, Harrison Ford here, inviting you to join me and Ryan Gosling on the set of the new Blade Runner movie, here in Budapest\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1772:\n",
      "  video_id: 97ENTofrmNo\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the best thing is, you'll be supporting three incredible causes\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1773:\n",
      "  video_id: 97ENTofrmNo\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: com/bladerunner now and donate generously\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1774:\n",
      "  video_id: 9GzFQBljNIY\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And so, and so the problem becomes that women are flighty\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 414, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1776:\n",
      "  video_id: 9GzFQBljNIY\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They wobble back and forth between different ideas and different beliefs and things like this\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1777:\n",
      "  video_id: 9GzFQBljNIY\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They can never make up their minds\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1778:\n",
      "  video_id: 9GzFQBljNIY\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: She's a, a tremendous proponent of rationality\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1779:\n",
      "  video_id: 9GzFQBljNIY\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And Wollstonecraft identifies this as a huge problem\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1780:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Most importantly, you can learn more about how you fit into this important framework  and how it operates at both the Agency and Center levels.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 427, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1782:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All Agency organizations, based on their specific roles and responsibilities, play  an active part in successful diversity and inclusion efforts.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1784:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Information referring to Diversity and Inclusion for all agency offices and related  centers and unions can be found here.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1785:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Diversity and Inclusion (also known as  D&amp;I) are critical components to the  success of NASA's missions in the 21st Century.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1786:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Here is where you will learn more about  NASA's strategic framework for D&amp;I,  beginning with how the Agency defines these important concepts.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 421, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1787:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In this section you will find how NASA is working to weave D&amp;I into the fabric of its  culture, and how we are seeking to utilize D&amp;I  to maximize the individual potentials of  our workforce.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 629, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1788:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For example, we need diverse points of view to come up with the best technical  solutions.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 326, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1789:\n",
      "  video_id: 9Lr4i7bIB6w\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This section will also familiarize you with the six principles on which NASA�s D&amp;I  Framework is built.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1790:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 24\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's build the right strategies or programs to increase customer loyalty, and let's take what our customers are saying and include their feedback\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1791:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 25\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That is how a customer-centric organization operates\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 299, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1792:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 26\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you don't believe in the customer-centric model, let's take a look at Amazon\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1793:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 27\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Amazon is a company that is a hundred-billion-dollar market capitalization\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 333, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1794:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 20\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Have you ever been in a meeting where a colleague has said, \"I think we should be doing this\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1795:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 21\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" And then the next colleague says, \"No, I think we should be doing this\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1796:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 22\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" Those are signs of an organization that is not customer centric because their internal people, their employees, are speaking on behalf of the customer\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 893, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1797:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 23\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A customer-centric organization speaks like this: Our customers are telling us we need to do more of this or less of that\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1798:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 28\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Their slogan, their mantra is to be the world's most customer-centric company\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1799:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 29\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, you're not gonna debate the financial success of Amazon with me, are you? Thank you so much for watching this episode\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1800:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: com, a customer experience video blog to grow your profits and people\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 374, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1801:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello everyone, and welcome to michelfalcon\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 144, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1802:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In this episode, I'm going to tell you the difference between customer experience, customer service, and customer centricity\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1803:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm Michel Falcon, and this is episode number one\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1806:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want to go see a movie, the experience often goes like this\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 519, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1808:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you arrive at the theater, you purchase your ticket through an employee, or perhaps there's a self-serve option\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 688, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1809:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You jump online; you select the movie that you want to see at the right location, at the right time\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1810:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then you move on perhaps to the bathroom or the concession stand, move into the theater, watch your movie, and then you leave\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 741, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1812:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Each one of those events can also be known as a customer touch point, and the entire customer experience can also be known as a customer corridor\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1813:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Every single one of those events makes up the entire customer experience\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1814:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Customer service is simply an action within the entire customer experience\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 508, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1815:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, that employee that sold you that bag of popcorn was giving you customer service\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1816:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Customer centricity is a belief\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1817:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 16\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Organizations who are known for delivering an amazing customer experience from beginning to end ensure that their customer service at every single touch point is exceptional\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1818:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 19\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let me give you an example\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 355, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1819:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is a belief that an organization operates behind the viewpoint of the customer\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1820:\n",
      "  video_id: 9PzZSheh10U\n",
      "  clip_id: 30\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you haven't done so, download my e-book, The 28 Traits of Organizations Who Are Customer Experience Titans\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 481, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1821:\n",
      "  video_id: 9TAGpMywQyE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're talking about presentation, and the next thing that we want to look at when we're evaluating a speaker is: Was he or she enthusiastic?\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 603, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1822:\n",
      "  video_id: 9cYNT_YSo8o\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With the trial chamber’s conviction, we move one step closer to closing another painful chapter in the story of the conflict in the former Yugoslavia.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 673, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1823:\n",
      "  video_id: 9cYNT_YSo8o\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We’ll never forget the horrors of genocide in Bosnia or the many other crimes committed on all sides of the conflict in the former Yugoslavia, nor will we ever stop honoring their victims and survivors.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1825:\n",
      "  video_id: A1lFJXUpxZo\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And there have been lots of people that have been working on providing those kinds of opportunities in our Promise Neighborhood area for many years.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1826:\n",
      "  video_id: A1lFJXUpxZo\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have some strong institutional partners and we also want to make sure that we involve grassroots community based organizations and individuals, parents, residents of the community, and young people that are growing up in the community in the decision making processes and the designing key elements of our pipeline of opportunitites.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1971, 1024])\n",
      "  vision_feature_shape: (39, 2048)\n",
      "Item 1827:\n",
      "  video_id: A1lFJXUpxZo\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And just like it took some time for some of the things we don't want to see happen in the Promise Neighborhood area, it's going to take some time for the good things we want to see happen getin place.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1036, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1828:\n",
      "  video_id: A1lFJXUpxZo\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think one of the things that New Futures is very well positioned to do is to get good input and involvement from the community into the Promise Neighborhood initiative.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1244, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 1829:\n",
      "  video_id: A1lFJXUpxZo\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My hope for the Promise Neighborhood Initiative is that we are able to pull together the key opportunities that all young people need in order to grow up healthy, happily, put together a life where they can really contribute and give back to their community.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1303, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 1832:\n",
      "  video_id: AB1PbMaW03s\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In order to shut down the Arduino, the calculator first had to tell the Arduino to go into restricted mode.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 366, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1833:\n",
      "  video_id: AB1PbMaW03s\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By the way, if you want to download the Axe source code for this program, click the link in the description.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1834:\n",
      "  video_id: AB1PbMaW03s\n",
      "  clip_id: 19\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you enjoyed this demo and/or think this is an awesome project, I'd appreciate it if you could click the Like button.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1837:\n",
      "  video_id: AB1PbMaW03s\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The goal of the project is to run theater lights from my TI-84. For more details, click the link in the description.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1839:\n",
      "  video_id: AB1PbMaW03s\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The program will basically turn on USB power to the Arduino, send some commands, and then turn off power.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1841:\n",
      "  video_id: AHiA9hohKr8\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the case of Mozambique, it's a country that's rich in mineral resources\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 297, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1843:\n",
      "  video_id: AHiA9hohKr8\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But so are other countries that are struggling to overcome conflict\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1845:\n",
      "  video_id: AHiA9hohKr8\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Congo receives huge amounts of investments in the mineral sector\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 271, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1846:\n",
      "  video_id: AHiA9hohKr8\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: PERIES: Leonce, that's a very important point\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 250, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1847:\n",
      "  video_id: AHiA9hohKr8\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But because it's still lacking the institutional basis, the institutional framework for managing the natural resources, you do not see the benefits in terms of development\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 685, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1848:\n",
      "  video_id: AHiA9hohKr8\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Obviously both Mozambique and Rwanda's success is prefaced by a leadership that actually understands some of these issues and problems, and therefore want--there's a great desire to address them\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 877, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1849:\n",
      "  video_id: AQ4Pktv4-Gc\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As a listener you want to try and take on the whole understanding of everything that the speaker is trying to say before you respond.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 796, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1850:\n",
      "  video_id: AgH84SNRx5s\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sherry McCormack here with your quick tip on how to optimize your online presence.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 315, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1851:\n",
      "  video_id: AgH84SNRx5s\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you're saving your personal photograph make sure you include your name, the word real estate and where you do real estate.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 405, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1852:\n",
      "  video_id: AlJX3Jw3xKk\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And when they do that, they don't have to pay taxes on the money.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 227, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1853:\n",
      "  video_id: AlJX3Jw3xKk\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They're in fact, the best differentiation is that a 401k is something that an individual has while they're still working.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 903, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1854:\n",
      "  video_id: An8x4UfwZ7k\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To improve performance, refiners will continually need to challenge all aspects of their business.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1857:\n",
      "  video_id: BJS5KCSowgU\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Ivy College has been pretty helpful in the support department so when it comes to getting stuck on an assignment or if you're working late and you need some help they're always there to help.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1858:\n",
      "  video_id: BJS5KCSowgU\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: it's really good to have no distractions and have a group of supporters around to help you get through.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1859:\n",
      "  video_id: BJS5KCSowgU\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sometimes you can't sleep and it's 11 o'clock at night and you think, 'you know what?' 'I've got some energy to burn, I'll start doing some assessments' and you do, and you get through them quite quick.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1860:\n",
      "  video_id: BR2pkk3TK-0\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A new report from Deloitte says invest in water management, productivity enhancement and technology optimization in the oil sands to build Canada's industrial future.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1862:\n",
      "  video_id: BRSyH6yfDLk\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The first person to greet me was Indian The immigration officer was Indian customs officer eating his lunch was Indian\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1863:\n",
      "  video_id: BRSyH6yfDLk\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \"curry on me\" and then it happened, in 2004 I landed in New York, and the first thing I realized was reality is the bitch\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 623, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1864:\n",
      "  video_id: BRSyH6yfDLk\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Fuckin hypocrite i had not seen as many Indians in New Delhi as I saw in New York Subway, Dunkin Donuts, Hudson news, Hudson Deli\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1009, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 1865:\n",
      "  video_id: BRSyH6yfDLk\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He made me throw all the food my mom had packed for my survival\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1867:\n",
      "  video_id: BTjV5dU_rfY\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They did a really nice job of leveraging their offline assets during the NCAA tournament, and pointing the people to facebook.com/vitaminwater.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 804, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1868:\n",
      "  video_id: Bpy61RdLAvo\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So screens on shopping carts or something like that, is the fact that it’s not really very scaleable.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1869:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" And when I heard that a lot of things started to make sense\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 374, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1870:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And he looked down at me and said \"Kofi, that program saved my life\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1871:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But you know what, about a year and a half ago I was at a concert for a guy that I knew from high school\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 604, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1873:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was a program called Oasis\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 266, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1874:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The young people did basketball, games, water fights\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1875:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was a summer recreation program\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 366, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1876:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was cool, it was important, but I didn't think it was a huge impact\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1877:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" And gave me props, pulled me into that you know, \"man hug\" we do without fully hugging\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1878:\n",
      "  video_id: C5-cY1nPQ20\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And as I was standing around one of the young men came to me and said \"Hey Kofi how you doing\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1879:\n",
      "  video_id: CKqDDh50gcU\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Go to YouTube.com/citizentube and submit and vote on your ideas today.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1880:\n",
      "  video_id: CKqDDh50gcU\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You may have noticed that the Congress has come to YouTube.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 223, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1881:\n",
      "  video_id: CKqDDh50gcU\n",
      "  clip_id: 3\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're really excited about it and we wanna know how you think Congress can use YouTube best.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 928, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1882:\n",
      "  video_id: CKqDDh50gcU\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Go to the citizentube YouTube channel and create a Google Moderator account there, and sumbit your answer to the question: What is the number one way that the U.S.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 761, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1883:\n",
      "  video_id: CKqDDh50gcU\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We'd love to hear your thoughts on this question and Congress would, too, but we wanna try a new way of collecting your ideas and letting you vote on the best ideas from other people as well.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 735, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1884:\n",
      "  video_id: CKqDDh50gcU\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then vote on the questions submitted by other people and we will submit the top three, or four, or five voted up questions from you to the Congress to help determine the way forward on YouTube.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 717, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1888:\n",
      "  video_id: CO2YoTZbUr0\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But not only that, sometimes absence of evidence IS evidence of absence if we look where the evidence should be and it isn't there\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 768, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1890:\n",
      "  video_id: CO2YoTZbUr0\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's say it's 1947 and you're in the town of Roswell, New Mexico\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1891:\n",
      "  video_id: CO2YoTZbUr0\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But before you get there, lots of military guys pull up in jeeps and grab you and take you away somewhere\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1892:\n",
      "  video_id: CO2YoTZbUr0\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You run to check it out\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1893:\n",
      "  video_id: CO2YoTZbUr0\n",
      "  clip_id: 9\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Once they're satisfied you've told them everything, they let you go, but warn you that if you talk to anyone about it you'll be arrested or even killed\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1895:\n",
      "  video_id: CO6n-skQJss\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Being that we are in week 3 and not to much to reflect on in the textbook I went with rituals of communication.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 509, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1897:\n",
      "  video_id: CO6n-skQJss\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I have applied it to behaviors tho, the best example I could give you is Adam in the garden because more often than not when you catch someone doing wrong the first thing they try to do is hide, the second thing is too use the proverbial fig leaf and try to cover it up and when all else fails they blame someone else, I think it's pretty scary how ritualistic we all really are.\n",
      "  text_feature_shape: (1, 83, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1626, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 1898:\n",
      "  video_id: CO6n-skQJss\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I believe that life is full of algorithms, patterns and history constantly repeating itself before last week I had never really applied that to communication and that was pretty enlightening.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 687, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1899:\n",
      "  video_id: CU6U-gS76K4\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that technology that allows us to have that personal interaction and it’s GPS, it’s specific to the day and the location, I think is really exciting and I think that’s where I see us going in the coming months.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 927, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1900:\n",
      "  video_id: CU6U-gS76K4\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To me, the exciting part is figuring out this whole new world of social media, but not just social media in, I think, its current form of Twitter and Facebook and blogging, but adding the kind of GPS technology to that.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 924, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1902:\n",
      "  video_id: CU6U-gS76K4\n",
      "  clip_id: 20\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if I’m talking to my father, he’s probably not so excited about Gowalla and Four Square, but he is using technology that I never thought he would use, which is his Facebook, ‘cause he loves to see his grandchildren on Facebook.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 734, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1903:\n",
      "  video_id: CU6U-gS76K4\n",
      "  clip_id: 23\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean just the fact that Facebook is what, the fourth or fifth largest-- the population of Facebook is bigger than four or five other-- or the rest of the-- other than four or five countries than the rest of the world.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 719, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1904:\n",
      "  video_id: CbRexsp1HKw\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And so, let's, you know\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1905:\n",
      "  video_id: CbRexsp1HKw\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And so, you know, a lot of Atheists don't believe that there's any kind of life after death because there's nothing, there is just what we have\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1906:\n",
      "  video_id: CbRexsp1HKw\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn't get a specific question, but let's look at just like one example of something that a person who is an Atheist might have an issue with\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 873, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1908:\n",
      "  video_id: CbRexsp1HKw\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And, you know, there's different Atheists, there's different Atheist beliefs as well, there're not all the same\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1909:\n",
      "  video_id: CbRexsp1HKw\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, but generally speaking they don't believe that there's any kind of life after death\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 225, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1910:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ” An action plan put together by summit attendees called for a presentation at the next APS winter show, to be held March 3-5 in Reno, Nevada\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 783, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1911:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He was quick to point out that the hobby itself is doing well, while organized philately — which includes stamp shows, the APS and other hobby groups — presents what he called “a different story\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 761, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1912:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you wish to offer your own ideas and suggestions for consideration, please send them via email to future@stamps\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 1913:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Those connections are the ones that matter most of all\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 326, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1914:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Finally, as we head into the festive Thanksgiving holiday, I encourage you to be safe during your travels and cherish the time you spend with family and friends\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 685, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1915:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 17\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Have a great week enjoying our wonderful hobby\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1917:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: On October 29, the American Philatelic Research Library in Bellefonte, Pa\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1918:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Greetings fellow stamp collectors! Welcome to the Monday Morning Brief for November 21\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 266, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1919:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This splendid facility is housed in the American Philatelic Center, which also is home to the American Philatelic Society\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 436, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1921:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Included among the more than 30 participants were representatives from the APS and APRL, the American Stamp Dealers Association, the Boston 2026 World Stamp Show, the National Postal Museum, the Royal Philatelic Society London, and the U\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 845, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1922:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The day before this important event, the APC played host to another gathering of consequence: the Summit on the Future of Philately\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1923:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Postal Service, among others\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 148, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1924:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ” Throughout the discussion, which often took the form of a brainstorming session, Scott English, executive director of the APS, guided the conversation with his own upbeat observations regarding the state of our beloved hobby\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 849, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1925:\n",
      "  video_id: ChhZna-aBK4\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As Linn’s associate editor Michael Baadke reports in our November 28 issue, attendees “enthusiastically discussed the topics of growing the hobby, the future of stamp shows, and dealers and philatelic partnerships, along with ways the leading organizations involved in the stamp hobby can work together to make it succeed and grow\n",
      "  text_feature_shape: (1, 70, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1206, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 1926:\n",
      "  video_id: CwF97vXPYX4\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There’ve been numerous credible reports of government security services using excessive force, obstructing and dispersing opposition rallies, and intimidating civil society activists.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 951, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1927:\n",
      "  video_id: CwF97vXPYX4\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We call on the government to permit its citizens to exercise their democratic rights and for all in Equatorial Guinea to address political differences through peaceful and consensual dialogue.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 734, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1928:\n",
      "  video_id: DMtFQjrY7Hg\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: and then to overview the commissioning process for each of the 31 PHNs\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 213, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1929:\n",
      "  video_id: DMtFQjrY7Hg\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It came straight from the mental health professionals and the sector and we've tried to turn that around very quickly\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1933:\n",
      "  video_id: DVAY-u_cJWU\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's, I mean, political, particularly for consumer-wise, in the economy development, I think I prefer the latter.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 863, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1935:\n",
      "  video_id: DVAY-u_cJWU\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I'm pretty sure that the domestic market in India will become a very strong driver for economic development, even to the level of superpower.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 883, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1936:\n",
      "  video_id: DebbnL-_rnI\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They're doing some really fun stuff with pop-up stores, and how they're integrating the brand into workshops.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1937:\n",
      "  video_id: DebbnL-_rnI\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ANDY MURRAY: If you look at the innovation advertising, I really like what Levi's is doing.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 1938:\n",
      "  video_id: DjcZrtcBZi4\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If we want to build organizations that can innovate time and again, we must unlearn our conventional notions of leadership\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1940:\n",
      "  video_id: DjcZrtcBZi4\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have a confession to make\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 89, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 1941:\n",
      "  video_id: DjcZrtcBZi4\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But recently, I've discovered that what many of us think of as great leadership does not work when it comes to leading innovation\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1942:\n",
      "  video_id: DjcZrtcBZi4\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So along with three co-conspirators, I spent nearly a decade observing up close and personal exceptional leaders of innovation\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1945:\n",
      "  video_id: DjcZrtcBZi4\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We studied 16 men and women, located in seven countries across the globe, working in 12 different industries\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1947:\n",
      "  video_id: DlX-WyVe-D0\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Make sure to like and comment on it, and also subscribe to my channel to see more of my content.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1948:\n",
      "  video_id: DlX-WyVe-D0\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm really happy and proud for the United States and their efforts in this Olympics.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1949:\n",
      "  video_id: Dm8AL84e11w\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hopefully you never have to because computers are really good at repeating things.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1950:\n",
      "  video_id: Dm8AL84e11w\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In this next puzzle, our goal is to help the actor do a job continuously.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1952:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: </i> <i> At an estimated cost of $25,000 an hour,</i> <i> the price for taxpayers</i> <i>would have been several hundred thousand dollars\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 439, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1953:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 0\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We need tax cuts and tax reform now\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 139, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 1955:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: it's a little bit weird how he moves his mouth\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 406, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1956:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like, what-what is going on here\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1957:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's almost like he's the ventriloquist and the dummy at the same time\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 353, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1959:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That's how I speak to people\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1960:\n",
      "  video_id: DnBHq5I52LM\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: REPORTER: <i>Newly married this past summer,</i> <i> multimillionaire Treasury Secretary Steven Mnuchin</i> <i> formally requested that he and his new wife Louise</i> <i> be allowed to travel in style in a government jet</i> <i> on their honeymoon to Europe\n",
      "  text_feature_shape: (1, 73, 768)\n",
      "  audio_feature_shape: torch.Size([1, 830, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1963:\n",
      "  video_id: DtbT85s3i94\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There was a study done that shows 80 percent of your pitching velocity comes from hip to shoulder separation\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 239, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 1964:\n",
      "  video_id: DtbT85s3i94\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Your hands want to separate down low here and you want to break them at an angle 45 degrees or more\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 536, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1965:\n",
      "  video_id: DtbT85s3i94\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thoracic extension all that means is just big chest ok curvature in your upper spine\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 339, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 1966:\n",
      "  video_id: DtbT85s3i94\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because if I do that, that puts me into a good spot when I get into my thoracic extension or scap load\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 1967:\n",
      "  video_id: DzdPl68gV5o\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Yo guys I'm in Milledgeville and Yeah, I want to stop\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 366, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1968:\n",
      "  video_id: DzdPl68gV5o\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was like that I really got I was bad and Yeah, I was like\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1970:\n",
      "  video_id: E1r0FrFyNTw\n",
      "  clip_id: 2\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're doing a lot of them and are pretty excited about it, so I'm happy to explain it to you.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 350, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1973:\n",
      "  video_id: EMS14J0odIE\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm a certified financial with Asti Financial Management and you can learn more about my company and my services at www.astifinancial.com.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1974:\n",
      "  video_id: EMS14J0odIE\n",
      "  clip_id: 17\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you have children, the main concern with a living trust is that you're going to want to take a look at who's going to be the guardian for the children and also how the assets are going to be disbursed over time.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1975:\n",
      "  video_id: EMS14J0odIE\n",
      "  clip_id: 16\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You're also talking about when your children would be able to inherit assets and that may be a tricky proposition.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 675, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1976:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Right now, the safest thing for businesses to do is nothing.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 1977:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Worse, will the government come up with fines or additional costs if businesses have to lay people off in the future?\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1978:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The other glaring problem with this proposed stimulus package is that it couples tax cuts with spending increases, which makes no sense when we are already heavily indebted to foreign countries.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 791, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1979:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Until we regain respect for the rule of law and remove some of this uncertainty, I'm afraid none of these temporary promises, made right before an election, will do much towards any economic improvement.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 982, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1980:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 15\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The private sector simply cannot bear the burden of our engorged public sector.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1982:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 17\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Indeed, the spending that the administration is now proposing arguably constitutes a bailout of the public sector and various union allies of the administration.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1983:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 16\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In fact, one reason earlier stimulus programs did not result in any private sector growth is because large amounts went to the public sector.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 875, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 1984:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 19\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The temptation is to do something, anything, proactive to attempt to stimulate the economy, but history has shown us that governments cannot spend their way into prosperity.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 941, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 1985:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: To explain why the last one didn't work, adherents to the Keynesian economic philosophy are claiming that they actually did work – it just looks like they didn't because we don't realize how much worse off we would be right now without trillions of dollars of public spending.\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 968, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 1986:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 0\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is Ron Paul with your weekly update for Faced with continuing economic decline and an impending election, the administration, predictably, is entertaining the idea of another stimulus package.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 664, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1987:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Until we have leaders who understand that debt is not the way to prosperity, there will be no stopping runaway government spending.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 824, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 1988:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The last administration bought into Keynesianism just as much as this one does, unfortunately.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 1989:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: While it is nice to hear about business tax breaks, the positive results of these tax cuts will be dwarfed by its negative effects.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 778, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1991:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Second of all, businesses are reluctant to hire and invest, not because they are looking for temporary credits, but because of future uncertainty; they simply don't know what the government is going to do next and how future government policies will affect decisions they make now.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1214, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 1992:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: What will the cost of compliance be for hiring new employees, and will that force them to simply lay off anyone they hire now?\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1993:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 20\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The best thing government could do is get back to its Constitutional limitations and let the economy stabilize, heal and recover without the crushing burden of government holding it back.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 1994:\n",
      "  video_id: EO_5o9Gup6g\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Will Congress convene a lame-duck session this winter to pass cap-and-trade and other destructive legislation?\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 1996:\n",
      "  video_id: EyoMU2yoJPY\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Grey parrots are great talkers and they learn usually quite well and quite rapid.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 1997:\n",
      "  video_id: EyoMU2yoJPY\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some children don't learn to talk until they're a great deal older than others, and some learn to talk very rapidly.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 1998:\n",
      "  video_id: EyoMU2yoJPY\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But they do talk, they talk usually quite soon and they want to please you.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 1999:\n",
      "  video_id: EyoMU2yoJPY\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't stress the parrot, don't overtire the parrot, don't expect too much at one time.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2000:\n",
      "  video_id: F2hc2FLOdhI\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So: three toddlers with identical plastic toys, but with very different reactions to failure\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2001:\n",
      "  video_id: F2hc2FLOdhI\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: until she slid the red button, the cute doggie popped out, and she squealed with delight\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2002:\n",
      "  video_id: F2hc2FLOdhI\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The only thing that prevented them from succeeding was that their mind tricked them into believing they could not\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2004:\n",
      "  video_id: F2hc2FLOdhI\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In fact, we all have a default set of feelings and beliefs that gets triggered whenever we encounter frustrations and setbacks\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2005:\n",
      "  video_id: F2hc2FLOdhI\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now, adults get tricked this way as well, all the time\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2007:\n",
      "  video_id: F7zQPzwFToE\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The problem is is that Alex doesn't like magic\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2008:\n",
      "  video_id: F7zQPzwFToE\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So she doesn't want it and she wants to do whatever she can to get rid of it\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2010:\n",
      "  video_id: F7zQPzwFToE\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But instead what it does is it takes her family and it causes her family to disappear\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2011:\n",
      "  video_id: F8eQI8E-6q4\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That crosses a completely different line so you have to stay calm, stay professional most times just by doing that and using the proper professional tone you can defuse a situation and you will calm a customer down.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1136, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2012:\n",
      "  video_id: F8eQI8E-6q4\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The customer comes at you with a very upset loud tone; don't match the customers tone.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2013:\n",
      "  video_id: F8eQI8E-6q4\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The worst thing that I can do is to become angry right along with them.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2014:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What you really want to do is keep your answers about them and how well the two of you can work together\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2015:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: something they take very seriously and that really set her apart from the rest of the group\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 229, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2016:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Take a look around at their website and see if they won any awards maybe for how they treat their employees or how they treat their customers\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2017:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Make sure you do research on the company before you go in for the interview\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2018:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I would love to join the team\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2019:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Second, talk about what a great fit you would be in this position\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2020:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 6\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the three things to answer this question really well are: First, talk about how much you admire the company\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 628, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2021:\n",
      "  video_id: FHDVQkU-nGI\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And third, show that you've done research on the company itself\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 306, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2022:\n",
      "  video_id: FMenDv3y8jc\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Since its inception in 2001, the Gilman program has included grantees with disabilities\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2023:\n",
      "  video_id: FMenDv3y8jc\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Scholarship recipient with cerebral palsy, studies in Wales\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2024:\n",
      "  video_id: FMenDv3y8jc\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In 2006, the Youth Exchange and Study, or YES program, which recruits students from countries with significant Muslim populations, begins including students with disabilities\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 727, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2025:\n",
      "  video_id: FMenDv3y8jc\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In 2005, the National Clearinghouse on Disability and Exchange publishes Survival Strategies for Going Abroad, A Guide for People with Disabilities by Laura Hershey\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 781, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2026:\n",
      "  video_id: FMenDv3y8jc\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In 2006, the first English Access Microscholarship program to include students with disabilities takes place in Libya\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2027:\n",
      "  video_id: FMenDv3y8jc\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In 2006, Open Doors, funded by ECA, begins collecting data on US students with disabilities who study abroad\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2028:\n",
      "  video_id: F_YaG_pvZrA\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What you're going to want to do first of course is you have lots of retail experience you're going to want to put your most recent and most impressive experience first.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2029:\n",
      "  video_id: F_YaG_pvZrA\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because in a retail job, it's sort of like you have these skills that you can just keep building on that are going to pretty much work pretty well for lots of different retail jobs.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2031:\n",
      "  video_id: F_YaG_pvZrA\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And also detail in your cover letter how your expertise and your level of expertise will help the company grow and prosper.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 791, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2034:\n",
      "  video_id: FqEekswKPWE\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or do you try to segment to that medium and say, okay, we’ll capture them when they’re in this frame of mind doing this particular activity?\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 719, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2035:\n",
      "  video_id: FqEekswKPWE\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Say a couple of the key trends that we’re seeing in marketing for education space has been pretty much what a lot of people are trying to do, which is experimentation and experimentation and mediums that are not necessarily proven.\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2038:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're struggling with a borrowing capacity then maybe going with the lender who takes all that rental income into account might mean that you can borrow more money .I do suggest that you always go and speak to your mortgage broker about this because he will have access to all the lenders, they know all the criteria and they can help you out.\n",
      "  text_feature_shape: (1, 70, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1185, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2039:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want more videos, articles and podcasts just like this one, this is a shortest one I've done a long time, head over to PositiveCashflowsAustarlia.com.au or if you are on your mobile phone just type in pci.im.\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1051, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2040:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So look out for that, it is coming down the pipeline very shortly.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 380, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2041:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Rental income if taking into account, can add to your serviceability of that property significantly.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2043:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm sure there are some lenders out there who won�t touch it and who won't take it into account but in most circumstances lenders will take a portion of rental income into account.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 774, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2044:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The answer is yes, some lenders will take rental income into account.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 703, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2045:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that will just give you an average rental yield of maybe 3 or 4 %, something pretty low and they'll just say �we don't care what the property is renting for we're going to say it's going to for the 3 % yield and here is what will allocate to you.\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1042, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2046:\n",
      "  video_id: GAVpYuhMZAw\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's one lender at the moment which I think is just Bankwest who don't take rental income into account, they take rental yield into account.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 799, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2047:\n",
      "  video_id: GK-Pprzh0t0\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it was talking about the violence and how there was great concern that there were mass atrocities and potential genocide.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2048:\n",
      "  video_id: GK-Pprzh0t0\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: How can we, in the United States, help stop the world's worst humanitarian crisis, thousands of miles away?\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2049:\n",
      "  video_id: GK-Pprzh0t0\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Here, people are willing to put their lives on the line but they just need boots, or they need maps, or walkie-talkies, or tents.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2050:\n",
      "  video_id: GK-Pprzh0t0\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the inspirations for this was reading about how the African Union was sorely underfunded.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 610, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2051:\n",
      "  video_id: GKsjv42t284\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But we're committed to working with you - the sector, consumers and communities - listening and, if necessary, adapting to ensure we get it right\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2052:\n",
      "  video_id: GKsjv42t284\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The scale and pace of change is, I recognise, large and comparatively fast and I'm aware that there are challenges as the reforms are being rolled out\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2053:\n",
      "  video_id: GKsjv42t284\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We are a very agile government and if you can help us improve programs or policies, we'll do so\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2054:\n",
      "  video_id: GKsjv42t284\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We cannot do this without you\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2055:\n",
      "  video_id: GKsjv42t284\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're committed to doing that\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2056:\n",
      "  video_id: GMa0cIAltnw\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If anyone wants to follow Jesus, they have to separate themselves from Christians who are in sin.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2057:\n",
      "  video_id: GMa0cIAltnw\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You must come out and be separate, start following Jesus and get into an exclusive relationship with Him.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 818, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2058:\n",
      "  video_id: GMa0cIAltnw\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But if they hear your testimony and they continue to go on in sin; if they continue to not repent, then you can do nothing for them.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2059:\n",
      "  video_id: GMa0cIAltnw\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you fellowship with them knowing they are in sin then YOU ALSO commit sin, and you also will lose your relationship with Jesus.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2060:\n",
      "  video_id: GNP0PFas12Y\n",
      "  clip_id: 24\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So those are the things that I would advise right now for tips.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2062:\n",
      "  video_id: GNP0PFas12Y\n",
      "  clip_id: 17\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's no substitute for practice, there's no substitute for failing in front of someone and saying O.K.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2063:\n",
      "  video_id: GNP0PFas12Y\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I think that I don't personally let any of the obstacles get in my way.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2064:\n",
      "  video_id: GNP0PFas12Y\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Number two, would be to start finding your niche if you'll excuse that word.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2065:\n",
      "  video_id: GNP0PFas12Y\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I'd say that probably your biggest tip first as I said is desire and commitment to do it no matter what.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2066:\n",
      "  video_id: GNP0PFas12Y\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the tip, the tip for right there in that little comment is your sincerity and your desire to really help people in their lives and in their businesses and in everything that they pass through everyday.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2068:\n",
      "  video_id: GXIfrEUJ5d4\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: of international human rights tribunals, and the UN human rights committees, all of these come under the scope and meaning of the prohibition of discrimination in international law\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 627, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2070:\n",
      "  video_id: Gc_zIjqqUys\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, I'm Robert Todd and I'm here to answer the question how do shareholders get money?\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2071:\n",
      "  video_id: Gc_zIjqqUys\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You've just invested in the stock market for the first time and you're thrilled and excited but it suddenly dawns on you, how are you going to make any money off of this investment?\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2073:\n",
      "  video_id: GlShH_ua_GU\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Keeping the test and the environment separate is very advantageous.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 366, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2074:\n",
      "  video_id: GmpDbIstUdc\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Remember, the questions are designed to see if there's a good marriage between you and the company and whether you move onto the next level.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 648, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2075:\n",
      "  video_id: GmpDbIstUdc\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Know what the Interviewer's going to ask, the questions are always very similar and make sure you have some great answers.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2076:\n",
      "  video_id: GmpDbIstUdc\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm always on time, I'm punctual.\" Then it comes to, \"Tell me something about your weaknesses.\" An example might be, \"Well, you know, I'm the kind of person that once I get started on a task, I have difficulty getting off that task, and getting on to something else\". You always want to have with the weakness, what you've done to compensate for that.\n",
      "  text_feature_shape: (1, 85, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1161, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2077:\n",
      "  video_id: H-74k5vclCU\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: How can I apply analytics techniques to improve the strategy of my organization?\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2078:\n",
      "  video_id: H-74k5vclCU\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: How do I predict what competitors will do and take advantage of it?\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 235, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2079:\n",
      "  video_id: H-74k5vclCU\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now join me as we tackle this leg of our journey into marketing analytics.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2081:\n",
      "  video_id: H9BNzzxlscA\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Christine Marquette and I'm a registered and licensed dietitian with the Austin Regional Clinic and I'm going to talk to you about how long a person can live without water.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2083:\n",
      "  video_id: H9BNzzxlscA\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's a hundred and twenty degrees, you would probably only survive about two days without water.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2085:\n",
      "  video_id: HA2AiTz-qxc\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Arbitration is whereby the insurance company selects an arbitrator or a panel of arbitrators who are third part, third persons who do not know anything about the case, and when the arbitrator or panel of arbitrators are selected a arbitration hearing date is scheduled.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1476, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 2088:\n",
      "  video_id: HAnQVHOd3hg\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Google, LinkedIn, all those founders got rejected dozens and dozens of times before they got their first investment.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2090:\n",
      "  video_id: HAnQVHOd3hg\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe you didn't approach the right investors in the first place.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2091:\n",
      "  video_id: HFPGeaEPy9o\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They argue that it creates social pathologies such as single parent families, excess fertility, and laziness\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2092:\n",
      "  video_id: HFPGeaEPy9o\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: These critics argue that the welfare state breeds dependence and incompetence among those who receive it\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2093:\n",
      "  video_id: HFPGeaEPy9o\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some argue that people who receive welfare benefits cannot spend their benefits rationally\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2095:\n",
      "  video_id: HJTxq72GuMs\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: More access to education and making their lives better and therefore the whole economy better as well as reducing poverty.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 823, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2097:\n",
      "  video_id: HJTxq72GuMs\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And Especially during this crisis , where poverty rates can go up, incomes will come down.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 728, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2098:\n",
      "  video_id: HJTxq72GuMs\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And finally I think the legal part, making sure that girls and women understand their rights so that if they succeed in business they have the property rights and they don't lose it just because everything is under their husband's name.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 856, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2099:\n",
      "  video_id: HJTxq72GuMs\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In the more medium term, I think how to change cultural values and traditions become s a much more longer term issue, but having role models, having girls understand that their self esteem should not just be measured by that fact that they're married and having children needs to be changed.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1291, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 2101:\n",
      "  video_id: HMRqR-P68Ws\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Don't let people push you into making decisions that you may later regret.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 495, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2102:\n",
      "  video_id: HMRqR-P68Ws\n",
      "  clip_id: 16\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Pharmaceutical drugs do work, but they work at a big price; a lot of side effects and suppression of symptoms and ultimately no cure.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2103:\n",
      "  video_id: HMRqR-P68Ws\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi there, Eric Bakker, naturopath with another frequently asked question regarding Candida yeast infections.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 418, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2104:\n",
      "  video_id: HMRqR-P68Ws\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That really depends on how chronic or severe your condition is and whether you've had it before, if it's recurring, if it's acute, there are many considerations here.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 949, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2106:\n",
      "  video_id: HMRqR-P68Ws\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I've seen many women with acute thrush issues, home treat, go to the doctor, get chronic treatment, then go back and home treat and end up with conditions like endometriosis, which I find quite often linked up with chronic recurring thrush.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1178, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2108:\n",
      "  video_id: HMRqR-P68Ws\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Once you know what you're dealing with, then you can treat them more adequately or work out whether you want to have conventional medical treatment or natural treatment.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2110:\n",
      "  video_id: HR18U0yAlTc\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: However, at this moment I don't have a spot in the Final 16 match.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1063, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2111:\n",
      "  video_id: HR18U0yAlTc\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Since July, I've felt that it was my duty as a pro to make some hard choices.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2339, 1024])\n",
      "  vision_feature_shape: (46, 2048)\n",
      "Item 2112:\n",
      "  video_id: HR18U0yAlTc\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's been 14 years since my debut and I've fought over 80 matches.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2113:\n",
      "  video_id: HR18U0yAlTc\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This year, I took a break from fighting and worked on getting myself in shape and let my injuries heal.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1608, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 2114:\n",
      "  video_id: HR18U0yAlTc\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm very proud of the career that I've had in the WGP and my more than 80 matches.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1103, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2116:\n",
      "  video_id: H_x5O9GdknI\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Buyelwa: I'm not confident that the global economics will recover in 2009. Especially given that the process of the problem is still unfolding.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 621, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2117:\n",
      "  video_id: HbaycY0VuZk\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey guys, Patricia Sweeney with SnagALife.com here, and I get a question a lot.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2118:\n",
      "  video_id: HbaycY0VuZk\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: the link below is to the page on my website that talks about the variety of things that i utilize online to make money and direct marketing is a big component of that and i teach my team exactly how to do that and that is totally free for those of you who are on my team.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1033, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2119:\n",
      "  video_id: HbaycY0VuZk\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: so i hope this is helpful please like, tweet, and share it and whatever you do.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 426, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2120:\n",
      "  video_id: Hq3cHc6X8BM\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: According to Ernst &amp; Young's latest quarterly global renewable energy Country Attractiveness Indices report released recently, having quadrupled its solar capacity target to 50 giga watts by 2020 and began an accelerated domestic installations program to tackle the oversupply of solar panels, China looks set to continue its domination of the global renewable energy market.\n",
      "  text_feature_shape: (1, 70, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1213, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2121:\n",
      "  video_id: I9iV9q3ePhI\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Julie Asti, I'm with Asti Financial Management and you can learn more about my company and my services online at www.astifinancial.com.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 654, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2123:\n",
      "  video_id: I9iV9q3ePhI\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Another option might be, if it's not the right interest rate environment to do, a full mortgage refinance so you'll have really a good rate.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2124:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 24\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My favorite is Dollar Shave Club\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2125:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 25\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I just go to YouTube and check out the Dollar Shave Club video made for four thousand dollars and look where -- look where it's gone, but there are many out there that are really compelling so we show them those, run them through the formula\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 705, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2126:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 26\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You put the two together and they're able to go to put together a pretty good story\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2127:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 27\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Like good communication, stories are situational so we definitely use a lot of different media\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2128:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 20\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Get that to where you're not only hooking the the audience but really engaging with them and then focus on -- on the medium that's really the first step we do, but we take them through a process of writing out what it is you want to say and how you make it more compelling\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1233, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2129:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 21\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are just steps and whether it's a personal story, corporate story, group story, that formula it can really work and after we run them through that a few times then they start to get it\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 961, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2130:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 22\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But we also show some examples\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 218, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2131:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 23\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are some fantastic examples of great storytelling out there\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 380, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2132:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 28\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We do a weekly podcast over at the business school where we interview CEOs and business leaders\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 656, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2133:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 29\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We actually pull some of those out and say we're having you listen to this -- not actually what he's talking about earnings -- but how he tells the story about earnings and they're in awe, \"Wow, that is -- that is so compelling\" and what they see is a great communicator and a great storyteller stands above all the rest, but we also show them video\n",
      "  text_feature_shape: (1, 80, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1178, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2135:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When we talk to employers, they're telling us they pretty much expect our students to have the technical skills, and, if they don't, companies have their own universities and their own training programs to bring our students and new grads up to speed\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2136:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now it's about storytelling\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 168, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2137:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They ask employers the most important skills they're seeking in new hires, and communication is number one every year since 1982 and it's evolved\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2138:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: How in the world do you cut through? How does our student cut through? They cut through by being a great storyteller\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 662, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2141:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The key to a -- to a great communicator is understanding the audience, of being very audience-centered\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 582, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2142:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They get the audience and so they're situational communicators\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2143:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's about one percent of the people out there do it, and that's what makes them so great\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2144:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know, back in the day, in TV -- if you watch local TV -- and the lead of the story would be the who, what, where, when, why, and how\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 786, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2145:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They don't talk to the grandmother the way they would talk in a sales pitch, for example, or the way they talk to the mechanic who's fixing their car, and so first of all understanding the audience is number one\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 847, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2146:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 13\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Okay now, instead we hook the audience, and the lead is you may be paying more at the gas pump next month\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 659, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2147:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You know, the White House says today oil prices may increase over the next quarter\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2148:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 15\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Understand the audience and make the story compelling by hooking them\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2149:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's how we hook them and that's what storytellers have to do\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 406, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2151:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: First thing we do is explain: it's the message, it's not the medium\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 379, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2154:\n",
      "  video_id: IHp8hd1jm6k\n",
      "  clip_id: 30\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's a very different concept if you're going to have the video elements, face-to-face, standing up in front of a group\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2156:\n",
      "  video_id: IIPYcCii7Sg\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: JARLSTROM WANTS TO TELL THE WORLD ABOUT WHAT HE FOUND\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2157:\n",
      "  video_id: IIPYcCii7Sg\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: HE SAYS SOME DRIVERS GET CAUGHT IN A NO MAN'S LAND WHEN SLOWING DOWN TO TURN RIGHT ON GREEN WHEN THE LIGHT SUDDENLY TURNS YELLOW,\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 536, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2158:\n",
      "  video_id: IIPYcCii7Sg\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: PRETTY COOL, BUT HERE'S WERE HERE THINGS GET INTERESTING FOR AN ENTIRELY DIFFERENT REASON\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2159:\n",
      "  video_id: IIPYcCii7Sg\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: SO HE SHARED HIS RESEARCH AT A , CONFERENCE OF PEOPLE WHO HELP SET NATIONAL TRAFFIC POLICY,\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2160:\n",
      "  video_id: IIPYcCii7Sg\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: INSTEAD, THAT BOARD ACCUSED JARLSTROM OF THE UNLICENSED PRACTICE OF ENGINEERING\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2161:\n",
      "  video_id: IOpWjKAHG8Q\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: About business resilience a lot of times I get overwhelmed because how do you reach the business community\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 971, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2162:\n",
      "  video_id: IOpWjKAHG8Q\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: to our Firewise program based on their success\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 163, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2163:\n",
      "  video_id: IOpWjKAHG8Q\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And one thing I heard today is think about businesses that you really need to stay open during and after a wildfire\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 671, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2164:\n",
      "  video_id: IOpWjKAHG8Q\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That is a huge sector of the population and really reaching them and getting them involved has been a challenge\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2166:\n",
      "  video_id: IOpWjKAHG8Q\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Think about your grocery stores, your fuel fueling stations, your hospitals, things like that really your whole community relies on\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2167:\n",
      "  video_id: IRSxo_XXArg\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: After that, I started telling the women to always pursue what they want  and never underestimate themselves or what they are good at even if it is cooking:  they have to tell the world about it and put it on the internet because it a tool for ameliorating their status be it social or financial.\n",
      "  text_feature_shape: (1, 65, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2074, 1024])\n",
      "  vision_feature_shape: (41, 2048)\n",
      "Item 2169:\n",
      "  video_id: IRSxo_XXArg\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Najla abou hamzeh, I am 62 years old and mother of 2 kids.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 238, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2171:\n",
      "  video_id: IRSxo_XXArg\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For me they offer a valuable opportunity for every woman it opens her horizons in all fields  societal and financial ones.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1110, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2172:\n",
      "  video_id: IRSxo_XXArg\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I didn’t know anything about computers and I had a friend in Sweden who contacted me asking for my help  because they are doing a handcrafts exhibition and they know that abadieh is very rich in this area.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1296, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 2175:\n",
      "  video_id: Ie6sDptjAsU\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean, I don't want to eat them, but like I'm I collect them\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2176:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 10\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So this whole experience has made American very rich and we respect the fact that Muslims and Jews, and Christians, and Hindus, and Buddhists and everyone else has equal rights under the law in the United States, and we see it through the way our American citizens live out their lives.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1121, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2177:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: These kinds of things are happening in America because it’s part and parcel of who we are.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 630, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2178:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 12\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You see churches and synagogues side-by-side coming to Iftar dinners at mosques, you see them opening doors and exchanging communities.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 794, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2179:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it is important to understand the American narrative as a whole, to understand the different immigrant groups that have come in, the different religious groups that have come in and how it has made our nation powerful, why it is and how it is Americans celebrate diversity.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 982, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2180:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well one of the things our office did right as we started was to do a lot of research with historians outside of government who could talk to us about the timeline of American presidents’ diplomacy, Islam, where along the trajectory are we seeing presidents talk about the importance of Islam in America and how does that fit it.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1069, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2181:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We see American communities living side by side with others, they aren’t in special places, they are all living side by side.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2182:\n",
      "  video_id: Iemw8vqt-54\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are people from every part of the world who are Muslim in America.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2183:\n",
      "  video_id: JATMzuV6sUE\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, this is Michael Niren, immigration lawyer and founder of visaplace.com.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 197, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2185:\n",
      "  video_id: JHJOK6cdW-0\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And that’s why this project says “Strong from the start – We give them wings”, because through that worry about a Roma family we show that it is most important for a society, in this case for the city of Kragujevac.\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1084, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2188:\n",
      "  video_id: JHJOK6cdW-0\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This award is very important for the city of Kragujevac, especially because the city showed support for those organizations of the civil society that in a very concrete way supports the Roma population.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1041, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2189:\n",
      "  video_id: JKueLneBoik\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That means there will be a new batch of State officers ready to come and take the reins\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2190:\n",
      "  video_id: JKueLneBoik\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey! 4-H Congress is almost here\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 144, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2192:\n",
      "  video_id: JKueLneBoik\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Watch out for the State officers that are going to be running\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2193:\n",
      "  video_id: JKueLneBoik\n",
      "  clip_id: 5\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's going to be huge! 4-H Congress will be here july 16 through 19\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2195:\n",
      "  video_id: JNhqI4JtPXA\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's quite amazing to see the self-confidence that they build throughout the week\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2196:\n",
      "  video_id: JNhqI4JtPXA\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: the fact that they are all the same those barriers have just been lifted and they feel fearless\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 310, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2197:\n",
      "  video_id: JNhqI4JtPXA\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we do think it's a unique place because this is the only place where they find friends who are just like them\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2198:\n",
      "  video_id: JNhqI4JtPXA\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Do you like it that there are other kids who are deaf here\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1014, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2199:\n",
      "  video_id: JNhqI4JtPXA\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well because they understand us, right\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 340, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2200:\n",
      "  video_id: JXYot3NDQn0\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's a tough trajectory, but I think you have a lot of advantages.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 484, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2201:\n",
      "  video_id: JXYot3NDQn0\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Number one, you have a population of young people coming up which everybody knows is going to be the heart of the energy of the country and of innovation in the country.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 536, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2202:\n",
      "  video_id: JXYot3NDQn0\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think probably the model is one that's more based on innovation, science and technology-based innovation I think is particularly important and channelling the energy of your youth, which you're going to have a phenomenal advantage in.\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 939, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2203:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 10\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Doctors aren't fully informed of the true risks of the drug.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2204:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 12\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm happy to have been afforded the opportunity to represent the relator in this case and to have championed such a great effort.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 832, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2205:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Particularly, he was a sales representative for this company and he was selling a drug, Mycamine, that was not FDA approved for use in children.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 915, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2206:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 0\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In early 2010, relator, Frank Smith approached my prior firm with another lawsuit and at that time, he also raised concerns about an issue that was happening in his work and something that was happening at Astellas, the pharmaceutical company for which he worked.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1188, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2207:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The company instructed the relator and other sales representatives to hand pediatric studies out to doctors to support use of the drug in children, however, at the same time the company never sought FDA approval for use in children.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1221, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2208:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 2\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: What he was instructed to do by the company was sell the drug to children's hospitals, specifically for use in pediatric patients, something that was not FDA approved.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 851, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2209:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The company wanted to....Astellas wanted to increase sales by promoting this drug for use in pediatric patients, but not spend the money to do the adequate studies to make sure that use in kids was safe.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2210:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some companies, Astellas in this case, was arming its sales representatives with a calculator to go in and show hospital administrators how much money they would save by buying this particular drug over its competitor that was pricier, but did have an FDA approval for use in children.\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1252, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 2211:\n",
      "  video_id: Jz1oMq6l-ZM\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: A lot of times, when a whistleblower comes forward with information, like the relator did in this case, he's, you know, policing the industry.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 953, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2212:\n",
      "  video_id: KB5hSnV1emg\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It really depends on what's converting the best in the end.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2217:\n",
      "  video_id: KB5hSnV1emg\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you're deciding to do a paid app or a paid game, make sure that the quality is extremely high because people are going to expect this for this type of an app.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 560, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2219:\n",
      "  video_id: KB5hSnV1emg\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For instance, if you want to get a lot of users very quickly and you're not too worried about the return during the holidays, you might want to lower a price point.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 808, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2220:\n",
      "  video_id: KB5hSnV1emg\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This might vary from country to country or from time of year.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 386, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2221:\n",
      "  video_id: KB5hSnV1emg\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Of course, having a paid app or game doesn't mean that you also can't have IAPs.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 616, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2222:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Husband took me to the Nutcracker ballet\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 241, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2223:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We were all decked out—me in a long red strapless dress, him in a crisp black tuxedo\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2224:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ” Husband must have raised his fist in a victory pump, because people started clapping and hooting\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 701, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2225:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I could hear people in the audience saying “What did she say\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2226:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then we’ll tell them about the wedding we had in an old historical church, me in a princess-cut dress, him in a crisp black tuxedo again\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2227:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was a great memory that brings a smile to our boys’ faces\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2228:\n",
      "  video_id: KRje7su4I5U\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’ll tell them about the path from the church to the reception area, and how deer came right up to us like I was living a real-life fairy tale\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2229:\n",
      "  video_id: KXsjl0DKgL0\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then translate that to people and give them a good, healthy experience of working with real estate and take some of the stress out of it.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 850, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2230:\n",
      "  video_id: KYQTwFVBzME\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What I cared about was my finances and I felt like I was a pretty smart person and yet you know my financial life was not going where I wanted it to go.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2231:\n",
      "  video_id: KZzFCrEyKF0\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But I would like to see how each channel in the marketing mix contributes and which is the most effective, I think is-- would be key.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 778, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2232:\n",
      "  video_id: KZzFCrEyKF0\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They may not be consuming it over a traditional set, but on line.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2234:\n",
      "  video_id: KZzFCrEyKF0\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But even if you think about, you know, your other-- you know, something like television, television still has relevancy as a broad reach vehicle.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2237:\n",
      "  video_id: KanWhGY33Hk\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, the funny thing is, is what happens to most people when they get up to give their speech, is they forget something very important.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2238:\n",
      "  video_id: Kn5eKHlPD0k\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The book end is probably one of the more civilized ways to end a conversation\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2239:\n",
      "  video_id: Kn5eKHlPD0k\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it almost doesn’t matter what you say in that fill-in-the-blank space\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 443, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2241:\n",
      "  video_id: Kn5eKHlPD0k\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You could say something like, “Well, if you’ll excuse me, I really need to go comb my mustache\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 367, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2242:\n",
      "  video_id: Kn5eKHlPD0k\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well if you'll excuse me, I told Kara I would help her set up the dessert table\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 253, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2243:\n",
      "  video_id: Kn5eKHlPD0k\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We all know that the easiest way to get out of a conversation is to tell someone you have to go to the restroom\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 461, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2244:\n",
      "  video_id: Kn5eKHlPD0k\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ” Of course, as you might have already guessed, the “Duty calls” technique does have double meaning\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2245:\n",
      "  video_id: Kn99u05vlpA\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're borrower Prosper offers unsecured loans at reasonable rates, if you're an investor you can stand a make a bit of money with wise loans.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2246:\n",
      "  video_id: Kn99u05vlpA\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Prosper helps a wide demographic of consumers by bringing people with money into contact with people who need money.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2247:\n",
      "  video_id: Kn99u05vlpA\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You must have an Experian score of 640 or higher, but that's to ensure that the lending peers don't take too much of a risk.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2248:\n",
      "  video_id: Kn99u05vlpA\n",
      "  clip_id: 6\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if you're borrower this peer to peer lending network might be just what you've been looking for.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2249:\n",
      "  video_id: KrmVX-HANew\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: How they were always a couple that you could count on to set an example for you and your husband or wife.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 565, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2251:\n",
      "  video_id: KrmVX-HANew\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But if you are married you can talk about these points in relation to your marriage.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 730, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2252:\n",
      "  video_id: Kyz32PTyP4I\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Here’s some good news: our economy in Saskatchewan is more diversified and more resilient than it ever has been.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 623, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2253:\n",
      "  video_id: Kyz32PTyP4I\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello to the civics students at Marion Graham and thanks for the great question about how do we diversify our economy.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2254:\n",
      "  video_id: Kyz32PTyP4I\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the evidence is this: that even despite a big downturn in the energy sector, where unfortunately two thousand jobs in Saskatchewan had been lost, our economy actually created 5,200 net new jobs because of the diversity of our economy, because of the strength in agriculture, because of the strength in manufacturing and tech and in mining.\n",
      "  text_feature_shape: (1, 67, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1313, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 2255:\n",
      "  video_id: Kyz32PTyP4I\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The other way is through some tax incentives we implemented in the budget that’s already been responded to by some forest companies and some others that are investing in the province, including a new helium plant; where Saskatchewan is going to get a helium plant in Mankota, Saskatchewan.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1183, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2256:\n",
      "  video_id: Kyz32PTyP4I\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So between tax incentives, the right regulatory regime, but also a government that’s prepared to look at training opportunities in, for example, the tech sector.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2257:\n",
      "  video_id: L-7oRnbi9-w\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So as you listen to the story piece by piece told by different teachers, pay attention to words you don't know.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 761, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2258:\n",
      "  video_id: L-7oRnbi9-w\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You'll also hear Gabby of GoNatrualEnglish say \"WhatsApp\". I had a question once from somebody, saying, \"What's the difference in pronunciation between 'WhatsApp' and 'What's up?'\" So at the end of the story, you will get a little video from me telling you the difference in pronunciation in these two phrases.\n",
      "  text_feature_shape: (1, 76, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1126, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2259:\n",
      "  video_id: L-7oRnbi9-w\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What are these new vocabulary words and how are they pronounced?\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2261:\n",
      "  video_id: L-a4Sh6iAcw\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Pretty much I’m going to try to do more videos, answer more questions in video form, you know that way we can help spread the word.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 497, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2262:\n",
      "  video_id: L-a4Sh6iAcw\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Pretty much right now I’m in the process of gathering signatures.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 206, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2263:\n",
      "  video_id: L-a4Sh6iAcw\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Today I’m contacting you and everyone on the Facebook universe to ask for help.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 526, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2264:\n",
      "  video_id: L-a4Sh6iAcw\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Right now I am included as someone you can vote for this primary as district one candidate.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2265:\n",
      "  video_id: L-a4Sh6iAcw\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With that you can see my face, it helps your odds of getting more votes, you get a little statement of me or a summary of my beliefs and it helps out a lot.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 647, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2268:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some people use different kinds of technologies, some use mobile phone, others used personal health records, some use the patient portals to the electronic records.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 738, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2269:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it's my pleasure to introduce these three wonderful individual whose use health it to manage their and improve their health.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2270:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As you know the national prevention strategies tried to make us become a more healthy and fit nation.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 734, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2271:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As Surgeon General I had the opportunity to launch the national patient -- national prevention strategy a few months ago.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 861, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2272:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With better coordinated care, improved quality and decreased errors.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2273:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And this particular program is one of the ways the make that national prevention strategy come to life.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2274:\n",
      "  video_id: LDKWr94J0wM\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also want you know your own health information empowers you to be more engaged in your health and your healthcare.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2275:\n",
      "  video_id: LFOwCSiGOvw\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think the global financial crisis is a situation where more than one country has to come to find a solution.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 869, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2277:\n",
      "  video_id: LFOwCSiGOvw\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It needs to make some internal changes as well as it goes through this financial crisis.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 663, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2278:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 20\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So they really helped me grow and move beyond that on a personal level\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2279:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 21\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They helped with everything from getting our very first LLC all the way down to negotiating the sale of our business\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2280:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 22\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Everything that involves my business has been impacted in a positive way by the incubator\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 596, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2281:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My business is recycle right which has grown into Right Environmental\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2282:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Brian Hoyer, and I am a business administration management major at UNI\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2283:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I work at Target Click powered by Mudd Advertising\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2284:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Therese Kuster and my major was public relations at UNI\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2285:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I got the idea originally I was involved with the UNI entrepreneurs organization here at UNI, and we are working on a sustainability challenge with a local business and part of that which provide curbside recycling\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 923, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2286:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The reason I really got into wanting to start my own business is because I realized the potential for working for myself\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2287:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There was all this recycling talk going on so I figured I could provide that service that was obviously in demand\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2288:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There was no one to provide that service at that time\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2289:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We provide a variety of online marketing solutions from our clients\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2290:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Target Click started in the RJ McElroy student business incubator with myself and another partner\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 606, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2291:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The student business incubator at the University of Northern Iowa is a learning laboratory designed to educate and inspire student entrepreneurs\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2292:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It can be anything from paid search to organic search, social media and content production essentially anything that helps them improve the effectiveness up their online presence\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 688, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2293:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 13\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We want to established a good, strong foundational knowledge for the students before they leave campus on how to start their own business\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2294:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The goal of the student business incubator first and foremost is to educate them\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 362, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2295:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: From you know accounting help to, providing the actual physical office space that we need, pretty much every aspect has been affected by the incubator\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2296:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 14\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The student business incubator was absolutely crucial in launching our business\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2297:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 17\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All of your neighbors are entrepreneurs and if you're stuck on any issue whether specific your business or for client or just anything that you're doing you can walk down the hall and find other people who've probably been through the same thing\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 813, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2298:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 16\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But more important than that I think was really the entrepreneurial spirit\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2299:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 19\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When Target Click first started I'd never considered myself an entrepreneur or in fact I considered myself risk adverse which is not typically a characteristic you see entrepreneurs\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 826, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2300:\n",
      "  video_id: LJGL2sGvSS0\n",
      "  clip_id: 18\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To be successful as an Entrepreneur you first of all you need to be passionate, you need to be willing to implement, you need to be willing to take that step forward, I also think you need to be very teachable and be willing to get advice from people when you need it\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 948, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2301:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -I take it as a complement if somebody comes up to me and says, you look just like my mother in the '50s\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 287, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2302:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It has got everything from burlesque to pop-up tattoo parlors\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 266, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2303:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -Right now, I would say definitely '50s inspired\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 186, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2304:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I also really like the '20s and the '40s\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 264, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2305:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've already put on the outfit that I'm ready to go in, OK\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2306:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If something happens to me, just put me in the box\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2307:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The New York Times actually posted a short doc about the rad fashions happening across the bridge\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 386, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2309:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want to do whatever you want to do to your, like, clothes, to your body, to your hair, whatever it is, people are really receptive to that\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 632, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2311:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The ultimate celebration of Americana, rockabilly\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2312:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: JACOB SOBOROFF: That was great, but I could do you one better\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 173, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2313:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It has been running for more than 18 years\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 149, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2314:\n",
      "  video_id: LcfubBagG6Q\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Viva Las Vegas is the biggest rockabilly gathering in the entire world\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 436, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2316:\n",
      "  video_id: LpTbjgELALo\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So what I was just saying, yes they are, but then again the quality and who they are is important.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2317:\n",
      "  video_id: LtlL-03S79Q\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But in this four part video series, I'm going to show you some basic design principles that will give your presentations a clean, professional look that will help you make a great impression and more importantly, get your message across to your audience.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1111, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2318:\n",
      "  video_id: LtlL-03S79Q\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Okay, so what you're going to learn is CRAP: Contrast, Repetition, Alignment and Proximity.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2319:\n",
      "  video_id: LtlL-03S79Q\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well, in case there's anyone who doesn't want to do that, check out my video about what a presentation is.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2320:\n",
      "  video_id: LtlL-03S79Q\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or at the very least, your audience will have an easier time following your presentations and understanding your message.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2321:\n",
      "  video_id: LtlL-03S79Q\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Applying these four design concepts to your presentations is simple, easy and will make people think you turned into a design guru.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2322:\n",
      "  video_id: LtlL-03S79Q\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, subscribe to my Channel, sign up for my newsletter or check back here next week to watch Presentation Design Quick Tip #1...C is for Contrast.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 943, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2323:\n",
      "  video_id: LueQT0vY1zI\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sue Brownsen: So I am here because I think health care, it’s a necessary right for everybody.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2324:\n",
      "  video_id: LyOq9mOEPuk\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Because what happens then is it starts to sound a bit wrote.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2325:\n",
      "  video_id: LyOq9mOEPuk\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, if you're good at thinking on your feet, this will be really easy for you.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 350, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2326:\n",
      "  video_id: LyOq9mOEPuk\n",
      "  clip_id: 13\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't be too familiar with your humor or it will fall flat.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 370, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2327:\n",
      "  video_id: M6HKUzJNlsE\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was accepted into the program, and by that time I was full time, all out, no holds barred— school was intense for 2 and a half years, but I made it through, and like I said, I let my professors know that I had brain injuries\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1469, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 2328:\n",
      "  video_id: M6HKUzJNlsE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [Kelli Williams Gary, PhD] By the summer of 1993, I had taken the prerequisites to become an occupational therapist\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 426, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2329:\n",
      "  video_id: M6HKUzJNlsE\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So by the summer of 1995 I had finished the program\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2330:\n",
      "  video_id: M6HKUzJNlsE\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It didn't stop me, and I didn't use it as a crutch, but they definitely had some understanding and would be patient with me in some situations when I really, really needed it\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 875, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2331:\n",
      "  video_id: M6HKUzJNlsE\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: 4 average, and with all the skills that I needed to be an occupational therapist\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 415, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2332:\n",
      "  video_id: M6HKUzJNlsE\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was the president of my student OT association class, and I graduated Cum Laude from Chicago State with a 3\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 586, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2333:\n",
      "  video_id: MHVrwCEWLPI\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Even still today, there are times when it's very difficult to bring all of those key stakeholders to the table, together around a cause\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2334:\n",
      "  video_id: MHVrwCEWLPI\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've been able to keep the Republicans and Democrats sitting and talking to each other and designing paths forward\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 435, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2335:\n",
      "  video_id: MHVrwCEWLPI\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, for more than three decades we've been able to keep that alliance together\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 310, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2336:\n",
      "  video_id: MHVrwCEWLPI\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Alliance has 16 sitting members of the U\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 178, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2339:\n",
      "  video_id: MHyW857u_X8\n",
      "  clip_id: 22\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I do miss my family once in a while, but I love going out on the road and doing it.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2340:\n",
      "  video_id: MHyW857u_X8\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The other thing is the improvement with my own life, and my own business.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2341:\n",
      "  video_id: MHyW857u_X8\n",
      "  clip_id: 18\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You can't constantly teach and speak about something, without it having a dramatic effect on how you live your life, how you do your business and etc, because you can't continuously teach something and live a completely different way, or do it a completely different way without being consider a fraud or a fake.\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 956, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2344:\n",
      "  video_id: MHyW857u_X8\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I love that part, I love my time in the hotel room alone.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2345:\n",
      "  video_id: MLegxOZBGUc\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I hope you learned something about raising the chi in your home, and I thank you very much.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2348:\n",
      "  video_id: MSHBEntSDjU\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And you want to use clever, creative coupling with those campaigns that's contextually relevant.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 614, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2349:\n",
      "  video_id: MYEyQUpMe3k\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Jin is majoring in emergency health services and during the day, she can be seen learning how to draw blood and perform CPR, two necessary skills required for any rescue operation\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2350:\n",
      "  video_id: MYEyQUpMe3k\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As she left the university campus, Sunmi&nbsp\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 405, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2357:\n",
      "  video_id: MZUr1DfYNNw\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The move was made to grow its financial restructuring, turnaround management and bankruptcy reorganization capabilities.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2358:\n",
      "  video_id: MZUr1DfYNNw\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Deloitte recently announced it had acquired substantially all of the assets of CRG Partners.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2360:\n",
      "  video_id: MtIklGnIMGo\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So then you have people that follow them that think well my leaders want peace, they say they want peace, I want peace so if they think it's okay to build more settlements, that will bring peace, they're going to follow those people but we're not going to get peace.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 901, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2361:\n",
      "  video_id: MvEw24PU2Ac\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And when it comes to health, it's incredibly important, because I've either just been diagnosed with something, a family member's been diagnosed with something, or you know what?\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2362:\n",
      "  video_id: MvEw24PU2Ac\n",
      "  clip_id: 15\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And they're not paying off that experience, and it's not useful for me.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2364:\n",
      "  video_id: N-NnCI6U52c\n",
      "  clip_id: 2\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We try to do our job in the safest possible manner, and we are dedicated to flying because we love it, it's a passion of ours and because people enjoy going places faster.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2365:\n",
      "  video_id: N-NnCI6U52c\n",
      "  clip_id: 5\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it's fun, it's diverse, it requires good communication skills and we also enjoy just hanging around talking about flying.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2367:\n",
      "  video_id: N2nCB34Am-E\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then you could always go on and say but we have to do this or we have to do that but try to be understanding and empathetic.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2368:\n",
      "  video_id: N2nCB34Am-E\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So try to listen and understand how they would feel and then respond with that empathy.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2369:\n",
      "  video_id: NIpuKcoJhGM\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Increasing women's entrepreneurship is just plain good economics.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 271, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2370:\n",
      "  video_id: NIpuKcoJhGM\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: When we talk about financial inclusion in small and medium enterprises, those are policies that are gender neutral, but we know that because of the barriers that women face, focusing on financial inclusion in small and medium enterprises will have a disproportionately positive impact on women and girls.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1112, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2371:\n",
      "  video_id: NIpuKcoJhGM\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It represents 85% of global GDP, and the fact that they have focused on financial inclusion, on the challenges of SME's, is a testament to the fact that they recognize that this is the key to economic opportunity for all.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1019, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2372:\n",
      "  video_id: NOGhjdK-rDI\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So your car just died and you need credit, and it doesn't look too good.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2373:\n",
      "  video_id: NVLPURuAVLU\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Certain things you're going to want to do is avoid salts and high sodium products as salt helps retain fluids and it won't let you get away from them as quickly.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 733, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2374:\n",
      "  video_id: NVLPURuAVLU\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also exercise helps but remember to drink fluids when you're exercising to help sweat out that excess fluid.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2375:\n",
      "  video_id: NVLPURuAVLU\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also if you find bloating is just not relieved with any of these, definitely consult a physician and see if maybe there's other alternatives that you can take to help you with bloating.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2376:\n",
      "  video_id: NaWmaHwjElo\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can also avoid loans altogether by applying for scholarship and grants and possibly, having a job and saving money.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2378:\n",
      "  video_id: NgENhhXf0LE\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I attend Walther Lutheran High School and I am interested in Western Illinois because of its strong Broadcasting program that they have, and how close it is to home.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 749, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2379:\n",
      "  video_id: NiAjz4ciA60\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm here to announce the winner of Round 1 of the #HartHouseWinterBlast sweepstakes which we've been doing throughout the week.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2380:\n",
      "  video_id: NiAjz4ciA60\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They were all randomly chosen ad we're going to have my lovely assistant here choose from among these three people.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 855, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2381:\n",
      "  video_id: NiAjz4ciA60\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have two people here who entered via Facebook, one on the Facebook event section and one via the Facebook wall, and I have one who entered via Twitter.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2382:\n",
      "  video_id: NiAjz4ciA60\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Please be sure to reply, otherwise we'll have to choose somebody else.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2383:\n",
      "  video_id: NlrCjfHELLE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Okay now it is the moment that you've all been waiting for.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 223, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2384:\n",
      "  video_id: NoOt0oU843M\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Again, we know that equipment is very important to you and having that safe, reliable equipment is a key to your success delivering to our customers safely and timely and for you to earn the miles and the pay that you deserve.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1123, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2385:\n",
      "  video_id: NoOt0oU843M\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As you rely on that equipment for your safety and your comfort as that is your workplace and your home out on the road.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2387:\n",
      "  video_id: NoOt0oU843M\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the things that we are doing is we are upgrading the seats in the freightliner tractors.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2388:\n",
      "  video_id: NoOt0oU843M\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We are upgrading to a better quality seat that provides you comfort on those long hour trips you have out there on the road.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2389:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And if you don't follow those prescribed rules, you are quote non-compliant.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2390:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 15\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So life for me in institutions was very difficult because I wanted to do things that weren't considered normal in that environment.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 862, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2391:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 16\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So for me, it was hard to realize that I could get out of bed when I wanted to, I couldn't go to bed when I wanted to, I couldn't eat when I wanted to, I couldn't eat what I wanted to.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1063, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2392:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Charlie Carr, Boston, Massachusetts It was an incredibly huge shock because my disability was traumatic.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2393:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So for me there was a huge denial factor going on that for someone who might have a congenital disability might not be as much of an issue.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 854, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2394:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But when I went there and I saw all these people in wheelchairs, I just remember thinking, \"This isn't me.\" But it was me.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 909, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2395:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 4\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was devastated and so when I put into an institution and I went into this segregated high school I was very angry because I couldn't be with my peers at the local high school.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1223, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2396:\n",
      "  video_id: NocexkPXja8\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And so I was very freaked out by what I saw and it hit me very hard, the realization that, \"You are these people.\" What really hurt me, then, was finding out what I lost.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1024, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2399:\n",
      "  video_id: O-b3DQg0QmA\n",
      "  clip_id: 2\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Start you know with style, best things to own, things that are Gonna Make you look cooler, more stylish, and just be on your A-game this year\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 709, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2400:\n",
      "  video_id: O2ShYliS3CU\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because versus television, online video provides better measurability, better targetability, and better share ability.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 851, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2402:\n",
      "  video_id: O4UkHVJlIs8\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Five days later I was back down again to screen test It was that strange.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2403:\n",
      "  video_id: O4UkHVJlIs8\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So a week later I got a call, with a free ticket to fly to LA So my understudy went on for the play and I went down to meet David Lynch and Raffaella De Laurentiis at the Universal Studios.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1230, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2404:\n",
      "  video_id: O4UkHVJlIs8\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So anyway, they came to Seattle, this one woman came to Seattle I met her, read for her, she was impressed enough to recommend me to David.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2405:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think there is another agenda here\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 201, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2406:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 0\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: JON TESTER: Look, I don't think it's going the move the ball\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 121, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2407:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And if that's the direction we're headed, then that's not the direction I want to go\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2408:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I don't think you get the conservatives with that bill\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 228, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2409:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think that that skinny bill, that bait-and-switch bill, whatever you want to call it, Trojan horse repeal bill, that bill is not where we will end up at\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 901, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2410:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I don't think you get the moderates either\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2411:\n",
      "  video_id: OFia3dWgaoI\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That's all very convoluted, in the weeds, but that's where we're headed\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2412:\n",
      "  video_id: OKJPFisBoPY\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's obviously a huge subject and there's a lot more to learn about it, but I've probably given you just a little overview of all the different aspects.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2413:\n",
      "  video_id: OKJPFisBoPY\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm Carmen Lynne with Expert Village and we've been talking about handwriting analysis and I hope you have realized how fascinating this whole subject is.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2414:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He said: 'Negotiations with the United States are on the nuclear issue and on nothing else.' And three days ago he made that clear again.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2415:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Iran's Supreme Leader, the Ayatollah Khamenei, said on March 21 that the deal does not limit Iran's aggression in any way.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 854, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2417:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In addition to filling Iran's terror war chest, this deal repeats the mistakes made with North Korea.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2418:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 19\n",
      "  label_1: -2.6666667461395264\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Israel is not bound by this deal with Iran and Israel is not bound by this deal with Iran because Iran continues to seek our destruction.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 874, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2419:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The leading international powers have bet our collective future on a deal with the foremost sponsor of international terrorism.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2420:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 3\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In fact, the deal gives Iran every incentive not to change.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 336, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2421:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 2\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They've gambled that in ten years' time, Iran's terrorist regime will change while removing any incentive for it to do so.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 876, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2422:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In the coming decade, the deal will reward Iran, the terrorist regime in Tehran, with hundreds of billions of dollars.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 783, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2423:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And just last Friday, that aggression was on display for all to see.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 526, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2424:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 6\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Amazingly, this bad deal does not require Iran to cease its aggressive behavior in any way.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 619, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2425:\n",
      "  video_id: OORklkFql3k\n",
      "  clip_id: 8\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: While the negotiators were closing the deal in Vienna, Iran's supposedly moderate President chose to go to a rally in Tehran and at this rally, a frenzied mob burned American and Israeli flags and chanted 'Death to America, Death to Israel!' Now, this didn't happen four years ago.\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1418, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 2427:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: monsters have a perpetual effect all the time\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 161, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2428:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that only happens to the active wizard, not to all the players in the game\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 265, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2431:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So these monsters are now the monsters you start out with roaming the halls of Wizard School\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2432:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You have freshmen level difficulty cards, you have sophomore level difficulty cards, you have junior level difficulty cards, and you have your senior year cards\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2433:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Step 4 is your main step where you can customize the difficulty of the game and that is with graduation cards\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2434:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Your freshmen year cards actually make the game a little bit easier\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 299, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2435:\n",
      "  video_id: OWWHjP3pX9o\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The senior year cards are very, very difficult\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 266, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2436:\n",
      "  video_id: OXsTIPdytiw\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Sometimes what we think we see is not actually what occurred.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2438:\n",
      "  video_id: OXsTIPdytiw\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So although the information they're giving you they may feel is absolutely 100% accurate, you should always find ways to get a second party to verify what they're doing.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2439:\n",
      "  video_id: OXsTIPdytiw\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A useful non-digital source of information is witnesses-- finding people who have seen something going on.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2440:\n",
      "  video_id: OXsTIPdytiw\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe they saw someone walk in the front door that they didn't recognize.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2442:\n",
      "  video_id: OXsTIPdytiw\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So you want to get something that's very top of mind, very fresh in their memory.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2444:\n",
      "  video_id: Oa2xVjzAMFc\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But a Sole Proprietorship is a great way to start your business.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2446:\n",
      "  video_id: Oa2xVjzAMFc\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I started my business and ran it for over twenty years as a Sole Proprietorship.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 669, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2447:\n",
      "  video_id: Oa2xVjzAMFc\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Sole Proprietorship who write off in Schedule-C's often get audited and certainly at a much higher rate than an S-Corp.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2448:\n",
      "  video_id: Oa2xVjzAMFc\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By being an S-Corp it actually costs you less in taxes, it allows you to write things off differently, and here's a big deal from someone who has been audited by the IRS, the probability of you being audited by the IRS, when you're an S-Corp, is a fraction of what it is when you're a Sole Proprietor.\n",
      "  text_feature_shape: (1, 78, 768)\n",
      "  audio_feature_shape: torch.Size([1, 964, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2449:\n",
      "  video_id: OaWYjsS02fk\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's about creating something that from the beginning as you're creating it is built in a way to have multiple uses\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2451:\n",
      "  video_id: OaWYjsS02fk\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, we got to capture that information in a unique way\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 312, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2452:\n",
      "  video_id: OaWYjsS02fk\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, it's about creating it once and delivering it often\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2454:\n",
      "  video_id: OctOcfI4KSs\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that's my take, you may not agree or you may agree, you can click like or unlike and feel free to visit us at www.visaplace.com.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 617, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2455:\n",
      "  video_id: OctOcfI4KSs\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: A lot of controversy surrounding whether or not an individual who is taking the oath of Canadian citizenship should have the right to cover up their face, usually for religious purposes while taking the oath.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 943, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2456:\n",
      "  video_id: OctOcfI4KSs\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you cover your face completely, will the oath taker be able to reveal themselves to the authorities, now that is obviously a concern.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 978, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2457:\n",
      "  video_id: OctOcfI4KSs\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well, generally speaking, I think they should have that right, however there is a concern about identity.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2458:\n",
      "  video_id: OctOcfI4KSs\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that it is essential that anyone taking the oath of Canadian citizenship has to identify themselves to the authorities.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2459:\n",
      "  video_id: OctOcfI4KSs\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If the oath taker who is wearing a religious garb, for example an hijab, can properly identify themselves, then they should have the right to do.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2462:\n",
      "  video_id: OyK86reBnJE\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the first lesson, we'll discuss integers and integer operations, such as addition, subtraction, multiplication, and division.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2463:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 20\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: People are surprisingly forgiving brands when they own up to mistakes, and unfortunately some haters out there love to point fingers and jump all over imperfections, but for the most part, people understand\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 936, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2464:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 22\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So sometimes however, the tools we use to automate some of our content distribution and sharing processes can exacerbate a mistake\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2465:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Processes can be automated, but one-on-one conversations meant to relationship-build cannot\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 541, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2466:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - One of the top questions I consistently get asked is: how do I scale my engagement across social? See, managing large communities or listening all the time, it's time consuming, and we've developed so many time-saving apps and software to help us automate the process, but herein lies the distinction\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 954, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2467:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's the blending of the two that's an art form, and it's always evolving\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2468:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The bottom line is that meaningful one-on-one conversations require human-to-human interaction and a personal touch\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2469:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And to achieve this, we use the rule of thirds to split between automation, sharing, and one-on-one interaction\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2470:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: See, when you can automate in the right places, the human touch points within any campaign, product release, or general sharing system, you've hit the jackpot\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2472:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This will make the difference for companies and for people\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 304, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2473:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: See, unfortunately the science of automation has taught your target audience to distrust most marketing\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2474:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The more complex we get with our automation systems, the harder we have to work at humanizing what we do\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2475:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Currently, there is no automated system that prevents humans from making mistakes or social errors online\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 345, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2476:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For instance, when you're doing e-mail triage every morning, do you question whether a particular e-mail is from a real person or is it an e-mail blast that's been personalized to you? Are you suspicious of the ads that you see are even re-targeted? Or do you stop looking at your direct messages on Twitter because all you seem to receive are automated messages? Your audience is just as sick of being bombarded with automation as you are, and in this discussion of automation, let's also consider the human error factor\n",
      "  text_feature_shape: (1, 114, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1624, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 2477:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But digital sharing, especially immediacy of social, has made many of us wish there were more filters in place to prevent human mistakes from coming in\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2478:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And as companies, we've been used to having a little space between developing content and distributing it\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2479:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 15\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: See, some of the errors committed online by corporations have been more than just embarrassing\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 309, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2480:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, where should we draw the line? People want us to be more human online, but part of the discomfort many companies have with embracing social business is the possibility of embarrassment due to that human error\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2481:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 17\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However, companies are learning to demonstrate humanity rather than knee-jerk reactions to save face\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 502, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2482:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 16\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They've been career-ending\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 140, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2483:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 19\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In the corporate world, there's still a little too much emphasis on appearing perfect\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2484:\n",
      "  video_id: P0UHzR4CmYg\n",
      "  clip_id: 18\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's a good thing\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2485:\n",
      "  video_id: P17tYiqMGRU\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It IS a wonderful blessing if Jesus has spoken to you in the past, whether it be 5, 10 or since the Lord Jesus spoke to you?\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2486:\n",
      "  video_id: PHZIx22aFhU\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: DAVID ROMAN: The answer is absolutely yes, no question about it.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 178, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2487:\n",
      "  video_id: Pbu6oAKFCvo\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello again everyone, Beverly here once more with yet another video about binary option trading and how you can improve at it.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2488:\n",
      "  video_id: Pbu6oAKFCvo\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Doing your research will ALWAYS pay off, even more so with stocks, if you're not a very tech savvy person, google or apple stock, great as they may be, will end up costing you money, similarly for BP stocks if you don't know the oil market and so on.\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1213, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2489:\n",
      "  video_id: Pbu6oAKFCvo\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Lastly - Pay attention to market conditions, large stocks like Apple, BP or General motors can often act as market drivers, instead of reacting to it, so you can sometimes pay attention to what they do and follow the trend with similar, yet smaller, stocks.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1055, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2490:\n",
      "  video_id: PcqKFt1p3UQ\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We don't have relations with China.' Two years later almost to the day, Kissinger went on TV saying Richard Nixon was going to China.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 743, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2491:\n",
      "  video_id: PcqKFt1p3UQ\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I'm living witness that Nixon came into office uh, thinking about uh, reestablishing relations with China.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2492:\n",
      "  video_id: PcqKFt1p3UQ\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I, uh... Don and I went into the Oval Office, just the three of us: the President, Don, and myself.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2494:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the advantages of going to your local ACDelco professional service center is that we offer timing belt service kits that could save you valuable time, money, and possibly prevent future engine failures\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 892, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2495:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 13\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Replacing these components when changing the timing belt saves money on labor in most cases, as your technician will have already removed them and other engine accessories to service the timing belt\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 804, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2496:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Replacing these wear components when replacing the timing belt is essential to ensuring the new belt performs to its mileage requirements\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2497:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some competitors’ kits don’t include any original-equipment components\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2499:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 17\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: An inferior timing belt may cost less initially, but may cost more down the road if fails prematurely\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 616, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2500:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 16\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That’s important enough for me to say it again: ACDelco timing belts are manufactured with materials and construction technology identical to the original timing belt in your vehicle\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 759, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2503:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thanks for tuning in\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 133, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2504:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because it is not often replaced, timing belt service is easy to overlook when your car is otherwise running well\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 410, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2505:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I’m Peter Robert from ACDelco and I’m here to discuss the timing belt and the importance of having it replaced as preventative maintenance\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 567, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2506:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It may simply break and the engine will stop running – whether you’re in your driveway or on the freeway\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2507:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Unfortunately, there are no warning signs or symptoms of a worn belt\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2508:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That’s why it’s very important to check your owner’s manual for the mandatory replacement recommendations starting as early as 40,000 miles, but may be as high as 100,000 miles\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 803, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2509:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: With some engine types, a broken timing belt could also cause severe internal engine damage that could require major engine repair or even a new engine\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 710, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2510:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: com and click on ‘find a service center’ to locate the closest ACDelco professional service center program participant\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2511:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you’re unsure about your vehicle, ask a representative from your ACDelco professional service center\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2512:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For all of you not able to do this service work yourselves, please go to acdelco\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 352, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2513:\n",
      "  video_id: PexNiFbPTYM\n",
      "  clip_id: 21\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For vehicles with a timing belt, the investment in preventative maintenance through an ACDelco professional service center program participant may save you more in the long run – and prevent the hassle of a broken belt occurring at the most inopportune time\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 755, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2514:\n",
      "  video_id: PzI6yY9Y2xQ\n",
      "  clip_id: 10\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By sharing best practices and brainstorming new initiatives, you are unlocking the potential of women across South Asia – and creating a brighter future for all citizens of the region.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 983, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2515:\n",
      "  video_id: PzI6yY9Y2xQ\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I look forward to hearing about the ideas you come up with.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2516:\n",
      "  video_id: PzI6yY9Y2xQ\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I also want to thank the Government of Bangladesh for hosting.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2517:\n",
      "  video_id: PzI6yY9Y2xQ\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: SECRETARY CLINTON: I’m sorry I couldn’t be there in person, but I am delighted to send best wishes to all of you as you come together to find ways to elevate the status of women.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2518:\n",
      "  video_id: PzI6yY9Y2xQ\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Closing the gender gap is a powerful prescription for economic growth.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2519:\n",
      "  video_id: PzI6yY9Y2xQ\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But all over the world, women still face enormous obstacles to starting new businesses or expanding existing ones.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 756, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2520:\n",
      "  video_id: QBc7X5jj8oA\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Unfortunately for Mark, he exercised some options at 92 cents per share last March for 225,000 shares and then sold them at half the $14.50 value.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 744, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2521:\n",
      "  video_id: QBc7X5jj8oA\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One has to remember, however, that when Mark Ordan took over at Sunrise, with its shares trading below 50 cents and bankruptcy looming, a sale of the company was always on the table, as sort of an \\'93exit\\'94 strategy if he could accomplish what many thought was a near impossible task.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1001, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2522:\n",
      "  video_id: QBc7X5jj8oA\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Oh well, no one is crying and he has plenty more low-priced options to exercise and sell at the full deal price.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2523:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know, that just amplified on that\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 293, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2525:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Plus, I was getting absolutely inundated with emails and pings on social media\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 236, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2526:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it was overwhelming, I mean I couldn't do that and be on the road at the same time\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2527:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And Stu kept assuring me, he said, you got tons of content\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 357, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2528:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Yeah initially I was really worried, wondering if we had enough content\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 215, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2529:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But I kept thinking, oh my gosh, I'm going to have to come up with this original content every single week\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2530:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know, you've got books, you've got all this content you've done your site\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 306, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2531:\n",
      "  video_id: QCR7uyowjhM\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What I found was that you can really repurpose the same content and it's extremely rare when somebody says, oh that's just that blog post you did a while back\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2533:\n",
      "  video_id: QIonRUsCqBs\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Listen May is just around the corner and that means we're gonna happen schedule changes that you're gonna like coming out for the network I encourage you to go to GEB America dot com click on the schedule link\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 669, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2534:\n",
      "  video_id: QIonRUsCqBs\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi I’m Amy with your GEB America update\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2535:\n",
      "  video_id: QIonRUsCqBs\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also don't forget to check out our Facebook, Twitter, Pinterest, YouTube some fun giveaways\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2536:\n",
      "  video_id: QIonRUsCqBs\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s easy to read plus you’ll get more information about our programmers\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2537:\n",
      "  video_id: QJBQIOmG1CA\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: E related questions and set them in a technical way ok don't bring in things that are your own opinions you know make sure that you know M&amp\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 896, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2541:\n",
      "  video_id: QVyxySAaehE\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that's one of those tools that became extremely helpful to me because it made it so easy for me to make an e-mail contact with my legislator you know just using the template that was there, personalizing a little bit.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 916, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2542:\n",
      "  video_id: QVyxySAaehE\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it's very rewarding I mean, you know, it's difficult to be kept in a box for me, and also, you know, as a speech-language pathologist, communication is extremely important.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 979, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2543:\n",
      "  video_id: QVyxySAaehE\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I think one thing that helped me to kind of realize the importance of advocacy and understand the issues that are going on not only locally, but at a national level was to subscribe to things like Action Alerts, so that you can see what's happening, you know especially in federal legislation.\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1088, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2544:\n",
      "  video_id: QWll4lS1qqI\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're meeting somebody, you may want to add \"and this was my really great cook that I was talking to you about.\" Adding those compliments make people respected and feel really good about themselves.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 861, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2545:\n",
      "  video_id: QWll4lS1qqI\n",
      "  clip_id: 14\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It can be really awkward if somebody feels that you're telling it just because you feel envy about it.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2546:\n",
      "  video_id: QWll4lS1qqI\n",
      "  clip_id: 16\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm Hazely Lopez from Hazely Academy of Refinements and Modeling and just a little tip, always remember to compliment your spouse once a day.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 819, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2547:\n",
      "  video_id: QXXexH-ow_k\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was always really thin in places, and I just was never happy with the kind of beard I could naturally grow.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2548:\n",
      "  video_id: Qfa1fY_07bQ\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The first ships from the United States Navy's  biofuel-powered fleet, officially known as the Great Green Fleet,  have sailed off to deployment in  the Western Pacific.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 669, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2549:\n",
      "  video_id: Qfa1fY_07bQ\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Good morning, I am Adelina Vasileva and  this is the daily report from our newsroom in Varna.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 233, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2550:\n",
      "  video_id: Qfa1fY_07bQ\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The six ships are powered by an alternative fuel blend made of 10% biofuel  and 90% conventional petroleum fuel.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 648, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2551:\n",
      "  video_id: Qfa1fY_07bQ\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Navy's five goals for reducing  the branch's energy and environmental footprint.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 540, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2553:\n",
      "  video_id: Qfa1fY_07bQ\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is all for today and if you'd like to learn more, please visit us at eatglobe.com\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 571, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2554:\n",
      "  video_id: Qfa1fY_07bQ\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Even though the 10:90 biofuel blend,  on which the ships sailed off, is much less greener than the 50:50,  with which they were tested, this small shift towards renewable energy  is still an improvement from several years ago.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 783, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2556:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You probably already know what you're supposed to do so this chapter is a reality check and a reminder that we need to take care of ourselves and that our health is our most prized possession\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2557:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In this chapter a lot of it's very very familiar\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 185, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2558:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: At this point in the semester it's a good time to think about those things we learned about keeping our brains healthy way back in a chapter on memory\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2559:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So 2:08review for most of you especially if you've taken the health three-unit health class which isn't required to transfer to a UC and even to transfer to a CSU you have a lot of options in that Area E but if you've taken it again this chapter will be just a good reminder\n",
      "  text_feature_shape: (1, 65, 768)\n",
      "  audio_feature_shape: torch.Size([1, 969, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2560:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So think about it this week and think about getting back on track and making sure as you get busier and busier and as finals approach that you do not dream of neglecting to take care of your most magnificent possession\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 834, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2561:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 14\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Remember was it sleep that you needed more? Or healthy vegetables? Or what is it that you need to keep your health your mind and your body healthy\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 459, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2562:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 17\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I got 86 so I'm pretty happy with that\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 209, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2563:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This week you also get a chance to take a little test to see how long you're going to live\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2564:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 19\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's see how many if you can beat me and a think that's it for my intro\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2566:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want you to imagine you are really really rich and you can have anything you want to have I want you think about might be a particular car, it might be a race horse it might be a house on the beach\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2567:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's use some of the creativity we talked about last week for this chapter\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2568:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want you imagine maybe even close your eyes and imagine that you have that possession\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 323, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2569:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Think about a possession that you would like to actually own\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 293, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2570:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Maybe and those of you have children I want you to think about how hard you strive to be the best parent you can be\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2571:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: How would you feel and how it would be to have that item in your life and now I want you to imagine how you would take care of that object If it was a car, for example, I know a lot of you have dream cars how would you take care of ti? Would you read the instruction manual? Would you make sure it had tune ups? Would you polish it to perfection and make sure it was always in its prime state\n",
      "  text_feature_shape: (1, 91, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1409, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 2572:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We know that good health is more important than anything\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 255, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2574:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: People who are sick or who don't have good health would give all away to have good health and yet how well do we take care of ourselves? Do we read our instrucion manual? Well we don't come with one but do we read articles about health and how to eat well and take care of our bodies? Do we eat well do we sleep do we do all those things we know we're supposed to do\n",
      "  text_feature_shape: (1, 88, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1148, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2575:\n",
      "  video_id: R9xTBw3MCWI\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's more important than that race car or that race horse or that magnificent house\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2576:\n",
      "  video_id: RB3HA-ZMtFw\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Getting out from liberalism does not mean to get out from the political vision of Benedetto Croce, which liberal political vision, in those days, was the philosophical legitimacy of the political world of the bourgeois civilization, the world of Goethe and Mozart, the world of the great bourgeois culture.\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1588, 1024])\n",
      "  vision_feature_shape: (31, 2048)\n",
      "Item 2577:\n",
      "  video_id: RChkXDS8ulE\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Um when an applicant asks how much do I have to do, um, that shouldn’t sound very good to them um because anytime you’re um presenting yourself or entering a professional school you uh really should be an individual that kinda goes above and beyond the call of what you have to do or what the basics are.\n",
      "  text_feature_shape: (1, 69, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1196, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2578:\n",
      "  video_id: RChkXDS8ulE\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Um and so I know there are some programs that may require a basic number of shadowing or volunteer hours um but I really think you should do it because you’re interested in it um and you, you, you want to enhance yourself uh in order to make yourself potentially a better doctor down the road in our case.\n",
      "  text_feature_shape: (1, 68, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1141, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2579:\n",
      "  video_id: RChkXDS8ulE\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Uh so please do volunteer work because you’re interested and you want to make a difference in other people’s lives and you’ll get a whole lot more out of it by following that.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2580:\n",
      "  video_id: RChkXDS8ulE\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Uh and so, you know, anytime I hear uh “how much do I have to do” with regard to volunteering, um, it’s probably not gonna be uh, uh good quality indicator if you’ve been doing it because you had to do it.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 889, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2581:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: From pushing trollies in Tesco when I was 15, I’ve worked for Tesco’s, for Sainsbury’s, I went to Sainsbury’s as a trainee buyer in London about 12-13 years ago then went to work for Waitrose as a buyer, then took the opportunity to come back up to Scotland (because there aren’t many buying jobs in Scotland) three years ago.\n",
      "  text_feature_shape: (1, 94, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1201, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2582:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I got to this position really by working in the retail industry for a long time.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 553, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2583:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So get a summer job at a local producer or farm, go to college and get your qualifications, be it relevant to the marketing side or retail, there are all sorts of degrees appropriate to the industry, and again work in a supermarket.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1168, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2584:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The advice I’d give to anyone interested in a career in the food industry is to get involved with the suppliers at an early age – know your products.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 761, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2585:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 14\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s one of those things which funds you through university, but it gives you that real learning about products and speaking to customers and helps you understand the whole industry.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2586:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Steven Wallace&gt;&gt; My name’s Steve Wallace, I’m the grocery, beers wines and spirits buyer for Sainsbury’s for Scotland and for Northern Ireland.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2587:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The best part of the job, I would say, would be when you’re giving a big new contract or a new listing to, in particular, a small supplier because that’s where it means jobs.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2588:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s looking for quality products that we can sell or our customers demand, it’s looking for different and exciting ideas within the marketplace.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 610, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2589:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Your decisions in your everyday job, from seeing the quality products to listing them on your shelves, that affects jobs and communities, it goes all the way down the chain.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2590:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You could list a product in 20 or 30 stores, it could mean an extra five or six jobs at that particular supplier, so that’s always a good good moment.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 774, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2592:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think you need to have a good eye for a product, you need to be very patient, you need to be good at communicating because we have to communicate within our retail side and our head office, government bodies, all sorts of suppliers and other people, so being a key communicator is absolutely essential.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 867, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2593:\n",
      "  video_id: ROC2YI3tDsk\n",
      "  clip_id: 8\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are great fun parts to the job about seeing great products, great suppliers, but actually there’s a lot of time needs to be spent doing the number crunching analysis, it’s a boring part but it needs to be done, it’s all part of the job.\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 975, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2594:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -In first place this year was Safeway – who last year was ranked 4th.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2595:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -The report ranks major US retailers according to their sustainable sourcing policies.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2596:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 13\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: -Five retailers failed Greenpeace’s ranking this year – including Giant Eagle, Publix, Supervalue, Winn-Dixie and Meijer.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 656, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2597:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -Rounding out the top five spots were Target – Wegmen’s – Whole Foods – and Ahold.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2599:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 17\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: --------Thank you for joining me for The Tradex Foods - \"3-Minute Sustainability Recap\" This is Ryan McKay - “BUY SMART” and “EAT MORE SEAFOOD”\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2600:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thank you for joining me for the 2nd edition of the Tradex Foods - \"3-Minute Sustainability Recap\" A summary of hot news items in sustainability – for seafood purchasers and industry.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 856, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2601:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello - my name is Ryan McKay - Director or Research &amp; Media with Tradex Foods.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 251, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2605:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Scottish Mackerel fillets – sourced from the Scottish Pelagic Sustainability Group – landed on retail shelves at UK-based Waitrose this past month.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2606:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: --------In other news, -An independent poll completed by the World Wildlife Fund found that greater than 90 percent of European customers in Portugal, France, Spain, Italy and Belgium want sustainable seafood.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 994, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2607:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: -And in Denmark - the first Baltic Cod fishery has been MSC – certified -Meanwhile, the Faeroese Mackerel Fishery has been denied MSC certification based on the fact that the fishery has failed to reach an agreement on mackerel quotas with Norway and the European Union.\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1148, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2608:\n",
      "  video_id: RVC8l5hf2Eg\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: -However, 72 percent of customers do not feel that they have adequate information when if comes to the origin of seafood that they buy.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2609:\n",
      "  video_id: Rb1uzHNcYcA\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Since it's the dreaded back-to-school time, I decided that it would be fun to do a back-to-school school expectations versus reality video\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 570, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2611:\n",
      "  video_id: Rb1uzHNcYcA\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Because I can think of a lot of things that everyone's like, oh my god, this is what's going to happen during school\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2612:\n",
      "  video_id: Rb1uzHNcYcA\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And also, I'm currently having a 500,000 subscriber giveaway where I give away a MacBook Pro, iPad Mini, and a GoPro camera as well $200 gift cards\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2613:\n",
      "  video_id: Rb1uzHNcYcA\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you can relate to any of these, give this video a thumbs up\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 216, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2614:\n",
      "  video_id: Rb1uzHNcYcA\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, if you didn't enter that video, I'm going to put it right over here\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 690, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2615:\n",
      "  video_id: Rb1uzHNcYcA\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's get on with this video\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 526, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2617:\n",
      "  video_id: RmX9t_HY_dU\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, taiwanese friends, I'm Songjoongki, long time no see!\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2618:\n",
      "  video_id: RsE2gYghZ2s\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Songs and other genres of music are shaped by the percussion or a lack thereof, most notably, ambient music or defined ambient by the fact that they don't have noticeable aspects to it like percussion.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1058, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2619:\n",
      "  video_id: RsE2gYghZ2s\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or, if you're good enough, you can make percussion ambient where it's background noise but it's still percussive and still beat, and it keeps time, but it's still there.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2621:\n",
      "  video_id: RvmTZVNAAuQ\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So let us know, do you plan to work with an Instagram partner and take advantage of the opportunity now?\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2622:\n",
      "  video_id: RvmTZVNAAuQ\n",
      "  clip_id: 12\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Either way thanks for watching, make sure you subscribe, and follow us on all our social media @SocialMediaDel and we will see you next time.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 890, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2623:\n",
      "  video_id: RvmTZVNAAuQ\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So if you are a small business you probably won't be able to take advantage of this until later this year.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 430, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2624:\n",
      "  video_id: RvmTZVNAAuQ\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For Instagram, what we are seeing now each post reaches close of 100% of its earned audience, and that is exceptional.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 738, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2625:\n",
      "  video_id: SBFnCNzlynQ\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: After he will not be\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 519, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2626:\n",
      "  video_id: SBFnCNzlynQ\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \"From family, parents, if they are against Islam, they teaching to be against Islam from beginning\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 736, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2627:\n",
      "  video_id: SD6wphlw72U\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi guys, its Jasmine from letslearnspanish.online chances are you landed on this video because you were searching for spanish language courses Recently, I have been searching for some Spanish language courses online but I got frustrated because everywhere I searched seemed to lead to products that just weren’t of good quality.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1054, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2628:\n",
      "  video_id: SD6wphlw72U\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What you'll find over there is tons more information on this wonderful course.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2629:\n",
      "  video_id: SD6wphlw72U\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Check out this product you can find it at letslearnspanish.online.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 359, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2630:\n",
      "  video_id: SH0OYx3fR7s\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To design the whole structure, to design the things so that we can achieve goals that we have set for our self.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2631:\n",
      "  video_id: SH0OYx3fR7s\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Yeah, economy may come back in 2009, maybe in 10, maybe in 11. That's not for me the most important issue because it will come back some day, today, tomorrow, or the day after.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2632:\n",
      "  video_id: SH0OYx3fR7s\n",
      "  clip_id: 26\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A world without poverty, a world that exists without hunger.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2633:\n",
      "  video_id: SH0OYx3fR7s\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or we never try to go back to that, we create a new normal situation which is quite different then what we have been going through.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 786, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2634:\n",
      "  video_id: SH0OYx3fR7s\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The worst of the crisis is the best of the opportunity to change things.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2635:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Through this, my mother was able to rise above her poverty, become a registered nurse, and come to the United States\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2636:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And so their family had a system: one sibling would graduate from college and then support the education of the next sibling until all the siblings graduated\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 625, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2637:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My mother moving to the US turned out to be critical for me\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2638:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Whether we acknowledge our role as a world leader in disability rights are not, other countries still look to the US for leadership on human rights issues\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2639:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm advocating for similar laws to be implemented everywhere\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2640:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: laws enabled me to access my fundamental rights especially in terms of having access to quality education\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2641:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: My mother was the 13th child in a very poor family from Eastern Samar in the Philippines\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 341, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2642:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Education is very important in my family\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 380, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2643:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However, despite their poverty, the family prioritize education because they believed in its power to transform lives\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2644:\n",
      "  video_id: SKTyBOhDX6U\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Her father, the breadwinner, died when she was barely a year old putting the family in a dire financial position\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2645:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What's Equity? Equity in your home is when you, well, it's what you own in your home\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2646:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - Hi, it's Tim Allwood from Compass Property, here today to talk to you about Equity\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2647:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The big problem is, a lot of people leave their equity sitting at home all day doing nothing, so to speak, in the cupboard\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 719, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2648:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if you take off what your home's worth, $500,000, say, if you owe $200,000, that's equity of $300,000, okay? So it's the difference between what you owe and what your house is worth, your equity\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 801, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2649:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So what we propose you do is what most clever Australians do, is grab some of that equity, keep it secure, don't take all of it, just a good amount of it\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2650:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: While you go and work your butt off, and your equity's sitting there doing nothing\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 531, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2652:\n",
      "  video_id: SYQ_zv8dWng\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we use that to purchase the income-producing asset, an investment property\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 296, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2655:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's needed to help answer the aspirations for opportunity and dignity that are at the root of this Arab Spring.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 437, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2656:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm pleased that the United States is represented in Doha by Attorney General Eric Holder and one of my key White House advisors, Mike Froman.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2657:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The President: I want to thank His Highness Sheikh Hamad bin Khalifa Al-Thani and the government of the State of Qatar for co-hosting this meeting, and all the countries that have joined in this important effort.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2658:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As President, I've made clear that the United States stands with those seeking their universal rights.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2659:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And at Deauville last year we joined with our G8 partners to support these transitions in the Middle East and North Africa.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2660:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've made it our policy to support reform across the region, and assist transitions to democracy.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2661:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And that's why at the G8 Summit this spring at Camp David, we called for this forum to make sure we're working together to recover stolen assets that must be returned to the people of countries like Tunisia, Egypt, and Libya.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 988, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2662:\n",
      "  video_id: SZ7HK5ns6mE\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This money, potentially billions of dollars, does not belong to those who wielded power, it belongs to the people.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2663:\n",
      "  video_id: Sb6ftNgzz9M\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This morning in the blog I gave you some information about  the mission of Marriage Standing Journal and I told you some things about myself, the moderator.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 754, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2664:\n",
      "  video_id: Sb6ftNgzz9M\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Welcome to the very first episode of Marriage Standing Journal video.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 535, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2665:\n",
      "  video_id: Sb6ftNgzz9M\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: admin@bethdurkee.me is email address and mark it, the subject line, attention to MSJ or attention to Marriage Standing Journal so that I can be sure to see it.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 629, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2667:\n",
      "  video_id: Sq6DIhFxPqQ\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So solar in a lot of parts of the world now is much cheaper than using fossil fuels, and that's because of the infrastructure needed\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2668:\n",
      "  video_id: Sq6DIhFxPqQ\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: and buying these electric vehicles, so all those lead to really good signs for this industry, as well as the renewable market is continuing to grow\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2671:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A great overall purchase no matter which one you buy The price and the value always match with Reward Hardwood Flooring This is Donnie with Flooring My Life product reviews\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 667, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2672:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This floor itself is a value choice\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2673:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Brazilian cherry, Santos mahogany, Brazilian cherry So a lot of design options as well as a lot with the texture so you'll have smooth, hand scraped, chatter marks, bleeding, a lot of different options for textures You have a lot of different things you can really do with the floor The product is made up pretty well\n",
      "  text_feature_shape: (1, 70, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1243, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2674:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi this is Donnie, welcome back to Flooring My Life product reviews Today we're going to give a review on Reward Hardwood Flooring First I want to go over a little of the company background of Reward Then I'll go over the design, construction, finish, maintenance, and installation of this product Reward is actually a brand of Galleher company Galleher is a large distributer here on the west coast and Reward is actually manufactured in China but they do a really good job of quality control by having employees actually employed in their China manufacture facilities The design is really what makes this product line You're going to have a lot of species options with red oak, white oak, maple, birch, American walnut, American cherry hickory, a lot of stain colors within those species as well also some exotics\n",
      "  text_feature_shape: (1, 169, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2303, 1024])\n",
      "  vision_feature_shape: (46, 2048)\n",
      "Item 2675:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some products come with 3 and 5 some only have 3, you also have some random width lines in here where you'll get 3, 5, 6 and 7 So there's a lot of different width options you can do which is really good for design Length is pretty average\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1124, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 2676:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's an engineered product overall There's half inch and three eighths options in terms of thickness 1 mil, 2 mil, 3 mil wear layer depending on what actual style you go with within Reward The longevity of the product will definitely depend on how thick of a wear layer you end up purchasing You're also going to get some good width options\n",
      "  text_feature_shape: (1, 71, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1644, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 2677:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is random so probably a little big above average in a lot of things you see out there so nothing overly spectacular about the board length\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2678:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You're going to get 48 inch average length\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2679:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can nail it, staple, glue, float That means you can pretty much put it in every room in your house Your basement all the way up to your top floor kitchen, bathroom\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2680:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In terms of the finish, it's got a great finish, it has the aluminum oxide finish on it It's always important to keep in mind, whatever finish you buy it's going to scratch So yes this hardwood will scratch but it also has a very nice 25 year warranty on the finish The product itself, the maintenance is very very easy Just like you would maintain any other hardwood floor, you're going to sweep dust mop, wipe up spills and every once in a while you can damp mop Make sure you keep felt pads under furniture, things like that Installation really has a lot of options here\n",
      "  text_feature_shape: (1, 125, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2144, 1024])\n",
      "  vision_feature_shape: (42, 2048)\n",
      "Item 2681:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It can be installed pretty much anywhere…very easy to maintain It's a very quality constructive product I think overall this is a great buy\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 909, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2682:\n",
      "  video_id: SqAiJrvHXNA\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Definitely don't recommend the bathroom but any common space, this product can be installed there So we kind of gave a basic overview of the design, you have a lot of design options within this line\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 819, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2683:\n",
      "  video_id: SqofxdeEcjg\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I guess on Leap Year it would be \"EDI 366\" but, oh well...small point.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 402, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2684:\n",
      "  video_id: SqofxdeEcjg\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And also that we create an environment that is equitable and that gives everybody a chance to make their contribution the most productive way.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2685:\n",
      "  video_id: SqofxdeEcjg\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The leadership that is in place, and about to be in place, with Deb Chew now taking on the role of creating this new version of the office and with Hanna Valantine, distinguished cardiologist coming from Stanford to be our new Chief Officer for Scientific Workforce Diversity, puts us in a place to emphasize this area of diversity and inclusion in new and creative ways.\n",
      "  text_feature_shape: (1, 76, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1779, 1024])\n",
      "  vision_feature_shape: (35, 2048)\n",
      "Item 2686:\n",
      "  video_id: SqofxdeEcjg\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We are in a circumstance here of kind of running a small town ...a wonderful town.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 749, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2687:\n",
      "  video_id: SqofxdeEcjg\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Everything from the senior investigators, the people working in the labs, the critical people who support all of this... administration, finances, facilities, public safety.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 856, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2688:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For instance, there is really no way of knowing who did it in this one until it's actually revealed by Sherlock Holmes who had committed the crime.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 690, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2690:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 13\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Really liked all the stuff that was told from Dr. John Watson's perspective.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2691:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 20\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I can't really tell Lestrade and Gregson, the two police detectives, apart and it's pretty clear that Watson is just sorta supposed to be the everyday person who is our insider look at the dazzling brilliance of Sherlock Holmes.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 906, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2692:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sherlock Holmes and Dr. John Watson's interactions are more memorable than Dr. Watson as an actual character.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2693:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 17\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It was a little bit too jarring when it happened and all of the sudden we were in the flashbacks and that I was like, \"Did I read the wrong page?\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2695:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 19\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He has so much personality that really comes through, even though I would argue that most the other characters feel somewhat one-dimensional.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 517, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2696:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 18\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What is going on?\" I found Sherlock Holmes to be a lot more likeable than I think most adaptations portray  him and I don't know if maybe he gets a more... difficult, shall we say, personality in the latter mysteries but in this novel I  thought he was a fairly likeable character.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1334, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 2697:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 23\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I do agree that it does feel like Doyle didn't really know anything about Mormonism and yet he tried to write Mormonism into this mystery.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2698:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: [music] Because I only finished two books in February, I will not be posting Monthly Minis video.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 425, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2701:\n",
      "  video_id: SwT0gh0V8fI\n",
      "  clip_id: 15\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There were some really great quotes in the sections that took place in London.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2702:\n",
      "  video_id: TLPlduck5II\n",
      "  clip_id: 1\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So when I argued with them and argued with my credit card company, they refused to reimburse me for the difference so I made a complaint with the Consumer Affairs.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 736, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2703:\n",
      "  video_id: TLPlduck5II\n",
      "  clip_id: 0\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I purchased a purse at a store that had a tag with a price on it and I found out later that they overcharged me what the purchase price was.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 446, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2706:\n",
      "  video_id: TLPlduck5II\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I would tell every New Yorker that there are government agencies like the Department of Consumer Affairs that are out there and are free; that you can use to help you resolve complaints.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 801, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2707:\n",
      "  video_id: TLPlduck5II\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It worked wonderfully; I got my money back in no time at all.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2709:\n",
      "  video_id: TXiOSZdaLJ8\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Both countries reaffirmed their commitment to strengthening the U.S.-Philippines alliance in terms of ensuring both countries – our mutual defense and security as well as jointly contributing to regional peace, stability, and economic prosperity.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2710:\n",
      "  video_id: TXiOSZdaLJ8\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They also discussed next steps for implementation of the EDCA and how it will support the United States efforts to help modernize the armed forces of the Philippines, develop capacity and capability for maritime security and domain awareness, and provide rapid humanitarian assistance to the people of the Philippines.\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 922, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2712:\n",
      "  video_id: TcTGCIh6e5s\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: this video we're going to have a brief talk about data exchange formats and more specifically about XML and JSON and why JSON is widely replacing XML nowadays\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2714:\n",
      "  video_id: TcTGCIh6e5s\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By sending data back and forth in some standardized way that they both know about such as XML and JSON\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2719:\n",
      "  video_id: TsfyeZ8hgwE\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Going to Denver was really hard because I had no friends or family, but I definitely learned independence through that.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2720:\n",
      "  video_id: TsfyeZ8hgwE\n",
      "  clip_id: 3\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So actually, since I've moved to Denver, I climbed my first 14,000 feet mountain, went rafting, and I also tried snowboarding for the first time this winter.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 492, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2721:\n",
      "  video_id: TsfyeZ8hgwE\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And, umm after I made friends in Denver, I was able to go explore more parts of Colorado and try a lot of outdoor activities I probably wouldn't have otherwise.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2723:\n",
      "  video_id: TtAyUQtmTLk\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This lesson is titled Whose Life is it Anyway and it begins with an article a short article that I wrote in direct response to the language that I heard many of my, as I always say, more traditionally inclined therapists using with their gay identified clients continually referring to this thing called internalized homophobia.\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1246, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2724:\n",
      "  video_id: TtAyUQtmTLk\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The article or the lesson then goes on to identified certain what I call fluid practices that ground me in the work, along with an article documenting my work with particular clients suffering from the effects childhood sexual abuse and our work over a period of about nine months.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1171, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 2725:\n",
      "  video_id: TtAyUQtmTLk\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's a great example of that kind of work and the lesson ends with an award-winning documentary film about the remarkable ability of people to come together and form community even in the face of what could otherwise be described as a devastating tragedy So enjoy and I look forward to hearing your thoughts.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1231, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 2726:\n",
      "  video_id: TtAyUQtmTLk\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also included an article on called Linking lives Around Shared Themes written by Chris Behan which engages narrative practices in a group context.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 673, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2727:\n",
      "  video_id: TxRtSItpGMo\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Chicago School of Professional Psychology is a foremost academic institution competitive with top universities today.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2728:\n",
      "  video_id: TxRtSItpGMo\n",
      "  clip_id: 2\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What makes TCSPP unique is that it prepares its students for a life of purpose, service, and leadership.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 818, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2729:\n",
      "  video_id: TxRtSItpGMo\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I especially appreciate the fact that faculty know their students personally.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2730:\n",
      "  video_id: TxRtSItpGMo\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Above all, we have an amazing president, Dr. Michelle Nealon-Woods, whose tireless support is essential for students' success.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2731:\n",
      "  video_id: TxRtSItpGMo\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The administrators and staff really care for the students and their support encourages students throughout the program.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2732:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 24\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're ever in Washington please come by it's your office, the door is always open, 2229 Rayburn House Office Building\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 455, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2733:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 25\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thank you for joining me for This Week with Wilson\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 176, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2734:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 20\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I especially appreciate that NFIB is a bottoms-up organization where the members vote on issues and endorsements that matter to them, not directed by Washington\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 661, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2735:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I enjoyed meeting with many constituent groups while they were in the Washington area this week\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 337, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2736:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 22\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I met with representatives from the American Cancer Society, South Carolina Principal of the Year Dr\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2737:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 23\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Bill Coon, and a group from the United Fresh Produce Association\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2738:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I spoke on Monday to pay tribute to the 15th anniversary of the attacks of September 11th\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 346, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2739:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thank you for watching the weekly video about my work in Congress\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2740:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Each time I speak on the House Floor I end my remarks by saying \"and may the President by his actions never forget September 11th and the Global War on Terrorism,\" because we must never forget this devastating mass murder of American families on U\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 840, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2741:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I also spoke this week about how under the President's failed legacy on drug policies, addiction rates and overdose deaths of opioids has increased dramatically\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 548, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2742:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm grateful that Congress acted to address the opioid crisis by passing the bipartisan Comprehensive Addiction Recovery Act that empowers communities to address the opioid crisis locally\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 605, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2743:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Sadly this Administration's reactions to the public health crisis are too little too late\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 337, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2744:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With the rapidly changing job market, quality education and training are vital for a thriving work force\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2745:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I also spoke on the house for this week to urge my colleagues to vote for the Strengthening Career and Technical Education for the 21st Century Act\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2746:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This week in Congress, I attended hearings in the House Foreign Affairs Committee and the House Committee on Education and Workforce\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 541, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2747:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm a grateful sponsor of this piece of legislation and was pleased when it passed the House to create jobs\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2750:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This week I sent a letter to the Acting Undersecretary for Terrorism and Financial Intelligence, demanding answers on what steps his office took to ensure that the payment will not be used to support terrorist activities to kill Americans\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 759, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2752:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Committee on Education and the Workforce met to discuss the Juvenile Justice Reform\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 420, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2753:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 16\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I look forward to continuing to advocate for this legislation when it comes before the full House led by Chairman Ed Royce\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 432, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2754:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This week I appreciated being recognized by the National Federation of Independent Business as a Guardian of Small Business and I am strongly committed to supporting small business, free enterprise, creating jobs in the 2nd Congressional District\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 782, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2755:\n",
      "  video_id: U-KihZeIfKI\n",
      "  clip_id: 18\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm grateful to support this legislation of the Supporting Youth Opportunity and Preventing Delinquency Act of 2016, because this legislation provides necessary resources to state and local officials to better serve at risk youth and drug offenders\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 835, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2756:\n",
      "  video_id: U6IqFbpM-VM\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What's great about the CashCourse dictionary is that I can look up things that I don't understand on, say, bills or applications for student loans.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2758:\n",
      "  video_id: U8VYG_g6yVE\n",
      "  clip_id: 10\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We want to share with you those to your promise land and we're going to tell you the truth, facts and give you everything that you need to succeed.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 79, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 2759:\n",
      "  video_id: U8VYG_g6yVE\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You know over the last 3 years I will tell you rewind 3 years ago that's what I was looking for I was looking for a team I was looking for a mentor and I was just really looking for somebody that could lay out an exact plan that could get me and my family to where we wanted to go.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 879, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2760:\n",
      "  video_id: U8VYG_g6yVE\n",
      "  clip_id: 5\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've raised up over 70 six figure income earners now on our team over a thousand people that have earned that free ViSalus paid for BMW payment and because of our simple system.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 609, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2761:\n",
      "  video_id: U8VYG_g6yVE\n",
      "  clip_id: 9\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A team that's always looking for the newest story that the newest brightest that as the most potential giving them everything that we got.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 449, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2762:\n",
      "  video_id: UNLD7eYPzfQ\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But certainly it has to be viable, because if you think that you're going to spend money doing it locally, you're going to spend a lot more money doing it on the road.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2763:\n",
      "  video_id: UNLD7eYPzfQ\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Certainly the one thing you don't want to do is butt heads with someone who's doing that already.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 724, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2764:\n",
      "  video_id: USkMa4Evv7U\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My agency – OSHA – was created to help prevent workers from getting sick, injured, or killed on the job.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 583, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2765:\n",
      "  video_id: USkMa4Evv7U\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s a contest to create apps that demonstrate the importance of workplace safety and health or and help young people understand their rights in the workplace.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 861, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2766:\n",
      "  video_id: USkMa4Evv7U\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That’s why we’ve launched the Worker Safety and Health Challenge at www.challenge.gov.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 350, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2767:\n",
      "  video_id: UTErYLpdAY0\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that marketers today are understanding that this is really a moment where you can educate and connect with people in a way that really is helpful to them as opposed to advertising at them the way that we have seen in the past.\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1054, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2771:\n",
      "  video_id: UiurP5k-f1A\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The organization has achieved a 30 percent reduction in administrative function costs.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 446, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2772:\n",
      "  video_id: UiurP5k-f1A\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In addition, the timeliness of the organization's quarterly and monthly financial reports and payroll processing substantially improved.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 866, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2773:\n",
      "  video_id: UiurP5k-f1A\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Accenture also provided project management to enable the Ballet to upgrade its technology capabilities without needing a full-time IT organization in-house.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2774:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A reminder to focus on your passions and what you want to do versus trying to please everyone else\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 680, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2775:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 10\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My favorite line from class today: At the end of your life, are you living for you, or are you living for someone else\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2776:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: - Something weird happened to me\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 109, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2777:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: - I forgot I'm working out\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 183, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 2778:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Who the hell am I\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 534, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2779:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - I like that he said, \"The next 45 minutes isn't gonna change your life, but it's gonna help change your day\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2780:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was more focusing on my dream, my goals, my fears, and how to achieve all this\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 459, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2781:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Yeah, maybe I should draw about now\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 129, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2782:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - David's definitely one of my favorite instructors\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 526, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2783:\n",
      "  video_id: UjqA6KVW2m8\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - I've been upping my weights so I started with two and then went to three and now I'm on five so definitely seeing some results\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 406, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2784:\n",
      "  video_id: Uu_XyXyKHAk\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And you have to like it and be interested in it, or trust me, it's going to get dreadfully boring for you to work on.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 738, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2785:\n",
      "  video_id: UweZVaFqruU\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is Tom Floyd, Vice President of Real Estate at Member One Federal Credit Union bringing you another Member One Money Minute\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2791:\n",
      "  video_id: UweZVaFqruU\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, you want to be very careful about those items\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2792:\n",
      "  video_id: UweZVaFqruU\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, hopefully these credit tips will help you so when it's time to buy your home, your credit will be in great shape and you'll have no problem at all\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 525, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2793:\n",
      "  video_id: UweZVaFqruU\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And at Member One, we also offer, besides mortgages, personal loans, we have credit cards, we have starter loans, so we have everything that you need to help build your credit if you're at that point\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 907, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2794:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For example, \"My parents are hosting a dinner party Saturday, and I´m totally going to get busted when they discover that all we´ve got in the bar is fraudka and Faker´s Mark\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 692, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2795:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [ Applause ] Our last new teen slang term is Brady Brunch\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 612, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2796:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [ Laughter ] Coming up next, it´s Rex Tillerson\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 421, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2797:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By far my favorite one, which I guess is why I´m the guy in his 40s\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2799:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is someone who is doing everything they can to get fired\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 371, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2800:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" [ Laughter and applause ] Still there, though\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 697, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2801:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He walked into his job at Starbucks 20 minutes late wearing no shirt and called his boss a [bleep] moron\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2802:\n",
      "  video_id: V0SvSPkiJUY\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What´s left when you steal your parents´ liquor and top the bottle off with water\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2805:\n",
      "  video_id: V2X1NU5RkwY\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: policies and laws from a human rights perspective to make recommendations\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 215, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2806:\n",
      "  video_id: V2X1NU5RkwY\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \"Regional authorities are very often responsible for providing social services\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 615, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2810:\n",
      "  video_id: V2X1NU5RkwY\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: there are various campaigns popping up around the country\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2811:\n",
      "  video_id: V7OFSHYcQD0\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't elaborate on the front end or the back end of the humorous element.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 531, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2813:\n",
      "  video_id: VDkBM0ZG4q8\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -The advantages of EN3 for society and for the environment are the usage of\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 601, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2814:\n",
      "  video_id: VDkBM0ZG4q8\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: households with electricity for 1 year\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 213, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2815:\n",
      "  video_id: VDkBM0ZG4q8\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: and is a valuable contribution to climate protection\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2819:\n",
      "  video_id: VDkBM0ZG4q8\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -Our system has been proven to work and is being used by a major\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 337, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2820:\n",
      "  video_id: VDkBM0ZG4q8\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: EN3 has developed a technology that solves this very problem\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 616, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2821:\n",
      "  video_id: VIVkYG31Oas\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the first thing that we need to remember is Stop trying to win the argument\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2822:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 11\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Why not apply for a free LeverageLine Quote today via our secure online form? You've got nothing to lose! For more information about our stock secured loan program, visit abnicholas\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2823:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 10\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Start by launching your long-term financial relationship with your LeverageLine as the first step\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2825:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We call this line of credit “LeverageLine”- a custom-built facility offered through one of several major, “household name” licensed U\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 500, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2826:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Nicholas, the most trusted source for lowest-interest, highest-loan-to-value stock secured loan programs for personal, business, and real estate applications\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 621, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2827:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 7\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: LeverageLine puts the value of your securities to work for you without the need to sell to obtain funds, so that you may obtain quick funding in a very low-cost and client-friendly package, with no mandatory lender-side fees\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2828:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Every LeverageLine credit line is managed at the institutional level by a fully licensed, top-rated FINRA-member executive advisor\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2829:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And your advisor is a long-time expert in helping you grow your business if you are buying a franchise, for example\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2830:\n",
      "  video_id: VLQgw-88v4Q\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Whether you are about to invest in real estate, buy a franchise, pay off taxes, or pay off a college education, LeverageLine’s wholesale interest rates are usually even better than the best mortgage rates\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 911, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2831:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Enforcement is fundamental to ASIC and our priorities of ensuring investors are confident and informed and market integrity maintained.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 731, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2832:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You might also want to take a look at ASIC's responses to Four Corners’ specific questions.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2833:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For more info on how we tackle wrongdoing, check out our website.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2834:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 1\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Today’s Fairfax papers report on bribery allegations against the Reserve Bank of Australia and its note printing subsidiaries - and ASIC’s decision not to take the matter further.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1028, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2835:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Let me be crystal clear: ASIC looked at this matter very closely but, based on the facts, decided not to take the matter further.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 999, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2836:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As there are related prosecutions before the court, we are not in a position to detail the reasons for our decision, but the public can be completely and utterly confident in what ASIC did.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 974, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2838:\n",
      "  video_id: VS7xSvno7NA\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: More broadly, ASIC's record on punishing wrongdoers is solid.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 404, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2839:\n",
      "  video_id: VVtx4IDsHZA\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, there is no need to fight for all this at all\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2841:\n",
      "  video_id: VXy21GwGs8o\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm now a Beltone member of the family and I just think that it has improved my way of living so much.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 903, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 2843:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: MSC was able to say that the surveyor recommended the fishery for certification.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2844:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 15\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As of August 14th the summer run estimation is 1,300,000 fish, which will not support commercial or recreational fishing.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2845:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 14\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: ---The Fraser river sockeye fishing is not going to take place according to the department of fisheries and Oceans.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2847:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 16\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: DFO reports there are no planned commercial or recreational sockeye fisheries at this time.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 442, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2848:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 19\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Sources have speculated for the past few weeks that the fishery would be closed based on very poor First Nations food fishing and on poor test fishery results.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2849:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 18\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: First Nations food fishing is underway in all areas, however are restricted due to constraints on the late run stocks.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 711, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2850:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Welcome to The Tradex Foods \"3-Minute Market Insight\" Here are some timely updates for you.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2851:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Strong landings of large and bright pink salmon are coming in.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 241, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2852:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: On a positive note suppliers have reported strong sales for export over the past week with both Europe and China active in the market.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2853:\n",
      "  video_id: Vdf1McvE9ao\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ---British Columbia Canada chum salmon is expected to be MSC certified any time now.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2855:\n",
      "  video_id: Vlas-mPydcg\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Um, but now I just roll my laundry hamper from the bedroom  to the laundry room and it's so easy.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2856:\n",
      "  video_id: Vlas-mPydcg\n",
      "  clip_id: 17\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if there's anything inside your own house that is difficult  to move, then I would highly recommend putting these on the  bottom of that furniture, or that bin, or that basket.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 810, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2858:\n",
      "  video_id: Vlas-mPydcg\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And one of those products are these self-adhesive instant wheels.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 421, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2859:\n",
      "  video_id: Vlas-mPydcg\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I went home and I put them on my  laundry hamper because my hamper is always so heavy to  move from my bedroom to my laundry room.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 777, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2860:\n",
      "  video_id: Vlas-mPydcg\n",
      "  clip_id: 4\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I discovered these wheels probably about six months ago  when I was just browsing The Container Store and I am so  glad I bought them.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 818, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2861:\n",
      "  video_id: VsXGwSZazwA\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Witnesses quite commonly will forget certain pieces of information, not be able to remember details and will change their mind about what happened and when, but that should be expected.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 756, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2863:\n",
      "  video_id: VsXGwSZazwA\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm Dr Graham Pike from the Department of Psychology at the OU and I'm a forensic psychologist.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 289, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2864:\n",
      "  video_id: VsXGwSZazwA\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One thing forensic psychologists have done is look at witness memory, particularly how we can help the police to get the most out of what a witness has seen of a crime.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2867:\n",
      "  video_id: VsXGwSZazwA\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By doing that the witness can remember more accurate information.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 371, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2868:\n",
      "  video_id: VsXGwSZazwA\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the information goes in, is stored perfectly and can just be retrieved perfectly.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 539, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2873:\n",
      "  video_id: VwGPIUNayKM\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: which are not very efficient windows and we identified that by replacing the old\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2874:\n",
      "  video_id: VwGPIUNayKM\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: there are 13 million homes in the UK that have windows that were fitted more than 10 years ago\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 379, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2875:\n",
      "  video_id: VwGPIUNayKM\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: we could save significant energy and significant levels of CO2\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 377, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2876:\n",
      "  video_id: VwGPIUNayKM\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: altered technology glass with modern, energy efficient glass\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 315, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2877:\n",
      "  video_id: VwGPIUNayKM\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Glass technology has advanced so much in the last 10 years\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 265, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2878:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 10\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Michelle is an extremely energetic, dynamic speaker\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2879:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I said, \"You know it was because of you- that you SAT with me, that I have SAT with over 100 people who have wanted to start their own businesses\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 560, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2880:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because she had no idea I was writing a book\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 237, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2881:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: she literally lost her breath for a moment\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 279, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2883:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: and one of the things that you can give when you have nothing else is appreciation\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2884:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I get a little choked up because it was a really special moment\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2886:\n",
      "  video_id: W1CWpktWtTs\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Always look for those opportunities, but be okay that you can't do them yet\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 245, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2888:\n",
      "  video_id: WBA79Q3e_PU\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This... just coming in... Korea's central bank has cut its key rate by a quarter-of-a-percentage point to one-point-two-five percent in June, ending an almost a year of leaving the key rate steady.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2891:\n",
      "  video_id: WJM8u2I2rQ4\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In California, there's one called BusBend, there's one called BusBySell, which is a national website.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2893:\n",
      "  video_id: WQFRctNL8AA\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You'd have to spend a great deal of money and make some giant room for a small pond to make that work\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 395, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2894:\n",
      "  video_id: WbtsuXkaGeg\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Frederick \"Ricky B.\" Burchell with B4 Entertainment on behalf of Expert Village, and today we're going to talk about producing, manufacturing, marketing, and distributing your independent CD.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 819, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2898:\n",
      "  video_id: WfNiQBXmPw8\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So much for your mom telling you that bullies are just insecure\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2899:\n",
      "  video_id: WfNiQBXmPw8\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" But those taboos break down pretty quickly and soon Roger is torturing other boys, a job he really enjoys\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 429, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2900:\n",
      "  video_id: WfNiQBXmPw8\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We'll act viciously as long as we think we can get away with it\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 355, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2901:\n",
      "  video_id: WfNiQBXmPw8\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What Golding is saying is that we're all bullies\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 205, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2903:\n",
      "  video_id: WfNiQBXmPw8\n",
      "  clip_id: 6\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Before he's killed, Piggy, the fat asthmatic intellectual, asks, \"What are we\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2905:\n",
      "  video_id: WfNiQBXmPw8\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" And Golding's answer is D -- all of the above\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 354, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2907:\n",
      "  video_id: WgI8IbJtXHw\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As a friend of Colombia, President Obama wants the people of this country to know that when you achieve that peace, the United States of America will do everything in our power to help respect it and to help you be able to implement it.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 976, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2911:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 11\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And Rihanna's vocals are definitely pretty screechy on this song and Kanye has some pretty tuneless singing.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2912:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's no drums in the song, this song unlike Only One doesn't sound like there are any keyboards there's no drums and no auto tune and it's basically Paul McCartney playing acoustic guitar and Rihanna and Kanye share vocal duties going back and forth.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 796, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2913:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Both artists are amazing talents, but together they didn't really have amazing song writing capabilities when they were working in the same space and this song sort of feels like this too.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2915:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 15\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If Kanye West, and Paul McCartney's name and Rihanna's name wasn't attached to this song and the song just got released by three unknown people and sounded the same it wouldn't be getting the attention it's getting.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 819, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2916:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In fact this song sounds like something i would hear if i went to some hippy coffee shop that only served free trade coffee and ran into three strangers that were just jamming together and came up with this song.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 769, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2917:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 17\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I give this song a 2/5. I'd like to know what you guys think leave your comments in the section below.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2922:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I wasn't a fan of Only One I thought it was pretty disappointing to me and this song I didn't have much expectation going in.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2923:\n",
      "  video_id: WoL4fCxGd8Q\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am a fan of Paul McCartney and Rihanna , but i am not a big Kanye fan, but i do recognize that he is a pretty talented guy.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2924:\n",
      "  video_id: Wu-wQTmxRgo\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't need that appeal like you guys allow you guys come here for the cinematic stuff for the positivity Which is what I love to spread the relationship stuff\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 475, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2925:\n",
      "  video_id: Wu-wQTmxRgo\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The corking is the messin around They always having fun\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2926:\n",
      "  video_id: WuaoxGAKue0\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, because it doesn't make any sense, I'm not going to remember any of it.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2929:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 20\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All of these things can be stored within the shapefile data as an attribute table-- can be displayed.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2930:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 21\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is what makes GIS software so powerful It is also-- In this section we also talk about knowing how good quality your data are.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1093, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 2931:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 22\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So making sure we know where to find metadata, what types of metadata makes your data better or how do we understand who produced the data what the projection was.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1016, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2933:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ArcMap allows us to display these not nonspatial features, for example population of the state, population change...  what else can we display... disease  rates.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 846, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2935:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 31\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You will see you have several files associated with each data set.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 439, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2938:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We start by taking a little bit of a refresher on the three components of the ArcGIS software.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 561, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2939:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In this module, we're are focusing specifically on spatial data.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 209, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2943:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is where you create your data, edit data, view data, analyze your map, create maps, it is the workhorse of the ArcGIS program.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 730, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 2944:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Where we get into looking at very specific geoprocessing tools.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 293, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2946:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Make sure you pay attention to the difference between our two key types of spatial data models vector and raster data.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2947:\n",
      "  video_id: X2Hs89fZ2-c\n",
      "  clip_id: 14\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The last part of these lecture slides really dive into those key concepts related to ArcGIS and GIS in general.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2948:\n",
      "  video_id: X6N7UEFJLNY\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now that we've talked about whether your choosing battery powered or hardwired, you've got to determine how and when you're going to use this.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 454, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2949:\n",
      "  video_id: X6N7UEFJLNY\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can set it so that it's motion activated  -- The minute you move your car, the GPS turns on.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2951:\n",
      "  video_id: X6N7UEFJLNY\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The beauty of it is no matter what you decide, you can log on to any computer as long as you have internet access, and you can see where your vehicle has been and what it's doing at any given time.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 893, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 2952:\n",
      "  video_id: X6N7UEFJLNY\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can also set it so that it's on every minute of every day.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2954:\n",
      "  video_id: XDVit9ASVUg\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The thing about a conclusion is that it is simply a wrap up.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2956:\n",
      "  video_id: XKyumlBmix8\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So it's very easily irritated again\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 241, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2959:\n",
      "  video_id: XKyumlBmix8\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's put it on pause for a second okay\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 104, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2960:\n",
      "  video_id: XKyumlBmix8\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Okay good now stop right there\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 472, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 2961:\n",
      "  video_id: XLjpZUsFEXo\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well that's important, you don't want to be doing it in a dark room.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2962:\n",
      "  video_id: XLjpZUsFEXo\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then the other thing you want to need is a little bit of a light of course we're shooting this here for Expert Village, we're lit and you can see me very clearly that's why on your video that you're watching me on right now looks great, the quality looks real good.\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1001, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2963:\n",
      "  video_id: XLjpZUsFEXo\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Even if it means getting a little desk lamp and aiming at you or aiming it at the ceiling and bouncing the light at you, whatever you can do to get a little bit of light in front of you will make your quality of your video that much better.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 974, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2964:\n",
      "  video_id: XLjpZUsFEXo\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now some computers nowadays even have them built in, of course this is an older webcam that still works great for what I'm doing but the newer webcams have better quality and they have microphones built right in.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1000, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 2965:\n",
      "  video_id: XLjpZUsFEXo\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: These cameras cost under 20 bucks, you can certainly find them on different websites online or even go to one of your big box stores and one of big box electronic stores, they might charge you between 20 and 30 at most.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 973, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 2967:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Jefferson is an Anti-Federalist - [Voiceover] Right\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 137, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 2969:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: - [Voiceover] Yeah, but let me point out that you did say all white men\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2970:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And his vision of manifest destiny really involves the eradication of all Native Americans\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 567, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2972:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This is when we see something called the Indian Removal Act, that is literally what it's called\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2973:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 4\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: - [Voiceover] I mean, this is a really dark time for American Indian policy\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 279, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 2974:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Jackson's presidency is also marked by the Cherokee Diaspora, the forced removal of the Cherokee along what's called the Trail of Tears\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2975:\n",
      "  video_id: XVWiAArXYpE\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, before Jackson, do we really have the Democratic Party as an institution\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 397, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 2976:\n",
      "  video_id: XWIp0zH3qDM\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I'm just gonna do it later today\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 239, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2979:\n",
      "  video_id: Xa086gxLJ3Y\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Many times these corporate kits include sample Articles of Incorporation.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 669, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2980:\n",
      "  video_id: Xa086gxLJ3Y\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello, I'm Robert Todd and I'm here to answer the question, how to write Articles of Incorporation?\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2981:\n",
      "  video_id: Xa086gxLJ3Y\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And you're going to have to decide in which state you wish to incorporate.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 603, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 2983:\n",
      "  video_id: XbkYA-iXUwA\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Emotional intelligence, or EQ, has been defined in many ways\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 2986:\n",
      "  video_id: XbkYA-iXUwA\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thus, EQ is about one's ability to process painful emotions, whereas IQ is about one's ability to learn and solve problems\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 764, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 2987:\n",
      "  video_id: XbkYA-iXUwA\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Low EQ, on the other hand, might cause you to deal with your pain by drinking or drugging, self-cutting, catastrophizing, beating up on yourself, of falling into hopelessness\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2988:\n",
      "  video_id: XlTYSOaZ_vM\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: com The full range of materials will be waiting for you\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 539, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2989:\n",
      "  video_id: XlTYSOaZ_vM\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey, what’s up?! Do you remember the session we did two weeks ago? Listen, next week there will be the opening of titan-gyms\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2991:\n",
      "  video_id: XrNaL-MTjXg\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if I say; if I'm talking to my best friend, I'm talking about this person who loves me, I say that he loves me; he knows me for who I am and he loves me, he can't help himself from loving me for exactly who I am.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 2992:\n",
      "  video_id: XrNaL-MTjXg\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In my mind’s eye; it's always good to pick a subject verb, a strong action.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 2993:\n",
      "  video_id: XrNaL-MTjXg\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have a real purpose objective; can't state the importance enough.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 2994:\n",
      "  video_id: XrNaL-MTjXg\n",
      "  clip_id: 6\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I see that he loves me; he knows me for who I am and he loves me, he can't help himself from loving me for exactly who I am and I love him too for exactly who he is.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 2997:\n",
      "  video_id: Xy57UpKRNEo\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So those first three years are hugely important\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 2998:\n",
      "  video_id: Xy57UpKRNEo\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Whereas the human body is about 18 percent adult size\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 2999:\n",
      "  video_id: Xy57UpKRNEo\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So a child who doesn't see light, they will be blind after a few years because the visual circuits need light waves for their development, they just don't otherwise\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 530, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3001:\n",
      "  video_id: Y2F51I-dzAg\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However, decades later we were shown that the two of them consummated the union… before the marriage itself\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3002:\n",
      "  video_id: Y2F51I-dzAg\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: May back in the seventies, but the marriage never ended up happening\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 198, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3003:\n",
      "  video_id: Y2F51I-dzAg\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This makes the time that Peter walked in on his aunt WAAAAY less intense by comparison\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3005:\n",
      "  video_id: Y2F51I-dzAg\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So hey, did you know that Wolverine and Squirrel Girl had a thing\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3006:\n",
      "  video_id: Y2F51I-dzAg\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: After several interviews, it was decided that Squirrel Girl was the best candidate which led to this incredibly awkward scene when she crossed paths with Wolverine\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 689, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3007:\n",
      "  video_id: Y8dI1GTWCk4\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Right off the bat, the Lemon decision is a little complicated because it combines two sets of facts, although they both involve public money and parochial schools\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3008:\n",
      "  video_id: Y8dI1GTWCk4\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Actually, none of that is what we're talking about\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 199, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3009:\n",
      "  video_id: Y8dI1GTWCk4\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What it means is you can't be prohibited from being part of a certain religion, although it doesn't mean that any religious practice is okay\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 475, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3013:\n",
      "  video_id: Y8dI1GTWCk4\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hialeah, because I love saying Lukumi Babalu Aye\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 415, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3015:\n",
      "  video_id: YCEllKyaCrc\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Greed has poisoned men’s souls, has barricaded the world with hate, has goose-stepped us into misery and bloodshed.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 778, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3016:\n",
      "  video_id: YCEllKyaCrc\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The way of life can be free and beautiful,  but we have lost the way.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 379, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3017:\n",
      "  video_id: YCEllKyaCrc\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We want to live by each other’s happiness - not by each other’s misery.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 184, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3019:\n",
      "  video_id: YLK58srjhNI\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There was a certain hostility to the play – no question about it.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3020:\n",
      "  video_id: YLK58srjhNI\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Of course we had fewer people here than they did in Europe.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3021:\n",
      "  video_id: YLK58srjhNI\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it may have been the first off-Broadway production, ever, and it became a big success then – in a much worse production than the original one, but they were passionate, and they really were terrific.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1393, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 3022:\n",
      "  video_id: YLK58srjhNI\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But then he died, and within a year a small group of young people did it off-Broadway.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3023:\n",
      "  video_id: YLK58srjhNI\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They had a great production in France with Simon Signoret and Yves Montand, I am told that created a real big clamor.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 721, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3024:\n",
      "  video_id: YQZPnHZRp1w\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So again we have a tool\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 168, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3025:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And again some of those values aren’t necessarily all that apparent,  but definitely important.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 305, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3026:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There’s a lot of value to that,  to these residents up here in this region.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 154, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3027:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We hope the science will inform  land management decisions and maybe also  as more of an education piece Again highlighting those links, those social and economic links  back to landscape conditions that aren't always that apparent.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3029:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well I think the biggest conservation challenge today,  is conservation itself as a land management strategy  going against competing land uses, largely driven by economic incentives.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 615, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3030:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Billy Gascoigne,  I’m an economist with the USGS Fort Collins Science Center  in Fort Collins Colorado I’m involved in incorporating  some of the economic and human dimensions research  for the Landscape Conservation Cooperative.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 648, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3031:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our research is designed to  highlight and estimate the economic contribution  of some of the conserved habitats here in the prairie and pothole region.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 562, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3032:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we want to highlight those impacts and make that link between habitat conditions and social and economic impacts.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3033:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For wetlands, for instance,   someone might say,  oh there’s not that much economic value to it.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 300, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3034:\n",
      "  video_id: YUNxD04EvfE\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It can also have value just to the local residents in terms of open view sheds and quality of life.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 364, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3035:\n",
      "  video_id: YgyeyooSz0g\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And, this is important for the borrower, to have some underlying security for the loan that they have put forward to you, because more often than not, their a savings institution and they have responsibility to their depositors to make sure that the money that they have in their institution, is secured by underlying assets.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1253, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 3036:\n",
      "  video_id: YsMM_1R1vtw\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Many teachers just aren't able to work all day and go to school in the evenings.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 328, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3037:\n",
      "  video_id: YsMM_1R1vtw\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our Master of Education degree in curriculum instruction offers a certification track, so you can become a state certified curriculum administrator.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 854, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3038:\n",
      "  video_id: YsMM_1R1vtw\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm your Dean of the School of Education at Southern New Hampshire University.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 264, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3039:\n",
      "  video_id: YsMM_1R1vtw\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A master's degree brings many benefits, including respect from colleagues and administrators, and a higher salary.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 656, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3040:\n",
      "  video_id: YsMM_1R1vtw\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can do your course work from home, the library, in the morning, at night, whenever you can make the time.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3042:\n",
      "  video_id: Z4iYSMMMycQ\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The free application for Federal Student Aid, or FAFSA, is available online at www.fafsa.ed.gov beginning January 1. The priority deadline for most financial aid is March 2, but you can always apply after that as well.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1096, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3043:\n",
      "  video_id: ZHUFlEgKk-w\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was all there, so I'm a history student\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3044:\n",
      "  video_id: ZHUFlEgKk-w\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: complications of decision making, temptation to sometimes make a pragmatic decision instead of a principled decision\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 309, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3045:\n",
      "  video_id: ZHUFlEgKk-w\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I hope people will watch it because hopefully it's a good drama\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 386, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3046:\n",
      "  video_id: ZHUFlEgKk-w\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's always a good place to start, but I think the obvious resonances I hope will make it interesting\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3047:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're athletes, this is what we do\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 305, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3048:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the Pack promised to work hard, saying \"If you put us in the sequel, we will practice, we will rehearse, we'll take it as a serious thing\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 475, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3049:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 1\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I looked down and thought I was looking at my guts when it was really just beans and rice\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 335, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3050:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: one threw at burrito at me and I fell over\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 121, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3051:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm a really bad twerker — I still haven't figured out how to do it\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3052:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I woke up the next morning and my back was completely tweaked out…from twerking\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3053:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I actually hurt my back one day\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 258, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3054:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But how on earth did that happen\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 120, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3055:\n",
      "  video_id: ZKErPftd--w\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" The Pack One of the most memorable scenes in Pitch Perfect 2 is when the Green Bay Packers compete in the riff-off\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3058:\n",
      "  video_id: ZKZ8UjaQQT4\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As I was saying a little bit ago having a picture of my husband on desk is a little different than having a picture of husband in his boxers on my desk.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 813, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3060:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have a full range of excellent speakers on the program including our very own Prime Minister the Rt Hon John Key\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3061:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Right here at this conference you have a huge opportunity to unlock the benefits of diversity\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 355, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3062:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Like Sir George and Wei, we need to harness the energy and innovation that diversity creates to support new business ventures as well as grow existing businesses\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 552, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3063:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 12\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have Wei Gao and Sir George Fistonich and they have typical migrant stories of struggle, hard work and success and I know in this conference centre there are many more stories of achievement that will play out going forward\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 785, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3065:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And you will receive expert insights as to the importance of marketing and customer relations\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3066:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 16\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I hope you Enjoy the conference, I hope you experience some of Auckland while you're there, And I hope that you get to explore the beauty of New Zealand and its people\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3067:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Welcome to EPIC conference 2016\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 255, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3069:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This conference is important to raise the visibility and awareness of migrant businesses\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 360, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3070:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As Minister of Ethnic Communities I welcome you all – especially those who have travelled from overseas and outside of Auckland\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3071:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: First it was a “supercity”\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 157, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3072:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is also about enabling local businesses to connect with other businesses both here and abroad\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3073:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have made it that way – and it’s a good thing\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 320, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3074:\n",
      "  video_id: ZS1Nb0OWYNE\n",
      "  clip_id: 9\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Superdiversity brings with it enormous benefits such as greater innovation, productivity and investment\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 392, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3076:\n",
      "  video_id: Zb7bdrjWyEY\n",
      "  clip_id: 3\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And perservication as a result of climate change is going to cause big drastic problems for the future.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 609, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3077:\n",
      "  video_id: ZcFzcd4ZoMg\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is the 8 of wands\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 140, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3080:\n",
      "  video_id: ZcFzcd4ZoMg\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am going to choose to believe that this card signifies hope\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 436, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3081:\n",
      "  video_id: ZcFzcd4ZoMg\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So this is either loss or it's hope\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 208, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3082:\n",
      "  video_id: ZcFzcd4ZoMg\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am leaving behind the bad past and moving into a hopeful future where I can work towards the wheel of fortune\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3083:\n",
      "  video_id: ZcFzcd4ZoMg\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That is how I am going to think of the future\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3084:\n",
      "  video_id: ZcFzcd4ZoMg\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is supposed to signify myself and my attitude towards\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 350, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3085:\n",
      "  video_id: ZeH7gZw94k0\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Wow It seems that we have Banana Can I have something to eat this banana with\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3087:\n",
      "  video_id: ZsLrKF7_Oos\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This meeting was particularly important to the grantees because it moved them in their evaluation thinking from making sure that they had a product or solution that was of good enough integrity to use with patients to thinking much more broadly about the evaluation: How was this going to impact the physician?\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 829, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3088:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The key question is that we have to move from a globalization that is unfair and unbalanced and unsustainable into something that actually people look at and say “hey, I’ve got a fair chance of being part of this”. That is not the situation today.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 914, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3089:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 24\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it is not a question of being optimistic or pessimistic, it is just acknowledging that it is a difficult task and sometimes the current is less strong, sometimes the current is stronger but it will always be against the current.\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 689, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3090:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And there are many people in the world that understand and believe this and we have to get this into the economic system.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3091:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The crisis has made it more difficult and that’s why the struggle for social justice  - because it is a struggle - is so fundamental and so key.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 429, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3092:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 20\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you fight for change, when you fight for social justice, you also took another decision.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 522, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3094:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So adults that define the policies have to ensure that we put in place the polices that permit the young people to enter into jobs.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 719, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3095:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The ILO has highlighted that there is a link between social justice and a fair globalization; in fact we put together a Declaration on that issue.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 931, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3097:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Social justice is a way of reacting to a crisis but also of organizing society and the essence of the whole thing is that it is an approach, it’s a system, it is the conviction that certain values have to be there.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 916, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3098:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Unfortunately that’s not the situation today, that’s why we have to fight for it.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 246, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3099:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that the essence of the way business has to approach social justice is to understand that it is also good for business.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 850, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3100:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today it means recognition that one of the best ways to get to social justice is decent work, it is the dignity of work, the dignity of the human being, the stability of the family, the peace in the community that decent work gives you.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 825, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3101:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That you have a fair chance at whatever wealth you contributed to creating and every successful enterprise knows that.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3102:\n",
      "  video_id: ZtocGyL3Tfc\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That productivity and competitiveness leads to a fair distribution of the fruits of labour and this is the essence of the ILO approach.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3103:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: BUT WE ARE STUCK HERE IN NEW MEXICO\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 170, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3104:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I KNOW FROM MY BUSINESS BACKGROUND, LOW COST ELECTRICITY IS ONE OF THE KEY THINGS THAT MAKES INDUSTRY POSSIBLE\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3105:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I WOULD LOOK TO ENERGY, CLEAN AND RENEWABLE ENERGY AS A SIGNIFICANT PART OF OUR FUTURE\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 422, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3106:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I WOULD ALSO LOOK TO CONNECT THE ENTIRE COUNTRY\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3107:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: NEW MEXICO HAS ALL OF THAT POTENTIAL\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 238, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3108:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: SO, BROADBAND, INTERNET SERVICE, THAT CONNECTIVITY LETS THE PEOPLE RIGHT HERE FIND OPPORTUNITIES, MOVE FORWARD\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 502, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3110:\n",
      "  video_id: ZznoGQVwTtw\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: WHEN WE ARE NOT CONNECTED WE ARE NOT GOING FORWARD AND BEING LEFT BEHIND\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 330, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3111:\n",
      "  video_id: _0efYOjQYRc\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He is the co-founder of Rossen and Vettese Limited and the former Executive Director of Uniform Final Examination (UFE) courses at Toronto's York University.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 694, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3112:\n",
      "  video_id: _0efYOjQYRc\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Chairman Glenn Ives said that Deloitte is very happy with the new appointment.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 484, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3113:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Next up - Anderson Seafoods has joined and the Aquarium of the Pacific’s Seafood for the Future Program.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3114:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: An alarming report found that in 2010 the stock was only about 20 percent of its fully rebuilt size and that fishing rates have been almost five times the overfishing level.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 519, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3116:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The program will help Andersons advance its' commitments with respect to seafood sustainability, educate existing suppliers and find new suppliers with similar positions on seafood sustainability.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 746, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3118:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 21\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Russian Salmon fisheries in Sakhalin and Kamchatka and Cod and Haddock fisheries in Russian waters of the Barents Sea are also working towards certification.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 33, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 3120:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 19\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: -And in Europe, all Norwegian North East Arctic Cod and Haddock fisheries have been MSC certified.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 302, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3121:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -Also in Asia – an independent adjudicator has upheld MSC certification of the Parties to the Nauru Agreement purse seine skipjack fishery.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3124:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: No other supermarkets received scores that merited an award.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 236, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3125:\n",
      "  video_id: _1nvuNk7EFY\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ISSF members advocate for improved fishing methods, fund scientific advancement and take direct action to spur change with respect to seafood sustainability.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3127:\n",
      "  video_id: _OmWVs0-6UM\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In terms of the academic benefits, having to persevere to keep to their higher standards meant I was better prepared for my year back here at Aston.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3128:\n",
      "  video_id: _OmWVs0-6UM\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Going through the situation with people of the same age meant that I felt more comfortable - I was at ease in dealing with living in such a different culture.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 973, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3129:\n",
      "  video_id: _OmWVs0-6UM\n",
      "  clip_id: 5\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I believe that my time in Rennes will continue to help me as I look for jobs in the Francophone world in the future as a valuable addition to my CV.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3130:\n",
      "  video_id: _WA0HtVEe8U\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They are at one level but if you can do without them it's fine.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3131:\n",
      "  video_id: _aJghSQmxD8\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So you want to make sure as you're evaluating that everything in the speech makes sense and goes together.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3132:\n",
      "  video_id: _aJghSQmxD8\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Staying in hostels, where to eat on the cheap, train travel that's less expensive -whatever it is, do those points match the speech and are they parallel?\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1159, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 3133:\n",
      "  video_id: _aJghSQmxD8\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If the topic is about how to take a cheap European vacation, do the main points and the sub points talk about how to take a cheap European vacation?\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 826, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3134:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 20\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They never go away, there's not a 7 or 10 year statute of limitations on student loans and you can't include them in bankruptcy\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3135:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 21\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Get out of your student loan debt, kick some serious butt and get motivated to make a change in your life\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 507, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3136:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 22\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you found this video to be helpful please like it, subscribe to our Channel and leave a comment\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3140:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Jesse Rodriguez with CreditCEO and I look at Credit Reports every single day\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 721, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3141:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Everyone gets in a bind with their student loans for a different reason\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3142:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today I'm going to show you how you can correct student loans that are reporting past late payments on your Credit\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 475, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3144:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There's not always going to be one solution what works for each person\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3146:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Option 1 is the student loan late payment forgiveness program\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3148:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The way that it works is they will set you up on a payment plan, if you’re not already on one\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3149:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 13\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you have student loans and you haven't even checked your credit in the last couple months, you could have late payments and not even know about it\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 844, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3150:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 12\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now, what if you paid all of your student loans on time, but they’re still reporting late payments? Then, what you need to do is, reach out to us and we will give you a free credit audit and consultation\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 840, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3151:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We can help you with that, so you don't make any mistakes, but you can also do it yourself\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 404, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3153:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 17\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I hope this was helpful and I hope that you can get your student loan late payments removed from your credit report\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3154:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's other videos here on our channel that explain what the dispute process is and how you can do it for yourself\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3155:\n",
      "  video_id: _on_E-ZWy0I\n",
      "  clip_id: 19\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you want to get an FHA loan, they're not going to allow you to get an FHA loan if you have past defaulted student loans\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 710, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3157:\n",
      "  video_id: _q7DM8WkzAQ\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Have them practice it, refine it, work it out so that it feels comfortable, it sounds good, and it's easy to listen to.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3158:\n",
      "  video_id: _q7DM8WkzAQ\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Choose your points carefully that will capture your listener's interest, develop the points, and make sure it's very easy to listen to and gives your listener a call to action.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 811, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3159:\n",
      "  video_id: _q7DM8WkzAQ\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And so you really have to do your best to capture the listener's interest in the beginning of the speech by connecting to an issue that's going to be of interest to them and of importance to them.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3160:\n",
      "  video_id: _q7DM8WkzAQ\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Believe it or not, people don't really want to listen to a long speech most of the time.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3161:\n",
      "  video_id: _q7DM8WkzAQ\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, the development of your speech is going to be a lot like developing an essay.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3162:\n",
      "  video_id: _q7DM8WkzAQ\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Jokes can be good, but they can also be very bad if they're not targeted directly, so, be really careful about how you use humor in your speech because it can actually end up doing more harm than good.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1008, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3165:\n",
      "  video_id: a4PHWxILDp0\n",
      "  clip_id: 13\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Jon Benjamin Styles within deadpan Deadpan can vary in subtlety.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 525, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3171:\n",
      "  video_id: a4PHWxILDp0\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This delivery is also called dry humor or dry wit, when the intent, but not the presentation, is humorous, blunt, oblique, sarcastic, laconic, or apparently unintentional.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3173:\n",
      "  video_id: a4PHWxILDp0\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Another example is the often philosophical comedy of Steven Wright.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3174:\n",
      "  video_id: a4PHWxILDp0\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some good current examples are the characters April Ludgate from the TV show Parks and Recreation played by Aubrey Plaza, or Bob Newhart as Arthur Jeffries in The Big Bang Theory.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 771, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3177:\n",
      "  video_id: a8UMRrUjavI\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: HE DID RECOGNIZE IN THE FIRST PART OF HIS COMMENTS THAT NORTH KOREA IS A FAMILY BUSINESS\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 279, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3179:\n",
      "  video_id: a8UMRrUjavI\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: THESE THINGS COULD HAVE MATERIAL CONSEQUENCES AS WE FOUND OUT WHEN THE MEXICAN PESO AND CANADIAN DOLLAR BOTH FELL\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 574, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3180:\n",
      "  video_id: a8UMRrUjavI\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: THAT HAS CONSEQUENCES FOR AMERICA'S ALLIES\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 272, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3181:\n",
      "  video_id: a8UMRrUjavI\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I WASN'T TRYING TO BE TOO CRITICAL OF HIM\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 358, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3182:\n",
      "  video_id: a8UMRrUjavI\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: TO KATTY'S POINT, I DON'T NECESSARILY DISAGREE WITH DONE ANY\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3183:\n",
      "  video_id: aa0J1AXSseY\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want to welcome you to digital storytelling\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 175, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3184:\n",
      "  video_id: aa0J1AXSseY\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi Everyone, I'm Kathy Graf\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 155, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3185:\n",
      "  video_id: aa0J1AXSseY\n",
      "  clip_id: 3\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I look forward to working with you this semester as you write your scripts, create your stories, edit your stories, and publish your stories\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 512, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3186:\n",
      "  video_id: aa0J1AXSseY\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm here on the Appalachian Trail today which is a great place for a digital story\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3187:\n",
      "  video_id: absh1hsZeF0\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now that means that shares have now fallen out of buy range after clearing a 79.26 entry point last month.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 778, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3189:\n",
      "  video_id: absh1hsZeF0\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: meanwhile Macy's is up around 1% continuing a five session win streak which is sort of an interesting juxtaposition for both department stores and off-price retailers, since off-pricers have generally been seen as outperformers in the retail space, while department stores have generally been struggling.\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1019, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3190:\n",
      "  video_id: absh1hsZeF0\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And of course, click in the link of the description of this video for more, and we'll have more live updates and a stock market video (wrap-up) at the end of the day today.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 938, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3191:\n",
      "  video_id: absh1hsZeF0\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We'll hav an after-hours update for you when those earnings roll out.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3192:\n",
      "  video_id: ahG9c_uaf8s\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm also co-director of the center for civic engagement which has a long history of active participation by sociologists here, and as co-director I arrange internships with community-based organizations working on social justice, deepening democracy and promoting sustainability in the area.\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1298, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 3194:\n",
      "  video_id: ahG9c_uaf8s\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You get not only a lot of experience but an idea whether of that is the right career path for you.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3195:\n",
      "  video_id: ahG9c_uaf8s\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sociology majors and minors can take these interships for sociology elective credit and get to practice sociology in the community while making a difference in the process.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 731, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3196:\n",
      "  video_id: an_GzG40hcE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, my name is Chloe, video marketer for Red Wagon Marketing.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3197:\n",
      "  video_id: an_GzG40hcE\n",
      "  clip_id: 13\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want to step up the quality of your production, we have useful videos in our VLOG.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 595, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3198:\n",
      "  video_id: an_GzG40hcE\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You are one form away form away from making video marketing easy, affordable and productive.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3199:\n",
      "  video_id: an_GzG40hcE\n",
      "  clip_id: 15\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: No editing, No hassel, No fuss, just videos to help grow your business, and remember we provide discount pricing for annual plans.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 948, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3200:\n",
      "  video_id: an_GzG40hcE\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Does the thought planning, creating and editing videos sound difficult and time-consuming?\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 452, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3202:\n",
      "  video_id: b86B3hP8ARM\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Traders and bond dealers have gotten together with mutual fund companies, and actually bundled up various offers for various municipalities, with high specialties.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3203:\n",
      "  video_id: b92iw0OAnI4\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Many Americans do not have a household budget, so as a result, they're ending up seeing less a month left and less money at the end of the month.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 816, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3205:\n",
      "  video_id: b92iw0OAnI4\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Make sure you have an effective line item schedule that you stick with, but don't be so critical on yourself that you can't allow some fun every now and then because it's very important to do that.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 874, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3206:\n",
      "  video_id: bCBMKwafZKY\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And so I wanna start us trending upwards again, so that we can have more women in office.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 555, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3207:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 10\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's important that you are practicing your stories because we are going to have a great opportunity here in Houston\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3208:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the event was called Career Accelerator\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3209:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Recently we had a great event thanks to the former National Society of Hispanic MBAs, which is now Prospanica\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 371, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3210:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A question that was asked a lot before, during, and after the event was: How to prepare for an interview? And there are several things that you have to do to be ready for an interview, but one important thing is to practice your stories\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 943, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3211:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was an opportunity for current MBA and graduate students to practice their interview and their resume skills\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 648, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3212:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Comedians practice their material all the time, not because they are fake just because they want their audience to have the time of their life\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 610, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3213:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And one thing I tell people to help them understand what practicing their stories means is that they have to think of themselves as comedians\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 646, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3214:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So always be thinking STAR method\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3215:\n",
      "  video_id: bNQOeiAotbk\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's exactly what you have to think of when you are going to an interview but instead of telling jokes you are telling your professional stories, you are telling the stories of the challenges you've faced in your professional career and you're gonna tell them the steps you took to overcome those challenges\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1077, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3218:\n",
      "  video_id: bWmrrWQOVCM\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So be fair for both parties, you know make sure that you're not going to overwork your nanny and make sure that it's enough duties for her and it's not some outlandish thing like you know, washing your car or something like that.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 973, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3219:\n",
      "  video_id: bWmrrWQOVCM\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So make sure that you write down your expectations, express them to the nanny and the you guys go extensively over the details and whatnot.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 754, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3221:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 24\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We are constantly looking into new ideas and believe it’s important to explore different avenues of technology, this combined with Axiory’s quality support which are always happy to answer any questions from the topics we've covered\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 879, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3222:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 25\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you have any feedback or ideas then please contact us as we would love to hear from you\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 499, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3223:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 20\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: These could give your profits a real lift or just make trading easier\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 500, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3225:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 22\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also our talented design team have been working hard to update the graphics\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3226:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 23\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is broadcast Monday through Friday and gives you the day’s fundamental, technical news and a look at some of the other traders available for you to join here at Axiory\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3227:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: 2012 is well underway and so are some of Axiory’s new products and services\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3228:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Welcome everyone, my name is Steve Buswell and thank you for tuning into Axiory's newsletter\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3229:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 3\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We start off with great news for all you fans of Apple products, MT4 for the mac is finally here\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3230:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I would like to present to you some of the exciting features and products that we have recently introduced to make the quality of your trading experience even better\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3231:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if there was an EA or an indicator that you found particularly useful, you can look forward to the same quality functionality for the OSX\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3232:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This gives you exactly the same great features as found on the Windows MT4 platform\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3233:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Through Algocharge you can use either your Visa or Mastercard connected to your current banking account\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3234:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In our aim to make life a little easier we have recently introduced a new way for depositing funds to your Axiory account\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3235:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’ve also started to cooperate with a third party independent company, Apex Financial Outsourcing Services Ltd\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 429, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3236:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This adds to the two other ways of depositing funds including bank transfer or liberty reserve\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 468, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3237:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Here at Axiory we believe that this is an important concept and have decided to cooperate with them so you can be completely confident in the security of your deposits\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3238:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: , In general, Apex monitors all fund transfers and makes sure that the process is transparent and ensures that clientele and brokerage funds always remain completely separate\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 894, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3239:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s much more user-friendly,reliable and generally responds altogether faster\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3240:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A brand new mobile platform is available for download on our website\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3241:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now you don't have to download anything at all, just login and enter your password and your ready to access your trading account, simple\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 724, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3242:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we have a new program for your smartphone browser called MobileTrader\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 346, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3243:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 17\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We are currently changing the format from presentation style to an interactive question and answer session where Jeff and I welcome any questions from you\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3244:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our live webinars are in the process of a makeover too\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 182, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3245:\n",
      "  video_id: bdFCD-3BCRg\n",
      "  clip_id: 19\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They will still be packed with information and cover some of the other products and services we offer\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 713, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3249:\n",
      "  video_id: bkX5FOX22Tw\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also have a new item\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3250:\n",
      "  video_id: bkX5FOX22Tw\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: By monitoring the stream in various location along the path, you can see exactly where the faults occurred\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 555, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3251:\n",
      "  video_id: bkX5FOX22Tw\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The advantage of that for an operator of a network, or even an individual station, is that you can see where there is a fault or a problem developing\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 527, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3254:\n",
      "  video_id: bnzVR2ETQQ8\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: someone coming from a stated non believing perspective treating what is too many people Sacred Scripture, you might get more friction and controversy there, too\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 603, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3255:\n",
      "  video_id: bnzVR2ETQQ8\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I really look forward to discussing with my students their take on the \"Noah\" movie\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3256:\n",
      "  video_id: bnzVR2ETQQ8\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think it's a real question some people have about using the sacred scriptures of particular faiths to create modern entertainment and there's ethics in that, there definitely are\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 661, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3258:\n",
      "  video_id: bvycs3BXtx0\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: More and more folks are using the social media outlets, both to find information, and frankly, to talk to other similarly situated individuals who've had the same disease, or the same problem with their child, or whose parents are similarly in a nursing home.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1234, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 3259:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 11\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I'm having a good time here on orbit\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3260:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We do a lot of scientific work, also a lot of maintenance\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3261:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you go outside as well, you need to have one of those, a space suit\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 386, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3263:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 15\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It takes a lot of work\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 146, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3265:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 17\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So therefore, we try to spend as least time as possible outside of the space station\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3268:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 18\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is why we use a lot of robotics tasks, for example\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3269:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Floating in orbit is just nice\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3270:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: MALE SPEAKER: Frank, Jerome is asking, how do you feel in orbit after several months? FRANK DE WINNE: Well as you can see, Jerome, I'm feeling just great\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3271:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the beginning, you're kind of going like all over the place\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3272:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can very nicely stay always in equilibrium after a couple of months\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 378, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3273:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So life is great here\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 288, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3274:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And now, it just seems so relaxing\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 186, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3275:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The company is good\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3276:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The food is good\n",
      "  text_feature_shape: (1, 6, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3277:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And also, the work is great\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 128, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3278:\n",
      "  video_id: c5VEvmutmVg\n",
      "  clip_id: 8\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have a fantastic crew\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 468, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3279:\n",
      "  video_id: c5zxqITn3ZM\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One is a tool that we developed which is called Star Com EQ, which is emotional intelligence research.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 694, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3281:\n",
      "  video_id: c5zxqITn3ZM\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it’s not always rational, it’s very much emotional at times.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3282:\n",
      "  video_id: c5zxqITn3ZM\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it’s actually become a wonderful tool in really understanding what is driving consumers channel selection.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3283:\n",
      "  video_id: c5zxqITn3ZM\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The other thing that we have done is we are putting in place global communities, it is called the mic at Star Com, and these are global listening communities that we have where we can at any point in time put out questions to these communities.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1041, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3284:\n",
      "  video_id: c5zxqITn3ZM\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we can ask them questions on a real time basis to let us understand kind of the pulse of, again, what are they thinking, what’s their view on culture today, what really motivates them, what intrigues them.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1060, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3285:\n",
      "  video_id: c5zxqITn3ZM\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The next community we’re established is women and mom based.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3288:\n",
      "  video_id: c9hE1ghElrM\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Some of the common side effects of Epogen include nausea, vomiting, fever, and tiredness\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3291:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 24\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want you all to meet my new girlfriend, Issy\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3293:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 26\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi Issy! What'd you think about the movie \"Cinderella\"? I liked it! Was it really good? Yeah\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 474, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3294:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 27\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: From a 1 to 10, what would you give the movie \"Cinderella\"? 10\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3296:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 21\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So it's the typical story of Cinderella, the structure is the same and it's very faithful to the source material that it's attempting to do\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 747, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3297:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 22\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I really liked the characters in the movie, the performances were really well, the visual effects were spectacular\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3298:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 23\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was amazed at how advanced they've gotten lately in movies when it comes to that\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 387, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3299:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 29\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As for me, I would give the movie an 8 out of 10\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 290, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3300:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 40\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also, if you wanna see my previous videos and/or get the chance to subscribe to my channel, please stay until the end of this video\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3301:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 41\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it'll direct you to that\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 202, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3303:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey folks, this is the Cinematic Seth\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 135, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3305:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now the reason for that is because of stuff in my personal life, such as work, my best friend, and my girlfriend who I've been spending a lot of time with\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 502, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3306:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today, I'm going to be reviewing a movie I saw weeks ago\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 299, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3307:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So that's what has been holding me back, as far as content goes\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 301, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3308:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm not referring to the old animated Disney movie or the movie \"Ever After\", which was a great adaptation\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3311:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, I'm going to be reviewing the newest \"Cinderella\" live-action movie\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3312:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 39\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Who knows? If you have any suggestions, requests, feedback, please leave them in the comments below\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 355, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3313:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 38\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hopefully soon, I'm going to do some top 10 lists, maybe list some of my favorite movies\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 362, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3314:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I was curious as to how they could pull it off and, surprisingly, they pull it off really well in this movie\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3316:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Who is Chris Weitz, you may ask? He is one of the two brothers who directed the 1999 teen raunchy comedy film \"American Pie\"\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 572, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3317:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 12\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Of course I stayed until the end to look at some of the credits and the ironic thing is I saw that the writing credit was to Chris Weitz\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3318:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A movie that had a lot of language and sexual content, this movie is toned down to PG\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3319:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [briefly chuckles] That's kind of like a contrast as far as content\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 325, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3321:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 32\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't know if it's still playing in theaters but I liked it, I thought it was pretty good\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3322:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 31\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that's my thoughts on \"Cinderella\"\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 218, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3323:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 30\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it's really good\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 143, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3324:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 37\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I just want to let all of my subscribers know that I did not quit making videos and that I'm going to keep making more of these movie reviews\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 505, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3325:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 36\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm really sorry I took a hiatus\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3326:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 35\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But I will stay up to date with my content posting\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3327:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 34\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Again, I don't have a weekly (upload) schedule, which is not a good thing\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 226, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3328:\n",
      "  video_id: cW-aX4dPVfk\n",
      "  clip_id: 33\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I hope you all enjoyed this video and if you did, feel free to like and subscribe, because I will be posting more content on this channel\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3329:\n",
      "  video_id: cX8FScpsfLE\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Oh, I kept the first for another day! Yet knowing how way leads on to way, I doubted if I should ever come back\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 706, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3330:\n",
      "  video_id: cX8FScpsfLE\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Road Not Taken BY ROBERT FROST Two roads diverged in a yellow wood, And sorry I could not travel both and be one traveler, Long I stood and looked down one as far as I could to where it bent in the undergrowth; Then took the other, as just as fair, And having perhaps the better claim, Because it was grassy and wanted wear; Though as for that the passing there had worn them really about the same, And both that morning equally lay In leaves no step had trodden black\n",
      "  text_feature_shape: (1, 108, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2241, 1024])\n",
      "  vision_feature_shape: (44, 2048)\n",
      "Item 3331:\n",
      "  video_id: cY8DcaHXNNs\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s extremely important to Car MD to continually improve on our products and not just rest on, okay, we’ve innovated it and we’re done.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 508, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3333:\n",
      "  video_id: cY8DcaHXNNs\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Social marketing opportunities where just a few weeks ago we had a Twitter party to communicate with consumers about the importance of car care and what’s on the minds of women in particular.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 808, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3334:\n",
      "  video_id: cia8OM3Oe7Q\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Lidia Vargas I've been coming to Lake Mead Dental for 5 years and I recommend Lake Mead Dental because the dentists are the best their personal is very kind and they're allways willing to solve any problems\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3335:\n",
      "  video_id: cml9rShionM\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If we want to get rid of social assistance, if we want the   national budget to be richer and to develop the local infrastructure,  then we have to invest in education.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3338:\n",
      "  video_id: cml9rShionM\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We are very warm-hearted   people, we put a lot of heart in communication.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 323, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3342:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's not like Romeo and Juliet, where the lovers are sacrificed and then Verona is healed\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3343:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Only the idle rich: Jordan Baker, Daisy and Tom Buchanan, Nick Carraway\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 353, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3344:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean, who even survives this novel\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3345:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As Nick writes, \"They were careless people, Tom and Daisy -- they smashed up things and creatures and then retreated back into their money or their vast carelessness\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3346:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They survive, and they are allowed to go on being careless\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3347:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To live without a care in the world is supposed to be the dream, right\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3348:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" They aren't cruel or malicious, they're just careless -- they don't care too much about Myrtle or Gatsby or their daughter or even each other\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 788, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3349:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 9\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But Fitzgerald shows us the horror of this care-free life, how Tom and Daisy's inability to care is in some ways more monstrous than outright cruelty would be\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3350:\n",
      "  video_id: cn0WZ8-0Z1Y\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Everyone wants a care-free life\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3351:\n",
      "  video_id: ctAZf4sMBUQ\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: with a lot of designers who were thinking very well of themselves because they were really focusing on users already and then having to accept a new discipline into their processes.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 891, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3352:\n",
      "  video_id: ctAZf4sMBUQ\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then when someone's triggered, they will come up with asking the questions - \"How did you come up with this knowledge?\" \"What were the methodologies?\" \"Where does this knowledge come from?\" So, yes, it's communication and trying to come up with the right tools to communicate knowledge about users.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1362, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 3353:\n",
      "  video_id: ctAZf4sMBUQ\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I came to Philips Design in the then newly group of social scientists, trying to come up with a more thorough research approach to designing.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 601, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3354:\n",
      "  video_id: d-Uw_uZyUys\n",
      "  clip_id: 1\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Let me tell you a story about my grandmother Every time that I used to date a new boyfriend She would ask his name and then she would go like \"and what part of the city does he live in?\" That was her way of asking if my boyfriend was white She was an out and out racist So I know the face of prejudice Governor Reston is telling me I don't have the balls to be president And he means that literally It's offensive It's offensive to me It's offensive to every woman out there who he is asking the votes for Tonight I am here stating that governor Reston is a sexist But you know what\n",
      "  text_feature_shape: (1, 128, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2279, 1024])\n",
      "  vision_feature_shape: (45, 2048)\n",
      "Item 3355:\n",
      "  video_id: d-Uw_uZyUys\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You see, Reston's campaign is saying that I don't have the experience to be president\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3356:\n",
      "  video_id: d-Uw_uZyUys\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's not even just about him going around and talking in codes about gender it's everyone Yourself included The only reason why we are here tonight in this interview in my house is because you requested it, right? it was entirely your idea and here still you are thinking that you are being welcomed into my lovely place You are thanking me for that This is the thing that you say to your next door lady that bakes you chocolate chips cookies This pitcher of iced tea is not even mine Your producer set it here And why is that? For the same reason that you call me a real life Cinderella story You are telling the world that I am a woman Without having to use the word And for you it's just an angle and I get it You might even think that it's innocuous But guess what? It's not\n",
      "  text_feature_shape: (1, 165, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2508, 1024])\n",
      "  vision_feature_shape: (50, 2048)\n",
      "Item 3357:\n",
      "  video_id: d-Uw_uZyUys\n",
      "  clip_id: 7\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For seven years I served the United States Army Which is seven years more than he ever did A fact that you conveniently omitted from my intro, James\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 587, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3358:\n",
      "  video_id: d-Uw_uZyUys\n",
      "  clip_id: 6\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Don't interrupt me while I am speaking You see, James, you are promoting stereotypes You are advancing this idea that women are weaker than men You are playing right into the hands of Reston And you know what? You are playing into the hands of anyone any imbecile out there that thinks women are not strong fit enough to be commander in chief Governor, I'm talking about you\n",
      "  text_feature_shape: (1, 79, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1316, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 3359:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's why the United States and our partners must continue our life-saving work to advocate for sexual health and reproductive rights.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3360:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For others, it's because their husbands or their communities simply don't support their use.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 621, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3361:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That includes universal access to voluntary family planning.\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3362:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we'll need to find new ways to remind people that when women and girls are better able to stay healthy and pursue new opportunities, they are also better able to contribute to the success of their families, their communities, their countries and the world.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1096, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3363:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We'll need to continue investing in effective programs like the United Nations Population Fund and the State Department's Global Health Initiative.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3364:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 19\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thank you for the work you're doing, and I hope you have a great meeting.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 317, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3365:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 18\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: State Department, I look forward to hearing what comes out of this important conference, and I look forward to working together to bring about a healthier and more prosperous future for families from Addis to Adelaide, and everywhere in between.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 998, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3366:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'd like to welcome the thousands of you from governments around the world, NGOs, public and private organizations, and elsewhere, who are taking part in the third biennial International Family Planning Conference.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 741, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3367:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Secretary of State and the father of two extraordinary young women, I am exceedingly grateful for your hard work and dedication to this cause.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 761, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3368:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Millions of women, men, and children have better lives today thanks to the work that many of you have done for decades.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3369:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Senator, I attended the historic International Conference on Population and Development.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 355, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3370:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For some, it's because they can't afford or don't have access to these services.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3371:\n",
      "  video_id: d1CDP6sMuLA\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: These are basic human necessities that hundreds of millions of women are forced to go without.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 486, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3372:\n",
      "  video_id: dHk--ExZbHs\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Thank you for joining us for The Tradex Foods - \"3-Minute Sustainability Recap\" A summary of hot news items in sustainability – for seafood purchasers and industry.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 447, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3373:\n",
      "  video_id: dHk--ExZbHs\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: -And Supervalue has announced that it will source 100 percent of its top 20 wild-caught products from sustainable fisheries by 2015. -Next up, you can add a two more seafood sustainability eco-labels to the already long list: -The Gulf of Maine Research Institute has partnered with Hannaford Supermarkets and a number of seafood suppliers to roll out a “Gulf of Maine Responsibly Harvested” label.\n",
      "  text_feature_shape: (1, 90, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1334, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 3374:\n",
      "  video_id: dHk--ExZbHs\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: --------In other news, retailers continue to make commitments to sourcing sustainable seafood - -Wakefern Food Corporation has adopted the Global Aquaculture Alliance’s Best Aquaculture Practices certification program for farmed seafood.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 733, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3376:\n",
      "  video_id: dR68gbeOWOc\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: convenes the leaders of the G-8 this coming weekend, there are three issues I think are going to be on many people's minds in watching the meetings unfold.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3377:\n",
      "  video_id: dR68gbeOWOc\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: can chorale its partners to deliver on the food security agenda.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3378:\n",
      "  video_id: dTcz1am1eUw\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it’s important to remember that we have to talk about the issue of engagement very very broadly.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3380:\n",
      "  video_id: dTcz1am1eUw\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have programs that are very robust on the educational level.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3381:\n",
      "  video_id: ddWHTdJz2O8\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Quality of service (53 percent), fees, (50 percent), ease of use (49 percent) and interest rates (49 percent) represent the biggest impact areas that banks need to address.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1048, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3382:\n",
      "  video_id: ddWHTdJz2O8\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Capgemini and Efma recently released the ninth annual World Retail Banking Report that indicates customer retention is in flux and nine percent of customers are likely to leave their banks in the next six months while 40 percent are unsure they'll stay long term.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3383:\n",
      "  video_id: ddWHTdJz2O8\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Jean Lassignardie, Global Head of Sales and Marketing, Capgemini Financial Services comments on the findings: \"Banks should be applauded for taking the necessary, initial steps to sustain customer relationships,\" he says.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 904, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3384:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I start out with using experiments to understand how do we make the decisions that we do, and why we make them.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 358, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3385:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then I develop nudges to push people, gently push them, to make improved decisions.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 683, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3386:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 15\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Waldo Emerson describes success in life in the following way, \"to know that one life has breathed easier because you have lived.\" That's my aspiration in life-- to ask big questions, to tackle big problems, so people can live easier and better lives.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1053, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3387:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 14\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I work with a range of organizations, from big multinationals to governments, from local organizations to nonprofits, cafes, and museums to help them, their employees, their customers, their communities, lead healthier, happier, and more productive lives.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1284, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 3388:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I try to get my students to think, to be sophisticated thinkers who ask questions-- because there are no answers, there are no solutions, without questions.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 794, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3389:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 18\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I encourage them to be compassionate and nice, to pay it forward, to think humanly-- because there are no business problems, there are no business solutions, without humans.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1073, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3390:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What's that one question you can ask on a first date to understand whether they are the one for you?\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 659, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3392:\n",
      "  video_id: dlE05KC95uk\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And this meeting point of East and West got me interested in a bigger question, which is what does it mean to be human?\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3393:\n",
      "  video_id: dxsPkcG-Q30\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: MR KIRBY: The United States congratulates Htin Kyaw on his election to the presidency.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 259, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3394:\n",
      "  video_id: dxsPkcG-Q30\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We look forward to cooperating with the new government as it works to make progress on a wide range of issues including further democratic reforms, promotion of human rights, economic development, and national reconciliation.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 655, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3395:\n",
      "  video_id: eD5cScqaf6c\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We use our own fleet of new fully equipped removal vehicles covering all postcodes within the M25, the UK and Europe.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3396:\n",
      "  video_id: eD5cScqaf6c\n",
      "  clip_id: 0\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Welcome at Gagomovers we are London based residential and commercial removals company specializing in all aspects of moving for private and business customers.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3397:\n",
      "  video_id: eD5cScqaf6c\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If are you Moving House or flat in London or national wide, Or Moving Office, Or you Need Storage Fell up the the form below and get your free quote in 30 second , thanks you\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 605, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3398:\n",
      "  video_id: eE8Qr9fOvVA\n",
      "  clip_id: 3\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They dedicated their lives to our family and this country, and I think that's something a number of us can relate to\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 454, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3399:\n",
      "  video_id: eE8Qr9fOvVA\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Who worked in nuclear arms control as a Green Beret in the military\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3400:\n",
      "  video_id: eE8Qr9fOvVA\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Like many people all over this country, and my family, the [\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 401, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3401:\n",
      "  video_id: eE8Qr9fOvVA\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: ] in this state of North Carolina, despite the repeated betrayal over hundreds of years\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 500, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3402:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is just a project of passion\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 144, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3403:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And, if you're looking to learn more about Sling TV, which I mentioned, just click somewhere up here\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 470, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3404:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That makes a world of difference\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 246, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3405:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Fire TV, also click somewhere up here\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 385, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3406:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 1\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm gonna add this to my Fire TV and my tablet\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 203, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3407:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - So how is Sling TV different from something like Pluto TV\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 371, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3408:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's different than Pluto but, again, this is 20 dollars per month and Pluto is completely free\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3409:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well with Sling, you're gonna get premium content like HGTV, Food TV, ESPN, live\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3410:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now if you like free content, all of the content I produce here is free on a volunteer basis\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3411:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that is your glimpse at free TV on demand\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 435, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3413:\n",
      "  video_id: eFV7iFPYZB4\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't make any money for my YouTube videos\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3414:\n",
      "  video_id: eJfT7-dDqzA\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And let me tell you - I am being serious while I say talk to yourself\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3415:\n",
      "  video_id: eJfT7-dDqzA\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now to practice these phases the easiest way is to talk to yourself\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 455, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3416:\n",
      "  video_id: eJfT7-dDqzA\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Just simply utter the words in your mind\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3418:\n",
      "  video_id: eJfT7-dDqzA\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Just utter the names of the foods that you are eating in your mind\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3419:\n",
      "  video_id: eJfT7-dDqzA\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For example- you are eating something\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3420:\n",
      "  video_id: eJfT7-dDqzA\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For Example - fish, banana, bringle, egg plant\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3423:\n",
      "  video_id: eQc5uI7FKCU\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That is amongst the largest, if not the largest at a single center annually\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3424:\n",
      "  video_id: eQc5uI7FKCU\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our experts are well versed on surgery, but also on non-surgical treatments for prostate cancer\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3425:\n",
      "  video_id: eQc5uI7FKCU\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've had a robot here at Hopkins since the year 2000 longer than most institutions in this country and around the world\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3426:\n",
      "  video_id: eQc5uI7FKCU\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [MUSIC] We perform about 600 robotic prostatectomies here at Johns Hopkins annually\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 446, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3427:\n",
      "  video_id: eQc5uI7FKCU\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also have a robotics division within our department where we build new robots and test technological tools during surgery\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3428:\n",
      "  video_id: eREud0qYR3s\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You're going to need to have kind of your outlet-type of presence out there, we're a beautiful match for that.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3429:\n",
      "  video_id: eREud0qYR3s\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've got 88 million active users that are looking for traffic.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3430:\n",
      "  video_id: eUwbRLhV1vs\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As we've seen, if else statements really give you control over your code.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 228, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3431:\n",
      "  video_id: ehZrOdw6PhA\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It can mimic something like 300 different diseases and so classically can fit that\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3432:\n",
      "  video_id: ehZrOdw6PhA\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In fact, Lyme disease has many, many, many more symptoms and it's known as the great mimicker\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 228, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3433:\n",
      "  video_id: ehZrOdw6PhA\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: All these things, insomnia, depression, all of these classic symptoms we see in fibromyalgia patients\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 720, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3434:\n",
      "  video_id: ex-dKshlXoY\n",
      "  clip_id: 11\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There’s still groups of people that you’re just not gonna reach with as much effectiveness on line as you are off line.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3435:\n",
      "  video_id: ex-dKshlXoY\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then we have your entire, you know, millions of pieces of information on, you know, how individuals across the country vote, how often they vote, you know, their party registration, you know, how long they’ve been registered to vote that we kind of combine together with those.\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 921, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3436:\n",
      "  video_id: ex-dKshlXoY\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think the one unique challenge is that, you know, we have access to so much data that probably corporate America even doesn’t have.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3438:\n",
      "  video_id: ey1lr8wFFDc\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There’s a number of reasons, first of all of course, economically, intellectual property is extremely important for Europe.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3440:\n",
      "  video_id: ey1lr8wFFDc\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And they do not have raw materials so their economy has to develop what the brains produce as opposed to what the earth produces, if you want to compare.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 587, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3441:\n",
      "  video_id: ezuWKsxPRSM\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The Treu Group is having an amazing success in \"the farms\" and we would love to help you, too; if you're thinking of selling.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 654, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3442:\n",
      "  video_id: ezuWKsxPRSM\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, It's Lisa Treu with the Treu Group and we sold another property in Jupiter Farms.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 299, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3443:\n",
      "  video_id: ezuWKsxPRSM\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We actually listed this property for two hundred and seventy-five thousand which the seller was just shocked that they could get that much.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 628, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3445:\n",
      "  video_id: f-VdKweez2U\n",
      "  clip_id: 8\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Finding problems to solve and trying to make the world a better place it's a lifelong pursuit.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 609, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3446:\n",
      "  video_id: f-VdKweez2U\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The freedom to follow your dreams, to work with people that you like to work with.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 359, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3448:\n",
      "  video_id: f-VdKweez2U\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Actually I think the most successful entrepreneurs start with the idea that they're gonna serve others.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 345, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3449:\n",
      "  video_id: f-VdKweez2U\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I believe entrepreneurship is the ability to think and create something that you would like to do in the world and try to make money doing it.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3451:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But at the end of the day, the evidence we uncover needs to stand up in court.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3452:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also use independent experts who have experience in the markets, particularly on materiality.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3453:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 13\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: My message on insider trading is this: it is a crime that undermines the integrity of Australia's capital markets.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 708, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3454:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 12\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Where there is this evidence we will pursue insider traders no matter who they are - from the Chairman of the Board through to junior staff.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 731, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3455:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ASIC has examined this matter thoroughly, including this proposal and decided there is insufficient evidence to take enforcement action.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 814, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3456:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I'm ASIC Commissioner John Price There has been a lot of reporting on ASIC's investigation into the share trading of David Jones two directors and the proposal from Myer.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 748, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3457:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Generally, there are four things ASIC must prove for any insider trading case.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3458:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This decision is not an exoneration or a tick of approval and if more evidence comes to light, the matter can be re-opened.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 825, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3460:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And last, ASIC needs to prove the trader knew or ought to have known the information was material and not publicly available.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3461:\n",
      "  video_id: fT6SrlsWV7M\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Third, that the information was \"material\" in that it would have a material effect on the price or value of the company's shares.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3462:\n",
      "  video_id: fU5AYkq0m9k\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We know that almonds do take a lot of water to grow, but dairy farms use 12 times as much water\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3463:\n",
      "  video_id: fU5AYkq0m9k\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that's because dairy milk requires about 12 times as much water as almond milk and that's something that people don't always consider\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3464:\n",
      "  video_id: fU5AYkq0m9k\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So 2500 dairy cows produce as much waste as 411,000 people\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3465:\n",
      "  video_id: fU5AYkq0m9k\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That is how much waste is going into the groundwater, and how much waste needs to be dealt with\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 595, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3466:\n",
      "  video_id: fVCDn6SdtVM\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Medivation jumped nearly 20% after Pfizer said it would buy the company and shares of Valeant Pharmaceuticals were also up nearly 8% after the company appointed a new CFO.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1232, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 3467:\n",
      "  video_id: fVCDn6SdtVM\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Oil stocks in general today struggled but things look better for parts of the biotech and pharmaceutical industries.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 829, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3469:\n",
      "  video_id: fWAKek8jA5M\n",
      "  clip_id: 0\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Wait, that doesn't make any sense\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 88, 1024])\n",
      "  vision_feature_shape: (1, 2048)\n",
      "Item 3470:\n",
      "  video_id: fWAKek8jA5M\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In fact, they go on to explain that\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 328, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3471:\n",
      "  video_id: fWAKek8jA5M\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But that's because everybody would have the new government-provided insurance instead\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3473:\n",
      "  video_id: fWAKek8jA5M\n",
      "  clip_id: 7\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" She also does another sleazy trick there\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 153, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3474:\n",
      "  video_id: fWAKek8jA5M\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The whole point of a single-payer plan is to make sure that coverage is simpler, more comprehensive, and more reliable than it is today\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3475:\n",
      "  video_id: fWAKek8jA5M\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The states, I mean, they're rejecting the Medicare expansion under Obamacare\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3477:\n",
      "  video_id: faUvT7zfsyk\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's basically it, and if you master tenses, you will be able to tell stories that span all of time, and I think that ability is kind of astonishing that language can express that sort of idea.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 974, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3478:\n",
      "  video_id: faUvT7zfsyk\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When we're talking about a verb, a verb can happen now, a verb can happen later, and a verb can have happened in the past, then.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3479:\n",
      "  video_id: faUvT7zfsyk\n",
      "  clip_id: 6\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you can command all of these, you will be a time wizard.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3482:\n",
      "  video_id: fcxbB7ybUfs\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It could even be part time income but you are going to want to look at what your income is and then you are going to want to subtract out all the sources of income that you are going to have coming in and what that is going to do is provide you with that need.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 813, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3483:\n",
      "  video_id: fdc7iyzKvFQ\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm going to tell you a personal story about myself\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 219, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3484:\n",
      "  video_id: fdc7iyzKvFQ\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I tell you he completely blew us away\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 611, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3485:\n",
      "  video_id: fdc7iyzKvFQ\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So all the cellists heard that this great Russian cellist was coming and we went we heard him play Sinfonia Concertante of Prokofiev that night\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 696, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3486:\n",
      "  video_id: fhADeWE5VgU\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm the author of \"How To Save Your Stuff From A Disaster.\" I've been an expert in disaster mitigation for thirty-five years, and much of what I know and the services that I provide are important to your clients.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 764, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3489:\n",
      "  video_id: fhADeWE5VgU\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let me give you my cell phone number: 805-570-4140. Another way to stay in touch is to sign up for the blog and when I do updates, which is often, then you can look at the types of projects that we're evaluating and the people that we're doing the work for.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1037, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3490:\n",
      "  video_id: frCWtiam4tE\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it’s something we talked about today at the Think Politics event.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3491:\n",
      "  video_id: frCWtiam4tE\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The three key trends that I see coming up more and more in campaigns, I think overwhelmingly the number one, and it sort of [INAUD] everything is two way communication.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3492:\n",
      "  video_id: frCWtiam4tE\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But I think overwhelmingly people are looking to engage in on line, but also be engaged with.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3493:\n",
      "  video_id: frCWtiam4tE\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that people are being bolder and more courageous with their on line media, and that’s reaping really big dividends.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3494:\n",
      "  video_id: fsBzpr4k3rY\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It causes me to not do bad and put myself in a bad situation\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 5159, 1024])\n",
      "  vision_feature_shape: (103, 2048)\n",
      "Item 3495:\n",
      "  video_id: fsd1qPLA3kY\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It doesn't sound very sexy, but, think of it as wearing a \"you were here\" sign, this is where you start.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 508, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3496:\n",
      "  video_id: fsd1qPLA3kY\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Look at where we come from so that we get perspective on where we're going.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 654, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3497:\n",
      "  video_id: fsd1qPLA3kY\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It includes leadership, marketing, finance, operations, HR, how we do these functions and how well they serve strategy.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 745, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3498:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 11\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can take a random chapter and it will blow your mind and completely change the way that you see the whole world\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3499:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So if I can give you one suggestion get this book, buy it on kindle start reading it\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 370, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3500:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't say this lightly but this is probably one of the best books I have ever read\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3501:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The book for this week was: Solve for Happy how to engineer your way to happiness by Mo Gawdat and he's the chief business officer of Google X\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 791, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3502:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Wow!! That's really all I can say about the book I read this week\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 261, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3503:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This guy's an engineer and he takes it very systematically\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3504:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now this book is pretty much what happens when you take one of the smartest people around and you tell them that that solve happiness\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 758, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3505:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is the systematic approach to solving happiness\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3507:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 7\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You will definitely be a happier and better person after reading this book and I know that usually in these videos I summarize something\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3508:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He covers a wide variety of topics, things like your idea of time, your idea of death and he explains them so simply but so fundamentally that it will definitely change the way you look at the world and it'll improve the way that you see everything in your life and it will solve your happiness equation\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1488, 1024])\n",
      "  vision_feature_shape: (29, 2048)\n",
      "Item 3509:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There is so much good information that I really couldn't pick one thing\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 467, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3510:\n",
      "  video_id: fz-MzQcOBwQ\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I give you guys one or two little tit-bits to take away, but I've been racking my brain trying to figure out what I was going to take out of this book to share with you and it's impossible\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 683, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3511:\n",
      "  video_id: g6VJg6ycUk0\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Schmidt were recently appointed as partners in the firm's Asset Management Tax practice.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3512:\n",
      "  video_id: gE7kUqMqQ9g\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So therefore, they still have the right to carry a credit card.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3513:\n",
      "  video_id: gE7kUqMqQ9g\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Or worse, an individual previously had good credit, but usually by no fault of their own, or perhaps by fault of their own, they have let their credit sag, and credit scores is very low.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1018, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3514:\n",
      "  video_id: gJjkCPO7iXg\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’ve assembled a strong team of dedicated personal injury attorneys, investigators, paralegals and case managers, all to insure that your case is treated with the importance it deserves\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 601, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3515:\n",
      "  video_id: gJjkCPO7iXg\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As one of the leading personal injury law firms in Arizona, Phillips Law Group realizes it takes more than just one person to handle the challenges behind a personal injury claim\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 494, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3516:\n",
      "  video_id: gJjkCPO7iXg\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Have any questions? Simply click the live chat button on any page and chat with someone 24 hours a day 7 days a week\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 806, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3517:\n",
      "  video_id: gJjkCPO7iXg\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Additionally, we have a wealth of information for victims of personal injury available on our website\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 449, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3520:\n",
      "  video_id: gL8h7lOPv1Q\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are multiple stages in this where the cell actually divides.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3521:\n",
      "  video_id: gL8h7lOPv1Q\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then you'll notice that there's just this little brief period of time.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3525:\n",
      "  video_id: gL8h7lOPv1Q\n",
      "  clip_id: 28\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So let's look closer at the actual process of interphase and break it down into its three little parts right here.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3526:\n",
      "  video_id: gL8h7lOPv1Q\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If we were to throw the stages of the cell cycle on to a little circular image, what you would see is that the cell is in a stage called interphase most of the time.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1074, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3527:\n",
      "  video_id: gL8h7lOPv1Q\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For example, during interphase the cell's DNA looks like this.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 672, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3529:\n",
      "  video_id: gL8h7lOPv1Q\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Dude, I feel like I've got Barkley the dog from \"Sesame Street\" hanging out here with me.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3530:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And that's why at the end, I'm asking myself, well, who is the referent here? \"The man did not need lamentations and there were no diseases that gave him any pain at the moment when he was escorted away\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 846, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3531:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I can just bet that the citizens of Athens as they thought about Sophocles towards the end of the 5th century would have thought about how the old man and his very, very long career, which is full of sufferings as well as successes, could be identified with Oedipus as a cult hero\n",
      "  text_feature_shape: (1, 65, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1526, 1024])\n",
      "  vision_feature_shape: (30, 2048)\n",
      "Item 3532:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 12\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: No, if there was ever any mortal who was wondrous, it was he\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 405, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3534:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And what do you think is new and different that you separated these parts out as separate focused passages? Well, what I want to emphasize about Text J, which is part of the Text I, it is this privileged position of Theseus as not only the founding hero of Athens as understood by the democracy in the 5th century, a version of the city of Athens but also his role as the initiator of all Athenians into what is called the Eleusinian Mysteries\n",
      "  text_feature_shape: (1, 96, 768)\n",
      "  audio_feature_shape: torch.Size([1, 2277, 1024])\n",
      "  vision_feature_shape: (45, 2048)\n",
      "Item 3536:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's the way an initiator initiates worshippers into mysteries\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3539:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that's why I want to come back to this part and try to make it understandable in terms of the fifth century of Athens, which was a very sophisticated period in the history of the city, but which is still clinging to these fundamental notions of what is a cult hero\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1154, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 3540:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But here, in Oedipus at Colonus, Sophocles, who's in his 90s, really identifies with this wretched old man and how he's struggling with the difficulties of old age and the prospect of dying\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 922, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3541:\n",
      "  video_id: gLTxaEcx41E\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the flip side is that's also why he's so fascinated with Oedipus himself who is a character that he has brought to life in other aspects of that character's life\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3542:\n",
      "  video_id: gR3igiwaeyc\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Working together allowed us to transcend our natural constraints, Marx argued, but the way labor is organized leads to massive inequalities\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3544:\n",
      "  video_id: gR3igiwaeyc\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But what Marx saw was that just as we freed ourselves from these natural constraints, we entangled ourselves in new social constraints\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3549:\n",
      "  video_id: gR3igiwaeyc\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But you also have the peasantry, who still worked constantly, making food\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3550:\n",
      "  video_id: gR3igiwaeyc\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That's not a natural constraint anymore, that's a social one\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 266, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3551:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 24\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: com if you wanna learn more about the what, the where and the how and everything to do with personal branding and setting up blogs and your add in to the online\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 428, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3552:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You might make it more official, but you actually don't create a personal brand that doesn't already exist within you\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 499, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3553:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that is my message for today\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3554:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 22\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you would like to leave your biggest takeaway message in the comments that you would be great\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 269, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3555:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 23\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I love to hear what you guys think and pop over to my blog torimackle\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 307, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3556:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I am Tori from torimackle\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 190, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3557:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - So what actually is personal branding? You hear people saying brand yourself and have a personal brand, but knowing actually what it is and how to do it is another story\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 555, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3560:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So when you brand yourself, you are at the centre of your business\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 357, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3561:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So with a personal brand, you can build a following of people that know, like and trust you\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3562:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So you probably heard this before, people actually relate to people and not businesses or companies\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 450, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3563:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With a personal brand, it doesn't matter what happens with social media or any company that you are associated with or any products that you recommend because you are at the centre of your business\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1062, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3564:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And when people trust you, they're now more likely to listen to your recommendations and want to know what it is that you are doing and how they can get the same thing or what it is what you are recommending because they trust that if they listen to you, they are going to get the solutions that they are after and it's the solutions that are the most important\n",
      "  text_feature_shape: (1, 76, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1081, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3565:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Everything else is like spokes that come off this central point which is you\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 404, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3566:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it doesn't matter what happens with those things because your business is always going to be long term and sustainable if it is about you and your personal brand\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 560, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3567:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Your personal brand really is about your values and what you stand for and showing people that\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 335, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3568:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, it may or may not be a surprise to you that you actually already have a personal brand\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 535, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3569:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 15\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you've got a lot of people that look up to you as an authority in a certain area, as a leader in some description, then you probably already have a personal brand\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3570:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So people can have a personal brand that actually don't have a business\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3571:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So what do other people say about you? What do other people say that you do for a living? Those are the things that are actually represented in a personal brand\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3572:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So a personal brand really is what you are known for by other people\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 267, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3574:\n",
      "  video_id: gcFECfN4BCU\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, personal brands can actually open a whole bunch of doors for you and if you make your personal brand official and make it a business, then you can actually monetize those opportunities which is what is super exciting about a personal brand and it is really something that you build overtime\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 956, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3575:\n",
      "  video_id: gpn71-aKWwQ\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I applied to a lot and basically just did a quick Google search of scholarships that pertained to things that I was interested in.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3576:\n",
      "  video_id: gpn71-aKWwQ\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: - So when looking at financial aid opportunities the first thing I looked at were scholarships.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 233, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3577:\n",
      "  video_id: gpn71-aKWwQ\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Applied to as many as I could, that was, you know, humanly feasible, and then I actually ended up getting a couple.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3578:\n",
      "  video_id: grsV1YN1z5s\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or, perhaps you're directing a play and you want to do the best directing job that you can.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 746, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3579:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 20\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you're aiming for 18-20 year old men, and the only people engaging with your content are 35-50 year old women, hmm, something's weird\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3580:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've gotta pivot here\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 204, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3582:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 23\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Differing objectives require different tactics, that result in different outcomes\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 387, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3583:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [Jazzy hip-hop music] If there's one thing that storytelling teaches us about life, it's that different objectives require different tactics, that achieve different results\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 542, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3584:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Applying this theme to marketing reveals at least one universal truth: at the beginning of any project, make sure your entire team, especially the final stakeholders and decision-makers, are all seeing the same objective as the end goal\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 732, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3585:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One thing always leads to another\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 185, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3586:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let me give you a hypothetical\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 222, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3587:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you have different and conflicting objectives, you're gonna look for different tactics to achieve different results, and you're setting yourself up for incoherence\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 517, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3588:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let's imagine that we have a client together, and their goal is to sell their product online to 15-21 year old men on YouTube\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 502, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3589:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We lay out a 180 day strategy\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 212, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3590:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's a clear objective\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 211, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3591:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sales start to go up, and they can see that the conversion is coming from the audience on YouTube\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3592:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We start creating daily content on YouTube for them\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3593:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" Or, \"We don't like that there aren't more people coming from YouTube to our other social channels as we'd like there to be\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3594:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But then as we get towards the end of the schedule, the end of the strategy, someone remarks, \"We don't like that the number of subscribers to our YouTube channel isn't as high as we'd like it to be\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3595:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The target objective was to sell to 18-21 year old men on YouTube\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 267, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3596:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 14\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" Those notes provide an excellent opportunity to pivot towards new goals, but they were never the target objective\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 306, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3597:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 17\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When your team all has the same objective in mind and is measuring success the exact same way, that becomes your North Star\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3598:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 16\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But at the end, not everyone's measuring success the same way\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3599:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It allows you to assess so much easier going forward\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3600:\n",
      "  video_id: h1ZZHUU4j0k\n",
      "  clip_id: 18\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It makes hard choices so much easier\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 261, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3603:\n",
      "  video_id: hE-sA5umuCk\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hello Google, Hello People, and Hello Local Guides My name is Kim, and i'm a Master Student Researcher in The National University of Malaysia (UKM) Why i want to be a Local Guide?\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 671, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3604:\n",
      "  video_id: hE-sA5umuCk\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I travel places but not Sans Francisco, That's one of the reasons why i planned to join, i really want to join the Local Guides Summit because i want to meet different people from different places, listening to their reviews, feedbacks and recommendations, and also interact with people how to make a better place for future visits And i think that's all ! Arigatou Gozaimasu (Japanese Thank-You)\n",
      "  text_feature_shape: (1, 87, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1613, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 3606:\n",
      "  video_id: hbJfSyJKBEA\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, you've obviously picked your topic because you're passionate about it, and you've picked your topic because your audience will like it.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3607:\n",
      "  video_id: huzEsVEJPaY\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the ability of advertising, again, whether it's from a hospital, a physician, a drug company device, needs to be specific enough to satisfy their needs for both basic information and a direct link to what their concern.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1399, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 3608:\n",
      "  video_id: iFxFTtCQ6zA\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Maybe it's your co-founders, maybe it's people that raise money from investors.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 261, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3609:\n",
      "  video_id: iFxFTtCQ6zA\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sometimes, it's you go to pitch competitions that's also a good way to practice but the more you say your story, the better it will become over time.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 763, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3610:\n",
      "  video_id: iPPp6MCythU\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am almost afraid to ask this, but what are some of the other good and bad things about this furnace brand?\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3612:\n",
      "  video_id: iPPp6MCythU\n",
      "  clip_id: 16\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think that 41 percent favorable opinion means I should look to another brand for my furnace.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 738, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3613:\n",
      "  video_id: iPPp6MCythU\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is your lucky day, oh Danny boy, I know quite a bit about Payne gas furnace consumer reviews.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 571, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3615:\n",
      "  video_id: iPPp6MCythU\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well, if you considering the purchase of Payne gas furnace, only 41 percent of consumers have a favorable opinion of them.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3616:\n",
      "  video_id: iPPp6MCythU\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Although some consumers point to the fact that the furnace is a reliable, it just depends on who you choose to listen to I guess.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3619:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 10\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Granted, we all have met someone who never seemed to alter what they were saying based upon other peopleÕs comments, but that is someone who either has a story they want to tell and is unwilling to take any conversational detours or else they lack the language or cognitive abilities to do the necessary language processing that allows appropriate reaction to the interlocutorÕs comments.\n",
      "  text_feature_shape: (1, 80, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1639, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 3620:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 13\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Without some basic rules, most native speakers would find themselves lost most of the time, so what hope is there for non-native speakers.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3621:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well, native speakers have production strategies, or tricks, that they use to make the process smoother.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3622:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What Speakers Do Part 1 of 4 Before we can teach speaking to language learners, we need to understand the speaking process for native speakers and realize ways it is different from writing, which is also a production skill.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 753, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3623:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Spontaneity Both writing and talking involve an audience, but in writing, the audience either does not respond directly to the author or does so long after the writing has occurred.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 729, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3625:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This interlocutor, the person we are talking with, may ask a question or offer words of encouragement.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3626:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is the issue of unstructured interaction that makes conversation so challenging.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3627:\n",
      "  video_id: iXiMifHNKPI\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The speaker needs to answer the question or encouragement while continuing with the information they are sharing.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3628:\n",
      "  video_id: ihPjsliqz5o\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So for those of you who are interested in starting your own business or dealing with entrepreneurship this is definitely a topic that you need to pay close attention to.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 900, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3629:\n",
      "  video_id: ihPjsliqz5o\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So this week we're going to be looking at a topic  that should be of interest to those of you who have thought about or have previously dealt with owning or helping manage a business, and that is forms of business ownership.\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3630:\n",
      "  video_id: ihPjsliqz5o\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we'll look at things like what is a sole proprietorship.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3632:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 42\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They will have a daily huddle that has everybody in the company\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3633:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 22\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So on Mondays, each of our business areas has a one-hour weekly action review meeting\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 552, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3634:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 43\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But we have 25 people in our company right now as I'm recording this\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3637:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 25\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So all of my direct reports, I meet with each of them for up to an hour\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 341, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3639:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 27\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it's a lot of meetings on Mondays but you really get to set the week off in the right way\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 714, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3640:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: People ask me about this a lot\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3641:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 21\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Is that we have most of our meetings on Monday\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 228, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3642:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 48\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's something that has really, really energized our company\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3643:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 49\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have a great rhythm now where we know every day what meetings are happening, when\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3644:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 46\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So reach out to me if you have any questions about any of this, or leave a comment under this video\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3645:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 47\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'd be happy to give you any thoughts on this\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 376, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3646:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 44\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And it just isn't effective\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3647:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 45\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think if you have over ten people in your company, having a daily company-wide just becomes a little bit inefficient\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3648:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 28\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You get to start the week on the right foot and then the rest of your week is clear to work on the priorities and the goals, and the projects that you set for yourself at the beginning of the week\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3649:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 29\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then throughout the rest of the week, we do a few different things\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3650:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 40\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And there are a lot of businesses\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 199, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3652:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're adding more people to your team, or if you've just already got a decent sized business\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 361, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3653:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ﻿If your company is growing\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 113, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3654:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And what kind of meetings your company should be having\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3655:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then you're probably thinking a lot about how your company can have more effective meetings\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3656:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So a couple months back, at the recommendation of some friends, I spent about a month diving into the best resources on meetings\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1049, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 3657:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that's what I want to talk about in this video\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 534, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3658:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Cameron Harold's, Meetings Suck\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3659:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Three books that I got were Patrick Lencioni Death by Meeting\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 675, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3660:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I believe it was either Scaling Up, or Retraction\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 371, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3661:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then I spent a lot of time reading the chapter on meetings in Scaling Up\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 681, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3662:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 39\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's the only meeting we have in our company that is everybody in the company for one hour\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 545, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3663:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 38\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then on Wednesdays, we have a one-hour company-wide meeting\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 670, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3664:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And at the end of the day, what I found is that all fast-growing companies that are successful have a regular rhythm, and are in a really cohesive structure for how they are meeting\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3665:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 10\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Both of those books have stuff on meetings\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3667:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They don't just willy-nilly have meetings at random times\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3668:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They have different one-on-one meetings\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3670:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 17\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the meetings are happening with a real rhythm and a real structure\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3672:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So what we ended up doing in our company\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3673:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 18\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Like I said, not just randomly\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 338, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3674:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 31\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we'll have a couple of different ones\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 534, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3675:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 30\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have daily huddles that are about 15 minutes long, sometimes less, depending on the number of people in them\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3676:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 51\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I'll tell you, everybody on our team that has really loved it and it's made us a lot more productive\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3678:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 35\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So on one day, I will attend a meeting with our training division\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3679:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 34\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And myself and our CEO, we will bounce in and out of different meetings each day\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3680:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 33\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And then each business area has a huddle each day\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3682:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 32\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have a leader huddle which is for the leaders in the company, our senior leadership\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 311, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3683:\n",
      "  video_id: j1m6ctAgjsM\n",
      "  clip_id: 50\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And a really specific structure for how these meetings are conducted\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3684:\n",
      "  video_id: jE3gYsxr_5s\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the three percent; there are many, many programs, state programs, local programs that will help a first time home buyer to obtain the remaining balance or what's left of the price, the purchase price in order to have a hundred percent financing.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1149, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 3686:\n",
      "  video_id: jE3gYsxr_5s\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Again, my name's Adriel Torres, and I'm the owner of ultimatecredittoday.com\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 293, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3688:\n",
      "  video_id: jLN6B0aSrW0\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: and sweat levels are related to emotional arousal and on your hands and on the soul of you feet and your forehead, sweating is related to emotional arousal\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 623, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3690:\n",
      "  video_id: jLN6B0aSrW0\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also pick up on your heart by putting sensors and how much you re moving around\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3691:\n",
      "  video_id: jLN6B0aSrW0\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But you could also in this interface look back in history\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3696:\n",
      "  video_id: jXQmVFcOiUI\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: DEAN DAVID: As a university we really cherish international friendship and collaborations.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 351, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3697:\n",
      "  video_id: jXQmVFcOiUI\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: CHAIR RICHARDS: It's fascinating because there was a language barrier in a lot of cases, as well as a cultural barrier.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3699:\n",
      "  video_id: jZe-2w7pkd8\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So do your original work, keep reading plays, find new plays, look at contemporary plays and commit yourself to finding something that has not been done before.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3701:\n",
      "  video_id: jZe-2w7pkd8\n",
      "  clip_id: 14\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They simply have been written to allow lazy actors easy speeches to audition with.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 834, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3702:\n",
      "  video_id: jZe-2w7pkd8\n",
      "  clip_id: 16\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You can tell that this is a book, because if you go to the end, you won't find anything that references the play these speeches are from.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 463, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3703:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Over the past four years, average County property taxes have gone up a total of only $9 – or less than $3 per year.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3704:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Even with this recommended increase, County taxes -- as a share of County residents’ personal income -- have decreased by 5 percent over the past ten years.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 903, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3706:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 17\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I believe this budget will continue our valuable work to move Montgomery forward and help build a better future for all of us.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3707:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 16\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want to thank County residents for all the input I have gotten from you over the past six months concerning what is important to you.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3708:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It increases County spending on the Montgomery County Public Schools by almost $136 million ($90 million over Maintenance of Effort) and It addresses a $50 million loss to County revenues caused by the Wynne court case.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1246, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 3709:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today I am pleased to release my Recommended FY17 Operating Budget of $5.3 billion for the year that begins on July 1, 2016. This budget does two big things.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 793, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3710:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Over the last ten years, I have closed over $3.3 billion in budget gaps while putting the County’s fiscal house back in order and making the investments necessary to build a better future.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 923, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3711:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Our public schools have been funded at, or below, the level defined as ‘Maintenance of Effort’ since FY 09. On a per-pupil basis, funding has not increased.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 998, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3712:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Lighting the lamp of learning is the most important thing we can do.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 356, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3713:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I believe we must provide the Superintendent and the Board of Education with additional funding to further address these challenges.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3714:\n",
      "  video_id: jj8aSNPHMw8\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There has not been sufficient progress in closing the achievement gap that exists between many of our minority students and non-minority students.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3716:\n",
      "  video_id: jqutn5ou8_0\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The S&amp;P 500 finished down 0.1% while the NASDAQ finished up 0.1% and the Dow finished down 0.2%. We have a weekly look at the markets coming up for you with the stock market today video, I'm about to go record that, and I also have details on four top-notch growth stocks that could provide actionable trading in the coming week.\n",
      "  text_feature_shape: (1, 85, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1284, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 3717:\n",
      "  video_id: jqutn5ou8_0\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's where you can get those four stocks as well as others that are good to keep an eye on.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3718:\n",
      "  video_id: jqutn5ou8_0\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also, as always, feel free to share your comments on the market action and be sure to like and share this video as well.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3719:\n",
      "  video_id: jqutn5ou8_0\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also, we have a link right now to our last stock market today story update, so if you want further detail on the market action and notable movers, you can check that out in the meantime.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3720:\n",
      "  video_id: jqutn5ou8_0\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And don't forget to subscribe to our live notifications so that way every time we go live you will get an alert.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3721:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 24\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Just reserve your time and your eyes and your ears and your entire life for Him, and He will lead you and He will guide you, He won't let you down.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 598, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3722:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There are so many distractions and people are not willing to get those out of their life.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3723:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Unless you rid yourself of all these distractions you are NOT going to be able to hear from the Holy Spirit clearly.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 561, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3724:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 27\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It is such a blessing, and I wouldn't trade it for anything.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3726:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And if you give Him your entire life and all of your time, He will NOT disappoint you.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 676, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3728:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 30\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Don't let the devil lie to you and tell you; \"It's boring it's miserable... you have to give up all this stuff...\" WHO CARES!! JESUS OFFERS ETERNAL LIFE!\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 760, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3729:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We would learn the reason we do not hear from God clearly is because of all the distractions and all the noise of our culture.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 863, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3730:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For many years I sat in church and would hear the pastor's sermon.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 271, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3731:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And if you are not obeying Him you cannot possibly be pleasing to Him.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3732:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 4\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you cannot hear from Him, HOW can you follow Him and obey Him?\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3733:\n",
      "  video_id: jscKL5jS-SQ\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It starts with a relationship with Him in prayer, seeking Him in private.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 396, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3734:\n",
      "  video_id: k1BrzX5bc7U\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" The first thing that you want to ask yourself is what is the dress code\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3736:\n",
      "  video_id: k1BrzX5bc7U\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They want to have a certain type of feeling which happens whenever people take the time to put themselves together\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 555, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3737:\n",
      "  video_id: k8yDywC4gt8\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: but the bonnet, when they're outside, has these things that are referred to as wings, and it's this white like cone kind of thing\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 652, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3738:\n",
      "  video_id: k8yDywC4gt8\n",
      "  clip_id: 3\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The interpretation of it at the show works so well visually\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 288, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3739:\n",
      "  video_id: k8yDywC4gt8\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They kind of show it on the cover of the book, this is like one person's interpretation of it\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3740:\n",
      "  video_id: k8yDywC4gt8\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: First of all the all red like tent dress which is both oddly kind of alluring\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 561, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3741:\n",
      "  video_id: kI6jzM_aLGs\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have experience in teaching general English business English  as well as exam preparation.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 400, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3742:\n",
      "  video_id: kI6jzM_aLGs\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I come from South Africa I'm a native English speaker and I'm currently teaching English online.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 404, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3744:\n",
      "  video_id: kLAXmTx2xOA\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You have a selective movement that continues to privilege certain voices and certain experiences\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 371, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3745:\n",
      "  video_id: kXhJ3hHK9hQ\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Gettier wrote a short but fabulously influential paper that turned the standard understanding of knowledge upside down\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 435, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3746:\n",
      "  video_id: kXhJ3hHK9hQ\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: cat as a cat through my direct contact with it It looks, feels, acts like a cat\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3748:\n",
      "  video_id: kXhJ3hHK9hQ\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Until American philosopher Edmund Gettier came along in the 1960s, philosophers were in pretty widespread agreement about the definition of knowledge -- that it’s justified true belief\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 742, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3749:\n",
      "  video_id: kXhJ3hHK9hQ\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And if something you thought you knew turns out not to be true, then the fact is, you never actually knew it, you just believed it\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3750:\n",
      "  video_id: kXhJ3hHK9hQ\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In other words, you can have a false belief, but you can’t have false knowledge\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3752:\n",
      "  video_id: kXiBdruxTvE\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We are from Elbasan and came to Tirana 5 years ago, and we pastor the church \" House of the Prayer\", located in Bregu I Lumit, Tirana.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 854, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3756:\n",
      "  video_id: kaudsLIvYC8\n",
      "  clip_id: 1\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The logistics were pretty tough getting supplies, getting people into Haiti, annd that has gotten better today.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 550, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3757:\n",
      "  video_id: kaudsLIvYC8\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well I think the good news is a government wide agressive assistance program is very much under way and things get better each and every day.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 611, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3758:\n",
      "  video_id: kaudsLIvYC8\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We at HHS have had just under 300 people on the ground in medical teams, in mortuary teams who have been assisting identifying and processing of the remains of victims and we have folks who have been assisting in the search and rescue mission.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1157, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 3760:\n",
      "  video_id: kbRtSmJM5aU\n",
      "  clip_id: 9\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Matter of fact, maybe it's a question of of doing that due diligence on yourself, and also start to build towards changing these behaviors so that you become this good person, and becoming more principled, dependable, honorable, etc.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1039, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3762:\n",
      "  video_id: kg-W6-hP2Do\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For example, I could take a set of data and from that data, I can find a relationship between any two of the given factors or more.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 477, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3763:\n",
      "  video_id: kg-W6-hP2Do\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And if this company ever needs to make some changes to the budget I can make myself useful there, too.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 326, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3764:\n",
      "  video_id: kg-W6-hP2Do\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By doing that, I would be able to save the accountants a lot of time whenever they check the records.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3765:\n",
      "  video_id: kg-W6-hP2Do\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I take my responsibilities very seriously, sir and I am not one to abuse his opportunities.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 317, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3766:\n",
      "  video_id: kg-W6-hP2Do\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm also very good at cooperative efforts and I can collaborate in groups just as well as when I work on my own.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 385, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3770:\n",
      "  video_id: kld9r0iFkWM\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you finish this course, you'll be able to answer three essential questions-- how do I identify the product features that customers want most?\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3771:\n",
      "  video_id: kld9r0iFkWM\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: How can I take advantage of each step in the sales process to boost sales?\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3772:\n",
      "  video_id: kld9r0iFkWM\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Which distribution channels, such as brick and mortar stores and e-commerce sites, should I use?\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3773:\n",
      "  video_id: kld9r0iFkWM\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now join me as we tackle this leg of our journey into marketing analytics.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3775:\n",
      "  video_id: kmgsC68hIL8\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Also, I love that he thinks the first thing a middle-class family would do with $1,000 is renovate their kitchen\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3776:\n",
      "  video_id: kmgsC68hIL8\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The best you could do with $1,000 is take Uber everywhere for a week\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 238, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3777:\n",
      "  video_id: kmgsC68hIL8\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: \" \"Oh, hey, I just found a $5 bill in my jeans\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3778:\n",
      "  video_id: kmgsC68hIL8\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Why don't I take us all to the movies\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3780:\n",
      "  video_id: kmgsC68hIL8\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" So Trump doesn't have the basic human decency to show compassion and grace towards victims of a natural disaster\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3781:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 11\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And, indeed, the United States will stand with the international community in affirming that there will be costs for any military intervention in Ukraine\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3782:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 10\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And just days after the world came to Russia for the olympic games it would invite the condemnation of nations around the world\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 569, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3783:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the Ukrainian people have also reminded us that human beings have a universal right to determine their own future\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3784:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 12\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The events of the past several months remind us of how difficult democracy can be in a country with deep divisions\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3785:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 15\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Vice President Biden just spoke with the Prime Minister of Ukraine to assure him that in this difficult moment the United States supports his government's efforts and stands for the sovereignty, territorial integrity and democratic future of Ukraine\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1174, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 3786:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 14\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Right now the situation remains very fluid\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 316, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3787:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And its commitment to uphold its international obligations\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3788:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 16\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I also commend the Ukrainian government's restraint\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3789:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 19\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We will continue to communicate directly with the Russian government\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 293, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3790:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We will continue to coordinate closely with our European allies\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3791:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Over the last several days the United States has been responding to events as they unfold in Ukraine\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3792:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: President Obama: Good afternoon everybody\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 184, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3793:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Together with our European allied, we have urged an end to the violence and encouraged Ukrainians to pursue a course in which they stabilize their country, forge a broad-based government, and move to elections this spring\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 926, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3794:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now throughout this crisis we have been very clear about one fundamental principle: the Ukrainian people deserve the opportunity to determine their own future\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3795:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 5\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: However, we are now deeply concerned by reports of military movements taken by the Russian Federation inside Ukraine\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3797:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But any violation of Ukraine's sovereignty and territorial integrity would be deeply destabilizing, which is not in the interest of Ukraine, Russia, or Europe\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 646, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3799:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 9\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It would be a clear violation of Russia's commitment to respect the independence and sovereignty and borders of Ukraine, and of international laws\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 621, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3800:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 20\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And we will continue to keep all of you in the press corps and the American people informed as events develop\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3801:\n",
      "  video_id: kpS4BXif_Sw\n",
      "  clip_id: 8\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It would represent a profound interference in matters that must be determined by the Ukrainian people\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3802:\n",
      "  video_id: ktblaVOnFVE\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: more than I ever have, to eat healthily\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 183, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3803:\n",
      "  video_id: ktblaVOnFVE\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I mean, I haven't cut down completely on cow's milk because i prefer the taste of cow's milk to almond milk and I'm not a vegan\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3804:\n",
      "  video_id: ktblaVOnFVE\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But since that conversation, I have been eating significantly healthier\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3805:\n",
      "  video_id: ktblaVOnFVE\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because I've always believed that both are equally as important, but generally, I try to be more logical than impulsive\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 519, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3806:\n",
      "  video_id: ktblaVOnFVE\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However, this got me thinking, I guess, about the value of impulse versus reason and logic and consideration\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 959, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3808:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 13\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: He has forced a discussion about problems that would have otherwise been ignored.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 489, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3809:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He has been the most authentic of the nearly two dozen who ran for President this year.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3810:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sanders may not win at the ballot box, but he has already won something just as important.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3811:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 14\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And he has done it without insulting entire classes of people, without hurling invective at his critics, without assaulting the sensibilities of half the American public.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 686, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3813:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 18\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Throughout the life of great democracies, great causes have been born because one candidate dared do, dared say, dared to champion an idea no one else would.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 751, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3815:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: No one better illustrates that example than Senator Bernie Sanders.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3816:\n",
      "  video_id: l0vCKpk6Aes\n",
      "  clip_id: 20\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And if you succeed in giving life to your cause, you win even if you come up short at the ballot box.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3817:\n",
      "  video_id: l1jW3OMXUzs\n",
      "  clip_id: 0\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: been thinking about the debate that always, you know, gets rehashed each time the minimum wage proposal is put on the table\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3818:\n",
      "  video_id: l4oMbKDuW3Y\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One of the problems that the Middle East is suffering from is how many young people do we have, and the amount of despair and lack of role models that exist.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 851, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3819:\n",
      "  video_id: l4oMbKDuW3Y\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They still have a clear vision, good education, good ethics, hard working, and really have a view for a better future for everybody not just in good of interest or other countries in the world.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 854, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3820:\n",
      "  video_id: l4oMbKDuW3Y\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think people are looking at today's leaders and we are brutally disappointed or feel lost.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3821:\n",
      "  video_id: l4oMbKDuW3Y\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And more importantly corruption seems to be the name of a lot of games being played whether it's in politics or across the world or just in the Middle East.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 995, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3823:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Once you're in a workplace others are going to tell your story and make sure that story of something that you want to hear\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 683, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3824:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Most of your career when you're in high school and college you're telling your story to get that next level\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 395, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3825:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 1\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I ran out of money, it was classic\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 353, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3829:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Local 863 and I was receiving selecting and shipping the loads that were going up toour non-foods\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 366, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3831:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And, you take that and you make that part of your story and your narrative as you go forward\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3832:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I examined a lot of leaders and Wakefern I was fortunate Wakefern as a lot of great leaders, and I took a little bit of each of their story about respect or communication or clarity or just being in the moment\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 931, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3833:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Create a story that others are going to tell about you\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3834:\n",
      "  video_id: lD4xtQ6NpDY\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And, there were a lot of mentors and a lot of leaders that were willing to take their time both formally and informally and guide us forward\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 760, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3835:\n",
      "  video_id: lO6N9dyvPTA\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it's fair to say that India is going to be a global superpower.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3839:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You can see the birth rates fall to US levels and sometimes below\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 309, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3840:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Latin America now has a workforce that is growing at a slower pace\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 273, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3841:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: At the same time you can watch the GDP per capita of these countries triple\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3842:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: When the US economy recovers, large-scale Latino immigration will not\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 450, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3843:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: At the same time, this work force has many new opportunities\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 477, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3844:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 9\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Nobody in Washington DC, Democrat or Republican, is willing to acknowledge the simple fact\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3845:\n",
      "  video_id: lYwgLa4R5XQ\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The people necessary to restart the immigration boom are simply not there\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 433, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3846:\n",
      "  video_id: lc5bSoGlQwY\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I am not a gifted man, but just an ordinary, average man,   like any one of you.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 659, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3848:\n",
      "  video_id: lc5bSoGlQwY\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I may not have been in the inner circle like Peter, but I haven't been in the outer circle either.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 334, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3849:\n",
      "  video_id: lc5bSoGlQwY\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I found the little lad with the five loaves and two fish  that day when Jesus fed the five thousand.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3850:\n",
      "  video_id: lc5bSoGlQwY\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: He must have seen something of value in me which the others overlooked,  because He selected me to be one of the twelve apostles.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 622, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3851:\n",
      "  video_id: lkIe41StoGI\n",
      "  clip_id: 11\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Call back as soon as possible\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 299, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3854:\n",
      "  video_id: lkIe41StoGI\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: To inquire about voicemail, press 3\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 139, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3855:\n",
      "  video_id: lkIe41StoGI\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you are using another provider please press *123 for sending voice mail\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 315, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3856:\n",
      "  video_id: lkIe41StoGI\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Charges on national calls are 8 cents per minute and 14 cents per minute on international calls\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 571, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3857:\n",
      "  video_id: lkIe41StoGI\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Charges per minute on national calls are 12 cents and 20 cents per minute on international calls\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 485, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3859:\n",
      "  video_id: lkIe41StoGI\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We are all waiting for you to cut my birthday cake\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3861:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't feel like it damaged me\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 239, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3862:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I remember being raised religious\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 112, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3863:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think a lot of Christians-- ex Christians would agree with that, too, but it didn't hurt me\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 399, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3864:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think I learned a lot of things that were untrue\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 400, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3865:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So, how could that be abusive in any way\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 235, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3866:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I felt good being religious because I thought my values and morals were in the right place\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 352, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3867:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Yeah, I think that's a form of child abuse\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 310, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3868:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And thankfully most states have laws that will prosecute the parents who let that happen\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 567, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3869:\n",
      "  video_id: lkeVfgI0eEk\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think if you're allowing your kids to die because prayers are going to save them, that's abuse\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3870:\n",
      "  video_id: lrjm6F3JJgg\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So definitely pickup a book, check with your library, they also have a lot of sample business plans, and just kind of do it piece by piece, you don't have to start from the beginning, and kind of start off with what you know the most.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1109, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 3872:\n",
      "  video_id: lwL4hjhkid4\n",
      "  clip_id: 0\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We're afraid to be depleted, and so we don't give\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 178, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 3873:\n",
      "  video_id: lwL4hjhkid4\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I was inspired by anthropologist Robin Dunbar, who says that the number of people with whom you can maintain stable, ongoing social interaction is approximately 150\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 742, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3874:\n",
      "  video_id: lwL4hjhkid4\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Beyond that, most of us lose our capacity for meaningful connection\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 525, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3875:\n",
      "  video_id: lwL4hjhkid4\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, in my Facebook experiment, I stayed friends with everyone, but I followed only a select few\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 597, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3876:\n",
      "  video_id: lxBKEPIUSgc\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Opposition leader Sheikh Imran was sentenced yesterday to 12 years in prison for speaking at an opposition rally.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3877:\n",
      "  video_id: lxBKEPIUSgc\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Imran is the third prominent politician to receive a lengthy sentence in just the past 12 months, and in each instance the government failed to provide an appropriate – or rather failed to provide appropriate procedural and substantive protections in accordance with Maldivian law and Maldives’ international obligations.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1011, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3878:\n",
      "  video_id: m-7yRWZLwLY\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we need to find out what we are doing like many other countries have done that, which means we need to set the right foundation, we need to identify what's our competitive advantage, make sure that we build on those.\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 623, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3880:\n",
      "  video_id: m-7yRWZLwLY\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Not an easy task, but then something that's good and I'm sure all of us here in India are raring to go.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 3881:\n",
      "  video_id: m-7yRWZLwLY\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And very clearly we have many weaknesses as well which need to work out.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3882:\n",
      "  video_id: mRqqH_gx7Q0\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Studies have shown that the more engaged a company is internationally, the more productive it is.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 324, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3883:\n",
      "  video_id: mRqqH_gx7Q0\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Directly, if they are invested in some of the high-growth sectors in California, such as computers and electronics -- and these are sectors that are growing very, very strongly into Europe -- and indirectly because California is home to the largest number of SME exporters, all of whom are going to benefit from T-TIP.\n",
      "  text_feature_shape: (1, 69, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1345, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 3884:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are actually two reasons\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 284, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3885:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because what I have in mind is a civil dialogue\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 319, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3886:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But maybe you can help us thinking about this\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 143, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3887:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But in a dialogue you really listen to the other person in order to really understand him or her\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3888:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Not a civil debate because in a debate you try to convince the other of your opinion\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 586, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3889:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 5\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we don’t have to agree on everything, but we just all have to feel comfortable about it\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 674, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3890:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And in this way we can formulate a response to the decision of the European court as a country\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3891:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But then the question is: How do you start a dialogue like that\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 495, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3893:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let’s start with the question why we have the life imprisonment sentence\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3894:\n",
      "  video_id: mVnqP-vLpuo\n",
      "  clip_id: 8\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Well, let me start the dialogue and then you can continue it by thinking about my opinion and by responding to it\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 446, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3895:\n",
      "  video_id: mZ_8em_-CGc\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: OK, I know what the weather is going to be like for Sunday when I plan to look at this particular property.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 679, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3896:\n",
      "  video_id: mZ_8em_-CGc\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And even though the weather forecasts were only essentially daily, and then they subsequently over time become refined to be hourly, that initial implementation of adding forecasts to open house information allowed us to market open houses in a new way.\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1229, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 3897:\n",
      "  video_id: mfpR4CN9LZo\n",
      "  clip_id: 24\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're more like a punky sort of vibe, then there's different advertising, different stores for that.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 576, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3899:\n",
      "  video_id: mfpR4CN9LZo\n",
      "  clip_id: 23\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want to be sort of more like a hippy-dippy, I feel like there's a look for that, and there's advertising geared towards that.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 606, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3903:\n",
      "  video_id: mgsvwAVQAQo\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And this was a thing that we had a bit of a conversation about before shooting the episode\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3904:\n",
      "  video_id: mgsvwAVQAQo\n",
      "  clip_id: 0\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: they were called all manner of names like sissy, girly, et cetera, et cetera\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 208, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3906:\n",
      "  video_id: mgsvwAVQAQo\n",
      "  clip_id: 5\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So thank you to everybody who wrote a comment about that idea, letting us know your experiences\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 603, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3907:\n",
      "  video_id: mgsvwAVQAQo\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But, of course, that doesn't mean that other people have had exactly that experience and so there was definitely room for more nuance when we made that point\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 743, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3909:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 21\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If there's no reaction, then you're probably safe to use these products together with your Genius Ultra\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3910:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 22\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I hope this helps clear up any questions that you had\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3911:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 1\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Have you treated your loved ones or yourself to a Genius Ultra? How rewarding would it be to give your mom, your sister, your brother or your best friend the gift of beautiful, youthful-looking skin in 2017? Today's Tuesday Tip is about which products work best with your Genius Ultra and which ones to avoid\n",
      "  text_feature_shape: (1, 65, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1331, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 3912:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi and welcome to the Tuesday Tip! We are in the middle of the gift giving season\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3913:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Here on my left are some products we recommend you use with the Genius Ultra\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 671, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3914:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The good news is that most Arbonne skincare products are perfect pairs to use with your Genius Ultra\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3915:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now on my right is a different story\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3916:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You'll see some RE9, some Calm some RE9 Advanced for Men and some body products! You're good to go! There are so many products outside of just what is here that you can use with your Genius Ultra\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 957, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3917:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I'll tell you why Don't use with products that contain SPF\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3919:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The efficacy of the SPF can be compromised if used together because of the chemical or mineral sunscreen composition\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3920:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is any day cream or moisturizer which says SPF on the front panel\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3921:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Just don't use them together\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 148, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 3922:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However, we do recommend using an SPF after you finish the Genius Ultra during the day\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 474, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3923:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 13\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This include the entire Clear Future Collection\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3925:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 15\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Last but not least, are products you would normally use with water\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 274, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3927:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 17\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Genius Ultra cannot be submerged or put under running water\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3928:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 16\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This includes cleansers, shaving creams, rinse-off masks\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3929:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now, if you're hesitant about how your skin will react to the Genius Ultra with specific Arbonne products, we recommend you test them together on the inside part of your forearm\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 633, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3930:\n",
      "  video_id: mmg_eTDHjkk\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it's best to steer clear when using these types of products with your Genius Ultra\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 461, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3931:\n",
      "  video_id: mzAu5gxjE-w\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: we've been in business for four years and we've been doing sustainability for four years before it was called sustainability.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 534, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3932:\n",
      "  video_id: mzAu5gxjE-w\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi I'm Tom McGovern, the President of Rockford Construction and we're a full service construction manager general contractor Cascade engineering is a manufacture of plastic injection molding parts.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3933:\n",
      "  video_id: mzAu5gxjE-w\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Over the past two years we've been very very a successful in growing our business to pre-recession levels we added approximately 40 members to our group we found that the talent that was available in the market was exceptional and we're very excited about that opportunity.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 911, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 3934:\n",
      "  video_id: mzAu5gxjE-w\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our shades of green is a green process which helps owners decide what will level of sustainability make sense for their business we can see additional sales coming in and more profits for the company with those profits we can then turn those around into environmental and sustainable and social improvements so we have the full picture of sustainability We're very excited.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1133, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 3935:\n",
      "  video_id: nFTo-Lz4Fr8\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we were very fortunate and were able to capitalize on that because we had a savings message out that the public was hearing.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 881, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3936:\n",
      "  video_id: nFTo-Lz4Fr8\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So finding the message that worked for the time really helped us capitalize on the situation.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 686, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3937:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 13\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's the kind of thing that earns our trust in those markets that helps the premium prices for our goods and demonstrates that we're an economy that isn't complacent, that understands what the market needs and will do what it takes to be successful in those markets.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1386, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 3938:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 14\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I think that's a bit of a contrast to the attitude we're seeing as the Opposition try to find a new leader where you'd think the job was done, we can all put our feet up and start handing out lollies to everybody.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 744, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3939:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 17\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The world we're in is one where New Zealand is increasingly succeeding because it's so resilient, our economy is more adaptable and flexible, and the Government is going to keep driving in that direction.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 712, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3940:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A few weeks ago the Governor of the Reserve Bank pointed out that New Zealand will in the next 12 months be one of the faster-growing developed economies.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3941:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We find the recovery is becoming increasingly positive but is still a bit patchy where some industries and businesses are still struggling and certainly there are still people looking for jobs.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 874, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 3942:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They've had decades with no recession, they're going through a bit of an adjustment and I've been a bit surprised at how much that has affected the legendary Australian confidence.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 739, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3943:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 4\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I was in Australia just last week and there's a mood there of some frustration, I think.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3944:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They've got some economic challenges too at the moment with the large emerging markets slowing down.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 686, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3945:\n",
      "  video_id: nTZSH0EwpnY\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The hot money that flowed in there a few years ago is starting to flow back to the US and that is a risk for New Zealand.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 676, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3947:\n",
      "  video_id: nZFPKP9kBkw\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Really, really a depth of understanding with our consumers is one of the biggest ways that we catalyze great creativity.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 461, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3948:\n",
      "  video_id: nZFPKP9kBkw\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And really giving people room to grow in that experience and take chances, I think, really does foster great creativity.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3951:\n",
      "  video_id: nZFPKP9kBkw\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that senior managers who make it a priority and build the capability in the organization and show the faith that both our external partners and internal to the company that we can get to great breakthrough is a key part of that as well.\n",
      "  text_feature_shape: (1, 49, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1046, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 3952:\n",
      "  video_id: naZi9AusrW4\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Over the past year, nearly 90% of European employees have either cut their budgets for training programs or discontinued spending altogether.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 479, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3953:\n",
      "  video_id: naZi9AusrW4\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They also are struggling to ensure their existing employees are able to rise to the various challenges they face.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3954:\n",
      "  video_id: namehdJxRIM\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that's the one I know the best\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3958:\n",
      "  video_id: namehdJxRIM\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And if I read that PowerPoint and those handouts, I could very well determine if that person was doing thoughtful, informed, evidence based scholarship\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 606, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3960:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 12\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well then you don't have any expendable income available to make a payment towards a mortgage.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 256, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3961:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And certainly over the next couple of years  you may be able to do that.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 218, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3962:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 16\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Most lenders, most mortgage lenders, assuming  you're able to show them you can make that  thirty percent pain thirty percent payment  will be willing to loan you the money after  eighteen to twenty four months.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 519, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3963:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Call me corny,  Everyone knows that buying a home is impossible once you file bankruptcy.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3965:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: but I've always dreamed of a quant house with a white picket fence and pristine grass since I was a little kid.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 237, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 3968:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In determing  why you're going to be able to get financing on a home after bankruptcy it's important to  understand what banks consider when determining whether or not to loan you money.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 490, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3970:\n",
      "  video_id: nbru7qLot04\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: other words how much outstanding debt you have relative to the income that you have In other words, how much outstanding debt you  have relative to the income that you have  to support those debt payments.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 325, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3972:\n",
      "  video_id: o2XbNJDpOlc\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: For a long time I was a Christian who could not perceive the Kingdom of Heaven.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3973:\n",
      "  video_id: o2XbNJDpOlc\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can read about this in Luke Chapter 11. Jesus promises the Holy Spirit to guide those who truly want to seek HIM.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 661, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3974:\n",
      "  video_id: o2XbNJDpOlc\n",
      "  clip_id: 17\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Because without the Holy Spirit you have NO POWER, you can do NOTHING.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 3975:\n",
      "  video_id: o2XbNJDpOlc\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you want the Holy Spirit baptism, where you need to go is Jesus.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 596, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3976:\n",
      "  video_id: o2XbNJDpOlc\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We can’t bring a soul into the Kingdom of Heaven unless we have entered the Kingdom of Heaven.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3980:\n",
      "  video_id: oBS-IW-BO00\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I want to tell you something, it's totally okay to cry in your eulogy, because the chances are that everybody else is going to be crying to.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 997, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 3981:\n",
      "  video_id: oGFDE-6nd7Q\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One of the ways to break this cycle of mind - body and back and forth, notice when my jaw is tense, to actually unlock it\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 3982:\n",
      "  video_id: oGFDE-6nd7Q\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: blood sugars decrease, my blood pressure decreases, my body relaxes a little bit which in turn signals to my brain that we're not under attack\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3983:\n",
      "  video_id: oGFDE-6nd7Q\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If I find that my neck is tight, relaxing it, stretching it, which will in turn send a signal to my mind that we're 'OK\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 3985:\n",
      "  video_id: oGFDE-6nd7Q\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the things you can do, is you can find people who will actually listen to you\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 297, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3986:\n",
      "  video_id: oGFDE-6nd7Q\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We assume that a lot of people don't want to hear us and don't want to listen to us complain\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 616, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3987:\n",
      "  video_id: oH9fMma8jiQ\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In that moment, I want to act as if that's the first time I'm ever allowing those words to come out of my mouth, and it's something that I'm very excited about, passionate about, enthusiastic about.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 733, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 3988:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sometimes, posting a TED talk about the subject, or an inspiring article can motivate students to stay engaged\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 3989:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 3\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: By posting even loosely connected ideas on Teams, you're encouraging a safe space for students to learn the same\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 552, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3990:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Even an image, a meme, or a funny cartoon can keep your Team space alive\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3991:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 5\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is great for teacher announcements, student suggestions, or questions\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 3992:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Likes are a form of recognizing that the teacher and or students have seen that post\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3993:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You'll be in a live space to invite others to discuss things out loud\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 3994:\n",
      "  video_id: oHff2W51wZ8\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Teachers can also suggest a live meeting with just one click of the meet now button at the bottom right of a conversation\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 586, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 3995:\n",
      "  video_id: oPlnhc0DkcU\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Home prices are stabilizing and even turning up in some markets.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 423, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3996:\n",
      "  video_id: oPlnhc0DkcU\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Tracking consumer cash flow as an indicator of future consumer spending, the Deloitte Consumer Spending Index (Index) posted its fourth consecutive increase in June.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 3997:\n",
      "  video_id: oPlnhc0DkcU\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Most refinances are being done for a lower payment as there is little equity to be cashed out.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 661, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 3998:\n",
      "  video_id: oPlnhc0DkcU\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Record low interest rates are giving a small boost to demand and helping to increase refinancing activity.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 3999:\n",
      "  video_id: oPlnhc0DkcU\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Alison Paul, vice chairman, Deloitte LLP and retail &amp; distribution sector leader comments: \"Retailers can capitalize on changing consumer behavior, such as embracing shoppers' use of mobile technology in the store,\" she said.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1003, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4000:\n",
      "  video_id: oQizLbmte0c\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Even the most trustworthy sales person can’t guarantee an investment will increase in value,  however the investor who understands risk management and knows how to avoid costly mistakes will be the investor that sleeps well at night and takes control of their future!!! The three keys to wealth are: Risk Management, then Compound interest, then Leverage.\n",
      "  text_feature_shape: (1, 70, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1383, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 4001:\n",
      "  video_id: oQizLbmte0c\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Creating an investment strategy for life is easy when you have the right tools; and I’ve done all the hard work for you.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 441, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4002:\n",
      "  video_id: oQizLbmte0c\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Making emotional decisions, Leverage, and Risking everything.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4003:\n",
      "  video_id: oQizLbmte0c\n",
      "  clip_id: 15\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All the best with your investing, I Look forward to chatting with you…Cheers Marty.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4004:\n",
      "  video_id: oQizLbmte0c\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you would like to know more, please view the blogs on my website, watch the videos on my youtube channel and if you like what you see;  please join my investing community by subscribing on youtube, joining my mailing list or liking my facebook page.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1126, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 4005:\n",
      "  video_id: oQizLbmte0c\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Did you know saving for a home deposit, paying off your mortgage faster, investing and Superannuation is really easy!\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 729, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4007:\n",
      "  video_id: oZxMx8e0x2U\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I get asked all the time from people that come in just off the street wondering if they pay too much tax.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4009:\n",
      "  video_id: oZxMx8e0x2U\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Mostly small business people wondering if they pay too much tax.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 341, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4011:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 11\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When I was pregnant for the first time, I started calling up friends of mine who had babies and making lists of everything I needed from the big to the small.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 611, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4012:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 26\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it's not like it's gonna be something you have to wait forever for.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 526, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4014:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 21\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And here are the benefits to waiting in my view... Three things.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4015:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 23\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can buy them online and get them quickly within one or two days shipping.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 522, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4016:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 33\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For that pair of stilettos that you couldn't wear when you were pregnant.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4017:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 31\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So you really wanna make sure you have a sense of your budget and you're saving money for the things that are right around the corner.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 621, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4018:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 30\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Number three, right around the corner, when it comes to babies, there's gonna be a ton of other things you have to buy, really essential things, new clothes, bathing suits, the high chair, it's gonna keep going.\n",
      "  text_feature_shape: (1, 50, 768)\n",
      "  audio_feature_shape: torch.Size([1, 756, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4019:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Read a very very interesting piece in the New York Times' Motherlode blog by KJ--I can never get this name right, Dell'Antonia, love that name.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 828, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4020:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 16\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I felt like I didn't know what I was doing and I didn't want to be caught without something that was truly essential.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4021:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want to know what the KJ stands for--talking about when moms buy for their babies and how there can be a tendency to buy too much.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 843, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4022:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's a doctor interviewed in the blog, her name is Dr. Jennifer Trachtenberg.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 343, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4023:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They buy because they think it's gonna to make baby care easier.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4024:\n",
      "  video_id: obGF3RfWQKE\n",
      "  clip_id: 25\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or if you live in a city, you can probably even get it messengered or you can run over there and pick it up.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 377, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4025:\n",
      "  video_id: ossKC1VrusE\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Psychologists are not the only people who are interested in attitudes, advertisers are as well.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 294, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4026:\n",
      "  video_id: ossKC1VrusE\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All of these things, motivation, influence, and sensation, and perception are involved in advertising.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4027:\n",
      "  video_id: ossKC1VrusE\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because they learn about what motivates people, what influences people or limits to sensation and perception, as well as how to measure satisfactions.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4028:\n",
      "  video_id: ossKC1VrusE\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Persuasion is the phenomenon of changing someone's beliefs or attitudes via communication by another person.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4030:\n",
      "  video_id: ozA7pRW4gFM\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have to articulate concrete solutions, actions that people with power can take to prevent and end human rights abuses\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 589, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4032:\n",
      "  video_id: ozA7pRW4gFM\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They're often small steps along the way to an end goal that is more bold and ambitious\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 646, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4035:\n",
      "  video_id: ozA7pRW4gFM\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And sixth is many points of leverage\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4036:\n",
      "  video_id: ozA7pRW4gFM\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Sometimes we think we know what will lead to change, but we hit an unexpected obstacle, or outside interests that are too powerful to overcome\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4037:\n",
      "  video_id: ozA7pRW4gFM\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Advocacy is an art, not a science\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 362, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4038:\n",
      "  video_id: p1zqEGwRMI8\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I find that to be an idea that the world that we live in today could certainly use a lot more of\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 861, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4039:\n",
      "  video_id: p4WmcxrXkc4\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I think the work that Quaker's done in the last year has been fantastic.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4040:\n",
      "  video_id: p4WmcxrXkc4\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When thinking about which advertisers are most innovative in talking to moms, I often talk about advertisers like Quaker out of Chicago, in understanding that a mass reach outdoor campaign can complement an online campaign, which can complement an influencer sampling program, and complement the insights that are driving the engagement of moms.\n",
      "  text_feature_shape: (1, 62, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1038, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4041:\n",
      "  video_id: p4WmcxrXkc4\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Not only reaching out to the mommy blogosphere and understanding what's in the hearts and minds of moms, but really trying to use insights to form their media, to shape their creative, and to engage across the spectrum, looking at online as a piece of the integrated campaign.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 935, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4042:\n",
      "  video_id: p4WmcxrXkc4\n",
      "  clip_id: 4\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So those are two that I think have done a terrific job in recent past.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 287, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4043:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Years and years ago, if a consumer wanted to lodge a complaint with a company, they would write a letter and submit it to customer service.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4044:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 13\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that's a very good thing and a very healthy thing because there's immediacy for the company, if they're listening, to be able to respond, to be able to improve their product, to be able to solve the problem.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4045:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 15\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Your most loyal customers are those who have complained when you've adequately been able to address and fix their problem.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4046:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 16\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Social media and immediacy of consumer feedback and how public that is today is a huge opportunity for companies to immediately address that, not only to the customer that's unhappy but to the public at large.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1124, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 4047:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: JEFF KING: Media fragmentation and multiple touch points is a huge topic.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 221, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4048:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The way we try to look at integration is to try to make it as simple as possible.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4049:\n",
      "  video_id: p7zuPEZgtY4\n",
      "  clip_id: 8\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \"The consumer's in control\" is quite a cliche in our industry right now.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4050:\n",
      "  video_id: pDRdCSIyjkA\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Ok we are working on developing our characteristics of our character for humorous.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 359, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4051:\n",
      "  video_id: pDRdCSIyjkA\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You only have certain placements that you're going to place your characters, but you want to place each one of them differently.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 877, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4052:\n",
      "  video_id: pDRdCSIyjkA\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now when we're picking the characteristics of the body we're not necessarily talking about maybe they slump over that would be very difficult to transition back and forth to.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 833, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4053:\n",
      "  video_id: pIaEcqnzI-s\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Are they available to students that wish to learn\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 209, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4056:\n",
      "  video_id: pIaEcqnzI-s\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The regulations of our 50 states are another million pages\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 578, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4057:\n",
      "  video_id: pIaEcqnzI-s\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Code of Federal Regulations is 170,000 pages of dense text\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 743, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4058:\n",
      "  video_id: pIaEcqnzI-s\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: These are the OSHA safety regulations that every business owner and factory worker must obey\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4060:\n",
      "  video_id: pIaEcqnzI-s\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Are these edicts of government available to citizens to inform themselves\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 603, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4064:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When you graduate, things change and your focus shifts toward finding work and paying back student loans.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 736, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4065:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Walking around Millenium or Grant Park gave me breaks between class to analyze and become more peaceful with what was happening in my life.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4066:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 13\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My time there I met great independent thinkers and made friendships that still last to this day.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4067:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 15\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I tend to get more from my undergraduate years as a student exploring my mental capabilities and talent's, than the latter years where it was driven more on graduation.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 816, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4068:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 14\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I personally feel most of Columbia's efforts go into marketing the school life and not the curriculum's available.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4070:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 19\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'all about connecting with people within my field and abroad, but I would much rather spend time developing my own projects outside of corporate marketing and material benefits.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4071:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The experiences were all rewarding within the six year period and I would not regret my time.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4072:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My five and a half years at Columbia College was a great learning experience.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4073:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It gave me a chance to see the city and experience what it had to offer.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4074:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Commuting gave me time to explore the parks in Chicago and view the lake.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 556, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4075:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My time on campus was also a chance to get more involved with my own personal relationship with nature.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 336, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4076:\n",
      "  video_id: pQpy7RSfWzM\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now that I have since graduated, I appreciate these times more.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 506, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4078:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We conquered two countries and initiated military operations all over the world the continue to this day.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 604, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4079:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 13\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We made a decision to temporarily give up some rights in order to fight these wars.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 653, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4080:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 15\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They want to keep on fighting these private little wars all over the world.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 373, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4081:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 14\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Eleven years later both the Republicans and the Democrats want to keep the Patriot Act.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 541, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4082:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 22\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Whether you are progressive or conservative there are great options.\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4083:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 23\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you still believe that the federal government can be a force for good why don't you vote for Jill stein of the Green Party?\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4084:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 33\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This fall, if a third party candidate gets a significant portion of the vote, we will show the major parties that we care about our freedoms and are sick of endless war.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 724, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4085:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 30\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: American history shows that when a third party candidate gets over 10 percent of the vote, he gets his issues addressed.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 516, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4086:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 35\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So this november, vote Green or... vote Libertarian and show the Democrats and Republicans that we are no longer afraid.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 721, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4087:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 34\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A vote for a third party candidate is not wasted It may be the most important vote you ever make.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 654, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4089:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 19\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: These issues won't be discussed in a meaningful way in the debates.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4090:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Mitt Romney and Barack Obama feel different but, if elected, they will make the same choices.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4091:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As amusing as arguments over who built the forty seven percent are, There is a basic truth to the Democrats and the Republicans that deserves more attention.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 929, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4092:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: On the war on drugs both candidates support our long failed policy of prohibition.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4093:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 4\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Obama and Romney will put pretty much the same people in charge of not changing our dangerous and bloated financial sector.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 531, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4094:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 7\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Both the Democrats and the Republicans believe that we the American people are pack of cowards.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 668, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4095:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I would like to speak to you today about the most important thing they have in common, however.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4096:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 9\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Eleven years ago, on September eleventh, a pack of malicious losers killed themselves in the worst way possible.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4097:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 8\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They think that they can do anything they want, as long as they promise to make the bad men go away.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4098:\n",
      "  video_id: pSxte-ms0t8\n",
      "  clip_id: 20\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They won't be discussed because they believe we are scared enough to permanently give up the rights that make us Americans.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4099:\n",
      "  video_id: pZye4zFzk3o\n",
      "  clip_id: 1\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They're worried about losing those jobs in the American industry\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4102:\n",
      "  video_id: pZye4zFzk3o\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: However, we want to see the issue in a deeper way, in a more fundamental way\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 744, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4103:\n",
      "  video_id: pZye4zFzk3o\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \" It's certainly not from the kindness of their heart\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4104:\n",
      "  video_id: pZye4zFzk3o\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Why would workers in China, in Vietnam, work long hours to send us shoes\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4107:\n",
      "  video_id: pZye4zFzk3o\n",
      "  clip_id: 9\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They are not doing it out of the goodness of their heart, but out of self-interest as Adam Smith said\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4108:\n",
      "  video_id: pZye4zFzk3o\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They are sending us goods because they want goods in return\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4109:\n",
      "  video_id: pnpFPX34Agk\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: and literally give them the resources so that they can empower themselves learning the things that they need to learn\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 318, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4110:\n",
      "  video_id: pnpFPX34Agk\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Or do you have to even separate them by age\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 383, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4111:\n",
      "  video_id: pnpFPX34Agk\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Do you have to separate kids by perceived ability level\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 308, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4112:\n",
      "  video_id: pnpFPX34Agk\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We really are a one room schoolhouse\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 285, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4113:\n",
      "  video_id: pnpFPX34Agk\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Can you get back to a world where older kids can mentor younger kids and younger kids can get that mentorship, older kids feel that sense of responsibility\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 465, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4114:\n",
      "  video_id: pnpFPX34Agk\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have all of our ages together\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 427, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4115:\n",
      "  video_id: pvIQWWiT4-0\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: &gt;&gt; So I believe India can definitely become a superpower as long as it learns to embrace its start-up culture of young entrepreneurs, and as long as its an open environment that fosters creativity and that we work together as a united population.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4116:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 21\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We've got a lot more to stay tuned on Expert Village Film Producing 101, be right back.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 370, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4117:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 19\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Within two months after that Jack Murray meeting, we got all of our money for that project.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 727, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4118:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 18\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I left the meeting with Jack Murray, phenomenal guy who since passed away, but this advice I use to this day.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 835, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4119:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Scott duPont here, award winning film producer and welcome back to Film Producing 101 on Expert Village.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4120:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Now the next segment we're going to do here is \"Who are the best film investors.\" And there's no real easy answer for that.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4121:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Number one, the wealthiest people sometimes are very, very conservative with their money and they don't like to do slightly risky ventures like film investment.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 926, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4122:\n",
      "  video_id: q17gSr9kNww\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's not necessarily just the richest people on your block or the wealthiest people you can imagine.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 786, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4124:\n",
      "  video_id: q5M1God4M6Y\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We use open loop control, which allows quick implementation without the use of sensors\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4127:\n",
      "  video_id: q5M1God4M6Y\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Due to this problems, we switched to the Piezo actuators from servo motors\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4129:\n",
      "  video_id: q5M1God4M6Y\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Especially, their quick movement allows for them to change shape rapidly\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4130:\n",
      "  video_id: q5M1God4M6Y\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Piezo actuators are great because they are fast, quiet, and have low power consumption\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 249, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4131:\n",
      "  video_id: q5M1God4M6Y\n",
      "  clip_id: 7\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With this actuator selection, now we would like to introduce how we built the hardware\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 544, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4133:\n",
      "  video_id: q5M1God4M6Y\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The device has touch sensing and communicate with the smartphone through Bluetooth\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4138:\n",
      "  video_id: qBanrqkzobg\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: and has opened up our students' eyes and job fairs that have opened doors to fantastic career opportunities for our students\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4139:\n",
      "  video_id: qBanrqkzobg\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It happened on the other side of the room\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4140:\n",
      "  video_id: qBanrqkzobg\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Nancy Jean's gift will accomplish two important purposes\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 524, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4141:\n",
      "  video_id: qBanrqkzobg\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In fact, Nancy Jean has attended many Ladies' Tea events in this room and it is those fond memories that inspired her to target her philanthropy right here\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 704, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4142:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So stay focused, stay to the point and try to get a positive outcome\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4143:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 0\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: are not protecting your future, you are ruining it\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 223, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4144:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 3\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Another thing that you need to make a note of is stop assuming\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4145:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Therefore it is important for you to control your emotions and not let your emotions control you\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4146:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: well stop jumping to any conclusions\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 374, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4147:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well someone says something and the next moment you start rolling your eyes with anger\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 619, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4148:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Try to understand and give the other person a benefit of doubt\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 433, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4149:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: relax, let not your brain go numb and think negatively\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 637, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4150:\n",
      "  video_id: qDfSYz0PX9g\n",
      "  clip_id: 8\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Yes, probably the other person said something incorrect\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 658, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4152:\n",
      "  video_id: qEuJj4uW93E\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The company's president, Richard Fifer, a native Panamanian, scoffs at the complaints\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 358, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4153:\n",
      "  video_id: qEuJj4uW93E\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's the best testament to how true that is, eh\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4154:\n",
      "  video_id: qEuJj4uW93E\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Every day up there that you do, there are hundreds of people swimming in the river\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 381, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4156:\n",
      "  video_id: qEuJj4uW93E\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: MELLISSA FUNG: Around Coclesito, it looks like one major construction zone, new roads, improved bridges\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4157:\n",
      "  video_id: qTkazqluJ_I\n",
      "  clip_id: 14\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I'm confident that working together, we'll continue to forge the partnerships that create the jobs, the opportunity, and the dignity that our people deserve.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 630, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4158:\n",
      "  video_id: qTkazqluJ_I\n",
      "  clip_id: 3\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: With your help, we're making progress towards the goal I set two years ago- doubling U.S.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 543, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4159:\n",
      "  video_id: qTkazqluJ_I\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because just as we have to harness our economic strengths to advance American leadership in the world, we need to harness our foreign policy to advance our prosperity here at home.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 686, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4160:\n",
      "  video_id: qTkazqluJ_I\n",
      "  clip_id: 5\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Today I'm proud to say that our exports have surged, to record levels - supporting nearly ten million American jobs That's the progress we've made; the momentum we have to sustain.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 741, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4161:\n",
      "  video_id: qTkazqluJ_I\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're making it easier for tourists to get visas and visit America.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 339, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4162:\n",
      "  video_id: qTkazqluJ_I\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, we're working to make it easier for companies to \"in source\" - to set up shop here in the United States.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4164:\n",
      "  video_id: qgC8_emxSIU\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You are also going to commit to memory, the very first line of the introduction, which is your 'attention-getter' and the very end of your speech, the last line or two of the conclusion.\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1021, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4166:\n",
      "  video_id: qyqVc352g3Q\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: you get the tools necessary to do a great job in something you love\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 529, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4167:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 24\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You don't need to have every little word scripted out\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 450, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4168:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 25\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're telling stories and you're talking - just try to stay natural\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4169:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 26\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Keep your body language active, don't stand rigid at the stage, and just relax\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 554, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4170:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 27\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Pretend its a conversation between two people not a conversation with 500 other people\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 424, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4171:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Of course if you've got an amazing story, and amazing connection with the groom or bride it can go a little longer\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 601, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4172:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 21\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But generally, the shorter, the more people are going to appreciate it, and the better they're going to be engaged\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4173:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 22\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Once you've timed your speech and you know how long its going to be you go a long way in keeping peoples attention\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4174:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 23\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And finally our last point in giving a strong, confident speech, is to be conversational\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 699, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4175:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 28\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A speech shouldn't really be a speech - it should be more of a conversation\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4176:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 29\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Each member of the audience should feel like they're being personally spoken to\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 418, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4177:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Its hard - you don't know what to do\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 179, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4178:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: a lot of people, they write a beautiful speech, and they're just not sure how to communicate it\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4179:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So how do you give a speech that is confident, funny, debonair and charming? Well it all comes down to execution our first tip in execution - lose those notes! If i'm looking down at my paper all the time, its really hard to form a connection\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 894, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4180:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 2\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are so many unfamiliar and unfriendly looking faces in the crowd\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4181:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So lose those notes, buy instead of having a whole script that you have to get through - having a few key points that you illustrate with stories\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4182:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You're just not going to register as much because it doesn't seem real\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 563, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4183:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So limit yourself to using stories, and your speech is going to be much more effectively communicated, and you're going to feel a lot more confident giving it\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4184:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Stories are easy to retell without needing notes because you already know them\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 403, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4185:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You want to make sure that you're looking all around at the various guests in the room\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 388, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4186:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Second point when you're delivering a speech is eye contact\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 528, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4187:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Try varying your gaze every few seconds to different parts of the room and that will make a huge difference in peoples ability just to interact with you and feel like they're being personally spoken to during your speech\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 659, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4188:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 10\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You want to make a personal connection with each and every one of them\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4189:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 13\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So one tip we can give you is to look at the friendly faces - focus on a few key people in the audience who are smiling, who ARE engaged, and just keep alternating between them when you're looking during your speech\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 951, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 4192:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 14\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Tip number 3 - you've lost your notes, you're making eye contact, that's great\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4193:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 17\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A 45 second speech is no good because people won't think its heartfelt, but a 45 minute speech is going to have your audience in tears - and not the good kind! So make sure you're practicing your speech in advance\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 711, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4194:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 16\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Stories are fantastic but they can also be long winded and drawn out\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 523, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4195:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 19\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A good speech length is anywhere from 5 to 10 minutes\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 321, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4196:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Pull out your iphone, your smartphone, and time yourself ahead of the wedding so that you know exactly how long it is\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4197:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 31\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So feel confident and enjoy this opportunity to tell the bride and the groom how much they mean to you\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 384, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4198:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 30\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you do that - you keep it conversational, you use stories, you make eye contact, you lose those notes, you're going to give an incredible wedding speech\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 474, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4199:\n",
      "  video_id: r46amqjpWgg\n",
      "  clip_id: 32\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You're going to do great! If you still aren't sure how to write your wedding speech, head back to our previous video: the 5 keys to writing a great wedding toast\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 726, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4201:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Two, demonstrate your knowledge of the California law related to child abuse and mandatory reporting.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 634, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4202:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Goals Speaker: Dr. Erma Jean Sims, Sonoma State University There are four main goals of this session on mandatory child abuse reporting.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 331, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4203:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The third goal is to help teachers recognize incidents of child abuse in their own classrooms.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4204:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 5\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We will accomplish these goals by reviewing the law that pertains to mandatory child abuse reporting.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 593, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4205:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The fourth one is to help teachers identify appropriate ways to respond to both known and suspected incidents of child abuse and neglect.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 612, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4206:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We will discuss scenarios in which you will have an opportunity to make real world application of the law to these scenarios.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4207:\n",
      "  video_id: rC29Qub0U7A\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One, understand and demonstrate your knowledge of the duty to report all incidents of child abuse.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4209:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 11\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Extroverted people don't like a lot of silence\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 382, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4210:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Cause they feel obligated and responsible\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 208, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4211:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As I mentioned, if you're tuning in you have a overly talkative person in your group\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 458, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4212:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: increase your skills to help you lead your teams with more excellence\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4216:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So they feel like by jumping in, they're helping break the ice and warm things up\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4217:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Once someone goes at the buffet, everybody can go to the buffet\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 368, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4218:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Nobody talks so they always want to talk\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 485, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4219:\n",
      "  video_id: rcfnqiD0y8o\n",
      "  clip_id: 8\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Then it starts to sometimes set into a pattern where nobody talks so they always want to talk\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4220:\n",
      "  video_id: rePYTlT5_AY\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: One of the big tactics is the Sunday supplement, the circular.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 361, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4222:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There are a lot of ones that I throw in different scenarios based on the context That's another one that I do use by the way: Creativity, Consistency and Context that's something I'm known for saying.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 818, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4223:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Some of ways to invest in your overall brand aside from just coming up with catchphrases and defining yourself in  as few adjectives as possible is investing in marketing materials like a good website that communicates your abilities and demonstrates your work and the value create for your customers.\n",
      "  text_feature_shape: (1, 57, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1101, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 4224:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 21\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As always you guys thanks so much for watching and Don't Forget Create Something Awesome today!\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 352, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4225:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 19\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have an article you should read about how you can build your personal brand as a designer over on HOW DESIGN's website there's a link in the description below so make sure you check that out anyway like this video if you like it don't forget to subscribe!\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 882, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4226:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 18\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Anyway I hope you guys enjoyed this video and this Quick Tip on Branding Yourself as a Graphic Designer.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4227:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 1\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Your brand is what people say about you when you're not in the room.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 631, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4228:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hey everybody this Graphic Designer Roberto Blake with another Graphic Design quick tip for you today's quick tip is about investing in your personal branding!\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 438, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4230:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you think about it's advertising and marketing its all frame in that way the same thing for other companies like Adobe and Sony.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 478, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4231:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I talked about creating your own visual style and that's definitely part in developing a brand but there are other things you need to do.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 533, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4232:\n",
      "  video_id: rhQB8e999-Q\n",
      "  clip_id: 9\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I have a couple them as you know: One of them is CREATE AWESOME another one is ALWAYS BE CREATING and one of my favorite ones is:  MAKING THE IMPOSSIBLE or  MAKING IT HAPPEN.\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4234:\n",
      "  video_id: ryE9VBiR3p8\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In other words how much in the way of disposable earnings does the corporation have to give back to its shareholders.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 484, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4235:\n",
      "  video_id: sIusv36VoBY\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The 2012 ranking was based on an evaluation of companies with inclusion and diversity strategies based on accountability, succession planning, representation, workplace inclusion, recruitment and board diversity.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 989, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 4236:\n",
      "  video_id: sfaWfZ2-4c0\n",
      "  clip_id: 1\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Instead, lawmakers decided to put their egos and their personal priorities above the needs of Kentucky's families – families that are struggling to pay their bills and hold on to their jobs in the worst recession of our lifetime.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 928, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4237:\n",
      "  video_id: sfaWfZ2-4c0\n",
      "  clip_id: 2\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now ... they passed a legislative budget to fund their own salaries, but they refused to fulfill their greatest duty – passing the people’s budget that funds our classrooms, our teachers, our health care programs, our job creation efforts and our efforts to keep prisoners safely locked away.\n",
      "  text_feature_shape: (1, 58, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1196, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 4238:\n",
      "  video_id: sfaWfZ2-4c0\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You will recall that the leadership of both chambers, after rejecting my budget proposal, said that writing their own budget would be their ‘defining moment.’ Well it was.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1063, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 4239:\n",
      "  video_id: skRqBxLLJkE\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I will be attending some industry meetings associated with PEXA which is all in preparation for the refinance mandate that is coming in August Apart from that keep working there is plenty of things to do Hope you have a great week\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1051, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 4240:\n",
      "  video_id: skRqBxLLJkE\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: good afternoon welcome to the fortnightly update I'm trying to keep things pretty brief today as everyone is very busy I'd like to start by welcoming Josipa Mijic into the team she joins us from WEF and will work now as a RM a long side Peter and Katie so welcome along Josipa and good luck to Emma in her new role at WEF February it was busy for February we think will be a little bit quieter a little bit easier to get through some work but compared to February last year if you felt busy it was because you were particularly if you were in Doc Prep and it was up by 21% in terms of volume on February last year here which is huge Fulfilment also had an uplift of about seven percent year-on-year compared to the month on month and hopefully that makes it and settlement obviously got the down stream effect and was very busy imitate them out very easy to the really good story of settlements though is that the ratio of purchases to sales of was in favour of purchases about 56 to 44 which has been a good sign to the bank and that's been two months running now apart from that we ran our first help SME session today which was a great success 50 special call out and thanks to and Sandeep Sandu our SME's who represented the business really well and then got that program working with SME off on a very good note apart from that on a personal note I look forward to seeing all people up in Concord I will be flying up on the Tuesday and hopefully say g'day when I am up there\n",
      "  text_feature_shape: (1, 321, 768)\n",
      "  audio_feature_shape: torch.Size([1, 5278, 1024])\n",
      "  vision_feature_shape: (105, 2048)\n",
      "Item 4241:\n",
      "  video_id: svsbGQn389o\n",
      "  clip_id: 8\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And banks, of course, are suffering credit crisis and not making loans as much as they used to.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 613, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4242:\n",
      "  video_id: svsbGQn389o\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And it's a great wealth-building tool, going forward, that works best when real estate house values are going up in value.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 868, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4243:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 10\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: She had an impact on whoever she touched,” he added\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 348, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4244:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 1\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Grewal’s boyfriend, Karan Singh Dhillon, has spoken out following the death of his girlfriend\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 332, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4245:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They have known each other for 10 years, but didn’t start a romantic relationship until 2015\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 649, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4246:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The couple just celebrated their 2-year anniversary together\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4247:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: She would give someone the clothes off her back\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 219, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4249:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: told the New York Daily News\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 309, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4250:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 6\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: She would give someone food and go hungry,” Dhillon&nbsp\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 159, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4251:\n",
      "  video_id: tC2KicUHB9Q\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: “She made me a better person\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 240, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4253:\n",
      "  video_id: tNd3--lvSXE\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Reese Witherspoon has still got it\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 128, 1024])\n",
      "  vision_feature_shape: (2, 2048)\n",
      "Item 4255:\n",
      "  video_id: tNd3--lvSXE\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But little did Witherspoon know that she was peaking, as she found herself starring in a string of box office flops for the next few years\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4256:\n",
      "  video_id: tNd3--lvSXE\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But one thing that is different this time around - and from Cotillard - is that this nomination also helps give Witherspoon some credibility as a producer\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 638, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4257:\n",
      "  video_id: tNd3--lvSXE\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So again, like Cotillard, at least she can still hang onto her artistic reputation with this nomination\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 633, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4258:\n",
      "  video_id: tNd3--lvSXE\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Wild actually has TWO Oscar nominations - also Laura Dern for Best Supporting Actress - plus what’s more Witherspoon produced Gone Girl for which Pike is nominated\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4259:\n",
      "  video_id: tO68uTk-T_E\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And being an active listener means being a great listener, and how you can be an active listener is first of all, pay attention.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 689, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4260:\n",
      "  video_id: tO68uTk-T_E\n",
      "  clip_id: 9\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can write it down, and them you can check back; okay, what I wrote here; what I understand you said was, and then you've got a reference for later when the conversation is over.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 901, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4261:\n",
      "  video_id: tO68uTk-T_E\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That way, you can write down what it is that you think you hear.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 573, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4262:\n",
      "  video_id: tO68uTk-T_E\n",
      "  clip_id: 10\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You've done your active listening, you've gone away to do your work, and you've got a reference note right there.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 328, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4263:\n",
      "  video_id: tW5xAWDnbGU\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Uhm, so just surround yourself with friends and stuff and I dont know dont let yourself hurt yourself i know thats being repetitive but that doesnt matter just DONT do it!\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 956, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 4264:\n",
      "  video_id: tW5xAWDnbGU\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Um hey I know you've been suffering from depression uh I just wanted to help.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 571, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4265:\n",
      "  video_id: tW5xAWDnbGU\n",
      "  clip_id: 7\n",
      "  label_1: -2.3333332538604736\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Dont, Just dont I'v e dont it all of the problems are still there\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4266:\n",
      "  video_id: tZDNinnrGf8\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: not entitled to overwrite my immunity\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 201, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4267:\n",
      "  video_id: tZDNinnrGf8\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It was the single most decisive and defining moment of my professional life in which the system of international rules, the old system, was cast away\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 883, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4268:\n",
      "  video_id: tZDNinnrGf8\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Two out of the five had voted for immunity\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 378, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4269:\n",
      "  video_id: tZDNinnrGf8\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And the Law Lords took their vote, very soon on we would two nil down\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 601, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4273:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 12\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So once again, thank you for doing your part to preserve the promise of America, and to help ensure that we live up to our highest ideals.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 471, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4274:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 14\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As they sieze their piece of the American dream we all share.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 581, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4275:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: That's the promise that made my story possible, and I know I'm not alone.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4276:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 0\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Our country stands for a basic promise; no matter who you are, what you look like, or what your name is, you can make it here if you try.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 409, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4277:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But keeping our country's basic promise has never been easy, so I want to thank you.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 283, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4278:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Because while Arab Americans belong to a unique community, you are also our friends, our neighbors, and our fellow citizens.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 444, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4279:\n",
      "  video_id: tnWmVXZ87h0\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When Arab Americans have a fair shot to reach their full potential, and contribute to the country they love, all of us benefit.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4280:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The same amount of time you could have enjoyed being with your loved ones or give that extra love to your business?\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4281:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Do you often waste an inappropriate amount of time typing your own recordings?\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 259, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4282:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Do you want to cut your administrative costs so you can allocate more to marketing and sales?\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 718, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4283:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 2\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Do you want excellently typed, proofread and edited transcripts of your audios and video?\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 408, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4284:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 5\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We help professionals like you spend more time with your family and friends; or on your business doing what you do best.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 673, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4285:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 4\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: TranscriptionPRO Services is a general transcription services provider dedicated to delivering excellent transcription services at affordable prices.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 716, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4286:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Spend more time doing what you love and work on things that makes your business successful.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4287:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also work for lawyers, real estate firms, successful online entrepreneurs, bloggers, PhD students, coaches, small business owners, professional firms and professional speakers.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 773, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4288:\n",
      "  video_id: ttfaZ8IIWCo\n",
      "  clip_id: 9\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We make your life easy with our online transcription workflow management and online payments that is easy and secure.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 731, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4289:\n",
      "  video_id: tymso_pAxhk\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: First of all I think we have to talk about protecting the environment and understanding that I perceive myself to be environmentalist.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 551, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4290:\n",
      "  video_id: tymso_pAxhk\n",
      "  clip_id: 18\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And that means I may have to accept that there is a wind turban that's sitting on my back hill in my own backyard and not think it has to be in somebody else's backyard.\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 804, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4291:\n",
      "  video_id: tymso_pAxhk\n",
      "  clip_id: 12\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: When we take a look at balancing things in the state of Vermont, I think that we've gone perhaps sometimes too far, our environmental issues versus business issues and succeeded.\n",
      "  text_feature_shape: (1, 36, 768)\n",
      "  audio_feature_shape: torch.Size([1, 797, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4293:\n",
      "  video_id: tymso_pAxhk\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And that does require looking at the good of the whole and not just yourself.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 623, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4294:\n",
      "  video_id: u9I5WD3Nglk\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The rules of timing follow a system of priority, which will be explained in the process of a flow chart.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4295:\n",
      "  video_id: u9ZV8jb_-U0\n",
      "  clip_id: 0\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: JAMES MENY: So let's just say, since most people are going to not sing correctly, that it's not working for you.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4296:\n",
      "  video_id: u9ZV8jb_-U0\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The only sound that we hear from the inside is our own voice, but it's distorted through flesh, muscle, bone tissue and stuff before it actually gets to our ears.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 776, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4297:\n",
      "  video_id: uVM4JWjfGgQ\n",
      "  clip_id: 11\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So it has the best return on investment for us to get one more stay out of our best customers.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 602, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4298:\n",
      "  video_id: uVM4JWjfGgQ\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For us, our most loyal customers are our loyalty club members.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 248, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4299:\n",
      "  video_id: uVM4JWjfGgQ\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we engage them in e-mail, we engage them at the property, we engage them still through direct mail we’ve found very, very helpful.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 456, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4302:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 15\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: [QUESTION: Hey Soojin, how exactly does this team exercise thing work?\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4303:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 27\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And even if your group doesn't seem to be 'getting it,' don't worry!\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 291, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4304:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Throughout the exercise we will be observing you as you communicate with others in your group, and how you interact and work as part of a team.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4305:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 21\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: [QUESTION: My co-worker's brother participated in the team exercise last year and told me that I should be prepared to stand out by being vocal and leading the group.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 473, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4306:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 23\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: What should I do?] Answer: Candidates always want to know exactly what we're looking for so they can perform exactly to our specifications.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4307:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 33\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The team exercise can be a lot of fun and I know that I personally am excited to start this process, and get to know each of you as much as I can.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4308:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 31\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's no single piece of the application that will make or break an applicant - including the team exercise.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 344, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4309:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 30\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If I blow it at the team exercise, should I kiss my chances of cheering \"GO BLUE\" goodbye?] Absolutely not.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4310:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 28\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We're not evaluating the group as a whole, we're looking at how you communicate and interact within the group that you're in.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 609, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4311:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 29\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: [QUESTION: Soojin, this whole process the application, the resume, the team exercise all of it, has me so nervous.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 564, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4312:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 35\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you have additional questions about the team exercise, please leave them in the comments and we'll be around to answer them.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4313:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 36\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And, be sure to like this video if you found it helpful - and don't forget to subscribe to the Michigan Ross YouTube channel.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 465, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4314:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Ever since we've started offering the team exercises as an optional part of our admissions process, we've been receiving a ton of questions about it from interested applicants.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 646, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4315:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, I'm Soojin Kwon, director of admissions at the Ross School of Business.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4316:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I want to take a minute to answer some of the most frequently asked questions, and help shed some light on the team exercise option.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 541, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4317:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If we invite you to interview after reviewing your application, you will also be invited to participate in the team exercise - which will be held on campus in all three admission rounds.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 791, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4318:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 4\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Rather, it's a team-based activity designed to give us additional insight into your interpersonal and communication skills.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4320:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You'll also get to meet potential future classmates, and current students or alumni.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 552, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4321:\n",
      "  video_id: unOeTDc2rlY\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Which if you remember my previous video about how to evaluate business schools, you'll remember it is a really important part of this process.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 786, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4322:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 24\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've been loving meeting them and brainstorming ideas and seeing different ways that we can work together.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4323:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 25\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Just wanted to give you guys a heads up that you are going to see some kind of different style of videos from me over the next little bit.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 428, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4324:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 26\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But never fear I'll get back to my usual video schedule soon.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 712, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4325:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 27\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I also wanted to introduce anew kind of feature on my channel and a way hopefully it will be a way to interact with you guys more and maybe see what you guys are doing and what you are up to.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 925, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4326:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 20\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the thing that is really kind of cool about being here is that it affords me the opportunity to collaborate with other people who love to make videos.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 831, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4327:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't have anyone, like, locally around me that likes to make videos like that that I could collaborate with.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 751, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4328:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 22\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So to be in one space for a week gives me the most awesome opportunity to collaborate with other YouTubers and people who are crafty and that cook and knit and just.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 955, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 4329:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 16\n",
      "  label_1: 2.6666667461395264\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've subscribed to so many people and it's been exciting to see some of those people here.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4330:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 19\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's been a really good experience to be around so many creative individuals.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 411, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4331:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 32\n",
      "  label_1: 3.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think I will be back on schedule on Monday with a new Make a Card Monday, but until then jut wanted to thank you guys for subscribing and if you are not a subscriber, I invite you to subscribe.\n",
      "  text_feature_shape: (1, 46, 768)\n",
      "  audio_feature_shape: torch.Size([1, 944, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4332:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 28\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So I'm really excited to hopefully launch that over the next couple of weeks and I think you guys will be really receptive to it.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 469, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4333:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 13\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I've met some amazing YouTubers, people who are just like me.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4334:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I just wanted to give you guys a really quick update on what's been going on and why you haven't been on such a regular schedule.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 504, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4336:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The main reason is I have a lot of family stuff come up recently and it's stuff that kind of takes me away from home.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 606, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4337:\n",
      "  video_id: uogwnZGb-iE\n",
      "  clip_id: 6\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So that's the main reason and everything's going to be okay.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 579, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4338:\n",
      "  video_id: ussfmzwftQ8\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So first, I want to apologize, second I wanna let you know that I'm super excited to put up a lot more videos in the coming weeks and months,and third, what I love is your participation.\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 978, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 4339:\n",
      "  video_id: ussfmzwftQ8\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It makes it a lot more fun for me to put videos that you want, and I think it's gonna make it more valuable for you as well, so I'm really excited to put up more videos for you soon in the coming weeks and months.\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 733, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4341:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 10\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Online Marketing Often times, word-of-mouth is not enough, and you need to find new customers.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 349, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4342:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 12\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: See the advertising on Google, Bing, Yahoo, and other search engines.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 276, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4343:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 15\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Events I've produced events for many years and they are a great way to connect with customers and could be a new revenue stream for your company.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 414, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4344:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You'll only pay when a prospective customer clicks on one of your links.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4345:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 16\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Customer Segmentation and Relationship Management It's absolutely critical that you have a database of your customers.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 834, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4346:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But you should consider having your customers in a proper relational database that enables you to manage a variety of contact information and profile information about them, something Excel does not do to well.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1100, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 4347:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Bill Gross of Idea Labs did this when he started Cars.com The Team The team you have in place for the overall execution of your company is one of the most essential components to ensuring you have the right people in place.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 853, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4349:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Online Content Marketing your product is essential and there are so many great ways you can market your product at very low cost.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 616, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4350:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A great web site There are many services that let you create your own web site or you can hire a professional to create one for you.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 548, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4351:\n",
      "  video_id: vGkIaClHKDg\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Trust me, your FIRST action should be to create an email newsletter that you can send on a regular basis to your customers and prospective customers.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 511, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4352:\n",
      "  video_id: vGxqVh_kJdo\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the things that I started doing recently is actually recording all of my lessons.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 754, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4354:\n",
      "  video_id: vI5JH0daNsM\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It’s going to be innovators, workers, entrepreneurs, those of you who’ve been hammering away at this challenge for many years, and frankly, because of that, who have, without a lot of incentive heretofore, compressed the cost pricing now to where it is almost competitive.\n",
      "  text_feature_shape: (1, 65, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1291, 1024])\n",
      "  vision_feature_shape: (25, 2048)\n",
      "Item 4355:\n",
      "  video_id: vI5JH0daNsM\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Make no mistake; it’s not going to be the government alone that gets us there, as I said.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 451, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4356:\n",
      "  video_id: vJDDEuE-FlY\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And sometimes they have needs that they're not vocally expressing.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4357:\n",
      "  video_id: vJDDEuE-FlY\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think conversely or in addition, what we need to make sure that we're doing is helping our consumers to understand that we do offer certain services.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 916, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4358:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So the initial visit, when parents come in, they can expect just to be asked a lot of questions and their kid gets to play.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 873, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4359:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: &gt;&gt; I do see picky eaters but I see everything from a typically developing kid with picky eating to kids that have significant developmental or medical issues who have not learned how to eat because of their developmental and medical issues.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 798, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4360:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The second session, I ask the parents to bring in food and we actually start feeding the kid then and I observe how it usually goes now and then based on what I observe, I start to intervene and start the treatment to see what works so I can send the parents home with a plan after just the second session.\n",
      "  text_feature_shape: (1, 66, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1310, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 4361:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If the kid is old enough to participate and answer questions, if they want, they can but it's just talking.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 341, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4362:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So figuring out exactly what's stressing them out, it tells me how quickly I can go so I'm not asking the family to do too much.\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 841, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4363:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 4\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I establish a relationship with the parents by listening very carefully to what's stressing them because when a kid isn't eating, it is extremely stressful to families.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 753, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4364:\n",
      "  video_id: vR90Pdx9wxs\n",
      "  clip_id: 7\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I try and make the sessions -- because I'm asking the kids to do things that are very hard and can be very scary for the kid, so I try to make it as fun as possible so the kids like to come, even though I'm asking them to do challenging things.\n",
      "  text_feature_shape: (1, 59, 768)\n",
      "  audio_feature_shape: torch.Size([1, 946, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4366:\n",
      "  video_id: vTAV6FThy30\n",
      "  clip_id: 0\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hay my name is Amanda and I just wanted to make a quick video about payday loans online and the experience I've had personally with them and I know that some people call them same day loans or online cash loans which they are all pretty much the same thing.\n",
      "  text_feature_shape: (1, 54, 768)\n",
      "  audio_feature_shape: torch.Size([1, 929, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4367:\n",
      "  video_id: vTAV6FThy30\n",
      "  clip_id: 2\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the website I've used for the last 3 payday loans that I've gotten has been absolutely the best, and so I went ahead and put a link in the description box for you if you want to check it out.\n",
      "  text_feature_shape: (1, 47, 768)\n",
      "  audio_feature_shape: torch.Size([1, 996, 1024])\n",
      "  vision_feature_shape: (19, 2048)\n",
      "Item 4368:\n",
      "  video_id: vTAV6FThy30\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I just applied online, filled the form on there web page out and the money was in my account the that afternoon.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 648, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4369:\n",
      "  video_id: vTAV6FThy30\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And now to get payday loans online you need to be at least 18 years old and you have to have a regular paycheck coming in but that's about it.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4370:\n",
      "  video_id: vTAV6FThy30\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A couple of weeks into paying the loan back I decided I wanted to up my payments so I could pay off my loan faster and it was no problem, the customer service was fast and easy there was no stress which is some thing that I really liked about the company.\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1339, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 4371:\n",
      "  video_id: vTAV6FThy30\n",
      "  clip_id: 9\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: OK so if your looking for a payday loan then this website is absolutely worth a look, I've has a stress free experience with them, and there is a link for that in the description and I'll add a link to a free credit score so you can check what your credit rating is before you apply.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1014, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4373:\n",
      "  video_id: v_8QeoNc4QY\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: As such the money is tied up for a definable period of time.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 429, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4374:\n",
      "  video_id: v_8QeoNc4QY\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: A money market account on the other hand is a completely liquid vehicle.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4375:\n",
      "  video_id: v_8QeoNc4QY\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: During that time you do not have access to your money or there will be a penalty.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 434, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4376:\n",
      "  video_id: v_8QeoNc4QY\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So, it is clear to see here that the most liquid investment between a CD, a certificate of deposit, and a money market account is clearly the money market account that is the most liquid investment.\n",
      "  text_feature_shape: (1, 42, 768)\n",
      "  audio_feature_shape: torch.Size([1, 915, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4377:\n",
      "  video_id: veA6ECsGFxI\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Accenture's ability to help its pharmaceutical clients achieve more efficient global regulatory submissions that will enable them to get medicines to market more quickly, safely and at a lower cost has been enhanced.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 726, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4380:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: There, she discovers that her Other Mother has tricked other children into leaving the real world.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 600, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4381:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If her Other Mother finds them first, Coraline will stay in the Other World.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4382:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As per agreement, if Coraline finds the souls first, she and the rest of them get to return to the real world.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 625, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4383:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Coraline finds all three souls in marbles throughout the house and find her parents in a snow globe.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4384:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 17\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the end, after trapping her Other Mother’s hand in a well, Coraline begins to fix her relationship with her parents.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 501, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4386:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 19\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: More importantly, this book explores how roles and relationships change in those dual worlds.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4387:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 18\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As always a lot can be said about this story, but what draws my interest and attention is the idea of dual worlds, as if everything in this world is mirrored in another world.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 886, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4388:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 28\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Don’t forget to subscribe for more Minute Book Reports and thanks for watching.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 584, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4389:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is a story about a girl named Coraline who lives in the countryside with her mother and father.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 449, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4390:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This is a quick summary and analysis of Coraline by Neil Gaiman.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 178, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4391:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: She lives in a large house that is divided into two other units.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 621, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4392:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Coraline challenges her Other Mother to find the three souls of the children and her parents.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 435, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4394:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 25\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In another world, you might be a “son” or “daughter”. And in yet another world, you might be an “employee”. You’re the same person looking back in a reflection, yet at the same time, you’re different.\n",
      "  text_feature_shape: (1, 64, 768)\n",
      "  audio_feature_shape: torch.Size([1, 625, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4395:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: However, when she tries to open the door a second time, she finds that it leads to a mysterious world that is similar to her own.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 691, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4397:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They treat her well and they want her to stay, but she insists that she go back to her own world in fear of having buttons sewn in her eyes.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 804, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4398:\n",
      "  video_id: wC_1M7KIv9s\n",
      "  clip_id: 21\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Coraline must save her parents and others - a role that she is not used to undertaking.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 637, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4399:\n",
      "  video_id: wHeZHLv9wGI\n",
      "  clip_id: 12\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You might even figure out, OK I'm using this deodorant one day and it really worked but the next day my deodorant hardly worked at all and I had a real problem, you know.\n",
      "  text_feature_shape: (1, 44, 768)\n",
      "  audio_feature_shape: torch.Size([1, 664, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4400:\n",
      "  video_id: wO8fUOC4OSE\n",
      "  clip_id: 0\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: &gt;&gt; There's often been a dichotomy set up or proposed that really pits morals against researchers in saying that in proposing that human embryonic stem cell creation is tantamount to murder as it involves the destruction of the blastocyst.\n",
      "  text_feature_shape: (1, 52, 768)\n",
      "  audio_feature_shape: torch.Size([1, 929, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4401:\n",
      "  video_id: wO8fUOC4OSE\n",
      "  clip_id: 5\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's not going to be used to create life; it's destined to be destroyed.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 213, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4402:\n",
      "  video_id: wd8VQ5E7o7o\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Really focuses on getting people around the table to to solve problems together rather than kinda following directions, so I think that that's one of the things that makes it unique and makes it one of those things that I think the graduates from the LSE program are gonna do some pretty amazing things.\n",
      "  text_feature_shape: (1, 60, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1006, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4403:\n",
      "  video_id: wd8VQ5E7o7o\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One of the attributes about the LSE program that I think makes it stand out more than anything else is its strong focus on leadership and not leadership in this kind of traditiona,l kind of top-down \"I'm gonna show you how to fix the problems\", but leadership in a more engaged and empowering sort of way.\n",
      "  text_feature_shape: (1, 68, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1345, 1024])\n",
      "  vision_feature_shape: (26, 2048)\n",
      "Item 4404:\n",
      "  video_id: wk5lFk5kFjY\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Once body, breath, senses mind, reason and ego are all integrated in the object of contemplation, the universal spirit\". So that's what we're going for.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1077, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 4405:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 25\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I know I'm a little older than a millennial and I don't so\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 266, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4406:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 20\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This idea of having trends and services on demand has allowed us to operate more freely and almost have this concierge type service\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 552, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4407:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's a trend that's not going to be reversed\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 169, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4408:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 22\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's not as big a faux pas to have a resume where you have multiple situations going on\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 443, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4409:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 23\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I don't think millennials really want to work eight hours a day\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 235, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4410:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It gives us the opportunity to do some of the things that we really want to do instead of working a full time job\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 362, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4411:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The gig economy is freelancers and people working for themselves\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 268, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4412:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 3\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This new frame of working where people provide services that they could do pretty easily to other people looking for them in a marketplace or technology enabled format\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 600, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4413:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 2\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: People go from project to project or day job to day job rather than having a job\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 436, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4414:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: For me my work was never just a way to make a living\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 299, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4415:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 4\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I would pick flexibility over a stable job with benefits because I like the idea that I can work when I need to and work really hard if I need more money and I'm my own boss\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 588, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4416:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I wanted it to be an expression of a passion\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 231, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4417:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 11\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Having a flexible job and doing something that I'm really good at is more important than being in a nine-to-five\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 421, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4419:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 13\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think that there are a lot of benefits out there that a lot of people don't know about\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 258, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4420:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The gig economy can empower the worker because you have more flexibility over creating a career\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 395, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4423:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 17\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it's good for the society\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 216, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4424:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 16\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think we're going to start seeing benefits packages pop up for the gig economy because so many people are missing out now on the tax front, on the healthcare front, on the retirement front\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 612, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4425:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 19\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So entrpreneurship kind of goes hand in hand\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 182, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4426:\n",
      "  video_id: wnL3ld9bM2o\n",
      "  clip_id: 18\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I think it gives people, especially people who aren't traditionally trained and low income, are able to kind of start up and do their own thing and seeing that others are doing that is helpful\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4427:\n",
      "  video_id: wznRBN1fWj4\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And groups of cells are just that\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 197, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4429:\n",
      "  video_id: wznRBN1fWj4\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Because water wars will take place in the southwest if not around the the rest of the world\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 546, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4431:\n",
      "  video_id: wznRBN1fWj4\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They don't therefore have the rights and human beings\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 350, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4433:\n",
      "  video_id: wznRBN1fWj4\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you've ever, as I have had the fortune of lecturing in medical schools and seeing in vitro fertilization process, there is no moment of conception\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 572, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4434:\n",
      "  video_id: x0rLwBIocuI\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Eventually, by the way, you should have about five or six monologues ready to perform, so that you really need to make sure that you have a one minute monologue, a few more one minute monologues, maybe one or two, two minute monologues for you to perform.\n",
      "  text_feature_shape: (1, 63, 768)\n",
      "  audio_feature_shape: torch.Size([1, 943, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4436:\n",
      "  video_id: x0rLwBIocuI\n",
      "  clip_id: 7\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If you have a one minute monologue and you go one ten or one fifteen, most likely you'll be disqualified from getting the part, and a director may well say, stop and leave the stage.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1008, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4437:\n",
      "  video_id: x266rUJQC_8\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Are they not giving any negative criticisms about themselves?\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 678, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4438:\n",
      "  video_id: x266rUJQC_8\n",
      "  clip_id: 12\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: They do it as professionally as they can and they sit down.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 244, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4439:\n",
      "  video_id: x266rUJQC_8\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Are they very tentative and unsure and hiding behind the podium and personifying lack of self-esteem, lack of confidence?\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 793, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4440:\n",
      "  video_id: x266rUJQC_8\n",
      "  clip_id: 5\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Get ready for this to be bad.\" That's not good, that's not what you want to do.\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4441:\n",
      "  video_id: x266rUJQC_8\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The last thing that we want to take a look at when we're talking about evaluating a speech and speaker with regards to presentation is overall poise and confidence.\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 711, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4443:\n",
      "  video_id: x2n19Cn96aw\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If they fill, if they said they have selected someone that skills are a better fit, stop back and reflect on a scale of one to a hundred, what was your skill set.\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 619, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4444:\n",
      "  video_id: x8UZQkN52o4\n",
      "  clip_id: 11\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: BECAUSE EVEN THOUGH HE WENT TO MILITARY SCHOOL AND KNOWS MORE THAN THE GENERALS, HE WAS GRANTED FIVE DRAFT DEFERMENTS, INCLUDING ONE FOR BONE SPURS IN HIS HEELS\n",
      "  text_feature_shape: (1, 53, 768)\n",
      "  audio_feature_shape: torch.Size([1, 682, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4445:\n",
      "  video_id: x8UZQkN52o4\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: BUT IF I WERE TRUMP I WOULDN'T BRING UP VIETNAM\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 491, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4447:\n",
      "  video_id: x8UZQkN52o4\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: BECAUSE HERE'S THE DEAL -- SENATOR BLUMENTHAL DID CLAIM HE SERVED IN VIETNAM WHEN, IN REALITY, HE WAS A MARINE RESERVE IN WASHINGTON D\n",
      "  text_feature_shape: (1, 48, 768)\n",
      "  audio_feature_shape: torch.Size([1, 737, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4448:\n",
      "  video_id: x8UZQkN52o4\n",
      "  clip_id: 2\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: ( AUDIENCE REACTS ) I FEEL LIKE MY HEART IS CRYING\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 418, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4450:\n",
      "  video_id: x8UZQkN52o4\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: SO HE DIDN'T SEE COMBAT, BUT HIS G\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 391, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4451:\n",
      "  video_id: x8UZQkN52o4\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ( LAUGHTER ) OKAY, THEY WERE FIGHTING COBRA\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4452:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's nothing sad about your solitude\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 406, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4453:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 0\n",
      "  label_1: 2.3333332538604736\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: what you will accomplish, waking up to a life made up of your every wish\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4454:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 3\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let it write poetry into the future so your book of poems will be published sooner\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 468, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4455:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Let it surround you like a prelude to understand your life's greatest magnitude\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 643, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4456:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 5\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's nothing wrong with enjoying writing instead of kid's toys\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4457:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 4\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's nothing wrong with losing yourself in books instead of boys\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 263, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4458:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 7\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: One day, the stares from others will be a lesson to remind you you are full of stunning blessing\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 487, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4459:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 6\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There's nothing wrong with liking sweatpants instead of dresses\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 568, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4460:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 9\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Your mother is one of your life's greatest gifts, so thank her every day for teaching you the meaning of homesick\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 789, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4461:\n",
      "  video_id: xBE9YWYGjtk\n",
      "  clip_id: 8\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Not everyone will miss their own start and wish sometimes they can replay their own childhood part by part\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4462:\n",
      "  video_id: xSCvspXYU9k\n",
      "  clip_id: 20\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This threshold, it's just completely on a different planet in my opinion.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 576, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4463:\n",
      "  video_id: xSCvspXYU9k\n",
      "  clip_id: 14\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Well, the government makes it even more difficult because they're accepting 500 applicants and will only choose 60 within a very short time frame.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 626, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4464:\n",
      "  video_id: xSCvspXYU9k\n",
      "  clip_id: 19\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If Canada wants to attract investment and investors, this is definitely not the way to do it.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 369, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4465:\n",
      "  video_id: xSCvspXYU9k\n",
      "  clip_id: 18\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I feel that it's unlikely that anybody will qualify for this.\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 483, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4466:\n",
      "  video_id: xSCvspXYU9k\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, this is Michael Niren, Immigration Lawyer and Founder of VisaPlace.com.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 201, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4467:\n",
      "  video_id: xSCvspXYU9k\n",
      "  clip_id: 5\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: I can say, unfortunately, I don't think it's a serious program.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 314, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4470:\n",
      "  video_id: xU3N7ujUB-g\n",
      "  clip_id: 1\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: ” Now, if you’re expressing these underlying emotions and you’re still feeling that there’s massive amounts of anger and you’re feeling really enraged or out of control, then you need to do something physical\n",
      "  text_feature_shape: (1, 51, 768)\n",
      "  audio_feature_shape: torch.Size([1, 664, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4471:\n",
      "  video_id: xU3N7ujUB-g\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Any kind of exercise will do it for you\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 183, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4472:\n",
      "  video_id: xU3N7ujUB-g\n",
      "  clip_id: 2\n",
      "  label_1: 2.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So exercise is a fantastic way of burning off anger\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 465, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4477:\n",
      "  video_id: xXXcgb9eZ9Y\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Beef and milk and cream and butter and leather and on and on and on\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 477, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4478:\n",
      "  video_id: xXXcgb9eZ9Y\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The pig has a couple of disadvantages that the cow doesn’t suffer from\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 354, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4480:\n",
      "  video_id: xXXcgb9eZ9Y\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Number 1, the pig competes with us for food\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 220, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4482:\n",
      "  video_id: xmLJHru6Z1M\n",
      "  clip_id: 12\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You want a low steady tone and steady pace, rather than a high pitched and fast pace.\n",
      "  text_feature_shape: (1, 21, 768)\n",
      "  audio_feature_shape: torch.Size([1, 752, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4483:\n",
      "  video_id: xmLJHru6Z1M\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You want to act like you're talking to your friend, just chatting to your mom or dad or somebody that you've known for years.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 493, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4484:\n",
      "  video_id: xmLJHru6Z1M\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You want to make sure that you have an open stance or an open posture.\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 566, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4487:\n",
      "  video_id: xmLJHru6Z1M\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can tuck your thumbs into your pockets, but you want to make sure the majority of your hands are visible.\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 540, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4491:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 11\n",
      "  label_1: -0.5\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They might require a kind of complex mathematical kind of analysis.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 654, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4493:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 13\n",
      "  label_1: 0.1666666716337204\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Often engineers or others who have gone through courses which build those skills find it an advantage.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 633, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4495:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 1\n",
      "  label_1: 0.8333333134651184\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But the core of the work that we do is about problem solving.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 346, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4496:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 0\n",
      "  label_1: 0.5\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If I look at our work, obviously, you need skills, fundamental skills, to understand if it's a go to market kind of work, then you need to understand how markets work.\n",
      "  text_feature_shape: (1, 40, 768)\n",
      "  audio_feature_shape: torch.Size([1, 831, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4497:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: On one hand, they do allow you to think about how to break down a problem and look at different competence and come to kind of a design solution.On the other hand, they can potentially straight jacket you in problem solving which means in some sense they force you to move very quickly into a solution without really exploring a lot of different options or develop divergent thinking.I am a very firm believer that before you converge into a solution, you really need to explore different solutions.\n",
      "  text_feature_shape: (1, 98, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1942, 1024])\n",
      "  vision_feature_shape: (38, 2048)\n",
      "Item 4498:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 2\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And having an engineering background or going through an engineering degree has its pros and cons.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 939, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4499:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 5\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: An engineering mindset is always to get to closure, get to the solution and then move on to execution.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 821, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4501:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 7\n",
      "  label_1: -0.5\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And sometimes you may end up missing out on a truly innovative solution if you do that, if you close out a problem very quickly.\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 871, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4502:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 6\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And doing that very quickly can be a challenge because you probably do not explore all the solution options.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 794, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4503:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 9\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Secondly, in a lot of the work, having mathematical skills and thinking is very critical.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 518, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4504:\n",
      "  video_id: y3r2kk8zvl0\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But, as I said, it does give you a good handle in how do you solve problems, how do you think about a problem?\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 503, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4505:\n",
      "  video_id: y5Jpf48SUX8\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I'm a Distinguished Professor of Economics and Health Policy.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 329, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4506:\n",
      "  video_id: y5Jpf48SUX8\n",
      "  clip_id: 7\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And I show how those movements can predict what is happening to the rest of the economy.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 641, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4507:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If so, you get free weekly emails in your inbox with English videos and lessons, as well stories of American culture and my own life\n",
      "  text_feature_shape: (1, 29, 768)\n",
      "  audio_feature_shape: torch.Size([1, 721, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4509:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: the creative process and finding new markets for the products that we create\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 243, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4510:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 3\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We’ll pick it up from here in the next video in this series\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4511:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the next video, we’ll go over three more common interview questions: ‘How did you hear about this position’, ‘what attracted you to our company\n",
      "  text_feature_shape: (1, 39, 768)\n",
      "  audio_feature_shape: torch.Size([1, 662, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4512:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There’s nothing better than walking out of an interview feeling that you were fully prepared\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 521, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4513:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 6\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: ’ I hope this video on job interviews has been helpful\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 250, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4514:\n",
      "  video_id: yBtMwyQFXwA\n",
      "  clip_id: 8\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you have interview-related questions or stories, please post them in the comments below\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 558, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4515:\n",
      "  video_id: yCpHmPSshKY\n",
      "  clip_id: 1\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And my bill is to help get support and care for children suffering from mental illnesses.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 539, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4516:\n",
      "  video_id: yCpHmPSshKY\n",
      "  clip_id: 0\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: My name is Louise and I'm at the Linus Pauling Mock Congress at LBCC this year and my bill is about mental health and mental illnesses in children and teens.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 559, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4517:\n",
      "  video_id: yCpHmPSshKY\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And the bill is to get health care facilities, hospitals, clinics to provide free or reduced priced treatment for children even if they walk in without a guardian or parent.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 814, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4518:\n",
      "  video_id: yCpHmPSshKY\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Because 50% of girls and 40% of guys have some form of mental disease.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 488, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4519:\n",
      "  video_id: yLo-Jl8nBXU\n",
      "  clip_id: 11\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I encouraged her to move forward in preparing for elections to take place no later than February of 2015. We have provided more than $100 million in support to the peacekeeping effort.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1206, 1024])\n",
      "  vision_feature_shape: (24, 2048)\n",
      "Item 4520:\n",
      "  video_id: yLo-Jl8nBXU\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We have in addition provided this year alone $45 million in humanitarian support and we will continue to support efforts until an ultimate solution is found for the situation in CAR.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1094, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 4522:\n",
      "  video_id: yLo-Jl8nBXU\n",
      "  clip_id: 7\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we're particularly grateful for the African troops that have been provided by the neighboring countries to help bring a level of security back to CAR.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 731, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4523:\n",
      "  video_id: yLo-Jl8nBXU\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We particularly thank the French Government for their efforts and the troops that they have put on the ground.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 599, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4524:\n",
      "  video_id: yLo-Jl8nBXU\n",
      "  clip_id: 9\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And I use this opportunity to call upon the people of CAR to end the violence, to find a way forward to peace.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 801, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4526:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Wielenberg is engaged in a two-front war\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 289, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4527:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 10\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Moreover, this kind of a \"same to you\" response on Wielenberg's part is apt to provide aid and comfort to the other opponents of which, against which, he's arguing; namely, his fellow atheists who deny the objectivity of moral values and duties\n",
      "  text_feature_shape: (1, 56, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1353, 1024])\n",
      "  vision_feature_shape: (27, 2048)\n",
      "Item 4529:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 12\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: On the one hand he's battling against theists who affirm the objectivity of moral values and duties, but ground them in God\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 679, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4530:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And by adopting this \"tu quoque\" strategy against the theist he seems tacitly to admit that both his view and theism are encumbered with these unresolved problems, and that's going to make his fellow secularists who deny the objectivity of moral values and duties feel very good indeed\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1399, 1024])\n",
      "  vision_feature_shape: (28, 2048)\n",
      "Item 4531:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 1\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This week, in addition to working on the doctrine of the atonement, I've been preparing for my upcoming debate with Eric Wielenberg on the foundations of morality\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 866, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4532:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 0\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi, it's good that you can join me in my study\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 208, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4533:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 3\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In response to my criticisms of his view, Wielenberg adopts a very interesting strategy\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4536:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 4\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Philosophers call this strategy \"tu quoque,\" which is Latin for \"the same to you\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 636, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4537:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 7\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Your view is just as bad as my view\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 198, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4538:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: You've got the same problem as me\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 476, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4539:\n",
      "  video_id: ySblgk7T7eQ\n",
      "  clip_id: 9\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It just says that the other guy's view is as bad as yours and if your opponent can show that his view is not really analogous to your view, then you're stuck with this unresolved problem\n",
      "  text_feature_shape: (1, 41, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1026, 1024])\n",
      "  vision_feature_shape: (20, 2048)\n",
      "Item 4541:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 11\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Is that voice going to be another Liberal or another NDP person who will be sitting silently in the backbenches and given an order paper every day? Or is it going to be somebody who brings forward a clear vision and is given the voice to speak as loud and strong as possible for this community\n",
      "  text_feature_shape: (1, 61, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1196, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 4542:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 10\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: So we need a voice that can bring people together, that can galvanize people, that can even attract some of the Conservatives in order to get anything past the Harper government until we have a general election again in 2015\n",
      "  text_feature_shape: (1, 45, 768)\n",
      "  audio_feature_shape: torch.Size([1, 885, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4545:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 15\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I’m a trusted confidante and I belong to a party that wants a bigger voice in Parliament that demands a bigger voice in Parliament And, it’s a party that respects the fact that individual members should have a voice and should always vote their conscience\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 944, 1024])\n",
      "  vision_feature_shape: (18, 2048)\n",
      "Item 4546:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 14\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I’ve worked with her for three years on Shadow Cabinet and several years before that\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 522, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4547:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 1\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The government of Canada will be fixed\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 466, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4548:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 0\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In the March 19th election, we will not be selecting a new government\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 278, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4549:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 3\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The differences in the numbers of the parties mean that there will be no dramatic shift in power\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4550:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It is there already, and it’s not going to change\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 594, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4552:\n",
      "  video_id: yUqNp-poh9M\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Now the Liberals and the NDP will tell you that it is critical that they get another member\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 639, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4558:\n",
      "  video_id: yXE_XZUb8qE\n",
      "  clip_id: 4\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The other problem is, variable annuities are comprised of mutual funds.\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4560:\n",
      "  video_id: ybK5wRaaUyE\n",
      "  clip_id: 13\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: As GOD has said: ‘I will dwell in them and walk among them.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 513, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4561:\n",
      "  video_id: ybK5wRaaUyE\n",
      "  clip_id: 19\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: DO WHATEVER IT TAKES to be severed from the world, because without being severed from the world there is NO WAY you can be righteous in the eyes of Jesus.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 779, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4562:\n",
      "  video_id: ybK5wRaaUyE\n",
      "  clip_id: 18\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: If they are a Christian who is going to church or religious but are NOT following Jesus in righteousness, if they are sinning then you NEED to BREAK yourself off from them to follow Jesus in righteousness.\n",
      "  text_feature_shape: (1, 43, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1086, 1024])\n",
      "  vision_feature_shape: (21, 2048)\n",
      "Item 4563:\n",
      "  video_id: ybK5wRaaUyE\n",
      "  clip_id: 0\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Satan has fooled many Christians into thinking they don’t have to be separate to follow Jesus.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 431, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4564:\n",
      "  video_id: ybK5wRaaUyE\n",
      "  clip_id: 3\n",
      "  label_1: -1.6666666269302368\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So many Christians are paying the LORD lip-service but they have NOT separated themselves from this world.\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 848, 1024])\n",
      "  vision_feature_shape: (16, 2048)\n",
      "Item 4565:\n",
      "  video_id: ybK5wRaaUyE\n",
      "  clip_id: 2\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They don’t think that they have to come out and be separate to follow Jesus, BUT SATAN knows that if he gets you to fellowship with sinners, to take part in what they are doing then you won’t really have your eyes on Jesus, you won’t really follow Jesus with your heart, but you will just pay Jesus lip-service, but He will NOT have your heart.\n",
      "  text_feature_shape: (1, 86, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1624, 1024])\n",
      "  vision_feature_shape: (32, 2048)\n",
      "Item 4566:\n",
      "  video_id: ydzNAuqUAnc\n",
      "  clip_id: 1\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In Afghanistan for example, we haven't had just one election or two elections, we've gone through three elections, presidential and parliamentary and what do we find\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 735, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4567:\n",
      "  video_id: ydzNAuqUAnc\n",
      "  clip_id: 0\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: of democratic systems of government which haven't had any of those side benefits\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 307, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4568:\n",
      "  video_id: ydzNAuqUAnc\n",
      "  clip_id: 2\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Do we find a flourishing civil society, a vigorous rule of law and good security\n",
      "  text_feature_shape: (1, 18, 768)\n",
      "  audio_feature_shape: torch.Size([1, 445, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4569:\n",
      "  video_id: ydzNAuqUAnc\n",
      "  clip_id: 6\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: In Pakistan, in lots of sub-saharan Africa, again you can see, democracy and elections are compatible with corrupt governments with states that are unstable and dangerous\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 684, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4570:\n",
      "  video_id: yoDMh8FlHR8\n",
      "  clip_id: 0\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: In the marketing puzzle you’re gonna have to include a large on line piece into that puzzle.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 281, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4571:\n",
      "  video_id: yoDMh8FlHR8\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It can’t just be something on the sidelines that you’re doing also because everybody else tells you you have to do.\n",
      "  text_feature_shape: (1, 30, 768)\n",
      "  audio_feature_shape: torch.Size([1, 591, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4572:\n",
      "  video_id: yzCHa2qchpg\n",
      "  clip_id: 1\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: They would really get warm at night, when I had covers on my feet; I had sharp, shooting pains going through my feet and they are getting better to stand on, because before they would really hurt and every step in every area of my foot would hurt.\n",
      "  text_feature_shape: (1, 55, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1193, 1024])\n",
      "  vision_feature_shape: (23, 2048)\n",
      "Item 4573:\n",
      "  video_id: yzCHa2qchpg\n",
      "  clip_id: 0\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Hi this is Diana Barchenger and I came to Dr. Polzin to help me take care of the pains that I had in my feet.\n",
      "  text_feature_shape: (1, 33, 768)\n",
      "  audio_feature_shape: torch.Size([1, 549, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4574:\n",
      "  video_id: yzCHa2qchpg\n",
      "  clip_id: 2\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: I encourage everybody to come in and give him a try, thanks.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 698, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4575:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 10\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The United States and the Department of State strongly recommends against all travel by U.S.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 644, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4576:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 14\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And now that Mr. Warmbier has gone through this criminal process, we would urge the DPRK to pardon him and grant him special amnesty and immediate release on humanitarian grounds.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 889, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4577:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 3\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Department believes that the sentence is unduly harsh for the actions Mr. Warmbier allegedly took.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 453, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4578:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 2\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Mr. Warmbier was reportedly charged with, quote, “hostile acts against the DPRK,” end quote, and sentenced to 15 years’ hard labor.\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 858, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4579:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 5\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: citizens arrested in the DPRK are not used for political purposes, it’s increasingly clear from its very public treatment of these cases that the DPRK does exactly that.\n",
      "  text_feature_shape: (1, 35, 768)\n",
      "  audio_feature_shape: torch.Size([1, 868, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4580:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 7\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The Department of State strongly recommends against all travel by U.S.\n",
      "  text_feature_shape: (1, 16, 768)\n",
      "  audio_feature_shape: torch.Size([1, 561, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4581:\n",
      "  video_id: z0y1ZxH1f74\n",
      "  clip_id: 6\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It only underscores the risks associated with travel to North Korea.\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4582:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 24\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If we \"think European\", everyone – businesses, consumers, governments – can travel, trade or transact online easily across borders, without the hassle of 27 different sets of rules.\n",
      "  text_feature_shape: (1, 37, 768)\n",
      "  audio_feature_shape: torch.Size([1, 1109, 1024])\n",
      "  vision_feature_shape: (22, 2048)\n",
      "Item 4583:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 25\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Embracing the cloud is good for business, good for public services, and good for our economy.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4584:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 13\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: This uncertainty makes it harder to trust the cloud, and harder to unlock its benefits.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 854, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4586:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 20\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Meanwhile, the European cloud partnership we are setting up will help us work together to find the best cloud solutions for the public sector.\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 496, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4587:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 21\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And stimulate a growing and maturing market: benefiting every cloud user, public or private.\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 443, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4589:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 23\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: The EU's single market is our crown jewel: and the cloud is a great digital home for it.\n",
      "  text_feature_shape: (1, 23, 768)\n",
      "  audio_feature_shape: torch.Size([1, 394, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4590:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 19\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And we'll help successful industry-led certification schemes work across borders in the EU: so you can find out which cloud providers you can trust.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 888, 1024])\n",
      "  vision_feature_shape: (17, 2048)\n",
      "Item 4592:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 5\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And enabling public services that are more integrated and effective, while saving taxpayers' money.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 538, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4594:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 6\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All together, the benefits from more and better use of cloud computing could be worth several hundred euros a year for every European.\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 587, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4595:\n",
      "  video_id: z441aDJvAcU\n",
      "  clip_id: 8\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Already today, many people use a number of cloud services without even realising it – from webmail to Facebook.\n",
      "  text_feature_shape: (1, 25, 768)\n",
      "  audio_feature_shape: torch.Size([1, 416, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4596:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 11\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We also want to allow our employees time to prepare their homes and property for the impact of the storm\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 398, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4599:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 12\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The governor has closed all state offices on Friday, as well\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4602:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 17\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Please continue to make preparations\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 298, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4607:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 3\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: That means we will have to close all schools on Friday\n",
      "  text_feature_shape: (1, 13, 768)\n",
      "  audio_feature_shape: torch.Size([1, 363, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4609:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 5\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: First, the EOC doesn’t want school buses full of school children on the roads as evacuees from other parts of the state are arriving here\n",
      "  text_feature_shape: (1, 34, 768)\n",
      "  audio_feature_shape: torch.Size([1, 468, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4611:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 7\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: We also use school buses to help evacuate special needs citizens to shelters\n",
      "  text_feature_shape: (1, 15, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4612:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 6\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: We expect thousands of south and east coast Floridians to seek shelter here, or to pass through on their way further north\n",
      "  text_feature_shape: (1, 27, 768)\n",
      "  audio_feature_shape: torch.Size([1, 580, 1024])\n",
      "  vision_feature_shape: (11, 2048)\n",
      "Item 4614:\n",
      "  video_id: zfZUOvZZTuk\n",
      "  clip_id: 20\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Everyone be safe! We will continue to post updates online, and will be in touch regarding the status of schools next week\n",
      "  text_feature_shape: (1, 26, 768)\n",
      "  audio_feature_shape: torch.Size([1, 448, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4616:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 42\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: All ways of being are valid\n",
      "  text_feature_shape: (1, 8, 768)\n",
      "  audio_feature_shape: torch.Size([1, 234, 1024])\n",
      "  vision_feature_shape: (4, 2048)\n",
      "Item 4617:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 43\n",
      "  label_1: 1.3333333730697632\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: Intellectually disabled people are awesome\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 353, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4618:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 24\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Or, they even use the r word\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 184, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4623:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 21\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But lateral violence in the disability community happens\n",
      "  text_feature_shape: (1, 10, 768)\n",
      "  audio_feature_shape: torch.Size([1, 286, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4625:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 23\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: There is autistic people, and they are talking about Autism and their neurotype, and they go to defend themselves by saying things like, \"Well, autistic people aren't stupid\"\n",
      "  text_feature_shape: (1, 38, 768)\n",
      "  audio_feature_shape: torch.Size([1, 612, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4626:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 46\n",
      "  label_1: 0.6666666865348816\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: This has been my first ever blog, I hope it went okay, here's Kitty\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 303, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4627:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 44\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: The concept of intelligence, and giving people value based on their intelligence, is super not-awesome\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 423, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4628:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 45\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: So all together, I think we as the a/Autistic community can do better for intellectually and cognitively disabled cousins and fellow a/Autistics\n",
      "  text_feature_shape: (1, 32, 768)\n",
      "  audio_feature_shape: torch.Size([1, 608, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4629:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 28\n",
      "  label_1: -1.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Which, by the way, IQ is totally not a thing\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 498, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4630:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 29\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: It's super racist and ableist in its origins, and it's just terrible, and not even that accurate\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 514, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4631:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 40\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: When it all comes down to it, human beings deserve respect, and autonomy, and inclusion, and accommodation because they are human beings\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 624, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n",
      "Item 4632:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 41\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Not because they're smart in the ways that our society perceives as being the most important or valid\n",
      "  text_feature_shape: (1, 22, 768)\n",
      "  audio_feature_shape: torch.Size([1, 393, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4634:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 3\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But it was going okay and I did my makeup and I was like, alright, let's do this, I got my notes\n",
      "  text_feature_shape: (1, 28, 768)\n",
      "  audio_feature_shape: torch.Size([1, 510, 1024])\n",
      "  vision_feature_shape: (10, 2048)\n",
      "Item 4637:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 4\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And then I was like three minutes in and the battery died\n",
      "  text_feature_shape: (1, 14, 768)\n",
      "  audio_feature_shape: torch.Size([1, 413, 1024])\n",
      "  vision_feature_shape: (8, 2048)\n",
      "Item 4640:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 9\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: You can see all my carbonated water over there\n",
      "  text_feature_shape: (1, 12, 768)\n",
      "  audio_feature_shape: torch.Size([1, 464, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4643:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 39\n",
      "  label_1: -1.3333333730697632\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And there is this valuing of traditional abled ideals of intelligence that is hurting the community\n",
      "  text_feature_shape: (1, 20, 768)\n",
      "  audio_feature_shape: torch.Size([1, 754, 1024])\n",
      "  vision_feature_shape: (15, 2048)\n",
      "Item 4644:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 12\n",
      "  label_1: 0.3333333432674408\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: And you can see my cat calendar over there\n",
      "  text_feature_shape: (1, 11, 768)\n",
      "  audio_feature_shape: torch.Size([1, 156, 1024])\n",
      "  vision_feature_shape: (3, 2048)\n",
      "Item 4646:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 14\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: It's all black cats\n",
      "  text_feature_shape: (1, 7, 768)\n",
      "  audio_feature_shape: torch.Size([1, 253, 1024])\n",
      "  vision_feature_shape: (5, 2048)\n",
      "Item 4647:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 17\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: Something I've wanted to address in the a/Autistic community is the \"throwing under the bus\" of intellectually and cognitively disabled people\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 743, 1024])\n",
      "  vision_feature_shape: (14, 2048)\n",
      "Item 4648:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 19\n",
      "  label_1: -0.3333333432674408\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: \"Amythest, no one's intending to hurt anybody else's feelings\n",
      "  text_feature_shape: (1, 17, 768)\n",
      "  audio_feature_shape: torch.Size([1, 313, 1024])\n",
      "  vision_feature_shape: (6, 2048)\n",
      "Item 4651:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 30\n",
      "  label_1: -0.6666666865348816\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: And super biased, towards white men\n",
      "  text_feature_shape: (1, 9, 768)\n",
      "  audio_feature_shape: torch.Size([1, 389, 1024])\n",
      "  vision_feature_shape: (7, 2048)\n",
      "Item 4655:\n",
      "  video_id: zhNksSReaQk\n",
      "  clip_id: 34\n",
      "  label_1: -2.0\n",
      "  label: Negative\n",
      "  mode: test\n",
      "  text: But the thing is that intelligence [scoffs] is this super racist, ableist, sexist concept\n",
      "  text_feature_shape: (1, 24, 768)\n",
      "  audio_feature_shape: torch.Size([1, 460, 1024])\n",
      "  vision_feature_shape: (9, 2048)\n",
      "Item 4657:\n",
      "  video_id: zvZd3V5D5Ik\n",
      "  clip_id: 3\n",
      "  label_1: 1.0\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: If you're ready to strengthen your skills, while learning more about yourself and the world around you, I'm excited to chat with you today.\n",
      "  text_feature_shape: (1, 31, 768)\n",
      "  audio_feature_shape: torch.Size([1, 651, 1024])\n",
      "  vision_feature_shape: (13, 2048)\n",
      "Item 4658:\n",
      "  video_id: zvZd3V5D5Ik\n",
      "  clip_id: 2\n",
      "  label_1: 1.6666666269302368\n",
      "  label: Positive\n",
      "  mode: test\n",
      "  text: But I can bridge the gap of language because I've instructed for over a decade.\n",
      "  text_feature_shape: (1, 19, 768)\n",
      "  audio_feature_shape: torch.Size([1, 618, 1024])\n",
      "  vision_feature_shape: (12, 2048)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#预处理数据的地址\n",
    "file_path = '/root/autodl-tmp/test_MOSEI_short_sbert_Hubert_long_features_with_labels.pkl'\n",
    "\n",
    "# 使用pickle加载文件\n",
    "with open(file_path, 'rb') as file:\n",
    "    features3 = pickle.load(file)\n",
    "\n",
    "# 在不包含标签为0的数据的实验中，我们只打印label为positive和negative的条目\n",
    "for i, item in enumerate(features3):\n",
    "    video_id = item.get('video_id', 'N/A')\n",
    "    clip_id = item.get('clip_id', 'N/A')\n",
    "    label_1 = item.get('label_1', 'N/A')\n",
    "    label = item.get('label', 'N/A')\n",
    "    mode = item.get('mode', 'N/A')\n",
    "    text = item.get('text', 'N/A')\n",
    "    text_feature_shape = item['text_feature'].shape if 'text_feature' in item else 'N/A'\n",
    "    audio_feature_shape = item['audio_feature'].shape if 'audio_feature' in item else 'N/A'\n",
    "    vision_feature_shape = item['vision_feature_resnet'].shape if 'vision_feature_resnet' in item else 'N/A'\n",
    "    \n",
    "    if label in ['Positive', 'Negative']:\n",
    "        print(f\"Item {i}:\")\n",
    "        print(f\"  video_id: {video_id}\")\n",
    "        print(f\"  clip_id: {clip_id}\")\n",
    "        print(f\"  label_1: {label_1}\")\n",
    "        print(f\"  label: {label}\")\n",
    "        print(f\"  mode: {mode}\")\n",
    "        print(f\"  text: {text}\")\n",
    "        print(f\"  text_feature_shape: {text_feature_shape}\")\n",
    "        print(f\"  audio_feature_shape: {audio_feature_shape}\")\n",
    "        print(f\"  vision_feature_shape: {vision_feature_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [item for item in features3 if item['mode'] == 'test' and item['label'] in ['Positive', 'Negative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array([item['label'] for item in test_data])\n",
    "test_X_text = [item['text_feature'] for item in test_data]\n",
    "test_X_audio = [item['audio_feature'] for item in test_data]\n",
    "test_X_vision = [item['vision_feature_resnet'] for item in test_data]\n",
    "\n",
    "\n",
    "# 初始化标签编码器\n",
    "label_encoder = LabelEncoder()\n",
    "test_Y = label_encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1887/946297277.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_feature = torch.tensor(feature)  # 将特征转换为tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature in test_audio at index 0 has shape: torch.Size([1104, 1024])\n",
      "Feature in test_audio at index 1 has shape: torch.Size([828, 1024])\n",
      "Feature in test_audio at index 2 has shape: torch.Size([609, 1024])\n",
      "Feature in test_audio at index 3 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 4 has shape: torch.Size([729, 1024])\n",
      "Feature in test_audio at index 5 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 6 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 7 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 8 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 9 has shape: torch.Size([1364, 1024])\n",
      "Feature in test_audio at index 10 has shape: torch.Size([849, 1024])\n",
      "Feature in test_audio at index 11 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 12 has shape: torch.Size([791, 1024])\n",
      "Feature in test_audio at index 13 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 14 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 15 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 16 has shape: torch.Size([868, 1024])\n",
      "Feature in test_audio at index 17 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 18 has shape: torch.Size([582, 1024])\n",
      "Feature in test_audio at index 19 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 20 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 21 has shape: torch.Size([686, 1024])\n",
      "Feature in test_audio at index 22 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 23 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 24 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 25 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 26 has shape: torch.Size([545, 1024])\n",
      "Feature in test_audio at index 27 has shape: torch.Size([800, 1024])\n",
      "Feature in test_audio at index 28 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 29 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 30 has shape: torch.Size([343, 1024])\n",
      "Feature in test_audio at index 31 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 32 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 33 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 34 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 35 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 36 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 37 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 38 has shape: torch.Size([771, 1024])\n",
      "Feature in test_audio at index 39 has shape: torch.Size([891, 1024])\n",
      "Feature in test_audio at index 40 has shape: torch.Size([625, 1024])\n",
      "Feature in test_audio at index 41 has shape: torch.Size([365, 1024])\n",
      "Feature in test_audio at index 42 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 43 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 44 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 45 has shape: torch.Size([741, 1024])\n",
      "Feature in test_audio at index 46 has shape: torch.Size([426, 1024])\n",
      "Feature in test_audio at index 47 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 48 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 49 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 50 has shape: torch.Size([333, 1024])\n",
      "Feature in test_audio at index 51 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 52 has shape: torch.Size([406, 1024])\n",
      "Feature in test_audio at index 53 has shape: torch.Size([1148, 1024])\n",
      "Feature in test_audio at index 54 has shape: torch.Size([910, 1024])\n",
      "Feature in test_audio at index 55 has shape: torch.Size([824, 1024])\n",
      "Feature in test_audio at index 56 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 57 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 58 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 59 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 60 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 61 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 62 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 63 has shape: torch.Size([238, 1024])\n",
      "Feature in test_audio at index 64 has shape: torch.Size([548, 1024])\n",
      "Feature in test_audio at index 65 has shape: torch.Size([600, 1024])\n",
      "Feature in test_audio at index 66 has shape: torch.Size([437, 1024])\n",
      "Feature in test_audio at index 67 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 68 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 69 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 70 has shape: torch.Size([402, 1024])\n",
      "Feature in test_audio at index 71 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 72 has shape: torch.Size([287, 1024])\n",
      "Feature in test_audio at index 73 has shape: torch.Size([345, 1024])\n",
      "Feature in test_audio at index 74 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 75 has shape: torch.Size([434, 1024])\n",
      "Feature in test_audio at index 76 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 77 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 78 has shape: torch.Size([262, 1024])\n",
      "Feature in test_audio at index 79 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 80 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 81 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 82 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 83 has shape: torch.Size([378, 1024])\n",
      "Feature in test_audio at index 84 has shape: torch.Size([633, 1024])\n",
      "Feature in test_audio at index 85 has shape: torch.Size([353, 1024])\n",
      "Feature in test_audio at index 86 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 87 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 88 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 89 has shape: torch.Size([747, 1024])\n",
      "Feature in test_audio at index 90 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 91 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 92 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 93 has shape: torch.Size([236, 1024])\n",
      "Feature in test_audio at index 94 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 95 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 96 has shape: torch.Size([230, 1024])\n",
      "Feature in test_audio at index 97 has shape: torch.Size([415, 1024])\n",
      "Feature in test_audio at index 98 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 99 has shape: torch.Size([703, 1024])\n",
      "Feature in test_audio at index 100 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 101 has shape: torch.Size([530, 1024])\n",
      "Feature in test_audio at index 102 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 103 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 104 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 105 has shape: torch.Size([1258, 1024])\n",
      "Feature in test_audio at index 106 has shape: torch.Size([426, 1024])\n",
      "Feature in test_audio at index 107 has shape: torch.Size([628, 1024])\n",
      "Feature in test_audio at index 108 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 109 has shape: torch.Size([625, 1024])\n",
      "Feature in test_audio at index 110 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 111 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 112 has shape: torch.Size([673, 1024])\n",
      "Feature in test_audio at index 113 has shape: torch.Size([1065, 1024])\n",
      "Feature in test_audio at index 114 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 115 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 116 has shape: torch.Size([659, 1024])\n",
      "Feature in test_audio at index 117 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 118 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 119 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 120 has shape: torch.Size([1116, 1024])\n",
      "Feature in test_audio at index 121 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 122 has shape: torch.Size([484, 1024])\n",
      "Feature in test_audio at index 123 has shape: torch.Size([436, 1024])\n",
      "Feature in test_audio at index 124 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 125 has shape: torch.Size([287, 1024])\n",
      "Feature in test_audio at index 126 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 127 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 128 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 129 has shape: torch.Size([1421, 1024])\n",
      "Feature in test_audio at index 130 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 131 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 132 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 133 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 134 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 135 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 136 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 137 has shape: torch.Size([459, 1024])\n",
      "Feature in test_audio at index 138 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 139 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 140 has shape: torch.Size([1014, 1024])\n",
      "Feature in test_audio at index 141 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 142 has shape: torch.Size([422, 1024])\n",
      "Feature in test_audio at index 143 has shape: torch.Size([729, 1024])\n",
      "Feature in test_audio at index 144 has shape: torch.Size([1042, 1024])\n",
      "Feature in test_audio at index 145 has shape: torch.Size([671, 1024])\n",
      "Feature in test_audio at index 146 has shape: torch.Size([402, 1024])\n",
      "Feature in test_audio at index 147 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 148 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 149 has shape: torch.Size([780, 1024])\n",
      "Feature in test_audio at index 150 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 151 has shape: torch.Size([713, 1024])\n",
      "Feature in test_audio at index 152 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 153 has shape: torch.Size([332, 1024])\n",
      "Feature in test_audio at index 154 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 155 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 156 has shape: torch.Size([665, 1024])\n",
      "Feature in test_audio at index 157 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 158 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 159 has shape: torch.Size([198, 1024])\n",
      "Feature in test_audio at index 160 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 161 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 162 has shape: torch.Size([582, 1024])\n",
      "Feature in test_audio at index 163 has shape: torch.Size([633, 1024])\n",
      "Feature in test_audio at index 164 has shape: torch.Size([607, 1024])\n",
      "Feature in test_audio at index 165 has shape: torch.Size([254, 1024])\n",
      "Feature in test_audio at index 166 has shape: torch.Size([1791, 1024])\n",
      "Feature in test_audio at index 167 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 168 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 169 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 170 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 171 has shape: torch.Size([793, 1024])\n",
      "Feature in test_audio at index 172 has shape: torch.Size([933, 1024])\n",
      "Feature in test_audio at index 173 has shape: torch.Size([669, 1024])\n",
      "Feature in test_audio at index 174 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 175 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 176 has shape: torch.Size([739, 1024])\n",
      "Feature in test_audio at index 177 has shape: torch.Size([756, 1024])\n",
      "Feature in test_audio at index 178 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 179 has shape: torch.Size([748, 1024])\n",
      "Feature in test_audio at index 180 has shape: torch.Size([571, 1024])\n",
      "Feature in test_audio at index 181 has shape: torch.Size([702, 1024])\n",
      "Feature in test_audio at index 182 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 183 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 184 has shape: torch.Size([351, 1024])\n",
      "Feature in test_audio at index 185 has shape: torch.Size([1116, 1024])\n",
      "Feature in test_audio at index 186 has shape: torch.Size([104, 1024])\n",
      "Feature in test_audio at index 187 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 188 has shape: torch.Size([587, 1024])\n",
      "Feature in test_audio at index 189 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 190 has shape: torch.Size([449, 1024])\n",
      "Feature in test_audio at index 191 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 192 has shape: torch.Size([428, 1024])\n",
      "Feature in test_audio at index 193 has shape: torch.Size([1229, 1024])\n",
      "Feature in test_audio at index 194 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 195 has shape: torch.Size([876, 1024])\n",
      "Feature in test_audio at index 196 has shape: torch.Size([713, 1024])\n",
      "Feature in test_audio at index 197 has shape: torch.Size([235, 1024])\n",
      "Feature in test_audio at index 198 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 199 has shape: torch.Size([901, 1024])\n",
      "Feature in test_audio at index 200 has shape: torch.Size([269, 1024])\n",
      "Feature in test_audio at index 201 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 202 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 203 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 204 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 205 has shape: torch.Size([1190, 1024])\n",
      "Feature in test_audio at index 206 has shape: torch.Size([296, 1024])\n",
      "Feature in test_audio at index 207 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 208 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 209 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 210 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 211 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 212 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 213 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 214 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 215 has shape: torch.Size([153, 1024])\n",
      "Feature in test_audio at index 216 has shape: torch.Size([675, 1024])\n",
      "Feature in test_audio at index 217 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 218 has shape: torch.Size([923, 1024])\n",
      "Feature in test_audio at index 219 has shape: torch.Size([813, 1024])\n",
      "Feature in test_audio at index 220 has shape: torch.Size([742, 1024])\n",
      "Feature in test_audio at index 221 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 222 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 223 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 224 has shape: torch.Size([209, 1024])\n",
      "Feature in test_audio at index 225 has shape: torch.Size([359, 1024])\n",
      "Feature in test_audio at index 226 has shape: torch.Size([575, 1024])\n",
      "Feature in test_audio at index 227 has shape: torch.Size([454, 1024])\n",
      "Feature in test_audio at index 228 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 229 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 230 has shape: torch.Size([872, 1024])\n",
      "Feature in test_audio at index 231 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 232 has shape: torch.Size([323, 1024])\n",
      "Feature in test_audio at index 233 has shape: torch.Size([1336, 1024])\n",
      "Feature in test_audio at index 234 has shape: torch.Size([873, 1024])\n",
      "Feature in test_audio at index 235 has shape: torch.Size([407, 1024])\n",
      "Feature in test_audio at index 236 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 237 has shape: torch.Size([1229, 1024])\n",
      "Feature in test_audio at index 238 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 239 has shape: torch.Size([1234, 1024])\n",
      "Feature in test_audio at index 240 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 241 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 242 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 243 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 244 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 245 has shape: torch.Size([369, 1024])\n",
      "Feature in test_audio at index 246 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 247 has shape: torch.Size([203, 1024])\n",
      "Feature in test_audio at index 248 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 249 has shape: torch.Size([246, 1024])\n",
      "Feature in test_audio at index 250 has shape: torch.Size([548, 1024])\n",
      "Feature in test_audio at index 251 has shape: torch.Size([565, 1024])\n",
      "Feature in test_audio at index 252 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 253 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 254 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 255 has shape: torch.Size([654, 1024])\n",
      "Feature in test_audio at index 256 has shape: torch.Size([346, 1024])\n",
      "Feature in test_audio at index 257 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 258 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 259 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 260 has shape: torch.Size([199, 1024])\n",
      "Feature in test_audio at index 261 has shape: torch.Size([499, 1024])\n",
      "Feature in test_audio at index 262 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 263 has shape: torch.Size([328, 1024])\n",
      "Feature in test_audio at index 264 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 265 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 266 has shape: torch.Size([459, 1024])\n",
      "Feature in test_audio at index 267 has shape: torch.Size([439, 1024])\n",
      "Feature in test_audio at index 268 has shape: torch.Size([226, 1024])\n",
      "Feature in test_audio at index 269 has shape: torch.Size([219, 1024])\n",
      "Feature in test_audio at index 270 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 271 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 272 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 273 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 274 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 275 has shape: torch.Size([970, 1024])\n",
      "Feature in test_audio at index 276 has shape: torch.Size([1601, 1024])\n",
      "Feature in test_audio at index 277 has shape: torch.Size([615, 1024])\n",
      "Feature in test_audio at index 278 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 279 has shape: torch.Size([739, 1024])\n",
      "Feature in test_audio at index 280 has shape: torch.Size([323, 1024])\n",
      "Feature in test_audio at index 281 has shape: torch.Size([188, 1024])\n",
      "Feature in test_audio at index 282 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 283 has shape: torch.Size([602, 1024])\n",
      "Feature in test_audio at index 284 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 285 has shape: torch.Size([379, 1024])\n",
      "Feature in test_audio at index 286 has shape: torch.Size([484, 1024])\n",
      "Feature in test_audio at index 287 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 288 has shape: torch.Size([946, 1024])\n",
      "Feature in test_audio at index 289 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 290 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 291 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 292 has shape: torch.Size([364, 1024])\n",
      "Feature in test_audio at index 293 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 294 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 295 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 296 has shape: torch.Size([343, 1024])\n",
      "Feature in test_audio at index 297 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 298 has shape: torch.Size([176, 1024])\n",
      "Feature in test_audio at index 299 has shape: torch.Size([454, 1024])\n",
      "Feature in test_audio at index 300 has shape: torch.Size([304, 1024])\n",
      "Feature in test_audio at index 301 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 302 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 303 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 304 has shape: torch.Size([1584, 1024])\n",
      "Feature in test_audio at index 305 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 306 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 307 has shape: torch.Size([723, 1024])\n",
      "Feature in test_audio at index 308 has shape: torch.Size([251, 1024])\n",
      "Feature in test_audio at index 309 has shape: torch.Size([512, 1024])\n",
      "Feature in test_audio at index 310 has shape: torch.Size([673, 1024])\n",
      "Feature in test_audio at index 311 has shape: torch.Size([417, 1024])\n",
      "Feature in test_audio at index 312 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 313 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 314 has shape: torch.Size([214, 1024])\n",
      "Feature in test_audio at index 315 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 316 has shape: torch.Size([285, 1024])\n",
      "Feature in test_audio at index 317 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 318 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 319 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 320 has shape: torch.Size([694, 1024])\n",
      "Feature in test_audio at index 321 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 322 has shape: torch.Size([1005, 1024])\n",
      "Feature in test_audio at index 323 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 324 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 325 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 326 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 327 has shape: torch.Size([824, 1024])\n",
      "Feature in test_audio at index 328 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 329 has shape: torch.Size([869, 1024])\n",
      "Feature in test_audio at index 330 has shape: torch.Size([241, 1024])\n",
      "Feature in test_audio at index 331 has shape: torch.Size([470, 1024])\n",
      "Feature in test_audio at index 332 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 333 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 334 has shape: torch.Size([753, 1024])\n",
      "Feature in test_audio at index 335 has shape: torch.Size([540, 1024])\n",
      "Feature in test_audio at index 336 has shape: torch.Size([469, 1024])\n",
      "Feature in test_audio at index 337 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 338 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 339 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 340 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 341 has shape: torch.Size([646, 1024])\n",
      "Feature in test_audio at index 342 has shape: torch.Size([340, 1024])\n",
      "Feature in test_audio at index 343 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 344 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 345 has shape: torch.Size([164, 1024])\n",
      "Feature in test_audio at index 346 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 347 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 348 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 349 has shape: torch.Size([1091, 1024])\n",
      "Feature in test_audio at index 350 has shape: torch.Size([1453, 1024])\n",
      "Feature in test_audio at index 351 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 352 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 353 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 354 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 355 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 356 has shape: torch.Size([1471, 1024])\n",
      "Feature in test_audio at index 357 has shape: torch.Size([801, 1024])\n",
      "Feature in test_audio at index 358 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 359 has shape: torch.Size([1611, 1024])\n",
      "Feature in test_audio at index 360 has shape: torch.Size([860, 1024])\n",
      "Feature in test_audio at index 361 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 362 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 363 has shape: torch.Size([1795, 1024])\n",
      "Feature in test_audio at index 364 has shape: torch.Size([420, 1024])\n",
      "Feature in test_audio at index 365 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 366 has shape: torch.Size([271, 1024])\n",
      "Feature in test_audio at index 367 has shape: torch.Size([517, 1024])\n",
      "Feature in test_audio at index 368 has shape: torch.Size([606, 1024])\n",
      "Feature in test_audio at index 369 has shape: torch.Size([1189, 1024])\n",
      "Feature in test_audio at index 370 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 371 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 372 has shape: torch.Size([826, 1024])\n",
      "Feature in test_audio at index 373 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 374 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 375 has shape: torch.Size([244, 1024])\n",
      "Feature in test_audio at index 376 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 377 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 378 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 379 has shape: torch.Size([611, 1024])\n",
      "Feature in test_audio at index 380 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 381 has shape: torch.Size([618, 1024])\n",
      "Feature in test_audio at index 382 has shape: torch.Size([226, 1024])\n",
      "Feature in test_audio at index 383 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 384 has shape: torch.Size([414, 1024])\n",
      "Feature in test_audio at index 385 has shape: torch.Size([723, 1024])\n",
      "Feature in test_audio at index 386 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 387 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 388 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 389 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 390 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 391 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 392 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 393 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 394 has shape: torch.Size([811, 1024])\n",
      "Feature in test_audio at index 395 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 396 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 397 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 398 has shape: torch.Size([627, 1024])\n",
      "Feature in test_audio at index 399 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 400 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 401 has shape: torch.Size([376, 1024])\n",
      "Feature in test_audio at index 402 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 403 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 404 has shape: torch.Size([214, 1024])\n",
      "Feature in test_audio at index 405 has shape: torch.Size([884, 1024])\n",
      "Feature in test_audio at index 406 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 407 has shape: torch.Size([1508, 1024])\n",
      "Feature in test_audio at index 408 has shape: torch.Size([618, 1024])\n",
      "Feature in test_audio at index 409 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 410 has shape: torch.Size([723, 1024])\n",
      "Feature in test_audio at index 411 has shape: torch.Size([661, 1024])\n",
      "Feature in test_audio at index 412 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 413 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 414 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 415 has shape: torch.Size([625, 1024])\n",
      "Feature in test_audio at index 416 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 417 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 418 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 419 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 420 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 421 has shape: torch.Size([673, 1024])\n",
      "Feature in test_audio at index 422 has shape: torch.Size([575, 1024])\n",
      "Feature in test_audio at index 423 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 424 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 425 has shape: torch.Size([230, 1024])\n",
      "Feature in test_audio at index 426 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 427 has shape: torch.Size([703, 1024])\n",
      "Feature in test_audio at index 428 has shape: torch.Size([326, 1024])\n",
      "Feature in test_audio at index 429 has shape: torch.Size([1094, 1024])\n",
      "Feature in test_audio at index 430 has shape: torch.Size([457, 1024])\n",
      "Feature in test_audio at index 431 has shape: torch.Size([703, 1024])\n",
      "Feature in test_audio at index 432 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 433 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 434 has shape: torch.Size([151, 1024])\n",
      "Feature in test_audio at index 435 has shape: torch.Size([119, 1024])\n",
      "Feature in test_audio at index 436 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 437 has shape: torch.Size([225, 1024])\n",
      "Feature in test_audio at index 438 has shape: torch.Size([108, 1024])\n",
      "Feature in test_audio at index 439 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 440 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 441 has shape: torch.Size([893, 1024])\n",
      "Feature in test_audio at index 442 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 443 has shape: torch.Size([61, 1024])\n",
      "Feature in test_audio at index 444 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 445 has shape: torch.Size([938, 1024])\n",
      "Feature in test_audio at index 446 has shape: torch.Size([1654, 1024])\n",
      "Feature in test_audio at index 447 has shape: torch.Size([258, 1024])\n",
      "Feature in test_audio at index 448 has shape: torch.Size([184, 1024])\n",
      "Feature in test_audio at index 449 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 450 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 451 has shape: torch.Size([340, 1024])\n",
      "Feature in test_audio at index 452 has shape: torch.Size([233, 1024])\n",
      "Feature in test_audio at index 453 has shape: torch.Size([423, 1024])\n",
      "Feature in test_audio at index 454 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 455 has shape: torch.Size([362, 1024])\n",
      "Feature in test_audio at index 456 has shape: torch.Size([358, 1024])\n",
      "Feature in test_audio at index 457 has shape: torch.Size([135, 1024])\n",
      "Feature in test_audio at index 458 has shape: torch.Size([992, 1024])\n",
      "Feature in test_audio at index 459 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 460 has shape: torch.Size([803, 1024])\n",
      "Feature in test_audio at index 461 has shape: torch.Size([300, 1024])\n",
      "Feature in test_audio at index 462 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 463 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 464 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 465 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 466 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 467 has shape: torch.Size([1114, 1024])\n",
      "Feature in test_audio at index 468 has shape: torch.Size([777, 1024])\n",
      "Feature in test_audio at index 469 has shape: torch.Size([1383, 1024])\n",
      "Feature in test_audio at index 470 has shape: torch.Size([534, 1024])\n",
      "Feature in test_audio at index 471 has shape: torch.Size([753, 1024])\n",
      "Feature in test_audio at index 472 has shape: torch.Size([1328, 1024])\n",
      "Feature in test_audio at index 473 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 474 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 475 has shape: torch.Size([1163, 1024])\n",
      "Feature in test_audio at index 476 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 477 has shape: torch.Size([1148, 1024])\n",
      "Feature in test_audio at index 478 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 479 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 480 has shape: torch.Size([490, 1024])\n",
      "Feature in test_audio at index 481 has shape: torch.Size([883, 1024])\n",
      "Feature in test_audio at index 482 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 483 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 484 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 485 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 486 has shape: torch.Size([601, 1024])\n",
      "Feature in test_audio at index 487 has shape: torch.Size([1419, 1024])\n",
      "Feature in test_audio at index 488 has shape: torch.Size([851, 1024])\n",
      "Feature in test_audio at index 489 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 490 has shape: torch.Size([697, 1024])\n",
      "Feature in test_audio at index 491 has shape: torch.Size([590, 1024])\n",
      "Feature in test_audio at index 492 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 493 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 494 has shape: torch.Size([808, 1024])\n",
      "Feature in test_audio at index 495 has shape: torch.Size([499, 1024])\n",
      "Feature in test_audio at index 496 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 497 has shape: torch.Size([289, 1024])\n",
      "Feature in test_audio at index 498 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 499 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 500 has shape: torch.Size([570, 1024])\n",
      "Feature in test_audio at index 501 has shape: torch.Size([406, 1024])\n",
      "Feature in test_audio at index 502 has shape: torch.Size([616, 1024])\n",
      "Feature in test_audio at index 503 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 504 has shape: torch.Size([164, 1024])\n",
      "Feature in test_audio at index 505 has shape: torch.Size([209, 1024])\n",
      "Feature in test_audio at index 506 has shape: torch.Size([519, 1024])\n",
      "Feature in test_audio at index 507 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 508 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 509 has shape: torch.Size([484, 1024])\n",
      "Feature in test_audio at index 510 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 511 has shape: torch.Size([428, 1024])\n",
      "Feature in test_audio at index 512 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 513 has shape: torch.Size([177, 1024])\n",
      "Feature in test_audio at index 514 has shape: torch.Size([548, 1024])\n",
      "Feature in test_audio at index 515 has shape: torch.Size([850, 1024])\n",
      "Feature in test_audio at index 516 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 517 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 518 has shape: torch.Size([462, 1024])\n",
      "Feature in test_audio at index 519 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 520 has shape: torch.Size([943, 1024])\n",
      "Feature in test_audio at index 521 has shape: torch.Size([249, 1024])\n",
      "Feature in test_audio at index 522 has shape: torch.Size([225, 1024])\n",
      "Feature in test_audio at index 523 has shape: torch.Size([158, 1024])\n",
      "Feature in test_audio at index 524 has shape: torch.Size([548, 1024])\n",
      "Feature in test_audio at index 525 has shape: torch.Size([426, 1024])\n",
      "Feature in test_audio at index 526 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 527 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 528 has shape: torch.Size([365, 1024])\n",
      "Feature in test_audio at index 529 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 530 has shape: torch.Size([711, 1024])\n",
      "Feature in test_audio at index 531 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 532 has shape: torch.Size([1109, 1024])\n",
      "Feature in test_audio at index 533 has shape: torch.Size([449, 1024])\n",
      "Feature in test_audio at index 534 has shape: torch.Size([955, 1024])\n",
      "Feature in test_audio at index 535 has shape: torch.Size([326, 1024])\n",
      "Feature in test_audio at index 536 has shape: torch.Size([223, 1024])\n",
      "Feature in test_audio at index 537 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 538 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 539 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 540 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 541 has shape: torch.Size([364, 1024])\n",
      "Feature in test_audio at index 542 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 543 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 544 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 545 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 546 has shape: torch.Size([800, 1024])\n",
      "Feature in test_audio at index 547 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 548 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 549 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 550 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 551 has shape: torch.Size([238, 1024])\n",
      "Feature in test_audio at index 552 has shape: torch.Size([687, 1024])\n",
      "Feature in test_audio at index 553 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 554 has shape: torch.Size([536, 1024])\n",
      "Feature in test_audio at index 555 has shape: torch.Size([1031, 1024])\n",
      "Feature in test_audio at index 556 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 557 has shape: torch.Size([724, 1024])\n",
      "Feature in test_audio at index 558 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 559 has shape: torch.Size([230, 1024])\n",
      "Feature in test_audio at index 560 has shape: torch.Size([652, 1024])\n",
      "Feature in test_audio at index 561 has shape: torch.Size([428, 1024])\n",
      "Feature in test_audio at index 562 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 563 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 564 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 565 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 566 has shape: torch.Size([378, 1024])\n",
      "Feature in test_audio at index 567 has shape: torch.Size([366, 1024])\n",
      "Feature in test_audio at index 568 has shape: torch.Size([612, 1024])\n",
      "Feature in test_audio at index 569 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 570 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 571 has shape: torch.Size([285, 1024])\n",
      "Feature in test_audio at index 572 has shape: torch.Size([224, 1024])\n",
      "Feature in test_audio at index 573 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 574 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 575 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 576 has shape: torch.Size([500, 1024])\n",
      "Feature in test_audio at index 577 has shape: torch.Size([826, 1024])\n",
      "Feature in test_audio at index 578 has shape: torch.Size([826, 1024])\n",
      "Feature in test_audio at index 579 has shape: torch.Size([481, 1024])\n",
      "Feature in test_audio at index 580 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 581 has shape: torch.Size([327, 1024])\n",
      "Feature in test_audio at index 582 has shape: torch.Size([414, 1024])\n",
      "Feature in test_audio at index 583 has shape: torch.Size([136, 1024])\n",
      "Feature in test_audio at index 584 has shape: torch.Size([753, 1024])\n",
      "Feature in test_audio at index 585 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 586 has shape: torch.Size([1018, 1024])\n",
      "Feature in test_audio at index 587 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 588 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 589 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 590 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 591 has shape: torch.Size([1293, 1024])\n",
      "Feature in test_audio at index 592 has shape: torch.Size([217, 1024])\n",
      "Feature in test_audio at index 593 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 594 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 595 has shape: torch.Size([1368, 1024])\n",
      "Feature in test_audio at index 596 has shape: torch.Size([114, 1024])\n",
      "Feature in test_audio at index 597 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 598 has shape: torch.Size([323, 1024])\n",
      "Feature in test_audio at index 599 has shape: torch.Size([94, 1024])\n",
      "Feature in test_audio at index 600 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 601 has shape: torch.Size([724, 1024])\n",
      "Feature in test_audio at index 602 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 603 has shape: torch.Size([265, 1024])\n",
      "Feature in test_audio at index 604 has shape: torch.Size([585, 1024])\n",
      "Feature in test_audio at index 605 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 606 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 607 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 608 has shape: torch.Size([223, 1024])\n",
      "Feature in test_audio at index 609 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 610 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 611 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 612 has shape: torch.Size([572, 1024])\n",
      "Feature in test_audio at index 613 has shape: torch.Size([1054, 1024])\n",
      "Feature in test_audio at index 614 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 615 has shape: torch.Size([459, 1024])\n",
      "Feature in test_audio at index 616 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 617 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 618 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 619 has shape: torch.Size([764, 1024])\n",
      "Feature in test_audio at index 620 has shape: torch.Size([508, 1024])\n",
      "Feature in test_audio at index 621 has shape: torch.Size([198, 1024])\n",
      "Feature in test_audio at index 622 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 623 has shape: torch.Size([194, 1024])\n",
      "Feature in test_audio at index 624 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 625 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 626 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 627 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 628 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 629 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 630 has shape: torch.Size([1108, 1024])\n",
      "Feature in test_audio at index 631 has shape: torch.Size([831, 1024])\n",
      "Feature in test_audio at index 632 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 633 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 634 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 635 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 636 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 637 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 638 has shape: torch.Size([619, 1024])\n",
      "Feature in test_audio at index 639 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 640 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 641 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 642 has shape: torch.Size([241, 1024])\n",
      "Feature in test_audio at index 643 has shape: torch.Size([944, 1024])\n",
      "Feature in test_audio at index 644 has shape: torch.Size([211, 1024])\n",
      "Feature in test_audio at index 645 has shape: torch.Size([96, 1024])\n",
      "Feature in test_audio at index 646 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 647 has shape: torch.Size([596, 1024])\n",
      "Feature in test_audio at index 648 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 649 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 650 has shape: torch.Size([783, 1024])\n",
      "Feature in test_audio at index 651 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 652 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 653 has shape: torch.Size([250, 1024])\n",
      "Feature in test_audio at index 654 has shape: torch.Size([596, 1024])\n",
      "Feature in test_audio at index 655 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 656 has shape: torch.Size([770, 1024])\n",
      "Feature in test_audio at index 657 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 658 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 659 has shape: torch.Size([249, 1024])\n",
      "Feature in test_audio at index 660 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 661 has shape: torch.Size([793, 1024])\n",
      "Feature in test_audio at index 662 has shape: torch.Size([273, 1024])\n",
      "Feature in test_audio at index 663 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 664 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 665 has shape: torch.Size([809, 1024])\n",
      "Feature in test_audio at index 666 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 667 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 668 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 669 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 670 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 671 has shape: torch.Size([687, 1024])\n",
      "Feature in test_audio at index 672 has shape: torch.Size([166, 1024])\n",
      "Feature in test_audio at index 673 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 674 has shape: torch.Size([445, 1024])\n",
      "Feature in test_audio at index 675 has shape: torch.Size([357, 1024])\n",
      "Feature in test_audio at index 676 has shape: torch.Size([1308, 1024])\n",
      "Feature in test_audio at index 677 has shape: torch.Size([749, 1024])\n",
      "Feature in test_audio at index 678 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 679 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 680 has shape: torch.Size([233, 1024])\n",
      "Feature in test_audio at index 681 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 682 has shape: torch.Size([461, 1024])\n",
      "Feature in test_audio at index 683 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 684 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 685 has shape: torch.Size([713, 1024])\n",
      "Feature in test_audio at index 686 has shape: torch.Size([730, 1024])\n",
      "Feature in test_audio at index 687 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 688 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 689 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 690 has shape: torch.Size([425, 1024])\n",
      "Feature in test_audio at index 691 has shape: torch.Size([934, 1024])\n",
      "Feature in test_audio at index 692 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 693 has shape: torch.Size([386, 1024])\n",
      "Feature in test_audio at index 694 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 695 has shape: torch.Size([815, 1024])\n",
      "Feature in test_audio at index 696 has shape: torch.Size([866, 1024])\n",
      "Feature in test_audio at index 697 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 698 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 699 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 700 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 701 has shape: torch.Size([1460, 1024])\n",
      "Feature in test_audio at index 702 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 703 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 704 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 705 has shape: torch.Size([596, 1024])\n",
      "Feature in test_audio at index 706 has shape: torch.Size([628, 1024])\n",
      "Feature in test_audio at index 707 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 708 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 709 has shape: torch.Size([664, 1024])\n",
      "Feature in test_audio at index 710 has shape: torch.Size([1036, 1024])\n",
      "Feature in test_audio at index 711 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 712 has shape: torch.Size([1196, 1024])\n",
      "Feature in test_audio at index 713 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 714 has shape: torch.Size([229, 1024])\n",
      "Feature in test_audio at index 715 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 716 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 717 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 718 has shape: torch.Size([154, 1024])\n",
      "Feature in test_audio at index 719 has shape: torch.Size([874, 1024])\n",
      "Feature in test_audio at index 720 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 721 has shape: torch.Size([557, 1024])\n",
      "Feature in test_audio at index 722 has shape: torch.Size([813, 1024])\n",
      "Feature in test_audio at index 723 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 724 has shape: torch.Size([226, 1024])\n",
      "Feature in test_audio at index 725 has shape: torch.Size([866, 1024])\n",
      "Feature in test_audio at index 726 has shape: torch.Size([732, 1024])\n",
      "Feature in test_audio at index 727 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 728 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 729 has shape: torch.Size([1324, 1024])\n",
      "Feature in test_audio at index 730 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 731 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 732 has shape: torch.Size([131, 1024])\n",
      "Feature in test_audio at index 733 has shape: torch.Size([969, 1024])\n",
      "Feature in test_audio at index 734 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 735 has shape: torch.Size([606, 1024])\n",
      "Feature in test_audio at index 736 has shape: torch.Size([138, 1024])\n",
      "Feature in test_audio at index 737 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 738 has shape: torch.Size([226, 1024])\n",
      "Feature in test_audio at index 739 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 740 has shape: torch.Size([4106, 1024])\n",
      "Feature in test_audio at index 741 has shape: torch.Size([508, 1024])\n",
      "Feature in test_audio at index 742 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 743 has shape: torch.Size([903, 1024])\n",
      "Feature in test_audio at index 744 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 745 has shape: torch.Size([645, 1024])\n",
      "Feature in test_audio at index 746 has shape: torch.Size([454, 1024])\n",
      "Feature in test_audio at index 747 has shape: torch.Size([711, 1024])\n",
      "Feature in test_audio at index 748 has shape: torch.Size([172, 1024])\n",
      "Feature in test_audio at index 749 has shape: torch.Size([102, 1024])\n",
      "Feature in test_audio at index 750 has shape: torch.Size([390, 1024])\n",
      "Feature in test_audio at index 751 has shape: torch.Size([774, 1024])\n",
      "Feature in test_audio at index 752 has shape: torch.Size([607, 1024])\n",
      "Feature in test_audio at index 753 has shape: torch.Size([889, 1024])\n",
      "Feature in test_audio at index 754 has shape: torch.Size([567, 1024])\n",
      "Feature in test_audio at index 755 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 756 has shape: torch.Size([1093, 1024])\n",
      "Feature in test_audio at index 757 has shape: torch.Size([758, 1024])\n",
      "Feature in test_audio at index 758 has shape: torch.Size([443, 1024])\n",
      "Feature in test_audio at index 759 has shape: torch.Size([144, 1024])\n",
      "Feature in test_audio at index 760 has shape: torch.Size([1166, 1024])\n",
      "Feature in test_audio at index 761 has shape: torch.Size([351, 1024])\n",
      "Feature in test_audio at index 762 has shape: torch.Size([183, 1024])\n",
      "Feature in test_audio at index 763 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 764 has shape: torch.Size([526, 1024])\n",
      "Feature in test_audio at index 765 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 766 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 767 has shape: torch.Size([359, 1024])\n",
      "Feature in test_audio at index 768 has shape: torch.Size([156, 1024])\n",
      "Feature in test_audio at index 769 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 770 has shape: torch.Size([744, 1024])\n",
      "Feature in test_audio at index 771 has shape: torch.Size([254, 1024])\n",
      "Feature in test_audio at index 772 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 773 has shape: torch.Size([539, 1024])\n",
      "Feature in test_audio at index 774 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 775 has shape: torch.Size([971, 1024])\n",
      "Feature in test_audio at index 776 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 777 has shape: torch.Size([576, 1024])\n",
      "Feature in test_audio at index 778 has shape: torch.Size([719, 1024])\n",
      "Feature in test_audio at index 779 has shape: torch.Size([522, 1024])\n",
      "Feature in test_audio at index 780 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 781 has shape: torch.Size([490, 1024])\n",
      "Feature in test_audio at index 782 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 783 has shape: torch.Size([351, 1024])\n",
      "Feature in test_audio at index 784 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 785 has shape: torch.Size([487, 1024])\n",
      "Feature in test_audio at index 786 has shape: torch.Size([759, 1024])\n",
      "Feature in test_audio at index 787 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 788 has shape: torch.Size([683, 1024])\n",
      "Feature in test_audio at index 789 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 790 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 791 has shape: torch.Size([502, 1024])\n",
      "Feature in test_audio at index 792 has shape: torch.Size([418, 1024])\n",
      "Feature in test_audio at index 793 has shape: torch.Size([664, 1024])\n",
      "Feature in test_audio at index 794 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 795 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 796 has shape: torch.Size([228, 1024])\n",
      "Feature in test_audio at index 797 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 798 has shape: torch.Size([273, 1024])\n",
      "Feature in test_audio at index 799 has shape: torch.Size([975, 1024])\n",
      "Feature in test_audio at index 800 has shape: torch.Size([175, 1024])\n",
      "Feature in test_audio at index 801 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 802 has shape: torch.Size([130, 1024])\n",
      "Feature in test_audio at index 803 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 804 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 805 has shape: torch.Size([604, 1024])\n",
      "Feature in test_audio at index 806 has shape: torch.Size([361, 1024])\n",
      "Feature in test_audio at index 807 has shape: torch.Size([732, 1024])\n",
      "Feature in test_audio at index 808 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 809 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 810 has shape: torch.Size([402, 1024])\n",
      "Feature in test_audio at index 811 has shape: torch.Size([354, 1024])\n",
      "Feature in test_audio at index 812 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 813 has shape: torch.Size([968, 1024])\n",
      "Feature in test_audio at index 814 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 815 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 816 has shape: torch.Size([380, 1024])\n",
      "Feature in test_audio at index 817 has shape: torch.Size([265, 1024])\n",
      "Feature in test_audio at index 818 has shape: torch.Size([118, 1024])\n",
      "Feature in test_audio at index 819 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 820 has shape: torch.Size([1049, 1024])\n",
      "Feature in test_audio at index 821 has shape: torch.Size([881, 1024])\n",
      "Feature in test_audio at index 822 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 823 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 824 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 825 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 826 has shape: torch.Size([415, 1024])\n",
      "Feature in test_audio at index 827 has shape: torch.Size([364, 1024])\n",
      "Feature in test_audio at index 828 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 829 has shape: torch.Size([374, 1024])\n",
      "Feature in test_audio at index 830 has shape: torch.Size([918, 1024])\n",
      "Feature in test_audio at index 831 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 832 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 833 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 834 has shape: torch.Size([289, 1024])\n",
      "Feature in test_audio at index 835 has shape: torch.Size([509, 1024])\n",
      "Feature in test_audio at index 836 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 837 has shape: torch.Size([637, 1024])\n",
      "Feature in test_audio at index 838 has shape: torch.Size([909, 1024])\n",
      "Feature in test_audio at index 839 has shape: torch.Size([146, 1024])\n",
      "Feature in test_audio at index 840 has shape: torch.Size([499, 1024])\n",
      "Feature in test_audio at index 841 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 842 has shape: torch.Size([358, 1024])\n",
      "Feature in test_audio at index 843 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 844 has shape: torch.Size([214, 1024])\n",
      "Feature in test_audio at index 845 has shape: torch.Size([481, 1024])\n",
      "Feature in test_audio at index 846 has shape: torch.Size([378, 1024])\n",
      "Feature in test_audio at index 847 has shape: torch.Size([176, 1024])\n",
      "Feature in test_audio at index 848 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 849 has shape: torch.Size([247, 1024])\n",
      "Feature in test_audio at index 850 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 851 has shape: torch.Size([1716, 1024])\n",
      "Feature in test_audio at index 852 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 853 has shape: torch.Size([215, 1024])\n",
      "Feature in test_audio at index 854 has shape: torch.Size([359, 1024])\n",
      "Feature in test_audio at index 855 has shape: torch.Size([869, 1024])\n",
      "Feature in test_audio at index 856 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 857 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 858 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 859 has shape: torch.Size([309, 1024])\n",
      "Feature in test_audio at index 860 has shape: torch.Size([186, 1024])\n",
      "Feature in test_audio at index 861 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 862 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 863 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 864 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 865 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 866 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 867 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 868 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 869 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 870 has shape: torch.Size([336, 1024])\n",
      "Feature in test_audio at index 871 has shape: torch.Size([633, 1024])\n",
      "Feature in test_audio at index 872 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 873 has shape: torch.Size([969, 1024])\n",
      "Feature in test_audio at index 874 has shape: torch.Size([369, 1024])\n",
      "Feature in test_audio at index 875 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 876 has shape: torch.Size([145, 1024])\n",
      "Feature in test_audio at index 877 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 878 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 879 has shape: torch.Size([277, 1024])\n",
      "Feature in test_audio at index 880 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 881 has shape: torch.Size([309, 1024])\n",
      "Feature in test_audio at index 882 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 883 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 884 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 885 has shape: torch.Size([539, 1024])\n",
      "Feature in test_audio at index 886 has shape: torch.Size([405, 1024])\n",
      "Feature in test_audio at index 887 has shape: torch.Size([218, 1024])\n",
      "Feature in test_audio at index 888 has shape: torch.Size([783, 1024])\n",
      "Feature in test_audio at index 889 has shape: torch.Size([749, 1024])\n",
      "Feature in test_audio at index 890 has shape: torch.Size([1164, 1024])\n",
      "Feature in test_audio at index 891 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 892 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 893 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 894 has shape: torch.Size([801, 1024])\n",
      "Feature in test_audio at index 895 has shape: torch.Size([537, 1024])\n",
      "Feature in test_audio at index 896 has shape: torch.Size([505, 1024])\n",
      "Feature in test_audio at index 897 has shape: torch.Size([255, 1024])\n",
      "Feature in test_audio at index 898 has shape: torch.Size([358, 1024])\n",
      "Feature in test_audio at index 899 has shape: torch.Size([1158, 1024])\n",
      "Feature in test_audio at index 900 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 901 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 902 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 903 has shape: torch.Size([377, 1024])\n",
      "Feature in test_audio at index 904 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 905 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 906 has shape: torch.Size([966, 1024])\n",
      "Feature in test_audio at index 907 has shape: torch.Size([652, 1024])\n",
      "Feature in test_audio at index 908 has shape: torch.Size([1247, 1024])\n",
      "Feature in test_audio at index 909 has shape: torch.Size([652, 1024])\n",
      "Feature in test_audio at index 910 has shape: torch.Size([415, 1024])\n",
      "Feature in test_audio at index 911 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 912 has shape: torch.Size([415, 1024])\n",
      "Feature in test_audio at index 913 has shape: torch.Size([230, 1024])\n",
      "Feature in test_audio at index 914 has shape: torch.Size([889, 1024])\n",
      "Feature in test_audio at index 915 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 916 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 917 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 918 has shape: torch.Size([98, 1024])\n",
      "Feature in test_audio at index 919 has shape: torch.Size([1441, 1024])\n",
      "Feature in test_audio at index 920 has shape: torch.Size([1338, 1024])\n",
      "Feature in test_audio at index 921 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 922 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 923 has shape: torch.Size([380, 1024])\n",
      "Feature in test_audio at index 924 has shape: torch.Size([61, 1024])\n",
      "Feature in test_audio at index 925 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 926 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 927 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 928 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 929 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 930 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 931 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 932 has shape: torch.Size([701, 1024])\n",
      "Feature in test_audio at index 933 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 934 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 935 has shape: torch.Size([793, 1024])\n",
      "Feature in test_audio at index 936 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 937 has shape: torch.Size([934, 1024])\n",
      "Feature in test_audio at index 938 has shape: torch.Size([1118, 1024])\n",
      "Feature in test_audio at index 939 has shape: torch.Size([376, 1024])\n",
      "Feature in test_audio at index 940 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 941 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 942 has shape: torch.Size([974, 1024])\n",
      "Feature in test_audio at index 943 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 944 has shape: torch.Size([1420, 1024])\n",
      "Feature in test_audio at index 945 has shape: torch.Size([748, 1024])\n",
      "Feature in test_audio at index 946 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 947 has shape: torch.Size([709, 1024])\n",
      "Feature in test_audio at index 948 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 949 has shape: torch.Size([703, 1024])\n",
      "Feature in test_audio at index 950 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 951 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 952 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 953 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 954 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 955 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 956 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 957 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 958 has shape: torch.Size([884, 1024])\n",
      "Feature in test_audio at index 959 has shape: torch.Size([1006, 1024])\n",
      "Feature in test_audio at index 960 has shape: torch.Size([720, 1024])\n",
      "Feature in test_audio at index 961 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 962 has shape: torch.Size([1546, 1024])\n",
      "Feature in test_audio at index 963 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 964 has shape: torch.Size([734, 1024])\n",
      "Feature in test_audio at index 965 has shape: torch.Size([596, 1024])\n",
      "Feature in test_audio at index 966 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 967 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 968 has shape: torch.Size([701, 1024])\n",
      "Feature in test_audio at index 969 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 970 has shape: torch.Size([969, 1024])\n",
      "Feature in test_audio at index 971 has shape: torch.Size([427, 1024])\n",
      "Feature in test_audio at index 972 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 973 has shape: torch.Size([923, 1024])\n",
      "Feature in test_audio at index 974 has shape: torch.Size([149, 1024])\n",
      "Feature in test_audio at index 975 has shape: torch.Size([422, 1024])\n",
      "Feature in test_audio at index 976 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 977 has shape: torch.Size([918, 1024])\n",
      "Feature in test_audio at index 978 has shape: torch.Size([582, 1024])\n",
      "Feature in test_audio at index 979 has shape: torch.Size([1376, 1024])\n",
      "Feature in test_audio at index 980 has shape: torch.Size([545, 1024])\n",
      "Feature in test_audio at index 981 has shape: torch.Size([729, 1024])\n",
      "Feature in test_audio at index 982 has shape: torch.Size([183, 1024])\n",
      "Feature in test_audio at index 983 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 984 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 985 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 986 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 987 has shape: torch.Size([376, 1024])\n",
      "Feature in test_audio at index 988 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 989 has shape: torch.Size([116, 1024])\n",
      "Feature in test_audio at index 990 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 991 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 992 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 993 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 994 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 995 has shape: torch.Size([1191, 1024])\n",
      "Feature in test_audio at index 996 has shape: torch.Size([683, 1024])\n",
      "Feature in test_audio at index 997 has shape: torch.Size([946, 1024])\n",
      "Feature in test_audio at index 998 has shape: torch.Size([376, 1024])\n",
      "Feature in test_audio at index 999 has shape: torch.Size([254, 1024])\n",
      "Feature in test_audio at index 1000 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 1001 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 1002 has shape: torch.Size([481, 1024])\n",
      "Feature in test_audio at index 1003 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 1004 has shape: torch.Size([808, 1024])\n",
      "Feature in test_audio at index 1005 has shape: torch.Size([241, 1024])\n",
      "Feature in test_audio at index 1006 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 1007 has shape: torch.Size([306, 1024])\n",
      "Feature in test_audio at index 1008 has shape: torch.Size([1089, 1024])\n",
      "Feature in test_audio at index 1009 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 1010 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 1011 has shape: torch.Size([744, 1024])\n",
      "Feature in test_audio at index 1012 has shape: torch.Size([1023, 1024])\n",
      "Feature in test_audio at index 1013 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 1014 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 1015 has shape: torch.Size([745, 1024])\n",
      "Feature in test_audio at index 1016 has shape: torch.Size([693, 1024])\n",
      "Feature in test_audio at index 1017 has shape: torch.Size([727, 1024])\n",
      "Feature in test_audio at index 1018 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 1019 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 1020 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 1021 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 1022 has shape: torch.Size([732, 1024])\n",
      "Feature in test_audio at index 1023 has shape: torch.Size([587, 1024])\n",
      "Feature in test_audio at index 1024 has shape: torch.Size([276, 1024])\n",
      "Feature in test_audio at index 1025 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 1026 has shape: torch.Size([602, 1024])\n",
      "Feature in test_audio at index 1027 has shape: torch.Size([582, 1024])\n",
      "Feature in test_audio at index 1028 has shape: torch.Size([812, 1024])\n",
      "Feature in test_audio at index 1029 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 1030 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 1031 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 1032 has shape: torch.Size([657, 1024])\n",
      "Feature in test_audio at index 1033 has shape: torch.Size([537, 1024])\n",
      "Feature in test_audio at index 1034 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 1035 has shape: torch.Size([693, 1024])\n",
      "Feature in test_audio at index 1036 has shape: torch.Size([562, 1024])\n",
      "Feature in test_audio at index 1037 has shape: torch.Size([693, 1024])\n",
      "Feature in test_audio at index 1038 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 1039 has shape: torch.Size([820, 1024])\n",
      "Feature in test_audio at index 1040 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 1041 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 1042 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 1043 has shape: torch.Size([824, 1024])\n",
      "Feature in test_audio at index 1044 has shape: torch.Size([680, 1024])\n",
      "Feature in test_audio at index 1045 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 1046 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 1047 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 1048 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 1049 has shape: torch.Size([485, 1024])\n",
      "Feature in test_audio at index 1050 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1051 has shape: torch.Size([269, 1024])\n",
      "Feature in test_audio at index 1052 has shape: torch.Size([39, 1024])\n",
      "Feature in test_audio at index 1053 has shape: torch.Size([745, 1024])\n",
      "Feature in test_audio at index 1054 has shape: torch.Size([351, 1024])\n",
      "Feature in test_audio at index 1055 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 1056 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 1057 has shape: torch.Size([1062, 1024])\n",
      "Feature in test_audio at index 1058 has shape: torch.Size([159, 1024])\n",
      "Feature in test_audio at index 1059 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 1060 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 1061 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 1062 has shape: torch.Size([255, 1024])\n",
      "Feature in test_audio at index 1063 has shape: torch.Size([377, 1024])\n",
      "Feature in test_audio at index 1064 has shape: torch.Size([655, 1024])\n",
      "Feature in test_audio at index 1065 has shape: torch.Size([764, 1024])\n",
      "Feature in test_audio at index 1066 has shape: torch.Size([811, 1024])\n",
      "Feature in test_audio at index 1067 has shape: torch.Size([829, 1024])\n",
      "Feature in test_audio at index 1068 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 1069 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 1070 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 1071 has shape: torch.Size([433, 1024])\n",
      "Feature in test_audio at index 1072 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 1073 has shape: torch.Size([826, 1024])\n",
      "Feature in test_audio at index 1074 has shape: torch.Size([251, 1024])\n",
      "Feature in test_audio at index 1075 has shape: torch.Size([461, 1024])\n",
      "Feature in test_audio at index 1076 has shape: torch.Size([249, 1024])\n",
      "Feature in test_audio at index 1077 has shape: torch.Size([166, 1024])\n",
      "Feature in test_audio at index 1078 has shape: torch.Size([249, 1024])\n",
      "Feature in test_audio at index 1079 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 1080 has shape: torch.Size([666, 1024])\n",
      "Feature in test_audio at index 1081 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 1082 has shape: torch.Size([206, 1024])\n",
      "Feature in test_audio at index 1083 has shape: torch.Size([361, 1024])\n",
      "Feature in test_audio at index 1084 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 1085 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 1086 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 1087 has shape: torch.Size([1018, 1024])\n",
      "Feature in test_audio at index 1088 has shape: torch.Size([1490, 1024])\n",
      "Feature in test_audio at index 1089 has shape: torch.Size([537, 1024])\n",
      "Feature in test_audio at index 1090 has shape: torch.Size([946, 1024])\n",
      "Feature in test_audio at index 1091 has shape: torch.Size([1158, 1024])\n",
      "Feature in test_audio at index 1092 has shape: torch.Size([1376, 1024])\n",
      "Feature in test_audio at index 1093 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 1094 has shape: torch.Size([1300, 1024])\n",
      "Feature in test_audio at index 1095 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 1096 has shape: torch.Size([261, 1024])\n",
      "Feature in test_audio at index 1097 has shape: torch.Size([603, 1024])\n",
      "Feature in test_audio at index 1098 has shape: torch.Size([400, 1024])\n",
      "Feature in test_audio at index 1099 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 1100 has shape: torch.Size([534, 1024])\n",
      "Feature in test_audio at index 1101 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 1102 has shape: torch.Size([228, 1024])\n",
      "Feature in test_audio at index 1103 has shape: torch.Size([896, 1024])\n",
      "Feature in test_audio at index 1104 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 1105 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 1106 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 1107 has shape: torch.Size([426, 1024])\n",
      "Feature in test_audio at index 1108 has shape: torch.Size([507, 1024])\n",
      "Feature in test_audio at index 1109 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 1110 has shape: torch.Size([1346, 1024])\n",
      "Feature in test_audio at index 1111 has shape: torch.Size([948, 1024])\n",
      "Feature in test_audio at index 1112 has shape: torch.Size([759, 1024])\n",
      "Feature in test_audio at index 1113 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 1114 has shape: torch.Size([459, 1024])\n",
      "Feature in test_audio at index 1115 has shape: torch.Size([709, 1024])\n",
      "Feature in test_audio at index 1116 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 1117 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 1118 has shape: torch.Size([225, 1024])\n",
      "Feature in test_audio at index 1119 has shape: torch.Size([629, 1024])\n",
      "Feature in test_audio at index 1120 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 1121 has shape: torch.Size([305, 1024])\n",
      "Feature in test_audio at index 1122 has shape: torch.Size([272, 1024])\n",
      "Feature in test_audio at index 1123 has shape: torch.Size([357, 1024])\n",
      "Feature in test_audio at index 1124 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 1125 has shape: torch.Size([685, 1024])\n",
      "Feature in test_audio at index 1126 has shape: torch.Size([785, 1024])\n",
      "Feature in test_audio at index 1127 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 1128 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 1129 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 1130 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 1131 has shape: torch.Size([490, 1024])\n",
      "Feature in test_audio at index 1132 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 1133 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 1134 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 1135 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 1136 has shape: torch.Size([565, 1024])\n",
      "Feature in test_audio at index 1137 has shape: torch.Size([571, 1024])\n",
      "Feature in test_audio at index 1138 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 1139 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 1140 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 1141 has shape: torch.Size([166, 1024])\n",
      "Feature in test_audio at index 1142 has shape: torch.Size([379, 1024])\n",
      "Feature in test_audio at index 1143 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 1144 has shape: torch.Size([206, 1024])\n",
      "Feature in test_audio at index 1145 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 1146 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 1147 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 1148 has shape: torch.Size([1074, 1024])\n",
      "Feature in test_audio at index 1149 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 1150 has shape: torch.Size([640, 1024])\n",
      "Feature in test_audio at index 1151 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 1152 has shape: torch.Size([550, 1024])\n",
      "Feature in test_audio at index 1153 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 1154 has shape: torch.Size([1219, 1024])\n",
      "Feature in test_audio at index 1155 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 1156 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 1157 has shape: torch.Size([629, 1024])\n",
      "Feature in test_audio at index 1158 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 1159 has shape: torch.Size([269, 1024])\n",
      "Feature in test_audio at index 1160 has shape: torch.Size([293, 1024])\n",
      "Feature in test_audio at index 1161 has shape: torch.Size([988, 1024])\n",
      "Feature in test_audio at index 1162 has shape: torch.Size([410, 1024])\n",
      "Feature in test_audio at index 1163 has shape: torch.Size([66, 1024])\n",
      "Feature in test_audio at index 1164 has shape: torch.Size([819, 1024])\n",
      "Feature in test_audio at index 1165 has shape: torch.Size([617, 1024])\n",
      "Feature in test_audio at index 1166 has shape: torch.Size([430, 1024])\n",
      "Feature in test_audio at index 1167 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 1168 has shape: torch.Size([339, 1024])\n",
      "Feature in test_audio at index 1169 has shape: torch.Size([861, 1024])\n",
      "Feature in test_audio at index 1170 has shape: torch.Size([851, 1024])\n",
      "Feature in test_audio at index 1171 has shape: torch.Size([351, 1024])\n",
      "Feature in test_audio at index 1172 has shape: torch.Size([693, 1024])\n",
      "Feature in test_audio at index 1173 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 1174 has shape: torch.Size([676, 1024])\n",
      "Feature in test_audio at index 1175 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1176 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 1177 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 1178 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 1179 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 1180 has shape: torch.Size([1068, 1024])\n",
      "Feature in test_audio at index 1181 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 1182 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 1183 has shape: torch.Size([652, 1024])\n",
      "Feature in test_audio at index 1184 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 1185 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 1186 has shape: torch.Size([741, 1024])\n",
      "Feature in test_audio at index 1187 has shape: torch.Size([343, 1024])\n",
      "Feature in test_audio at index 1188 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 1189 has shape: torch.Size([778, 1024])\n",
      "Feature in test_audio at index 1190 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 1191 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 1192 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 1193 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 1194 has shape: torch.Size([557, 1024])\n",
      "Feature in test_audio at index 1195 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 1196 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 1197 has shape: torch.Size([939, 1024])\n",
      "Feature in test_audio at index 1198 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 1199 has shape: torch.Size([531, 1024])\n",
      "Feature in test_audio at index 1200 has shape: torch.Size([676, 1024])\n",
      "Feature in test_audio at index 1201 has shape: torch.Size([663, 1024])\n",
      "Feature in test_audio at index 1202 has shape: torch.Size([306, 1024])\n",
      "Feature in test_audio at index 1203 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 1204 has shape: torch.Size([619, 1024])\n",
      "Feature in test_audio at index 1205 has shape: torch.Size([769, 1024])\n",
      "Feature in test_audio at index 1206 has shape: torch.Size([517, 1024])\n",
      "Feature in test_audio at index 1207 has shape: torch.Size([757, 1024])\n",
      "Feature in test_audio at index 1208 has shape: torch.Size([615, 1024])\n",
      "Feature in test_audio at index 1209 has shape: torch.Size([727, 1024])\n",
      "Feature in test_audio at index 1210 has shape: torch.Size([295, 1024])\n",
      "Feature in test_audio at index 1211 has shape: torch.Size([547, 1024])\n",
      "Feature in test_audio at index 1212 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 1213 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 1214 has shape: torch.Size([1021, 1024])\n",
      "Feature in test_audio at index 1215 has shape: torch.Size([664, 1024])\n",
      "Feature in test_audio at index 1216 has shape: torch.Size([724, 1024])\n",
      "Feature in test_audio at index 1217 has shape: torch.Size([509, 1024])\n",
      "Feature in test_audio at index 1218 has shape: torch.Size([921, 1024])\n",
      "Feature in test_audio at index 1219 has shape: torch.Size([249, 1024])\n",
      "Feature in test_audio at index 1220 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 1221 has shape: torch.Size([454, 1024])\n",
      "Feature in test_audio at index 1222 has shape: torch.Size([141, 1024])\n",
      "Feature in test_audio at index 1223 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 1224 has shape: torch.Size([211, 1024])\n",
      "Feature in test_audio at index 1225 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 1226 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 1227 has shape: torch.Size([629, 1024])\n",
      "Feature in test_audio at index 1228 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 1229 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 1230 has shape: torch.Size([288, 1024])\n",
      "Feature in test_audio at index 1231 has shape: torch.Size([1011, 1024])\n",
      "Feature in test_audio at index 1232 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 1233 has shape: torch.Size([522, 1024])\n",
      "Feature in test_audio at index 1234 has shape: torch.Size([863, 1024])\n",
      "Feature in test_audio at index 1235 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 1236 has shape: torch.Size([369, 1024])\n",
      "Feature in test_audio at index 1237 has shape: torch.Size([469, 1024])\n",
      "Feature in test_audio at index 1238 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 1239 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 1240 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 1241 has shape: torch.Size([1159, 1024])\n",
      "Feature in test_audio at index 1242 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 1243 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 1244 has shape: torch.Size([739, 1024])\n",
      "Feature in test_audio at index 1245 has shape: torch.Size([761, 1024])\n",
      "Feature in test_audio at index 1246 has shape: torch.Size([1224, 1024])\n",
      "Feature in test_audio at index 1247 has shape: torch.Size([611, 1024])\n",
      "Feature in test_audio at index 1248 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 1249 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 1250 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 1251 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 1252 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 1253 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 1254 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 1255 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 1256 has shape: torch.Size([1028, 1024])\n",
      "Feature in test_audio at index 1257 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 1258 has shape: torch.Size([758, 1024])\n",
      "Feature in test_audio at index 1259 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 1260 has shape: torch.Size([783, 1024])\n",
      "Feature in test_audio at index 1261 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 1262 has shape: torch.Size([1109, 1024])\n",
      "Feature in test_audio at index 1263 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 1264 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 1265 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 1266 has shape: torch.Size([784, 1024])\n",
      "Feature in test_audio at index 1267 has shape: torch.Size([711, 1024])\n",
      "Feature in test_audio at index 1268 has shape: torch.Size([784, 1024])\n",
      "Feature in test_audio at index 1269 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 1270 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 1271 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 1272 has shape: torch.Size([618, 1024])\n",
      "Feature in test_audio at index 1273 has shape: torch.Size([719, 1024])\n",
      "Feature in test_audio at index 1274 has shape: torch.Size([531, 1024])\n",
      "Feature in test_audio at index 1275 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 1276 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 1277 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 1278 has shape: torch.Size([326, 1024])\n",
      "Feature in test_audio at index 1279 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 1280 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 1281 has shape: torch.Size([461, 1024])\n",
      "Feature in test_audio at index 1282 has shape: torch.Size([604, 1024])\n",
      "Feature in test_audio at index 1283 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 1284 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 1285 has shape: torch.Size([336, 1024])\n",
      "Feature in test_audio at index 1286 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 1287 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 1288 has shape: torch.Size([749, 1024])\n",
      "Feature in test_audio at index 1289 has shape: torch.Size([679, 1024])\n",
      "Feature in test_audio at index 1290 has shape: torch.Size([183, 1024])\n",
      "Feature in test_audio at index 1291 has shape: torch.Size([541, 1024])\n",
      "Feature in test_audio at index 1292 has shape: torch.Size([1448, 1024])\n",
      "Feature in test_audio at index 1293 has shape: torch.Size([767, 1024])\n",
      "Feature in test_audio at index 1294 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 1295 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 1296 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 1297 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 1298 has shape: torch.Size([640, 1024])\n",
      "Feature in test_audio at index 1299 has shape: torch.Size([1264, 1024])\n",
      "Feature in test_audio at index 1300 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 1301 has shape: torch.Size([855, 1024])\n",
      "Feature in test_audio at index 1302 has shape: torch.Size([809, 1024])\n",
      "Feature in test_audio at index 1303 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 1304 has shape: torch.Size([146, 1024])\n",
      "Feature in test_audio at index 1305 has shape: torch.Size([713, 1024])\n",
      "Feature in test_audio at index 1306 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 1307 has shape: torch.Size([669, 1024])\n",
      "Feature in test_audio at index 1308 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 1309 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 1310 has shape: torch.Size([723, 1024])\n",
      "Feature in test_audio at index 1311 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 1312 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 1313 has shape: torch.Size([98, 1024])\n",
      "Feature in test_audio at index 1314 has shape: torch.Size([410, 1024])\n",
      "Feature in test_audio at index 1315 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 1316 has shape: torch.Size([220, 1024])\n",
      "Feature in test_audio at index 1317 has shape: torch.Size([1418, 1024])\n",
      "Feature in test_audio at index 1318 has shape: torch.Size([604, 1024])\n",
      "Feature in test_audio at index 1319 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 1320 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 1321 has shape: torch.Size([731, 1024])\n",
      "Feature in test_audio at index 1322 has shape: torch.Size([508, 1024])\n",
      "Feature in test_audio at index 1323 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 1324 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 1325 has shape: torch.Size([414, 1024])\n",
      "Feature in test_audio at index 1326 has shape: torch.Size([345, 1024])\n",
      "Feature in test_audio at index 1327 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 1328 has shape: torch.Size([364, 1024])\n",
      "Feature in test_audio at index 1329 has shape: torch.Size([948, 1024])\n",
      "Feature in test_audio at index 1330 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 1331 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 1332 has shape: torch.Size([374, 1024])\n",
      "Feature in test_audio at index 1333 has shape: torch.Size([959, 1024])\n",
      "Feature in test_audio at index 1334 has shape: torch.Size([764, 1024])\n",
      "Feature in test_audio at index 1335 has shape: torch.Size([1339, 1024])\n",
      "Feature in test_audio at index 1336 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 1337 has shape: torch.Size([886, 1024])\n",
      "Feature in test_audio at index 1338 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 1339 has shape: torch.Size([509, 1024])\n",
      "Feature in test_audio at index 1340 has shape: torch.Size([809, 1024])\n",
      "Feature in test_audio at index 1341 has shape: torch.Size([386, 1024])\n",
      "Feature in test_audio at index 1342 has shape: torch.Size([737, 1024])\n",
      "Feature in test_audio at index 1343 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 1344 has shape: torch.Size([883, 1024])\n",
      "Feature in test_audio at index 1345 has shape: torch.Size([738, 1024])\n",
      "Feature in test_audio at index 1346 has shape: torch.Size([446, 1024])\n",
      "Feature in test_audio at index 1347 has shape: torch.Size([343, 1024])\n",
      "Feature in test_audio at index 1348 has shape: torch.Size([430, 1024])\n",
      "Feature in test_audio at index 1349 has shape: torch.Size([265, 1024])\n",
      "Feature in test_audio at index 1350 has shape: torch.Size([213, 1024])\n",
      "Feature in test_audio at index 1351 has shape: torch.Size([333, 1024])\n",
      "Feature in test_audio at index 1352 has shape: torch.Size([323, 1024])\n",
      "Feature in test_audio at index 1353 has shape: torch.Size([510, 1024])\n",
      "Feature in test_audio at index 1354 has shape: torch.Size([540, 1024])\n",
      "Feature in test_audio at index 1355 has shape: torch.Size([213, 1024])\n",
      "Feature in test_audio at index 1356 has shape: torch.Size([642, 1024])\n",
      "Feature in test_audio at index 1357 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 1358 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 1359 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 1360 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 1361 has shape: torch.Size([378, 1024])\n",
      "Feature in test_audio at index 1362 has shape: torch.Size([688, 1024])\n",
      "Feature in test_audio at index 1363 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 1364 has shape: torch.Size([276, 1024])\n",
      "Feature in test_audio at index 1365 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 1366 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 1367 has shape: torch.Size([372, 1024])\n",
      "Feature in test_audio at index 1368 has shape: torch.Size([425, 1024])\n",
      "Feature in test_audio at index 1369 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 1370 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1371 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 1372 has shape: torch.Size([414, 1024])\n",
      "Feature in test_audio at index 1373 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 1374 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 1375 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 1376 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 1377 has shape: torch.Size([427, 1024])\n",
      "Feature in test_audio at index 1378 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 1379 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 1380 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 1381 has shape: torch.Size([421, 1024])\n",
      "Feature in test_audio at index 1382 has shape: torch.Size([629, 1024])\n",
      "Feature in test_audio at index 1383 has shape: torch.Size([326, 1024])\n",
      "Feature in test_audio at index 1384 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 1385 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 1386 has shape: torch.Size([299, 1024])\n",
      "Feature in test_audio at index 1387 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 1388 has shape: torch.Size([333, 1024])\n",
      "Feature in test_audio at index 1389 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 1390 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 1391 has shape: torch.Size([893, 1024])\n",
      "Feature in test_audio at index 1392 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 1393 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 1394 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 1395 has shape: torch.Size([374, 1024])\n",
      "Feature in test_audio at index 1396 has shape: torch.Size([144, 1024])\n",
      "Feature in test_audio at index 1397 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 1398 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 1399 has shape: torch.Size([519, 1024])\n",
      "Feature in test_audio at index 1400 has shape: torch.Size([688, 1024])\n",
      "Feature in test_audio at index 1401 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 1402 has shape: torch.Size([741, 1024])\n",
      "Feature in test_audio at index 1403 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 1404 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 1405 has shape: torch.Size([508, 1024])\n",
      "Feature in test_audio at index 1406 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 1407 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 1408 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 1409 has shape: torch.Size([355, 1024])\n",
      "Feature in test_audio at index 1410 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 1411 has shape: torch.Size([481, 1024])\n",
      "Feature in test_audio at index 1412 has shape: torch.Size([603, 1024])\n",
      "Feature in test_audio at index 1413 has shape: torch.Size([673, 1024])\n",
      "Feature in test_audio at index 1414 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 1415 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 1416 has shape: torch.Size([1971, 1024])\n",
      "Feature in test_audio at index 1417 has shape: torch.Size([1036, 1024])\n",
      "Feature in test_audio at index 1418 has shape: torch.Size([1244, 1024])\n",
      "Feature in test_audio at index 1419 has shape: torch.Size([1303, 1024])\n",
      "Feature in test_audio at index 1420 has shape: torch.Size([366, 1024])\n",
      "Feature in test_audio at index 1421 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 1422 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 1423 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 1424 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 1425 has shape: torch.Size([297, 1024])\n",
      "Feature in test_audio at index 1426 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 1427 has shape: torch.Size([271, 1024])\n",
      "Feature in test_audio at index 1428 has shape: torch.Size([250, 1024])\n",
      "Feature in test_audio at index 1429 has shape: torch.Size([685, 1024])\n",
      "Feature in test_audio at index 1430 has shape: torch.Size([877, 1024])\n",
      "Feature in test_audio at index 1431 has shape: torch.Size([796, 1024])\n",
      "Feature in test_audio at index 1432 has shape: torch.Size([315, 1024])\n",
      "Feature in test_audio at index 1433 has shape: torch.Size([405, 1024])\n",
      "Feature in test_audio at index 1434 has shape: torch.Size([227, 1024])\n",
      "Feature in test_audio at index 1435 has shape: torch.Size([903, 1024])\n",
      "Feature in test_audio at index 1436 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 1437 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 1438 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 1439 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 1440 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 1441 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 1442 has shape: torch.Size([623, 1024])\n",
      "Feature in test_audio at index 1443 has shape: torch.Size([1009, 1024])\n",
      "Feature in test_audio at index 1444 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 1445 has shape: torch.Size([804, 1024])\n",
      "Feature in test_audio at index 1446 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 1447 has shape: torch.Size([374, 1024])\n",
      "Feature in test_audio at index 1448 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 1449 has shape: torch.Size([604, 1024])\n",
      "Feature in test_audio at index 1450 has shape: torch.Size([266, 1024])\n",
      "Feature in test_audio at index 1451 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 1452 has shape: torch.Size([366, 1024])\n",
      "Feature in test_audio at index 1453 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 1454 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 1455 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 1456 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 1457 has shape: torch.Size([223, 1024])\n",
      "Feature in test_audio at index 1458 has shape: torch.Size([928, 1024])\n",
      "Feature in test_audio at index 1459 has shape: torch.Size([761, 1024])\n",
      "Feature in test_audio at index 1460 has shape: torch.Size([735, 1024])\n",
      "Feature in test_audio at index 1461 has shape: torch.Size([717, 1024])\n",
      "Feature in test_audio at index 1462 has shape: torch.Size([768, 1024])\n",
      "Feature in test_audio at index 1463 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 1464 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 1465 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 1466 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 1467 has shape: torch.Size([509, 1024])\n",
      "Feature in test_audio at index 1468 has shape: torch.Size([1626, 1024])\n",
      "Feature in test_audio at index 1469 has shape: torch.Size([687, 1024])\n",
      "Feature in test_audio at index 1470 has shape: torch.Size([927, 1024])\n",
      "Feature in test_audio at index 1471 has shape: torch.Size([924, 1024])\n",
      "Feature in test_audio at index 1472 has shape: torch.Size([734, 1024])\n",
      "Feature in test_audio at index 1473 has shape: torch.Size([719, 1024])\n",
      "Feature in test_audio at index 1474 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 1475 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 1476 has shape: torch.Size([873, 1024])\n",
      "Feature in test_audio at index 1477 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 1478 has shape: torch.Size([225, 1024])\n",
      "Feature in test_audio at index 1479 has shape: torch.Size([783, 1024])\n",
      "Feature in test_audio at index 1480 has shape: torch.Size([761, 1024])\n",
      "Feature in test_audio at index 1481 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 1482 has shape: torch.Size([326, 1024])\n",
      "Feature in test_audio at index 1483 has shape: torch.Size([685, 1024])\n",
      "Feature in test_audio at index 1484 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 1485 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 1486 has shape: torch.Size([266, 1024])\n",
      "Feature in test_audio at index 1487 has shape: torch.Size([436, 1024])\n",
      "Feature in test_audio at index 1488 has shape: torch.Size([845, 1024])\n",
      "Feature in test_audio at index 1489 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 1490 has shape: torch.Size([148, 1024])\n",
      "Feature in test_audio at index 1491 has shape: torch.Size([849, 1024])\n",
      "Feature in test_audio at index 1492 has shape: torch.Size([1206, 1024])\n",
      "Feature in test_audio at index 1493 has shape: torch.Size([951, 1024])\n",
      "Feature in test_audio at index 1494 has shape: torch.Size([734, 1024])\n",
      "Feature in test_audio at index 1495 has shape: torch.Size([213, 1024])\n",
      "Feature in test_audio at index 1496 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 1497 has shape: torch.Size([863, 1024])\n",
      "Feature in test_audio at index 1498 has shape: torch.Size([883, 1024])\n",
      "Feature in test_audio at index 1499 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 1500 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 1501 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 1502 has shape: torch.Size([89, 1024])\n",
      "Feature in test_audio at index 1503 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 1504 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 1505 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 1506 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 1507 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 1508 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 1509 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 1510 has shape: torch.Size([439, 1024])\n",
      "Feature in test_audio at index 1511 has shape: torch.Size([139, 1024])\n",
      "Feature in test_audio at index 1512 has shape: torch.Size([406, 1024])\n",
      "Feature in test_audio at index 1513 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 1514 has shape: torch.Size([353, 1024])\n",
      "Feature in test_audio at index 1515 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 1516 has shape: torch.Size([830, 1024])\n",
      "Feature in test_audio at index 1517 has shape: torch.Size([239, 1024])\n",
      "Feature in test_audio at index 1518 has shape: torch.Size([536, 1024])\n",
      "Feature in test_audio at index 1519 has shape: torch.Size([339, 1024])\n",
      "Feature in test_audio at index 1520 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 1521 has shape: torch.Size([366, 1024])\n",
      "Feature in test_audio at index 1522 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 1523 has shape: torch.Size([350, 1024])\n",
      "Feature in test_audio at index 1524 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 1525 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 1526 has shape: torch.Size([675, 1024])\n",
      "Feature in test_audio at index 1527 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 1528 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 1529 has shape: torch.Size([791, 1024])\n",
      "Feature in test_audio at index 1530 has shape: torch.Size([982, 1024])\n",
      "Feature in test_audio at index 1531 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 1532 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 1533 has shape: torch.Size([875, 1024])\n",
      "Feature in test_audio at index 1534 has shape: torch.Size([941, 1024])\n",
      "Feature in test_audio at index 1535 has shape: torch.Size([968, 1024])\n",
      "Feature in test_audio at index 1536 has shape: torch.Size([664, 1024])\n",
      "Feature in test_audio at index 1537 has shape: torch.Size([824, 1024])\n",
      "Feature in test_audio at index 1538 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 1539 has shape: torch.Size([778, 1024])\n",
      "Feature in test_audio at index 1540 has shape: torch.Size([1214, 1024])\n",
      "Feature in test_audio at index 1541 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 1542 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 1543 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 1544 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 1545 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 1546 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 1547 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 1548 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 1549 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 1550 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 1551 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 1552 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 1553 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 1554 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 1555 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 1556 has shape: torch.Size([1136, 1024])\n",
      "Feature in test_audio at index 1557 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 1558 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 1559 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 1560 has shape: torch.Size([229, 1024])\n",
      "Feature in test_audio at index 1561 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 1562 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 1563 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 1564 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 1565 has shape: torch.Size([628, 1024])\n",
      "Feature in test_audio at index 1566 has shape: torch.Size([306, 1024])\n",
      "Feature in test_audio at index 1567 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 1568 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 1569 has shape: torch.Size([727, 1024])\n",
      "Feature in test_audio at index 1570 has shape: torch.Size([781, 1024])\n",
      "Feature in test_audio at index 1571 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 1572 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 1573 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 1574 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 1575 has shape: torch.Size([791, 1024])\n",
      "Feature in test_audio at index 1576 has shape: torch.Size([719, 1024])\n",
      "Feature in test_audio at index 1577 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 1578 has shape: torch.Size([1185, 1024])\n",
      "Feature in test_audio at index 1579 has shape: torch.Size([1051, 1024])\n",
      "Feature in test_audio at index 1580 has shape: torch.Size([380, 1024])\n",
      "Feature in test_audio at index 1581 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 1582 has shape: torch.Size([774, 1024])\n",
      "Feature in test_audio at index 1583 has shape: torch.Size([703, 1024])\n",
      "Feature in test_audio at index 1584 has shape: torch.Size([1042, 1024])\n",
      "Feature in test_audio at index 1585 has shape: torch.Size([799, 1024])\n",
      "Feature in test_audio at index 1586 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1587 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 1588 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 1589 has shape: torch.Size([610, 1024])\n",
      "Feature in test_audio at index 1590 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 1591 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 1592 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 1593 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 1594 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 1595 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 1596 has shape: torch.Size([818, 1024])\n",
      "Feature in test_audio at index 1597 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 1598 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 1599 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 1600 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 1601 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 1602 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 1603 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 1604 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 1605 has shape: torch.Size([627, 1024])\n",
      "Feature in test_audio at index 1606 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 1607 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 1608 has shape: torch.Size([366, 1024])\n",
      "Feature in test_audio at index 1609 has shape: torch.Size([648, 1024])\n",
      "Feature in test_audio at index 1610 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 1611 has shape: torch.Size([1161, 1024])\n",
      "Feature in test_audio at index 1612 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 1613 has shape: torch.Size([235, 1024])\n",
      "Feature in test_audio at index 1614 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 1615 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 1616 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 1617 has shape: torch.Size([1476, 1024])\n",
      "Feature in test_audio at index 1618 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 1619 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 1620 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 1621 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 1622 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1623 has shape: torch.Size([823, 1024])\n",
      "Feature in test_audio at index 1624 has shape: torch.Size([728, 1024])\n",
      "Feature in test_audio at index 1625 has shape: torch.Size([856, 1024])\n",
      "Feature in test_audio at index 1626 has shape: torch.Size([1291, 1024])\n",
      "Feature in test_audio at index 1627 has shape: torch.Size([495, 1024])\n",
      "Feature in test_audio at index 1628 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 1629 has shape: torch.Size([418, 1024])\n",
      "Feature in test_audio at index 1630 has shape: torch.Size([949, 1024])\n",
      "Feature in test_audio at index 1631 has shape: torch.Size([1178, 1024])\n",
      "Feature in test_audio at index 1632 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 1633 has shape: torch.Size([1063, 1024])\n",
      "Feature in test_audio at index 1634 has shape: torch.Size([2339, 1024])\n",
      "Feature in test_audio at index 1635 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 1636 has shape: torch.Size([1608, 1024])\n",
      "Feature in test_audio at index 1637 has shape: torch.Size([1103, 1024])\n",
      "Feature in test_audio at index 1638 has shape: torch.Size([621, 1024])\n",
      "Feature in test_audio at index 1639 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 1640 has shape: torch.Size([1033, 1024])\n",
      "Feature in test_audio at index 1641 has shape: torch.Size([426, 1024])\n",
      "Feature in test_audio at index 1642 has shape: torch.Size([1213, 1024])\n",
      "Feature in test_audio at index 1643 has shape: torch.Size([654, 1024])\n",
      "Feature in test_audio at index 1644 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 1645 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 1646 has shape: torch.Size([705, 1024])\n",
      "Feature in test_audio at index 1647 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 1648 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 1649 has shape: torch.Size([1233, 1024])\n",
      "Feature in test_audio at index 1650 has shape: torch.Size([961, 1024])\n",
      "Feature in test_audio at index 1651 has shape: torch.Size([218, 1024])\n",
      "Feature in test_audio at index 1652 has shape: torch.Size([380, 1024])\n",
      "Feature in test_audio at index 1653 has shape: torch.Size([656, 1024])\n",
      "Feature in test_audio at index 1654 has shape: torch.Size([1178, 1024])\n",
      "Feature in test_audio at index 1655 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 1656 has shape: torch.Size([168, 1024])\n",
      "Feature in test_audio at index 1657 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 1658 has shape: torch.Size([662, 1024])\n",
      "Feature in test_audio at index 1659 has shape: torch.Size([582, 1024])\n",
      "Feature in test_audio at index 1660 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 1661 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 1662 has shape: torch.Size([786, 1024])\n",
      "Feature in test_audio at index 1663 has shape: torch.Size([847, 1024])\n",
      "Feature in test_audio at index 1664 has shape: torch.Size([659, 1024])\n",
      "Feature in test_audio at index 1665 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 1666 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 1667 has shape: torch.Size([406, 1024])\n",
      "Feature in test_audio at index 1668 has shape: torch.Size([379, 1024])\n",
      "Feature in test_audio at index 1669 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 1670 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 1671 has shape: torch.Size([536, 1024])\n",
      "Feature in test_audio at index 1672 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 1673 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 1674 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 1675 has shape: torch.Size([971, 1024])\n",
      "Feature in test_audio at index 1676 has shape: torch.Size([163, 1024])\n",
      "Feature in test_audio at index 1677 has shape: torch.Size([671, 1024])\n",
      "Feature in test_audio at index 1678 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 1679 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 1680 has shape: torch.Size([2074, 1024])\n",
      "Feature in test_audio at index 1681 has shape: torch.Size([238, 1024])\n",
      "Feature in test_audio at index 1682 has shape: torch.Size([1110, 1024])\n",
      "Feature in test_audio at index 1683 has shape: torch.Size([1296, 1024])\n",
      "Feature in test_audio at index 1684 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 1685 has shape: torch.Size([1121, 1024])\n",
      "Feature in test_audio at index 1686 has shape: torch.Size([630, 1024])\n",
      "Feature in test_audio at index 1687 has shape: torch.Size([794, 1024])\n",
      "Feature in test_audio at index 1688 has shape: torch.Size([982, 1024])\n",
      "Feature in test_audio at index 1689 has shape: torch.Size([1069, 1024])\n",
      "Feature in test_audio at index 1690 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 1691 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 1692 has shape: torch.Size([197, 1024])\n",
      "Feature in test_audio at index 1693 has shape: torch.Size([1084, 1024])\n",
      "Feature in test_audio at index 1694 has shape: torch.Size([1041, 1024])\n",
      "Feature in test_audio at index 1695 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 1696 has shape: torch.Size([144, 1024])\n",
      "Feature in test_audio at index 1697 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 1698 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 1699 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 1700 has shape: torch.Size([310, 1024])\n",
      "Feature in test_audio at index 1701 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 1702 has shape: torch.Size([1014, 1024])\n",
      "Feature in test_audio at index 1703 has shape: torch.Size([340, 1024])\n",
      "Feature in test_audio at index 1704 has shape: torch.Size([484, 1024])\n",
      "Feature in test_audio at index 1705 has shape: torch.Size([536, 1024])\n",
      "Feature in test_audio at index 1706 has shape: torch.Size([939, 1024])\n",
      "Feature in test_audio at index 1707 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 1708 has shape: torch.Size([832, 1024])\n",
      "Feature in test_audio at index 1709 has shape: torch.Size([915, 1024])\n",
      "Feature in test_audio at index 1710 has shape: torch.Size([1188, 1024])\n",
      "Feature in test_audio at index 1711 has shape: torch.Size([1221, 1024])\n",
      "Feature in test_audio at index 1712 has shape: torch.Size([851, 1024])\n",
      "Feature in test_audio at index 1713 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 1714 has shape: torch.Size([1252, 1024])\n",
      "Feature in test_audio at index 1715 has shape: torch.Size([953, 1024])\n",
      "Feature in test_audio at index 1716 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 1717 has shape: torch.Size([560, 1024])\n",
      "Feature in test_audio at index 1718 has shape: torch.Size([808, 1024])\n",
      "Feature in test_audio at index 1719 has shape: torch.Size([386, 1024])\n",
      "Feature in test_audio at index 1720 has shape: torch.Size([616, 1024])\n",
      "Feature in test_audio at index 1721 has shape: torch.Size([241, 1024])\n",
      "Feature in test_audio at index 1722 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 1723 has shape: torch.Size([701, 1024])\n",
      "Feature in test_audio at index 1724 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 1725 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 1726 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 1727 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 1728 has shape: torch.Size([850, 1024])\n",
      "Feature in test_audio at index 1729 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 1730 has shape: torch.Size([778, 1024])\n",
      "Feature in test_audio at index 1731 has shape: torch.Size([618, 1024])\n",
      "Feature in test_audio at index 1732 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 1733 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 1734 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 1735 has shape: torch.Size([443, 1024])\n",
      "Feature in test_audio at index 1736 has shape: torch.Size([367, 1024])\n",
      "Feature in test_audio at index 1737 has shape: torch.Size([253, 1024])\n",
      "Feature in test_audio at index 1738 has shape: torch.Size([461, 1024])\n",
      "Feature in test_audio at index 1739 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 1740 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 1741 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 1742 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 1743 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 1744 has shape: torch.Size([565, 1024])\n",
      "Feature in test_audio at index 1745 has shape: torch.Size([730, 1024])\n",
      "Feature in test_audio at index 1746 has shape: torch.Size([623, 1024])\n",
      "Feature in test_audio at index 1747 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 1748 has shape: torch.Size([1313, 1024])\n",
      "Feature in test_audio at index 1749 has shape: torch.Size([1183, 1024])\n",
      "Feature in test_audio at index 1750 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 1751 has shape: torch.Size([761, 1024])\n",
      "Feature in test_audio at index 1752 has shape: torch.Size([1126, 1024])\n",
      "Feature in test_audio at index 1753 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 1754 has shape: torch.Size([497, 1024])\n",
      "Feature in test_audio at index 1755 has shape: torch.Size([206, 1024])\n",
      "Feature in test_audio at index 1756 has shape: torch.Size([526, 1024])\n",
      "Feature in test_audio at index 1757 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 1758 has shape: torch.Size([647, 1024])\n",
      "Feature in test_audio at index 1759 has shape: torch.Size([738, 1024])\n",
      "Feature in test_audio at index 1760 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1761 has shape: torch.Size([734, 1024])\n",
      "Feature in test_audio at index 1762 has shape: torch.Size([861, 1024])\n",
      "Feature in test_audio at index 1763 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 1764 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 1765 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 1766 has shape: torch.Size([869, 1024])\n",
      "Feature in test_audio at index 1767 has shape: torch.Size([663, 1024])\n",
      "Feature in test_audio at index 1768 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 1769 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 1770 has shape: torch.Size([596, 1024])\n",
      "Feature in test_audio at index 1771 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 1772 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 1773 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 1774 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 1775 has shape: torch.Size([923, 1024])\n",
      "Feature in test_audio at index 1776 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 1777 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 1778 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 1779 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 1780 has shape: torch.Size([606, 1024])\n",
      "Feature in test_audio at index 1781 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 1782 has shape: torch.Size([688, 1024])\n",
      "Feature in test_audio at index 1783 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 1784 has shape: torch.Size([362, 1024])\n",
      "Feature in test_audio at index 1785 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 1786 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 1787 has shape: torch.Size([813, 1024])\n",
      "Feature in test_audio at index 1788 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 1789 has shape: torch.Size([826, 1024])\n",
      "Feature in test_audio at index 1790 has shape: torch.Size([948, 1024])\n",
      "Feature in test_audio at index 1791 has shape: torch.Size([287, 1024])\n",
      "Feature in test_audio at index 1792 has shape: torch.Size([266, 1024])\n",
      "Feature in test_audio at index 1793 has shape: torch.Size([186, 1024])\n",
      "Feature in test_audio at index 1794 has shape: torch.Size([264, 1024])\n",
      "Feature in test_audio at index 1795 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 1796 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 1797 has shape: torch.Size([386, 1024])\n",
      "Feature in test_audio at index 1798 has shape: torch.Size([632, 1024])\n",
      "Feature in test_audio at index 1799 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 1800 has shape: torch.Size([173, 1024])\n",
      "Feature in test_audio at index 1801 has shape: torch.Size([149, 1024])\n",
      "Feature in test_audio at index 1802 has shape: torch.Size([436, 1024])\n",
      "Feature in test_audio at index 1803 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 1804 has shape: torch.Size([1111, 1024])\n",
      "Feature in test_audio at index 1805 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 1806 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 1807 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 1808 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 1809 has shape: torch.Size([943, 1024])\n",
      "Feature in test_audio at index 1810 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 1811 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 1812 has shape: torch.Size([350, 1024])\n",
      "Feature in test_audio at index 1813 has shape: torch.Size([370, 1024])\n",
      "Feature in test_audio at index 1814 has shape: torch.Size([1469, 1024])\n",
      "Feature in test_audio at index 1815 has shape: torch.Size([426, 1024])\n",
      "Feature in test_audio at index 1816 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 1817 has shape: torch.Size([875, 1024])\n",
      "Feature in test_audio at index 1818 has shape: torch.Size([415, 1024])\n",
      "Feature in test_audio at index 1819 has shape: torch.Size([586, 1024])\n",
      "Feature in test_audio at index 1820 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 1821 has shape: torch.Size([435, 1024])\n",
      "Feature in test_audio at index 1822 has shape: torch.Size([310, 1024])\n",
      "Feature in test_audio at index 1823 has shape: torch.Size([178, 1024])\n",
      "Feature in test_audio at index 1824 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 1825 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 1826 has shape: torch.Size([956, 1024])\n",
      "Feature in test_audio at index 1827 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 1828 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 1829 has shape: torch.Size([614, 1024])\n",
      "Feature in test_audio at index 1830 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 1831 has shape: torch.Size([405, 1024])\n",
      "Feature in test_audio at index 1832 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 1833 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 1834 has shape: torch.Size([901, 1024])\n",
      "Feature in test_audio at index 1835 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 1836 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 1837 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 1838 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 1839 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 1840 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 1841 has shape: torch.Size([271, 1024])\n",
      "Feature in test_audio at index 1842 has shape: torch.Size([1112, 1024])\n",
      "Feature in test_audio at index 1843 has shape: torch.Size([1019, 1024])\n",
      "Feature in test_audio at index 1844 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 1845 has shape: torch.Size([733, 1024])\n",
      "Feature in test_audio at index 1846 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 1847 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 1848 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 1849 has shape: torch.Size([749, 1024])\n",
      "Feature in test_audio at index 1850 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 1851 has shape: torch.Size([855, 1024])\n",
      "Feature in test_audio at index 1852 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 1853 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 1854 has shape: torch.Size([223, 1024])\n",
      "Feature in test_audio at index 1855 has shape: torch.Size([1123, 1024])\n",
      "Feature in test_audio at index 1856 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 1857 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 1858 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 1859 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 1860 has shape: torch.Size([862, 1024])\n",
      "Feature in test_audio at index 1861 has shape: torch.Size([1063, 1024])\n",
      "Feature in test_audio at index 1862 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 1863 has shape: torch.Size([854, 1024])\n",
      "Feature in test_audio at index 1864 has shape: torch.Size([909, 1024])\n",
      "Feature in test_audio at index 1865 has shape: torch.Size([1223, 1024])\n",
      "Feature in test_audio at index 1866 has shape: torch.Size([1024, 1024])\n",
      "Feature in test_audio at index 1867 has shape: torch.Size([709, 1024])\n",
      "Feature in test_audio at index 1868 has shape: torch.Size([851, 1024])\n",
      "Feature in test_audio at index 1869 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 1870 has shape: torch.Size([1230, 1024])\n",
      "Feature in test_audio at index 1871 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 1872 has shape: torch.Size([201, 1024])\n",
      "Feature in test_audio at index 1873 has shape: torch.Size([121, 1024])\n",
      "Feature in test_audio at index 1874 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 1875 has shape: torch.Size([228, 1024])\n",
      "Feature in test_audio at index 1876 has shape: torch.Size([901, 1024])\n",
      "Feature in test_audio at index 1877 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 1878 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 1879 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 1880 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 1881 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 1882 has shape: torch.Size([854, 1024])\n",
      "Feature in test_audio at index 1883 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 1884 has shape: torch.Size([874, 1024])\n",
      "Feature in test_audio at index 1885 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 1886 has shape: torch.Size([336, 1024])\n",
      "Feature in test_audio at index 1887 has shape: torch.Size([876, 1024])\n",
      "Feature in test_audio at index 1888 has shape: torch.Size([783, 1024])\n",
      "Feature in test_audio at index 1889 has shape: torch.Size([526, 1024])\n",
      "Feature in test_audio at index 1890 has shape: torch.Size([619, 1024])\n",
      "Feature in test_audio at index 1891 has shape: torch.Size([1418, 1024])\n",
      "Feature in test_audio at index 1892 has shape: torch.Size([161, 1024])\n",
      "Feature in test_audio at index 1893 has shape: torch.Size([265, 1024])\n",
      "Feature in test_audio at index 1894 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 1895 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 1896 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 1897 has shape: torch.Size([299, 1024])\n",
      "Feature in test_audio at index 1898 has shape: torch.Size([266, 1024])\n",
      "Feature in test_audio at index 1899 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 1900 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 1901 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 1902 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 1903 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 1904 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 1905 has shape: torch.Size([669, 1024])\n",
      "Feature in test_audio at index 1906 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 1907 has shape: torch.Size([964, 1024])\n",
      "Feature in test_audio at index 1908 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 1909 has shape: torch.Size([312, 1024])\n",
      "Feature in test_audio at index 1910 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 1911 has shape: torch.Size([617, 1024])\n",
      "Feature in test_audio at index 1912 has shape: torch.Size([943, 1024])\n",
      "Feature in test_audio at index 1913 has shape: torch.Size([978, 1024])\n",
      "Feature in test_audio at index 1914 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 1915 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 1916 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 1917 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 1918 has shape: torch.Size([936, 1024])\n",
      "Feature in test_audio at index 1919 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 1920 has shape: torch.Size([541, 1024])\n",
      "Feature in test_audio at index 1921 has shape: torch.Size([954, 1024])\n",
      "Feature in test_audio at index 1922 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 1923 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 1924 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 1925 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 1926 has shape: torch.Size([304, 1024])\n",
      "Feature in test_audio at index 1927 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 1928 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 1929 has shape: torch.Size([345, 1024])\n",
      "Feature in test_audio at index 1930 has shape: torch.Size([1624, 1024])\n",
      "Feature in test_audio at index 1931 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 1932 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 1933 has shape: torch.Size([309, 1024])\n",
      "Feature in test_audio at index 1934 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 1935 has shape: torch.Size([502, 1024])\n",
      "Feature in test_audio at index 1936 has shape: torch.Size([140, 1024])\n",
      "Feature in test_audio at index 1937 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 1938 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 1939 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 1940 has shape: torch.Size([178, 1024])\n",
      "Feature in test_audio at index 1941 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 1942 has shape: torch.Size([1213, 1024])\n",
      "Feature in test_audio at index 1943 has shape: torch.Size([1055, 1024])\n",
      "Feature in test_audio at index 1944 has shape: torch.Size([743, 1024])\n",
      "Feature in test_audio at index 1945 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 1946 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 1947 has shape: torch.Size([892, 1024])\n",
      "Feature in test_audio at index 1948 has shape: torch.Size([804, 1024])\n",
      "Feature in test_audio at index 1949 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 1950 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 1951 has shape: torch.Size([616, 1024])\n",
      "Feature in test_audio at index 1952 has shape: torch.Size([759, 1024])\n",
      "Feature in test_audio at index 1953 has shape: torch.Size([133, 1024])\n",
      "Feature in test_audio at index 1954 has shape: torch.Size([410, 1024])\n",
      "Feature in test_audio at index 1955 has shape: torch.Size([567, 1024])\n",
      "Feature in test_audio at index 1956 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 1957 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 1958 has shape: torch.Size([803, 1024])\n",
      "Feature in test_audio at index 1959 has shape: torch.Size([710, 1024])\n",
      "Feature in test_audio at index 1960 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 1961 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 1962 has shape: torch.Size([352, 1024])\n",
      "Feature in test_audio at index 1963 has shape: torch.Size([755, 1024])\n",
      "Feature in test_audio at index 1964 has shape: torch.Size([983, 1024])\n",
      "Feature in test_audio at index 1965 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 1966 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 1967 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 1968 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 1969 has shape: torch.Size([756, 1024])\n",
      "Feature in test_audio at index 1970 has shape: torch.Size([744, 1024])\n",
      "Feature in test_audio at index 1971 has shape: torch.Size([1001, 1024])\n",
      "Feature in test_audio at index 1972 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 1973 has shape: torch.Size([293, 1024])\n",
      "Feature in test_audio at index 1974 has shape: torch.Size([236, 1024])\n",
      "Feature in test_audio at index 1975 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 1976 has shape: torch.Size([357, 1024])\n",
      "Feature in test_audio at index 1977 has shape: torch.Size([215, 1024])\n",
      "Feature in test_audio at index 1978 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 1979 has shape: torch.Size([306, 1024])\n",
      "Feature in test_audio at index 1980 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 1981 has shape: torch.Size([669, 1024])\n",
      "Feature in test_audio at index 1982 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 1983 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 1984 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 1985 has shape: torch.Size([896, 1024])\n",
      "Feature in test_audio at index 1986 has shape: torch.Size([916, 1024])\n",
      "Feature in test_audio at index 1987 has shape: torch.Size([979, 1024])\n",
      "Feature in test_audio at index 1988 has shape: torch.Size([1088, 1024])\n",
      "Feature in test_audio at index 1989 has shape: torch.Size([861, 1024])\n",
      "Feature in test_audio at index 1990 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 1991 has shape: torch.Size([819, 1024])\n",
      "Feature in test_audio at index 1992 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 1993 has shape: torch.Size([669, 1024])\n",
      "Feature in test_audio at index 1994 has shape: torch.Size([233, 1024])\n",
      "Feature in test_audio at index 1995 has shape: torch.Size([648, 1024])\n",
      "Feature in test_audio at index 1996 has shape: torch.Size([540, 1024])\n",
      "Feature in test_audio at index 1997 has shape: torch.Size([571, 1024])\n",
      "Feature in test_audio at index 1998 has shape: torch.Size([783, 1024])\n",
      "Feature in test_audio at index 1999 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 2000 has shape: torch.Size([185, 1024])\n",
      "Feature in test_audio at index 2001 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 2002 has shape: torch.Size([969, 1024])\n",
      "Feature in test_audio at index 2003 has shape: torch.Size([834, 1024])\n",
      "Feature in test_audio at index 2004 has shape: torch.Size([459, 1024])\n",
      "Feature in test_audio at index 2005 has shape: torch.Size([209, 1024])\n",
      "Feature in test_audio at index 2006 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 2007 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 2008 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 2009 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 2010 has shape: torch.Size([323, 1024])\n",
      "Feature in test_audio at index 2011 has shape: torch.Size([293, 1024])\n",
      "Feature in test_audio at index 2012 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 2013 has shape: torch.Size([1409, 1024])\n",
      "Feature in test_audio at index 2014 has shape: torch.Size([255, 1024])\n",
      "Feature in test_audio at index 2015 has shape: torch.Size([1148, 1024])\n",
      "Feature in test_audio at index 2016 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 2017 has shape: torch.Size([1588, 1024])\n",
      "Feature in test_audio at index 2018 has shape: torch.Size([1196, 1024])\n",
      "Feature in test_audio at index 2019 has shape: torch.Size([1141, 1024])\n",
      "Feature in test_audio at index 2020 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 2021 has shape: torch.Size([889, 1024])\n",
      "Feature in test_audio at index 2022 has shape: torch.Size([1201, 1024])\n",
      "Feature in test_audio at index 2023 has shape: torch.Size([553, 1024])\n",
      "Feature in test_audio at index 2024 has shape: torch.Size([1168, 1024])\n",
      "Feature in test_audio at index 2025 has shape: torch.Size([761, 1024])\n",
      "Feature in test_audio at index 2026 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 2027 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 2028 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 2029 has shape: torch.Size([610, 1024])\n",
      "Feature in test_audio at index 2030 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 2031 has shape: torch.Size([774, 1024])\n",
      "Feature in test_audio at index 2032 has shape: torch.Size([867, 1024])\n",
      "Feature in test_audio at index 2033 has shape: torch.Size([975, 1024])\n",
      "Feature in test_audio at index 2034 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 2035 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 2036 has shape: torch.Size([656, 1024])\n",
      "Feature in test_audio at index 2037 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 2038 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 2039 has shape: torch.Size([856, 1024])\n",
      "Feature in test_audio at index 2040 has shape: torch.Size([251, 1024])\n",
      "Feature in test_audio at index 2041 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 2042 has shape: torch.Size([994, 1024])\n",
      "Feature in test_audio at index 2043 has shape: torch.Size([1148, 1024])\n",
      "Feature in test_audio at index 2044 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 2045 has shape: torch.Size([570, 1024])\n",
      "Feature in test_audio at index 2046 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 2047 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 2048 has shape: torch.Size([216, 1024])\n",
      "Feature in test_audio at index 2049 has shape: torch.Size([690, 1024])\n",
      "Feature in test_audio at index 2050 has shape: torch.Size([526, 1024])\n",
      "Feature in test_audio at index 2051 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2052 has shape: torch.Size([1058, 1024])\n",
      "Feature in test_audio at index 2053 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 2054 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 2055 has shape: torch.Size([890, 1024])\n",
      "Feature in test_audio at index 2056 has shape: torch.Size([430, 1024])\n",
      "Feature in test_audio at index 2057 has shape: torch.Size([738, 1024])\n",
      "Feature in test_audio at index 2058 has shape: torch.Size([519, 1024])\n",
      "Feature in test_audio at index 2059 has shape: torch.Size([736, 1024])\n",
      "Feature in test_audio at index 2060 has shape: torch.Size([1054, 1024])\n",
      "Feature in test_audio at index 2061 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 2062 has shape: torch.Size([359, 1024])\n",
      "Feature in test_audio at index 2063 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 2064 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 2065 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 2066 has shape: torch.Size([786, 1024])\n",
      "Feature in test_audio at index 2067 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 2068 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 2069 has shape: torch.Size([625, 1024])\n",
      "Feature in test_audio at index 2070 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 2071 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 2072 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 2073 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 2074 has shape: torch.Size([341, 1024])\n",
      "Feature in test_audio at index 2075 has shape: torch.Size([380, 1024])\n",
      "Feature in test_audio at index 2076 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 2077 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 2078 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 2079 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 2080 has shape: torch.Size([719, 1024])\n",
      "Feature in test_audio at index 2081 has shape: torch.Size([801, 1024])\n",
      "Feature in test_audio at index 2082 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 2083 has shape: torch.Size([531, 1024])\n",
      "Feature in test_audio at index 2084 has shape: torch.Size([296, 1024])\n",
      "Feature in test_audio at index 2085 has shape: torch.Size([437, 1024])\n",
      "Feature in test_audio at index 2086 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 2087 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 2088 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 2089 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 2090 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 2091 has shape: torch.Size([988, 1024])\n",
      "Feature in test_audio at index 2092 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 2093 has shape: torch.Size([754, 1024])\n",
      "Feature in test_audio at index 2094 has shape: torch.Size([535, 1024])\n",
      "Feature in test_audio at index 2095 has shape: torch.Size([629, 1024])\n",
      "Feature in test_audio at index 2096 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2097 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2098 has shape: torch.Size([667, 1024])\n",
      "Feature in test_audio at index 2099 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 2100 has shape: torch.Size([1243, 1024])\n",
      "Feature in test_audio at index 2101 has shape: torch.Size([2303, 1024])\n",
      "Feature in test_audio at index 2102 has shape: torch.Size([1124, 1024])\n",
      "Feature in test_audio at index 2103 has shape: torch.Size([1644, 1024])\n",
      "Feature in test_audio at index 2104 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 2105 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2106 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 2107 has shape: torch.Size([2144, 1024])\n",
      "Feature in test_audio at index 2108 has shape: torch.Size([909, 1024])\n",
      "Feature in test_audio at index 2109 has shape: torch.Size([819, 1024])\n",
      "Feature in test_audio at index 2110 has shape: torch.Size([402, 1024])\n",
      "Feature in test_audio at index 2111 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 2112 has shape: torch.Size([1779, 1024])\n",
      "Feature in test_audio at index 2113 has shape: torch.Size([749, 1024])\n",
      "Feature in test_audio at index 2114 has shape: torch.Size([856, 1024])\n",
      "Feature in test_audio at index 2115 has shape: torch.Size([690, 1024])\n",
      "Feature in test_audio at index 2116 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 2117 has shape: torch.Size([906, 1024])\n",
      "Feature in test_audio at index 2118 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 2119 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 2120 has shape: torch.Size([517, 1024])\n",
      "Feature in test_audio at index 2121 has shape: torch.Size([1334, 1024])\n",
      "Feature in test_audio at index 2122 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 2123 has shape: torch.Size([425, 1024])\n",
      "Feature in test_audio at index 2124 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 2125 has shape: torch.Size([736, 1024])\n",
      "Feature in test_audio at index 2126 has shape: torch.Size([446, 1024])\n",
      "Feature in test_audio at index 2127 has shape: torch.Size([801, 1024])\n",
      "Feature in test_audio at index 2128 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 2129 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 2130 has shape: torch.Size([922, 1024])\n",
      "Feature in test_audio at index 2131 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 2132 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 2133 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 2134 has shape: torch.Size([492, 1024])\n",
      "Feature in test_audio at index 2135 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 2136 has shape: torch.Size([1246, 1024])\n",
      "Feature in test_audio at index 2137 has shape: torch.Size([1171, 1024])\n",
      "Feature in test_audio at index 2138 has shape: torch.Size([1231, 1024])\n",
      "Feature in test_audio at index 2139 has shape: torch.Size([673, 1024])\n",
      "Feature in test_audio at index 2140 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 2141 has shape: torch.Size([818, 1024])\n",
      "Feature in test_audio at index 2142 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 2143 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 2144 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 2145 has shape: torch.Size([455, 1024])\n",
      "Feature in test_audio at index 2146 has shape: torch.Size([176, 1024])\n",
      "Feature in test_audio at index 2147 has shape: torch.Size([661, 1024])\n",
      "Feature in test_audio at index 2148 has shape: torch.Size([337, 1024])\n",
      "Feature in test_audio at index 2149 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 2150 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 2151 has shape: torch.Size([346, 1024])\n",
      "Feature in test_audio at index 2152 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 2153 has shape: torch.Size([840, 1024])\n",
      "Feature in test_audio at index 2154 has shape: torch.Size([548, 1024])\n",
      "Feature in test_audio at index 2155 has shape: torch.Size([605, 1024])\n",
      "Feature in test_audio at index 2156 has shape: torch.Size([337, 1024])\n",
      "Feature in test_audio at index 2157 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 2158 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2159 has shape: torch.Size([541, 1024])\n",
      "Feature in test_audio at index 2160 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 2161 has shape: torch.Size([759, 1024])\n",
      "Feature in test_audio at index 2162 has shape: torch.Size([420, 1024])\n",
      "Feature in test_audio at index 2163 has shape: torch.Size([432, 1024])\n",
      "Feature in test_audio at index 2164 has shape: torch.Size([782, 1024])\n",
      "Feature in test_audio at index 2165 has shape: torch.Size([835, 1024])\n",
      "Feature in test_audio at index 2166 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 2167 has shape: torch.Size([79, 1024])\n",
      "Feature in test_audio at index 2168 has shape: torch.Size([879, 1024])\n",
      "Feature in test_audio at index 2169 has shape: torch.Size([609, 1024])\n",
      "Feature in test_audio at index 2170 has shape: torch.Size([449, 1024])\n",
      "Feature in test_audio at index 2171 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 2172 has shape: torch.Size([724, 1024])\n",
      "Feature in test_audio at index 2173 has shape: torch.Size([583, 1024])\n",
      "Feature in test_audio at index 2174 has shape: torch.Size([861, 1024])\n",
      "Feature in test_audio at index 2175 has shape: torch.Size([350, 1024])\n",
      "Feature in test_audio at index 2176 has shape: torch.Size([1054, 1024])\n",
      "Feature in test_audio at index 2177 has shape: torch.Size([446, 1024])\n",
      "Feature in test_audio at index 2178 has shape: torch.Size([866, 1024])\n",
      "Feature in test_audio at index 2179 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 2180 has shape: torch.Size([680, 1024])\n",
      "Feature in test_audio at index 2181 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 2182 has shape: torch.Size([109, 1024])\n",
      "Feature in test_audio at index 2183 has shape: torch.Size([183, 1024])\n",
      "Feature in test_audio at index 2184 has shape: torch.Size([534, 1024])\n",
      "Feature in test_audio at index 2185 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 2186 has shape: torch.Size([459, 1024])\n",
      "Feature in test_audio at index 2187 has shape: torch.Size([129, 1024])\n",
      "Feature in test_audio at index 2188 has shape: torch.Size([526, 1024])\n",
      "Feature in test_audio at index 2189 has shape: torch.Size([406, 1024])\n",
      "Feature in test_audio at index 2190 has shape: torch.Size([738, 1024])\n",
      "Feature in test_audio at index 2191 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2192 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 2193 has shape: torch.Size([525, 1024])\n",
      "Feature in test_audio at index 2194 has shape: torch.Size([907, 1024])\n",
      "Feature in test_audio at index 2195 has shape: torch.Size([692, 1024])\n",
      "Feature in test_audio at index 2196 has shape: torch.Size([612, 1024])\n",
      "Feature in test_audio at index 2197 has shape: torch.Size([421, 1024])\n",
      "Feature in test_audio at index 2198 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 2199 has shape: torch.Size([371, 1024])\n",
      "Feature in test_audio at index 2200 has shape: torch.Size([697, 1024])\n",
      "Feature in test_audio at index 2201 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 2202 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 2203 has shape: torch.Size([215, 1024])\n",
      "Feature in test_audio at index 2204 has shape: torch.Size([615, 1024])\n",
      "Feature in test_audio at index 2205 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 2206 has shape: torch.Size([531, 1024])\n",
      "Feature in test_audio at index 2207 has shape: torch.Size([601, 1024])\n",
      "Feature in test_audio at index 2208 has shape: torch.Size([213, 1024])\n",
      "Feature in test_audio at index 2209 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 2210 has shape: torch.Size([337, 1024])\n",
      "Feature in test_audio at index 2211 has shape: torch.Size([616, 1024])\n",
      "Feature in test_audio at index 2212 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 2213 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 2214 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 2215 has shape: torch.Size([500, 1024])\n",
      "Feature in test_audio at index 2216 has shape: torch.Size([621, 1024])\n",
      "Feature in test_audio at index 2217 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 2218 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 2219 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2220 has shape: torch.Size([911, 1024])\n",
      "Feature in test_audio at index 2221 has shape: torch.Size([731, 1024])\n",
      "Feature in test_audio at index 2222 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 2223 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2224 has shape: torch.Size([1028, 1024])\n",
      "Feature in test_audio at index 2225 has shape: torch.Size([999, 1024])\n",
      "Feature in test_audio at index 2226 has shape: torch.Size([974, 1024])\n",
      "Feature in test_audio at index 2227 has shape: torch.Size([404, 1024])\n",
      "Feature in test_audio at index 2228 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 2229 has shape: torch.Size([903, 1024])\n",
      "Feature in test_audio at index 2230 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 2231 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 2232 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 2233 has shape: torch.Size([442, 1024])\n",
      "Feature in test_audio at index 2234 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 2235 has shape: torch.Size([711, 1024])\n",
      "Feature in test_audio at index 2236 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 2237 has shape: torch.Size([241, 1024])\n",
      "Feature in test_audio at index 2238 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 2239 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 2240 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 2241 has shape: torch.Size([810, 1024])\n",
      "Feature in test_audio at index 2242 has shape: torch.Size([421, 1024])\n",
      "Feature in test_audio at index 2243 has shape: torch.Size([777, 1024])\n",
      "Feature in test_audio at index 2244 has shape: torch.Size([818, 1024])\n",
      "Feature in test_audio at index 2245 has shape: torch.Size([756, 1024])\n",
      "Feature in test_audio at index 2246 has shape: torch.Size([289, 1024])\n",
      "Feature in test_audio at index 2247 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 2248 has shape: torch.Size([371, 1024])\n",
      "Feature in test_audio at index 2249 has shape: torch.Size([539, 1024])\n",
      "Feature in test_audio at index 2250 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 2251 has shape: torch.Size([379, 1024])\n",
      "Feature in test_audio at index 2252 has shape: torch.Size([377, 1024])\n",
      "Feature in test_audio at index 2253 has shape: torch.Size([315, 1024])\n",
      "Feature in test_audio at index 2254 has shape: torch.Size([265, 1024])\n",
      "Feature in test_audio at index 2255 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2256 has shape: torch.Size([560, 1024])\n",
      "Feature in test_audio at index 2257 has shape: torch.Size([237, 1024])\n",
      "Feature in test_audio at index 2258 has shape: torch.Size([279, 1024])\n",
      "Feature in test_audio at index 2259 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 2260 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 2261 has shape: torch.Size([245, 1024])\n",
      "Feature in test_audio at index 2262 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 2263 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 2264 has shape: torch.Size([395, 1024])\n",
      "Feature in test_audio at index 2265 has shape: torch.Size([819, 1024])\n",
      "Feature in test_audio at index 2266 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 2267 has shape: torch.Size([429, 1024])\n",
      "Feature in test_audio at index 2268 has shape: torch.Size([355, 1024])\n",
      "Feature in test_audio at index 2269 has shape: torch.Size([205, 1024])\n",
      "Feature in test_audio at index 2270 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 2271 has shape: torch.Size([354, 1024])\n",
      "Feature in test_audio at index 2272 has shape: torch.Size([976, 1024])\n",
      "Feature in test_audio at index 2273 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 2274 has shape: torch.Size([796, 1024])\n",
      "Feature in test_audio at index 2275 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 2276 has shape: torch.Size([819, 1024])\n",
      "Feature in test_audio at index 2277 has shape: torch.Size([769, 1024])\n",
      "Feature in test_audio at index 2278 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 2279 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 2280 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 2281 has shape: torch.Size([475, 1024])\n",
      "Feature in test_audio at index 2282 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2283 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 2284 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 2285 has shape: torch.Size([1093, 1024])\n",
      "Feature in test_audio at index 2286 has shape: torch.Size([1016, 1024])\n",
      "Feature in test_audio at index 2287 has shape: torch.Size([846, 1024])\n",
      "Feature in test_audio at index 2288 has shape: torch.Size([439, 1024])\n",
      "Feature in test_audio at index 2289 has shape: torch.Size([561, 1024])\n",
      "Feature in test_audio at index 2290 has shape: torch.Size([209, 1024])\n",
      "Feature in test_audio at index 2291 has shape: torch.Size([730, 1024])\n",
      "Feature in test_audio at index 2292 has shape: torch.Size([293, 1024])\n",
      "Feature in test_audio at index 2293 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 2294 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 2295 has shape: torch.Size([454, 1024])\n",
      "Feature in test_audio at index 2296 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 2297 has shape: torch.Size([893, 1024])\n",
      "Feature in test_audio at index 2298 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 2299 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 2300 has shape: torch.Size([241, 1024])\n",
      "Feature in test_audio at index 2301 has shape: torch.Size([104, 1024])\n",
      "Feature in test_audio at index 2302 has shape: torch.Size([472, 1024])\n",
      "Feature in test_audio at index 2303 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 2304 has shape: torch.Size([1001, 1024])\n",
      "Feature in test_audio at index 2305 has shape: torch.Size([974, 1024])\n",
      "Feature in test_audio at index 2306 has shape: torch.Size([1000, 1024])\n",
      "Feature in test_audio at index 2307 has shape: torch.Size([973, 1024])\n",
      "Feature in test_audio at index 2308 has shape: torch.Size([137, 1024])\n",
      "Feature in test_audio at index 2309 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 2310 has shape: torch.Size([567, 1024])\n",
      "Feature in test_audio at index 2311 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 2312 has shape: torch.Size([279, 1024])\n",
      "Feature in test_audio at index 2313 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 2314 has shape: torch.Size([397, 1024])\n",
      "Feature in test_audio at index 2315 has shape: torch.Size([239, 1024])\n",
      "Feature in test_audio at index 2316 has shape: torch.Size([669, 1024])\n",
      "Feature in test_audio at index 2317 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 2318 has shape: torch.Size([603, 1024])\n",
      "Feature in test_audio at index 2319 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 2320 has shape: torch.Size([764, 1024])\n",
      "Feature in test_audio at index 2321 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 2322 has shape: torch.Size([539, 1024])\n",
      "Feature in test_audio at index 2323 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 2324 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 2325 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 2326 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 2327 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 2328 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 2329 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 2330 has shape: torch.Size([530, 1024])\n",
      "Feature in test_audio at index 2331 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 2332 has shape: torch.Size([198, 1024])\n",
      "Feature in test_audio at index 2333 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 2334 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 2335 has shape: torch.Size([689, 1024])\n",
      "Feature in test_audio at index 2336 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 2337 has shape: torch.Size([199, 1024])\n",
      "Feature in test_audio at index 2338 has shape: torch.Size([475, 1024])\n",
      "Feature in test_audio at index 2339 has shape: torch.Size([415, 1024])\n",
      "Feature in test_audio at index 2340 has shape: torch.Size([778, 1024])\n",
      "Feature in test_audio at index 2341 has shape: torch.Size([379, 1024])\n",
      "Feature in test_audio at index 2342 has shape: torch.Size([184, 1024])\n",
      "Feature in test_audio at index 2343 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 2344 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 2345 has shape: torch.Size([1393, 1024])\n",
      "Feature in test_audio at index 2346 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 2347 has shape: torch.Size([721, 1024])\n",
      "Feature in test_audio at index 2348 has shape: torch.Size([168, 1024])\n",
      "Feature in test_audio at index 2349 has shape: torch.Size([305, 1024])\n",
      "Feature in test_audio at index 2350 has shape: torch.Size([154, 1024])\n",
      "Feature in test_audio at index 2351 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 2352 has shape: torch.Size([615, 1024])\n",
      "Feature in test_audio at index 2353 has shape: torch.Size([648, 1024])\n",
      "Feature in test_audio at index 2354 has shape: torch.Size([562, 1024])\n",
      "Feature in test_audio at index 2355 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 2356 has shape: torch.Size([300, 1024])\n",
      "Feature in test_audio at index 2357 has shape: torch.Size([364, 1024])\n",
      "Feature in test_audio at index 2358 has shape: torch.Size([1253, 1024])\n",
      "Feature in test_audio at index 2359 has shape: torch.Size([328, 1024])\n",
      "Feature in test_audio at index 2360 has shape: torch.Size([854, 1024])\n",
      "Feature in test_audio at index 2361 has shape: torch.Size([264, 1024])\n",
      "Feature in test_audio at index 2362 has shape: torch.Size([656, 1024])\n",
      "Feature in test_audio at index 2363 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2364 has shape: torch.Size([1096, 1024])\n",
      "Feature in test_audio at index 2365 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 2366 has shape: torch.Size([309, 1024])\n",
      "Feature in test_audio at index 2367 has shape: torch.Size([386, 1024])\n",
      "Feature in test_audio at index 2368 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2369 has shape: torch.Size([305, 1024])\n",
      "Feature in test_audio at index 2370 has shape: torch.Size([475, 1024])\n",
      "Feature in test_audio at index 2371 has shape: torch.Size([335, 1024])\n",
      "Feature in test_audio at index 2372 has shape: torch.Size([121, 1024])\n",
      "Feature in test_audio at index 2373 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2374 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2375 has shape: torch.Size([258, 1024])\n",
      "Feature in test_audio at index 2376 has shape: torch.Size([120, 1024])\n",
      "Feature in test_audio at index 2377 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 2378 has shape: torch.Size([813, 1024])\n",
      "Feature in test_audio at index 2379 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 2380 has shape: torch.Size([355, 1024])\n",
      "Feature in test_audio at index 2381 has shape: torch.Size([552, 1024])\n",
      "Feature in test_audio at index 2382 has shape: torch.Size([785, 1024])\n",
      "Feature in test_audio at index 2383 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 2384 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 2385 has shape: torch.Size([255, 1024])\n",
      "Feature in test_audio at index 2386 has shape: torch.Size([360, 1024])\n",
      "Feature in test_audio at index 2387 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 2388 has shape: torch.Size([157, 1024])\n",
      "Feature in test_audio at index 2389 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 2390 has shape: torch.Size([320, 1024])\n",
      "Feature in test_audio at index 2391 has shape: torch.Size([392, 1024])\n",
      "Feature in test_audio at index 2392 has shape: torch.Size([609, 1024])\n",
      "Feature in test_audio at index 2393 has shape: torch.Size([140, 1024])\n",
      "Feature in test_audio at index 2394 has shape: torch.Size([436, 1024])\n",
      "Feature in test_audio at index 2395 has shape: torch.Size([208, 1024])\n",
      "Feature in test_audio at index 2396 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 2397 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 2398 has shape: torch.Size([350, 1024])\n",
      "Feature in test_audio at index 2399 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2400 has shape: torch.Size([829, 1024])\n",
      "Feature in test_audio at index 2401 has shape: torch.Size([914, 1024])\n",
      "Feature in test_audio at index 2402 has shape: torch.Size([689, 1024])\n",
      "Feature in test_audio at index 2403 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 2404 has shape: torch.Size([429, 1024])\n",
      "Feature in test_audio at index 2405 has shape: torch.Size([522, 1024])\n",
      "Feature in test_audio at index 2406 has shape: torch.Size([719, 1024])\n",
      "Feature in test_audio at index 2407 has shape: torch.Size([931, 1024])\n",
      "Feature in test_audio at index 2408 has shape: torch.Size([916, 1024])\n",
      "Feature in test_audio at index 2409 has shape: torch.Size([246, 1024])\n",
      "Feature in test_audio at index 2410 has shape: torch.Size([850, 1024])\n",
      "Feature in test_audio at index 2411 has shape: torch.Size([825, 1024])\n",
      "Feature in test_audio at index 2412 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 2413 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 2414 has shape: torch.Size([170, 1024])\n",
      "Feature in test_audio at index 2415 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 2416 has shape: torch.Size([422, 1024])\n",
      "Feature in test_audio at index 2417 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 2418 has shape: torch.Size([238, 1024])\n",
      "Feature in test_audio at index 2419 has shape: torch.Size([502, 1024])\n",
      "Feature in test_audio at index 2420 has shape: torch.Size([330, 1024])\n",
      "Feature in test_audio at index 2421 has shape: torch.Size([694, 1024])\n",
      "Feature in test_audio at index 2422 has shape: torch.Size([484, 1024])\n",
      "Feature in test_audio at index 2423 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 2424 has shape: torch.Size([519, 1024])\n",
      "Feature in test_audio at index 2425 has shape: torch.Size([746, 1024])\n",
      "Feature in test_audio at index 2426 has shape: torch.Size([33, 1024])\n",
      "Feature in test_audio at index 2427 has shape: torch.Size([302, 1024])\n",
      "Feature in test_audio at index 2428 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 2429 has shape: torch.Size([236, 1024])\n",
      "Feature in test_audio at index 2430 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 2431 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 2432 has shape: torch.Size([973, 1024])\n",
      "Feature in test_audio at index 2433 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 2434 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 2435 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 2436 has shape: torch.Size([1159, 1024])\n",
      "Feature in test_audio at index 2437 has shape: torch.Size([826, 1024])\n",
      "Feature in test_audio at index 2438 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 2439 has shape: torch.Size([507, 1024])\n",
      "Feature in test_audio at index 2440 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 2441 has shape: torch.Size([721, 1024])\n",
      "Feature in test_audio at index 2442 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 2443 has shape: torch.Size([475, 1024])\n",
      "Feature in test_audio at index 2444 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 2445 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 2446 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 2447 has shape: torch.Size([844, 1024])\n",
      "Feature in test_audio at index 2448 has shape: torch.Size([840, 1024])\n",
      "Feature in test_audio at index 2449 has shape: torch.Size([404, 1024])\n",
      "Feature in test_audio at index 2450 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 2451 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 2452 has shape: torch.Size([710, 1024])\n",
      "Feature in test_audio at index 2453 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 2454 has shape: torch.Size([811, 1024])\n",
      "Feature in test_audio at index 2455 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 2456 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 2457 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 2458 has shape: torch.Size([1008, 1024])\n",
      "Feature in test_audio at index 2459 has shape: torch.Size([525, 1024])\n",
      "Feature in test_audio at index 2460 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 2461 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 2462 has shape: torch.Size([771, 1024])\n",
      "Feature in test_audio at index 2463 has shape: torch.Size([279, 1024])\n",
      "Feature in test_audio at index 2464 has shape: torch.Size([574, 1024])\n",
      "Feature in test_audio at index 2465 has shape: torch.Size([272, 1024])\n",
      "Feature in test_audio at index 2466 has shape: torch.Size([358, 1024])\n",
      "Feature in test_audio at index 2467 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 2468 has shape: torch.Size([175, 1024])\n",
      "Feature in test_audio at index 2469 has shape: torch.Size([155, 1024])\n",
      "Feature in test_audio at index 2470 has shape: torch.Size([512, 1024])\n",
      "Feature in test_audio at index 2471 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 2472 has shape: torch.Size([778, 1024])\n",
      "Feature in test_audio at index 2473 has shape: torch.Size([1019, 1024])\n",
      "Feature in test_audio at index 2474 has shape: torch.Size([938, 1024])\n",
      "Feature in test_audio at index 2475 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2476 has shape: torch.Size([1298, 1024])\n",
      "Feature in test_audio at index 2477 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 2478 has shape: torch.Size([731, 1024])\n",
      "Feature in test_audio at index 2479 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 2480 has shape: torch.Size([595, 1024])\n",
      "Feature in test_audio at index 2481 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 2482 has shape: torch.Size([948, 1024])\n",
      "Feature in test_audio at index 2483 has shape: torch.Size([452, 1024])\n",
      "Feature in test_audio at index 2484 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 2485 has shape: torch.Size([816, 1024])\n",
      "Feature in test_audio at index 2486 has shape: torch.Size([874, 1024])\n",
      "Feature in test_audio at index 2487 has shape: torch.Size([555, 1024])\n",
      "Feature in test_audio at index 2488 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 2489 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 2490 has shape: torch.Size([371, 1024])\n",
      "Feature in test_audio at index 2491 has shape: torch.Size([943, 1024])\n",
      "Feature in test_audio at index 2492 has shape: torch.Size([648, 1024])\n",
      "Feature in test_audio at index 2493 has shape: torch.Size([610, 1024])\n",
      "Feature in test_audio at index 2494 has shape: torch.Size([646, 1024])\n",
      "Feature in test_audio at index 2495 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 2496 has shape: torch.Size([1077, 1024])\n",
      "Feature in test_audio at index 2497 has shape: torch.Size([973, 1024])\n",
      "Feature in test_audio at index 2498 has shape: torch.Size([754, 1024])\n",
      "Feature in test_audio at index 2499 has shape: torch.Size([879, 1024])\n",
      "Feature in test_audio at index 2500 has shape: torch.Size([499, 1024])\n",
      "Feature in test_audio at index 2501 has shape: torch.Size([500, 1024])\n",
      "Feature in test_audio at index 2502 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 2503 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 2504 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 2505 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 2506 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 2507 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 2508 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 2509 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 2510 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 2511 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 2512 has shape: torch.Size([429, 1024])\n",
      "Feature in test_audio at index 2513 has shape: torch.Size([468, 1024])\n",
      "Feature in test_audio at index 2514 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 2515 has shape: torch.Size([894, 1024])\n",
      "Feature in test_audio at index 2516 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 2517 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 2518 has shape: torch.Size([724, 1024])\n",
      "Feature in test_audio at index 2519 has shape: torch.Size([346, 1024])\n",
      "Feature in test_audio at index 2520 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 2521 has shape: torch.Size([182, 1024])\n",
      "Feature in test_audio at index 2522 has shape: torch.Size([713, 1024])\n",
      "Feature in test_audio at index 2523 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 2524 has shape: torch.Size([555, 1024])\n",
      "Feature in test_audio at index 2525 has shape: torch.Size([527, 1024])\n",
      "Feature in test_audio at index 2526 has shape: torch.Size([603, 1024])\n",
      "Feature in test_audio at index 2527 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 2528 has shape: torch.Size([661, 1024])\n",
      "Feature in test_audio at index 2529 has shape: torch.Size([1234, 1024])\n",
      "Feature in test_audio at index 2530 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 2531 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 2532 has shape: torch.Size([386, 1024])\n",
      "Feature in test_audio at index 2533 has shape: torch.Size([146, 1024])\n",
      "Feature in test_audio at index 2534 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 2535 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 2536 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 2537 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 2538 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 2539 has shape: torch.Size([378, 1024])\n",
      "Feature in test_audio at index 2540 has shape: torch.Size([288, 1024])\n",
      "Feature in test_audio at index 2541 has shape: torch.Size([186, 1024])\n",
      "Feature in test_audio at index 2542 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 2543 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 2544 has shape: torch.Size([128, 1024])\n",
      "Feature in test_audio at index 2545 has shape: torch.Size([468, 1024])\n",
      "Feature in test_audio at index 2546 has shape: torch.Size([694, 1024])\n",
      "Feature in test_audio at index 2547 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 2548 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 2549 has shape: torch.Size([1041, 1024])\n",
      "Feature in test_audio at index 2550 has shape: torch.Size([1060, 1024])\n",
      "Feature in test_audio at index 2551 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2552 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 2553 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 2554 has shape: torch.Size([474, 1024])\n",
      "Feature in test_audio at index 2555 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 2556 has shape: torch.Size([747, 1024])\n",
      "Feature in test_audio at index 2557 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 2558 has shape: torch.Size([387, 1024])\n",
      "Feature in test_audio at index 2559 has shape: torch.Size([290, 1024])\n",
      "Feature in test_audio at index 2560 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 2561 has shape: torch.Size([202, 1024])\n",
      "Feature in test_audio at index 2562 has shape: torch.Size([135, 1024])\n",
      "Feature in test_audio at index 2563 has shape: torch.Size([502, 1024])\n",
      "Feature in test_audio at index 2564 has shape: torch.Size([299, 1024])\n",
      "Feature in test_audio at index 2565 has shape: torch.Size([301, 1024])\n",
      "Feature in test_audio at index 2566 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 2567 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 2568 has shape: torch.Size([355, 1024])\n",
      "Feature in test_audio at index 2569 has shape: torch.Size([362, 1024])\n",
      "Feature in test_audio at index 2570 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 2571 has shape: torch.Size([572, 1024])\n",
      "Feature in test_audio at index 2572 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 2573 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 2574 has shape: torch.Size([325, 1024])\n",
      "Feature in test_audio at index 2575 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 2576 has shape: torch.Size([218, 1024])\n",
      "Feature in test_audio at index 2577 has shape: torch.Size([143, 1024])\n",
      "Feature in test_audio at index 2578 has shape: torch.Size([505, 1024])\n",
      "Feature in test_audio at index 2579 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 2580 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 2581 has shape: torch.Size([226, 1024])\n",
      "Feature in test_audio at index 2582 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 2583 has shape: torch.Size([706, 1024])\n",
      "Feature in test_audio at index 2584 has shape: torch.Size([2241, 1024])\n",
      "Feature in test_audio at index 2585 has shape: torch.Size([508, 1024])\n",
      "Feature in test_audio at index 2586 has shape: torch.Size([808, 1024])\n",
      "Feature in test_audio at index 2587 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 2588 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 2589 has shape: torch.Size([323, 1024])\n",
      "Feature in test_audio at index 2590 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 2591 has shape: torch.Size([353, 1024])\n",
      "Feature in test_audio at index 2592 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 2593 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 2594 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 2595 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 2596 has shape: torch.Size([788, 1024])\n",
      "Feature in test_audio at index 2597 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 2598 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 2599 has shape: torch.Size([891, 1024])\n",
      "Feature in test_audio at index 2600 has shape: torch.Size([1362, 1024])\n",
      "Feature in test_audio at index 2601 has shape: torch.Size([601, 1024])\n",
      "Feature in test_audio at index 2602 has shape: torch.Size([2279, 1024])\n",
      "Feature in test_audio at index 2603 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 2604 has shape: torch.Size([2508, 1024])\n",
      "Feature in test_audio at index 2605 has shape: torch.Size([587, 1024])\n",
      "Feature in test_audio at index 2606 has shape: torch.Size([1316, 1024])\n",
      "Feature in test_audio at index 2607 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 2608 has shape: torch.Size([621, 1024])\n",
      "Feature in test_audio at index 2609 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 2610 has shape: torch.Size([1096, 1024])\n",
      "Feature in test_audio at index 2611 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 2612 has shape: torch.Size([317, 1024])\n",
      "Feature in test_audio at index 2613 has shape: torch.Size([998, 1024])\n",
      "Feature in test_audio at index 2614 has shape: torch.Size([741, 1024])\n",
      "Feature in test_audio at index 2615 has shape: torch.Size([761, 1024])\n",
      "Feature in test_audio at index 2616 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 2617 has shape: torch.Size([355, 1024])\n",
      "Feature in test_audio at index 2618 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 2619 has shape: torch.Size([486, 1024])\n",
      "Feature in test_audio at index 2620 has shape: torch.Size([447, 1024])\n",
      "Feature in test_audio at index 2621 has shape: torch.Size([1334, 1024])\n",
      "Feature in test_audio at index 2622 has shape: torch.Size([733, 1024])\n",
      "Feature in test_audio at index 2623 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 2624 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 2625 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 2626 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 2627 has shape: torch.Size([1048, 1024])\n",
      "Feature in test_audio at index 2628 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 2629 has shape: torch.Size([904, 1024])\n",
      "Feature in test_audio at index 2630 has shape: torch.Size([358, 1024])\n",
      "Feature in test_audio at index 2631 has shape: torch.Size([683, 1024])\n",
      "Feature in test_audio at index 2632 has shape: torch.Size([1053, 1024])\n",
      "Feature in test_audio at index 2633 has shape: torch.Size([1284, 1024])\n",
      "Feature in test_audio at index 2634 has shape: torch.Size([794, 1024])\n",
      "Feature in test_audio at index 2635 has shape: torch.Size([1073, 1024])\n",
      "Feature in test_audio at index 2636 has shape: torch.Size([659, 1024])\n",
      "Feature in test_audio at index 2637 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 2638 has shape: torch.Size([259, 1024])\n",
      "Feature in test_audio at index 2639 has shape: torch.Size([655, 1024])\n",
      "Feature in test_audio at index 2640 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 2641 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 2642 has shape: torch.Size([605, 1024])\n",
      "Feature in test_audio at index 2643 has shape: torch.Size([454, 1024])\n",
      "Feature in test_audio at index 2644 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 2645 has shape: torch.Size([401, 1024])\n",
      "Feature in test_audio at index 2646 has shape: torch.Size([500, 1024])\n",
      "Feature in test_audio at index 2647 has shape: torch.Size([144, 1024])\n",
      "Feature in test_audio at index 2648 has shape: torch.Size([470, 1024])\n",
      "Feature in test_audio at index 2649 has shape: torch.Size([246, 1024])\n",
      "Feature in test_audio at index 2650 has shape: torch.Size([385, 1024])\n",
      "Feature in test_audio at index 2651 has shape: torch.Size([203, 1024])\n",
      "Feature in test_audio at index 2652 has shape: torch.Size([371, 1024])\n",
      "Feature in test_audio at index 2653 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 2654 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 2655 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2656 has shape: torch.Size([435, 1024])\n",
      "Feature in test_audio at index 2657 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 2658 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 2659 has shape: torch.Size([455, 1024])\n",
      "Feature in test_audio at index 2660 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 2661 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 2662 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 2663 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 2664 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 2665 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 2666 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 2667 has shape: torch.Size([446, 1024])\n",
      "Feature in test_audio at index 2668 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 2669 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 2670 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 2671 has shape: torch.Size([228, 1024])\n",
      "Feature in test_audio at index 2672 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 2673 has shape: torch.Size([228, 1024])\n",
      "Feature in test_audio at index 2674 has shape: torch.Size([720, 1024])\n",
      "Feature in test_audio at index 2675 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2676 has shape: torch.Size([921, 1024])\n",
      "Feature in test_audio at index 2677 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 2678 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 2679 has shape: torch.Size([587, 1024])\n",
      "Feature in test_audio at index 2680 has shape: torch.Size([654, 1024])\n",
      "Feature in test_audio at index 2681 has shape: torch.Size([299, 1024])\n",
      "Feature in test_audio at index 2682 has shape: torch.Size([628, 1024])\n",
      "Feature in test_audio at index 2683 has shape: torch.Size([609, 1024])\n",
      "Feature in test_audio at index 2684 has shape: torch.Size([359, 1024])\n",
      "Feature in test_audio at index 2685 has shape: torch.Size([345, 1024])\n",
      "Feature in test_audio at index 2686 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 2687 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 2688 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 2689 has shape: torch.Size([708, 1024])\n",
      "Feature in test_audio at index 2690 has shape: torch.Size([731, 1024])\n",
      "Feature in test_audio at index 2691 has shape: torch.Size([814, 1024])\n",
      "Feature in test_audio at index 2692 has shape: torch.Size([748, 1024])\n",
      "Feature in test_audio at index 2693 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 2694 has shape: torch.Size([825, 1024])\n",
      "Feature in test_audio at index 2695 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 2696 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 2697 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 2698 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 2699 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 2700 has shape: torch.Size([595, 1024])\n",
      "Feature in test_audio at index 2701 has shape: torch.Size([1232, 1024])\n",
      "Feature in test_audio at index 2702 has shape: torch.Size([829, 1024])\n",
      "Feature in test_audio at index 2703 has shape: torch.Size([88, 1024])\n",
      "Feature in test_audio at index 2704 has shape: torch.Size([328, 1024])\n",
      "Feature in test_audio at index 2705 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 2706 has shape: torch.Size([153, 1024])\n",
      "Feature in test_audio at index 2707 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2708 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 2709 has shape: torch.Size([974, 1024])\n",
      "Feature in test_audio at index 2710 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 2711 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 2712 has shape: torch.Size([813, 1024])\n",
      "Feature in test_audio at index 2713 has shape: torch.Size([219, 1024])\n",
      "Feature in test_audio at index 2714 has shape: torch.Size([611, 1024])\n",
      "Feature in test_audio at index 2715 has shape: torch.Size([696, 1024])\n",
      "Feature in test_audio at index 2716 has shape: torch.Size([764, 1024])\n",
      "Feature in test_audio at index 2717 has shape: torch.Size([1037, 1024])\n",
      "Feature in test_audio at index 2718 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 2719 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 2720 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 2721 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 2722 has shape: torch.Size([5159, 1024])\n",
      "Feature in test_audio at index 2723 has shape: torch.Size([508, 1024])\n",
      "Feature in test_audio at index 2724 has shape: torch.Size([654, 1024])\n",
      "Feature in test_audio at index 2725 has shape: torch.Size([745, 1024])\n",
      "Feature in test_audio at index 2726 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 2727 has shape: torch.Size([370, 1024])\n",
      "Feature in test_audio at index 2728 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 2729 has shape: torch.Size([791, 1024])\n",
      "Feature in test_audio at index 2730 has shape: torch.Size([261, 1024])\n",
      "Feature in test_audio at index 2731 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2732 has shape: torch.Size([758, 1024])\n",
      "Feature in test_audio at index 2733 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2734 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 2735 has shape: torch.Size([1488, 1024])\n",
      "Feature in test_audio at index 2736 has shape: torch.Size([467, 1024])\n",
      "Feature in test_audio at index 2737 has shape: torch.Size([683, 1024])\n",
      "Feature in test_audio at index 2738 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 2739 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 2740 has shape: torch.Size([1018, 1024])\n",
      "Feature in test_audio at index 2741 has shape: torch.Size([601, 1024])\n",
      "Feature in test_audio at index 2742 has shape: torch.Size([494, 1024])\n",
      "Feature in test_audio at index 2743 has shape: torch.Size([806, 1024])\n",
      "Feature in test_audio at index 2744 has shape: torch.Size([449, 1024])\n",
      "Feature in test_audio at index 2745 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 2746 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 2747 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 2748 has shape: torch.Size([1074, 1024])\n",
      "Feature in test_audio at index 2749 has shape: torch.Size([672, 1024])\n",
      "Feature in test_audio at index 2750 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 2751 has shape: torch.Size([846, 1024])\n",
      "Feature in test_audio at index 2752 has shape: torch.Size([1526, 1024])\n",
      "Feature in test_audio at index 2753 has shape: torch.Size([405, 1024])\n",
      "Feature in test_audio at index 2754 has shape: torch.Size([2277, 1024])\n",
      "Feature in test_audio at index 2755 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2756 has shape: torch.Size([1154, 1024])\n",
      "Feature in test_audio at index 2757 has shape: torch.Size([922, 1024])\n",
      "Feature in test_audio at index 2758 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 2759 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 2760 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 2761 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 2762 has shape: torch.Size([266, 1024])\n",
      "Feature in test_audio at index 2763 has shape: torch.Size([428, 1024])\n",
      "Feature in test_audio at index 2764 has shape: torch.Size([499, 1024])\n",
      "Feature in test_audio at index 2765 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 2766 has shape: torch.Size([269, 1024])\n",
      "Feature in test_audio at index 2767 has shape: torch.Size([307, 1024])\n",
      "Feature in test_audio at index 2768 has shape: torch.Size([190, 1024])\n",
      "Feature in test_audio at index 2769 has shape: torch.Size([555, 1024])\n",
      "Feature in test_audio at index 2770 has shape: torch.Size([357, 1024])\n",
      "Feature in test_audio at index 2771 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 2772 has shape: torch.Size([450, 1024])\n",
      "Feature in test_audio at index 2773 has shape: torch.Size([1062, 1024])\n",
      "Feature in test_audio at index 2774 has shape: torch.Size([1081, 1024])\n",
      "Feature in test_audio at index 2775 has shape: torch.Size([404, 1024])\n",
      "Feature in test_audio at index 2776 has shape: torch.Size([560, 1024])\n",
      "Feature in test_audio at index 2777 has shape: torch.Size([335, 1024])\n",
      "Feature in test_audio at index 2778 has shape: torch.Size([535, 1024])\n",
      "Feature in test_audio at index 2779 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 2780 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 2781 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 2782 has shape: torch.Size([267, 1024])\n",
      "Feature in test_audio at index 2783 has shape: torch.Size([956, 1024])\n",
      "Feature in test_audio at index 2784 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 2785 has shape: torch.Size([233, 1024])\n",
      "Feature in test_audio at index 2786 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 2787 has shape: torch.Size([746, 1024])\n",
      "Feature in test_audio at index 2788 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 2789 has shape: torch.Size([204, 1024])\n",
      "Feature in test_audio at index 2790 has shape: torch.Size([387, 1024])\n",
      "Feature in test_audio at index 2791 has shape: torch.Size([542, 1024])\n",
      "Feature in test_audio at index 2792 has shape: torch.Size([732, 1024])\n",
      "Feature in test_audio at index 2793 has shape: torch.Size([185, 1024])\n",
      "Feature in test_audio at index 2794 has shape: torch.Size([222, 1024])\n",
      "Feature in test_audio at index 2795 has shape: torch.Size([517, 1024])\n",
      "Feature in test_audio at index 2796 has shape: torch.Size([502, 1024])\n",
      "Feature in test_audio at index 2797 has shape: torch.Size([212, 1024])\n",
      "Feature in test_audio at index 2798 has shape: torch.Size([211, 1024])\n",
      "Feature in test_audio at index 2799 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2800 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 2801 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2802 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 2803 has shape: torch.Size([267, 1024])\n",
      "Feature in test_audio at index 2804 has shape: torch.Size([306, 1024])\n",
      "Feature in test_audio at index 2805 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 2806 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 2807 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 2808 has shape: torch.Size([261, 1024])\n",
      "Feature in test_audio at index 2809 has shape: torch.Size([671, 1024])\n",
      "Feature in test_audio at index 2810 has shape: torch.Size([1613, 1024])\n",
      "Feature in test_audio at index 2811 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 2812 has shape: torch.Size([1399, 1024])\n",
      "Feature in test_audio at index 2813 has shape: torch.Size([261, 1024])\n",
      "Feature in test_audio at index 2814 has shape: torch.Size([763, 1024])\n",
      "Feature in test_audio at index 2815 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2816 has shape: torch.Size([738, 1024])\n",
      "Feature in test_audio at index 2817 has shape: torch.Size([571, 1024])\n",
      "Feature in test_audio at index 2818 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 2819 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 2820 has shape: torch.Size([1639, 1024])\n",
      "Feature in test_audio at index 2821 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 2822 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2823 has shape: torch.Size([753, 1024])\n",
      "Feature in test_audio at index 2824 has shape: torch.Size([729, 1024])\n",
      "Feature in test_audio at index 2825 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 2826 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 2827 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 2828 has shape: torch.Size([900, 1024])\n",
      "Feature in test_audio at index 2829 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 2830 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 2831 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 2832 has shape: torch.Size([552, 1024])\n",
      "Feature in test_audio at index 2833 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 2834 has shape: torch.Size([341, 1024])\n",
      "Feature in test_audio at index 2835 has shape: torch.Size([714, 1024])\n",
      "Feature in test_audio at index 2836 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 2837 has shape: torch.Size([228, 1024])\n",
      "Feature in test_audio at index 2838 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 2839 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 2840 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 2841 has shape: torch.Size([376, 1024])\n",
      "Feature in test_audio at index 2842 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 2843 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2844 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 2845 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 2846 has shape: torch.Size([199, 1024])\n",
      "Feature in test_audio at index 2847 has shape: torch.Size([361, 1024])\n",
      "Feature in test_audio at index 2848 has shape: torch.Size([113, 1024])\n",
      "Feature in test_audio at index 2849 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 2850 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 2851 has shape: torch.Size([1049, 1024])\n",
      "Feature in test_audio at index 2852 has shape: torch.Size([534, 1024])\n",
      "Feature in test_audio at index 2853 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 2854 has shape: torch.Size([675, 1024])\n",
      "Feature in test_audio at index 2855 has shape: torch.Size([371, 1024])\n",
      "Feature in test_audio at index 2856 has shape: torch.Size([681, 1024])\n",
      "Feature in test_audio at index 2857 has shape: torch.Size([545, 1024])\n",
      "Feature in test_audio at index 2858 has shape: torch.Size([670, 1024])\n",
      "Feature in test_audio at index 2859 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 2860 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 2861 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 2862 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 2863 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 2864 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2865 has shape: torch.Size([338, 1024])\n",
      "Feature in test_audio at index 2866 has shape: torch.Size([534, 1024])\n",
      "Feature in test_audio at index 2867 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 2868 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 2869 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 2870 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 2871 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 2872 has shape: torch.Size([311, 1024])\n",
      "Feature in test_audio at index 2873 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 2874 has shape: torch.Size([1149, 1024])\n",
      "Feature in test_audio at index 2875 has shape: torch.Size([293, 1024])\n",
      "Feature in test_audio at index 2876 has shape: torch.Size([623, 1024])\n",
      "Feature in test_audio at index 2877 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 2878 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 2879 has shape: torch.Size([351, 1024])\n",
      "Feature in test_audio at index 2880 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 2881 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 2882 has shape: torch.Size([834, 1024])\n",
      "Feature in test_audio at index 2883 has shape: torch.Size([463, 1024])\n",
      "Feature in test_audio at index 2884 has shape: torch.Size([618, 1024])\n",
      "Feature in test_audio at index 2885 has shape: torch.Size([903, 1024])\n",
      "Feature in test_audio at index 2886 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 2887 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 2888 has shape: torch.Size([1246, 1024])\n",
      "Feature in test_audio at index 2889 has shape: torch.Size([793, 1024])\n",
      "Feature in test_audio at index 2890 has shape: torch.Size([923, 1024])\n",
      "Feature in test_audio at index 2891 has shape: torch.Size([998, 1024])\n",
      "Feature in test_audio at index 2892 has shape: torch.Size([356, 1024])\n",
      "Feature in test_audio at index 2893 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 2894 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 2895 has shape: torch.Size([1284, 1024])\n",
      "Feature in test_audio at index 2896 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 2897 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 2898 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 2899 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 2900 has shape: torch.Size([598, 1024])\n",
      "Feature in test_audio at index 2901 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 2902 has shape: torch.Size([561, 1024])\n",
      "Feature in test_audio at index 2903 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 2904 has shape: torch.Size([676, 1024])\n",
      "Feature in test_audio at index 2905 has shape: torch.Size([760, 1024])\n",
      "Feature in test_audio at index 2906 has shape: torch.Size([863, 1024])\n",
      "Feature in test_audio at index 2907 has shape: torch.Size([271, 1024])\n",
      "Feature in test_audio at index 2908 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 2909 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 2910 has shape: torch.Size([396, 1024])\n",
      "Feature in test_audio at index 2911 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 2912 has shape: torch.Size([555, 1024])\n",
      "Feature in test_audio at index 2913 has shape: torch.Size([652, 1024])\n",
      "Feature in test_audio at index 2914 has shape: torch.Size([288, 1024])\n",
      "Feature in test_audio at index 2915 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 2916 has shape: torch.Size([561, 1024])\n",
      "Feature in test_audio at index 2917 has shape: torch.Size([400, 1024])\n",
      "Feature in test_audio at index 2918 has shape: torch.Size([404, 1024])\n",
      "Feature in test_audio at index 2919 has shape: torch.Size([371, 1024])\n",
      "Feature in test_audio at index 2920 has shape: torch.Size([435, 1024])\n",
      "Feature in test_audio at index 2921 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 2922 has shape: torch.Size([742, 1024])\n",
      "Feature in test_audio at index 2923 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 2924 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 2925 has shape: torch.Size([854, 1024])\n",
      "Feature in test_audio at index 2926 has shape: torch.Size([550, 1024])\n",
      "Feature in test_audio at index 2927 has shape: torch.Size([611, 1024])\n",
      "Feature in test_audio at index 2928 has shape: torch.Size([1157, 1024])\n",
      "Feature in test_audio at index 2929 has shape: torch.Size([1039, 1024])\n",
      "Feature in test_audio at index 2930 has shape: torch.Size([477, 1024])\n",
      "Feature in test_audio at index 2931 has shape: torch.Size([326, 1024])\n",
      "Feature in test_audio at index 2932 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 2933 has shape: torch.Size([317, 1024])\n",
      "Feature in test_audio at index 2934 has shape: torch.Size([385, 1024])\n",
      "Feature in test_audio at index 2935 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 2936 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 2937 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 2938 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 2939 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 2940 has shape: torch.Size([238, 1024])\n",
      "Feature in test_audio at index 2941 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 2942 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 2943 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 2944 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 2945 has shape: torch.Size([569, 1024])\n",
      "Feature in test_audio at index 2946 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 2947 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 2948 has shape: torch.Size([1174, 1024])\n",
      "Feature in test_audio at index 2949 has shape: torch.Size([316, 1024])\n",
      "Feature in test_audio at index 2950 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 2951 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 2952 has shape: torch.Size([293, 1024])\n",
      "Feature in test_audio at index 2953 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 2954 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 2955 has shape: torch.Size([184, 1024])\n",
      "Feature in test_audio at index 2956 has shape: torch.Size([926, 1024])\n",
      "Feature in test_audio at index 2957 has shape: torch.Size([618, 1024])\n",
      "Feature in test_audio at index 2958 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 2959 has shape: torch.Size([646, 1024])\n",
      "Feature in test_audio at index 2960 has shape: torch.Size([621, 1024])\n",
      "Feature in test_audio at index 2961 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 2962 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 2963 has shape: torch.Size([183, 1024])\n",
      "Feature in test_audio at index 2964 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2965 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 2966 has shape: torch.Size([519, 1024])\n",
      "Feature in test_audio at index 2967 has shape: torch.Size([959, 1024])\n",
      "Feature in test_audio at index 2968 has shape: torch.Size([489, 1024])\n",
      "Feature in test_audio at index 2969 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 2970 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 2971 has shape: torch.Size([686, 1024])\n",
      "Feature in test_audio at index 2972 has shape: torch.Size([751, 1024])\n",
      "Feature in test_audio at index 2973 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2974 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 2975 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 2976 has shape: torch.Size([851, 1024])\n",
      "Feature in test_audio at index 2977 has shape: torch.Size([854, 1024])\n",
      "Feature in test_audio at index 2978 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 2979 has shape: torch.Size([995, 1024])\n",
      "Feature in test_audio at index 2980 has shape: torch.Size([683, 1024])\n",
      "Feature in test_audio at index 2981 has shape: torch.Size([395, 1024])\n",
      "Feature in test_audio at index 2982 has shape: torch.Size([353, 1024])\n",
      "Feature in test_audio at index 2983 has shape: torch.Size([366, 1024])\n",
      "Feature in test_audio at index 2984 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 2985 has shape: torch.Size([931, 1024])\n",
      "Feature in test_audio at index 2986 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 2987 has shape: torch.Size([760, 1024])\n",
      "Feature in test_audio at index 2988 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 2989 has shape: torch.Size([309, 1024])\n",
      "Feature in test_audio at index 2990 has shape: torch.Size([273, 1024])\n",
      "Feature in test_audio at index 2991 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 2992 has shape: torch.Size([450, 1024])\n",
      "Feature in test_audio at index 2993 has shape: torch.Size([477, 1024])\n",
      "Feature in test_audio at index 2994 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 2995 has shape: torch.Size([433, 1024])\n",
      "Feature in test_audio at index 2996 has shape: torch.Size([659, 1024])\n",
      "Feature in test_audio at index 2997 has shape: torch.Size([334, 1024])\n",
      "Feature in test_audio at index 2998 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 2999 has shape: torch.Size([622, 1024])\n",
      "Feature in test_audio at index 3000 has shape: torch.Size([299, 1024])\n",
      "Feature in test_audio at index 3001 has shape: torch.Size([139, 1024])\n",
      "Feature in test_audio at index 3002 has shape: torch.Size([315, 1024])\n",
      "Feature in test_audio at index 3003 has shape: torch.Size([571, 1024])\n",
      "Feature in test_audio at index 3004 has shape: torch.Size([485, 1024])\n",
      "Feature in test_audio at index 3005 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 3006 has shape: torch.Size([239, 1024])\n",
      "Feature in test_audio at index 3007 has shape: torch.Size([112, 1024])\n",
      "Feature in test_audio at index 3008 has shape: torch.Size([399, 1024])\n",
      "Feature in test_audio at index 3009 has shape: torch.Size([400, 1024])\n",
      "Feature in test_audio at index 3010 has shape: torch.Size([235, 1024])\n",
      "Feature in test_audio at index 3011 has shape: torch.Size([352, 1024])\n",
      "Feature in test_audio at index 3012 has shape: torch.Size([310, 1024])\n",
      "Feature in test_audio at index 3013 has shape: torch.Size([567, 1024])\n",
      "Feature in test_audio at index 3014 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 3015 has shape: torch.Size([1109, 1024])\n",
      "Feature in test_audio at index 3016 has shape: torch.Size([178, 1024])\n",
      "Feature in test_audio at index 3017 has shape: torch.Size([742, 1024])\n",
      "Feature in test_audio at index 3018 has shape: torch.Size([525, 1024])\n",
      "Feature in test_audio at index 3019 has shape: torch.Size([597, 1024])\n",
      "Feature in test_audio at index 3020 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 3021 has shape: torch.Size([1011, 1024])\n",
      "Feature in test_audio at index 3022 has shape: torch.Size([623, 1024])\n",
      "Feature in test_audio at index 3023 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 3024 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 3025 has shape: torch.Size([324, 1024])\n",
      "Feature in test_audio at index 3026 has shape: torch.Size([1345, 1024])\n",
      "Feature in test_audio at index 3027 has shape: torch.Size([284, 1024])\n",
      "Feature in test_audio at index 3028 has shape: torch.Size([319, 1024])\n",
      "Feature in test_audio at index 3029 has shape: torch.Size([143, 1024])\n",
      "Feature in test_audio at index 3030 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 3031 has shape: torch.Size([586, 1024])\n",
      "Feature in test_audio at index 3032 has shape: torch.Size([674, 1024])\n",
      "Feature in test_audio at index 3033 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 3034 has shape: torch.Size([495, 1024])\n",
      "Feature in test_audio at index 3035 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 3036 has shape: torch.Size([446, 1024])\n",
      "Feature in test_audio at index 3037 has shape: torch.Size([679, 1024])\n",
      "Feature in test_audio at index 3038 has shape: torch.Size([1229, 1024])\n",
      "Feature in test_audio at index 3039 has shape: torch.Size([576, 1024])\n",
      "Feature in test_audio at index 3040 has shape: torch.Size([606, 1024])\n",
      "Feature in test_audio at index 3041 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 3042 has shape: torch.Size([208, 1024])\n",
      "Feature in test_audio at index 3043 has shape: torch.Size([603, 1024])\n",
      "Feature in test_audio at index 3044 has shape: torch.Size([743, 1024])\n",
      "Feature in test_audio at index 3045 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 3046 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 3047 has shape: torch.Size([1331, 1024])\n",
      "Feature in test_audio at index 3048 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 3049 has shape: torch.Size([671, 1024])\n",
      "Feature in test_audio at index 3050 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 3051 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 3052 has shape: torch.Size([957, 1024])\n",
      "Feature in test_audio at index 3053 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 3054 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 3055 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 3056 has shape: torch.Size([148, 1024])\n",
      "Feature in test_audio at index 3057 has shape: torch.Size([474, 1024])\n",
      "Feature in test_audio at index 3058 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 3059 has shape: torch.Size([274, 1024])\n",
      "Feature in test_audio at index 3060 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 3061 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 3062 has shape: torch.Size([633, 1024])\n",
      "Feature in test_audio at index 3063 has shape: torch.Size([461, 1024])\n",
      "Feature in test_audio at index 3064 has shape: torch.Size([534, 1024])\n",
      "Feature in test_audio at index 3065 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 3066 has shape: torch.Size([911, 1024])\n",
      "Feature in test_audio at index 3067 has shape: torch.Size([1133, 1024])\n",
      "Feature in test_audio at index 3068 has shape: torch.Size([881, 1024])\n",
      "Feature in test_audio at index 3069 has shape: torch.Size([686, 1024])\n",
      "Feature in test_audio at index 3070 has shape: torch.Size([1386, 1024])\n",
      "Feature in test_audio at index 3071 has shape: torch.Size([744, 1024])\n",
      "Feature in test_audio at index 3072 has shape: torch.Size([712, 1024])\n",
      "Feature in test_audio at index 3073 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 3074 has shape: torch.Size([874, 1024])\n",
      "Feature in test_audio at index 3075 has shape: torch.Size([739, 1024])\n",
      "Feature in test_audio at index 3076 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 3077 has shape: torch.Size([686, 1024])\n",
      "Feature in test_audio at index 3078 has shape: torch.Size([676, 1024])\n",
      "Feature in test_audio at index 3079 has shape: torch.Size([461, 1024])\n",
      "Feature in test_audio at index 3080 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 3081 has shape: torch.Size([1046, 1024])\n",
      "Feature in test_audio at index 3082 has shape: torch.Size([479, 1024])\n",
      "Feature in test_audio at index 3083 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 3084 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 3085 has shape: torch.Size([606, 1024])\n",
      "Feature in test_audio at index 3086 has shape: torch.Size([256, 1024])\n",
      "Feature in test_audio at index 3087 has shape: torch.Size([218, 1024])\n",
      "Feature in test_audio at index 3088 has shape: torch.Size([519, 1024])\n",
      "Feature in test_audio at index 3089 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 3090 has shape: torch.Size([237, 1024])\n",
      "Feature in test_audio at index 3091 has shape: torch.Size([490, 1024])\n",
      "Feature in test_audio at index 3092 has shape: torch.Size([325, 1024])\n",
      "Feature in test_audio at index 3093 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 3094 has shape: torch.Size([661, 1024])\n",
      "Feature in test_audio at index 3095 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 3096 has shape: torch.Size([596, 1024])\n",
      "Feature in test_audio at index 3097 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 3098 has shape: torch.Size([997, 1024])\n",
      "Feature in test_audio at index 3099 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 3100 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3101 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 3102 has shape: torch.Size([297, 1024])\n",
      "Feature in test_audio at index 3103 has shape: torch.Size([616, 1024])\n",
      "Feature in test_audio at index 3104 has shape: torch.Size([733, 1024])\n",
      "Feature in test_audio at index 3105 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 3106 has shape: torch.Size([552, 1024])\n",
      "Feature in test_audio at index 3107 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 3108 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 3109 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 3110 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 3111 has shape: torch.Size([586, 1024])\n",
      "Feature in test_audio at index 3112 has shape: torch.Size([423, 1024])\n",
      "Feature in test_audio at index 3113 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 3114 has shape: torch.Size([661, 1024])\n",
      "Feature in test_audio at index 3115 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 3116 has shape: torch.Size([1003, 1024])\n",
      "Feature in test_audio at index 3117 has shape: torch.Size([1383, 1024])\n",
      "Feature in test_audio at index 3118 has shape: torch.Size([441, 1024])\n",
      "Feature in test_audio at index 3119 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 3120 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 3121 has shape: torch.Size([1126, 1024])\n",
      "Feature in test_audio at index 3122 has shape: torch.Size([729, 1024])\n",
      "Feature in test_audio at index 3123 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 3124 has shape: torch.Size([341, 1024])\n",
      "Feature in test_audio at index 3125 has shape: torch.Size([611, 1024])\n",
      "Feature in test_audio at index 3126 has shape: torch.Size([526, 1024])\n",
      "Feature in test_audio at index 3127 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 3128 has shape: torch.Size([522, 1024])\n",
      "Feature in test_audio at index 3129 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 3130 has shape: torch.Size([621, 1024])\n",
      "Feature in test_audio at index 3131 has shape: torch.Size([756, 1024])\n",
      "Feature in test_audio at index 3132 has shape: torch.Size([828, 1024])\n",
      "Feature in test_audio at index 3133 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 3134 has shape: torch.Size([843, 1024])\n",
      "Feature in test_audio at index 3135 has shape: torch.Size([343, 1024])\n",
      "Feature in test_audio at index 3136 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 3137 has shape: torch.Size([377, 1024])\n",
      "Feature in test_audio at index 3138 has shape: torch.Size([294, 1024])\n",
      "Feature in test_audio at index 3139 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 3140 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 3141 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 3142 has shape: torch.Size([589, 1024])\n",
      "Feature in test_audio at index 3143 has shape: torch.Size([646, 1024])\n",
      "Feature in test_audio at index 3144 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 3145 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 3146 has shape: torch.Size([362, 1024])\n",
      "Feature in test_audio at index 3147 has shape: torch.Size([861, 1024])\n",
      "Feature in test_audio at index 3148 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 3149 has shape: torch.Size([1038, 1024])\n",
      "Feature in test_audio at index 3150 has shape: torch.Size([935, 1024])\n",
      "Feature in test_audio at index 3151 has shape: torch.Size([287, 1024])\n",
      "Feature in test_audio at index 3152 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 3153 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 3154 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 3155 has shape: torch.Size([1124, 1024])\n",
      "Feature in test_audio at index 3156 has shape: torch.Size([221, 1024])\n",
      "Feature in test_audio at index 3157 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 3158 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 3159 has shape: torch.Size([359, 1024])\n",
      "Feature in test_audio at index 3160 has shape: torch.Size([877, 1024])\n",
      "Feature in test_audio at index 3161 has shape: torch.Size([833, 1024])\n",
      "Feature in test_audio at index 3162 has shape: torch.Size([209, 1024])\n",
      "Feature in test_audio at index 3163 has shape: torch.Size([578, 1024])\n",
      "Feature in test_audio at index 3164 has shape: torch.Size([743, 1024])\n",
      "Feature in test_audio at index 3165 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 3166 has shape: torch.Size([603, 1024])\n",
      "Feature in test_audio at index 3167 has shape: torch.Size([736, 1024])\n",
      "Feature in test_audio at index 3168 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 3169 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 3170 has shape: torch.Size([816, 1024])\n",
      "Feature in test_audio at index 3171 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 3172 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 3173 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 3174 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 3175 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 3176 has shape: torch.Size([556, 1024])\n",
      "Feature in test_audio at index 3177 has shape: torch.Size([336, 1024])\n",
      "Feature in test_audio at index 3178 has shape: torch.Size([506, 1024])\n",
      "Feature in test_audio at index 3179 has shape: torch.Size([604, 1024])\n",
      "Feature in test_audio at index 3180 has shape: torch.Size([653, 1024])\n",
      "Feature in test_audio at index 3181 has shape: torch.Size([373, 1024])\n",
      "Feature in test_audio at index 3182 has shape: torch.Size([541, 1024])\n",
      "Feature in test_audio at index 3183 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 3184 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 3185 has shape: torch.Size([724, 1024])\n",
      "Feature in test_audio at index 3186 has shape: torch.Size([516, 1024])\n",
      "Feature in test_audio at index 3187 has shape: torch.Size([721, 1024])\n",
      "Feature in test_audio at index 3188 has shape: torch.Size([654, 1024])\n",
      "Feature in test_audio at index 3189 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 3190 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 3191 has shape: torch.Size([929, 1024])\n",
      "Feature in test_audio at index 3192 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 3193 has shape: torch.Size([531, 1024])\n",
      "Feature in test_audio at index 3194 has shape: torch.Size([668, 1024])\n",
      "Feature in test_audio at index 3195 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 3196 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 3197 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 3198 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 3199 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 3200 has shape: torch.Size([744, 1024])\n",
      "Feature in test_audio at index 3201 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 3202 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 3203 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3204 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 3205 has shape: torch.Size([318, 1024])\n",
      "Feature in test_audio at index 3206 has shape: torch.Size([383, 1024])\n",
      "Feature in test_audio at index 3207 has shape: torch.Size([308, 1024])\n",
      "Feature in test_audio at index 3208 has shape: torch.Size([285, 1024])\n",
      "Feature in test_audio at index 3209 has shape: torch.Size([465, 1024])\n",
      "Feature in test_audio at index 3210 has shape: torch.Size([427, 1024])\n",
      "Feature in test_audio at index 3211 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 3212 has shape: torch.Size([370, 1024])\n",
      "Feature in test_audio at index 3213 has shape: torch.Size([727, 1024])\n",
      "Feature in test_audio at index 3214 has shape: torch.Size([835, 1024])\n",
      "Feature in test_audio at index 3215 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 3216 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 3217 has shape: torch.Size([926, 1024])\n",
      "Feature in test_audio at index 3218 has shape: torch.Size([786, 1024])\n",
      "Feature in test_audio at index 3219 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 3220 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 3221 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 3222 has shape: torch.Size([249, 1024])\n",
      "Feature in test_audio at index 3223 has shape: torch.Size([544, 1024])\n",
      "Feature in test_audio at index 3224 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 3225 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 3226 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 3227 has shape: torch.Size([524, 1024])\n",
      "Feature in test_audio at index 3228 has shape: torch.Size([704, 1024])\n",
      "Feature in test_audio at index 3229 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 3230 has shape: torch.Size([223, 1024])\n",
      "Feature in test_audio at index 3231 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 3232 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 3233 has shape: torch.Size([374, 1024])\n",
      "Feature in test_audio at index 3234 has shape: torch.Size([619, 1024])\n",
      "Feature in test_audio at index 3235 has shape: torch.Size([433, 1024])\n",
      "Feature in test_audio at index 3236 has shape: torch.Size([637, 1024])\n",
      "Feature in test_audio at index 3237 has shape: torch.Size([658, 1024])\n",
      "Feature in test_audio at index 3238 has shape: torch.Size([358, 1024])\n",
      "Feature in test_audio at index 3239 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3240 has shape: torch.Size([381, 1024])\n",
      "Feature in test_audio at index 3241 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 3242 has shape: torch.Size([630, 1024])\n",
      "Feature in test_audio at index 3243 has shape: torch.Size([543, 1024])\n",
      "Feature in test_audio at index 3244 has shape: torch.Size([686, 1024])\n",
      "Feature in test_audio at index 3245 has shape: torch.Size([741, 1024])\n",
      "Feature in test_audio at index 3246 has shape: torch.Size([339, 1024])\n",
      "Feature in test_audio at index 3247 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 3248 has shape: torch.Size([1021, 1024])\n",
      "Feature in test_audio at index 3249 has shape: torch.Size([529, 1024])\n",
      "Feature in test_audio at index 3250 has shape: torch.Size([450, 1024])\n",
      "Feature in test_audio at index 3251 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 3252 has shape: torch.Size([554, 1024])\n",
      "Feature in test_audio at index 3253 has shape: torch.Size([424, 1024])\n",
      "Feature in test_audio at index 3254 has shape: torch.Size([601, 1024])\n",
      "Feature in test_audio at index 3255 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 3256 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 3257 has shape: torch.Size([699, 1024])\n",
      "Feature in test_audio at index 3258 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 3259 has shape: torch.Size([418, 1024])\n",
      "Feature in test_audio at index 3260 has shape: torch.Size([179, 1024])\n",
      "Feature in test_audio at index 3261 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 3262 has shape: torch.Size([894, 1024])\n",
      "Feature in test_audio at index 3263 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 3264 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 3265 has shape: torch.Size([563, 1024])\n",
      "Feature in test_audio at index 3266 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 3267 has shape: torch.Size([403, 1024])\n",
      "Feature in test_audio at index 3268 has shape: torch.Size([388, 1024])\n",
      "Feature in test_audio at index 3269 has shape: torch.Size([528, 1024])\n",
      "Feature in test_audio at index 3270 has shape: torch.Size([659, 1024])\n",
      "Feature in test_audio at index 3271 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3272 has shape: torch.Size([951, 1024])\n",
      "Feature in test_audio at index 3273 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 3274 has shape: torch.Size([711, 1024])\n",
      "Feature in test_audio at index 3275 has shape: torch.Size([523, 1024])\n",
      "Feature in test_audio at index 3276 has shape: torch.Size([321, 1024])\n",
      "Feature in test_audio at index 3277 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 3278 has shape: torch.Size([384, 1024])\n",
      "Feature in test_audio at index 3279 has shape: torch.Size([474, 1024])\n",
      "Feature in test_audio at index 3280 has shape: torch.Size([726, 1024])\n",
      "Feature in test_audio at index 3281 has shape: torch.Size([634, 1024])\n",
      "Feature in test_audio at index 3282 has shape: torch.Size([331, 1024])\n",
      "Feature in test_audio at index 3283 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3284 has shape: torch.Size([593, 1024])\n",
      "Feature in test_audio at index 3285 has shape: torch.Size([612, 1024])\n",
      "Feature in test_audio at index 3286 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 3287 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 3288 has shape: torch.Size([382, 1024])\n",
      "Feature in test_audio at index 3289 has shape: torch.Size([208, 1024])\n",
      "Feature in test_audio at index 3290 has shape: torch.Size([458, 1024])\n",
      "Feature in test_audio at index 3291 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 3292 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 3293 has shape: torch.Size([368, 1024])\n",
      "Feature in test_audio at index 3294 has shape: torch.Size([485, 1024])\n",
      "Feature in test_audio at index 3295 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 3296 has shape: torch.Size([361, 1024])\n",
      "Feature in test_audio at index 3297 has shape: torch.Size([818, 1024])\n",
      "Feature in test_audio at index 3298 has shape: torch.Size([1101, 1024])\n",
      "Feature in test_audio at index 3299 has shape: torch.Size([352, 1024])\n",
      "Feature in test_audio at index 3300 has shape: torch.Size([882, 1024])\n",
      "Feature in test_audio at index 3301 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 3302 has shape: torch.Size([631, 1024])\n",
      "Feature in test_audio at index 3303 has shape: torch.Size([438, 1024])\n",
      "Feature in test_audio at index 3304 has shape: torch.Size([478, 1024])\n",
      "Feature in test_audio at index 3305 has shape: torch.Size([533, 1024])\n",
      "Feature in test_audio at index 3306 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 3307 has shape: torch.Size([484, 1024])\n",
      "Feature in test_audio at index 3308 has shape: torch.Size([989, 1024])\n",
      "Feature in test_audio at index 3309 has shape: torch.Size([928, 1024])\n",
      "Feature in test_audio at index 3310 has shape: torch.Size([1196, 1024])\n",
      "Feature in test_audio at index 3311 has shape: torch.Size([1063, 1024])\n",
      "Feature in test_audio at index 3312 has shape: torch.Size([1051, 1024])\n",
      "Feature in test_audio at index 3313 has shape: torch.Size([5278, 1024])\n",
      "Feature in test_audio at index 3314 has shape: torch.Size([613, 1024])\n",
      "Feature in test_audio at index 3315 has shape: torch.Size([868, 1024])\n",
      "Feature in test_audio at index 3316 has shape: torch.Size([348, 1024])\n",
      "Feature in test_audio at index 3317 has shape: torch.Size([332, 1024])\n",
      "Feature in test_audio at index 3318 has shape: torch.Size([649, 1024])\n",
      "Feature in test_audio at index 3319 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 3320 has shape: torch.Size([219, 1024])\n",
      "Feature in test_audio at index 3321 has shape: torch.Size([309, 1024])\n",
      "Feature in test_audio at index 3322 has shape: torch.Size([159, 1024])\n",
      "Feature in test_audio at index 3323 has shape: torch.Size([240, 1024])\n",
      "Feature in test_audio at index 3324 has shape: torch.Size([128, 1024])\n",
      "Feature in test_audio at index 3325 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 3326 has shape: torch.Size([638, 1024])\n",
      "Feature in test_audio at index 3327 has shape: torch.Size([633, 1024])\n",
      "Feature in test_audio at index 3328 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 3329 has shape: torch.Size([689, 1024])\n",
      "Feature in test_audio at index 3330 has shape: torch.Size([901, 1024])\n",
      "Feature in test_audio at index 3331 has shape: torch.Size([573, 1024])\n",
      "Feature in test_audio at index 3332 has shape: torch.Size([328, 1024])\n",
      "Feature in test_audio at index 3333 has shape: torch.Size([956, 1024])\n",
      "Feature in test_audio at index 3334 has shape: torch.Size([571, 1024])\n",
      "Feature in test_audio at index 3335 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 3336 has shape: torch.Size([201, 1024])\n",
      "Feature in test_audio at index 3337 has shape: torch.Size([883, 1024])\n",
      "Feature in test_audio at index 3338 has shape: torch.Size([378, 1024])\n",
      "Feature in test_audio at index 3339 has shape: torch.Size([601, 1024])\n",
      "Feature in test_audio at index 3340 has shape: torch.Size([471, 1024])\n",
      "Feature in test_audio at index 3341 has shape: torch.Size([581, 1024])\n",
      "Feature in test_audio at index 3342 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 3343 has shape: torch.Size([409, 1024])\n",
      "Feature in test_audio at index 3344 has shape: torch.Size([283, 1024])\n",
      "Feature in test_audio at index 3345 has shape: torch.Size([444, 1024])\n",
      "Feature in test_audio at index 3346 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 3347 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 3348 has shape: torch.Size([259, 1024])\n",
      "Feature in test_audio at index 3349 has shape: torch.Size([718, 1024])\n",
      "Feature in test_audio at index 3350 has shape: torch.Size([408, 1024])\n",
      "Feature in test_audio at index 3351 has shape: torch.Size([673, 1024])\n",
      "Feature in test_audio at index 3352 has shape: torch.Size([716, 1024])\n",
      "Feature in test_audio at index 3353 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 3354 has shape: torch.Size([773, 1024])\n",
      "Feature in test_audio at index 3355 has shape: torch.Size([731, 1024])\n",
      "Feature in test_audio at index 3356 has shape: torch.Size([551, 1024])\n",
      "Feature in test_audio at index 3357 has shape: torch.Size([804, 1024])\n",
      "Feature in test_audio at index 3358 has shape: torch.Size([797, 1024])\n",
      "Feature in test_audio at index 3359 has shape: torch.Size([623, 1024])\n",
      "Feature in test_audio at index 3360 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 3361 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 3362 has shape: torch.Size([776, 1024])\n",
      "Feature in test_audio at index 3363 has shape: torch.Size([602, 1024])\n",
      "Feature in test_audio at index 3364 has shape: torch.Size([248, 1024])\n",
      "Feature in test_audio at index 3365 has shape: torch.Size([456, 1024])\n",
      "Feature in test_audio at index 3366 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 3367 has shape: torch.Size([291, 1024])\n",
      "Feature in test_audio at index 3368 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 3369 has shape: torch.Size([473, 1024])\n",
      "Feature in test_audio at index 3370 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 3371 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 3372 has shape: torch.Size([344, 1024])\n",
      "Feature in test_audio at index 3373 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 3374 has shape: torch.Size([609, 1024])\n",
      "Feature in test_audio at index 3375 has shape: torch.Size([564, 1024])\n",
      "Feature in test_audio at index 3376 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 3377 has shape: torch.Size([465, 1024])\n",
      "Feature in test_audio at index 3378 has shape: torch.Size([646, 1024])\n",
      "Feature in test_audio at index 3379 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 3380 has shape: torch.Size([541, 1024])\n",
      "Feature in test_audio at index 3381 has shape: torch.Size([791, 1024])\n",
      "Feature in test_audio at index 3382 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 3383 has shape: torch.Size([552, 1024])\n",
      "Feature in test_audio at index 3384 has shape: torch.Size([786, 1024])\n",
      "Feature in test_audio at index 3385 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3386 has shape: torch.Size([428, 1024])\n",
      "Feature in test_audio at index 3387 has shape: torch.Size([712, 1024])\n",
      "Feature in test_audio at index 3388 has shape: torch.Size([925, 1024])\n",
      "Feature in test_audio at index 3389 has shape: torch.Size([831, 1024])\n",
      "Feature in test_audio at index 3390 has shape: torch.Size([751, 1024])\n",
      "Feature in test_audio at index 3391 has shape: torch.Size([955, 1024])\n",
      "Feature in test_audio at index 3392 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 3393 has shape: torch.Size([411, 1024])\n",
      "Feature in test_audio at index 3394 has shape: torch.Size([944, 1024])\n",
      "Feature in test_audio at index 3395 has shape: torch.Size([469, 1024])\n",
      "Feature in test_audio at index 3396 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 3397 has shape: torch.Size([504, 1024])\n",
      "Feature in test_audio at index 3398 has shape: torch.Size([606, 1024])\n",
      "Feature in test_audio at index 3399 has shape: torch.Size([579, 1024])\n",
      "Feature in test_audio at index 3400 has shape: torch.Size([978, 1024])\n",
      "Feature in test_audio at index 3401 has shape: torch.Size([733, 1024])\n",
      "Feature in test_audio at index 3402 has shape: torch.Size([349, 1024])\n",
      "Feature in test_audio at index 3403 has shape: torch.Size([276, 1024])\n",
      "Feature in test_audio at index 3404 has shape: torch.Size([414, 1024])\n",
      "Feature in test_audio at index 3405 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 3406 has shape: torch.Size([834, 1024])\n",
      "Feature in test_audio at index 3407 has shape: torch.Size([1100, 1024])\n",
      "Feature in test_audio at index 3408 has shape: torch.Size([853, 1024])\n",
      "Feature in test_audio at index 3409 has shape: torch.Size([616, 1024])\n",
      "Feature in test_audio at index 3410 has shape: torch.Size([548, 1024])\n",
      "Feature in test_audio at index 3411 has shape: torch.Size([511, 1024])\n",
      "Feature in test_audio at index 3412 has shape: torch.Size([754, 1024])\n",
      "Feature in test_audio at index 3413 has shape: torch.Size([1291, 1024])\n",
      "Feature in test_audio at index 3414 has shape: torch.Size([451, 1024])\n",
      "Feature in test_audio at index 3415 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 3416 has shape: torch.Size([916, 1024])\n",
      "Feature in test_audio at index 3417 has shape: torch.Size([873, 1024])\n",
      "Feature in test_audio at index 3418 has shape: torch.Size([798, 1024])\n",
      "Feature in test_audio at index 3419 has shape: torch.Size([1310, 1024])\n",
      "Feature in test_audio at index 3420 has shape: torch.Size([341, 1024])\n",
      "Feature in test_audio at index 3421 has shape: torch.Size([841, 1024])\n",
      "Feature in test_audio at index 3422 has shape: torch.Size([753, 1024])\n",
      "Feature in test_audio at index 3423 has shape: torch.Size([946, 1024])\n",
      "Feature in test_audio at index 3424 has shape: torch.Size([929, 1024])\n",
      "Feature in test_audio at index 3425 has shape: torch.Size([996, 1024])\n",
      "Feature in test_audio at index 3426 has shape: torch.Size([648, 1024])\n",
      "Feature in test_audio at index 3427 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 3428 has shape: torch.Size([1339, 1024])\n",
      "Feature in test_audio at index 3429 has shape: torch.Size([1014, 1024])\n",
      "Feature in test_audio at index 3430 has shape: torch.Size([429, 1024])\n",
      "Feature in test_audio at index 3431 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 3432 has shape: torch.Size([434, 1024])\n",
      "Feature in test_audio at index 3433 has shape: torch.Size([915, 1024])\n",
      "Feature in test_audio at index 3434 has shape: torch.Size([726, 1024])\n",
      "Feature in test_audio at index 3435 has shape: torch.Size([600, 1024])\n",
      "Feature in test_audio at index 3436 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 3437 has shape: torch.Size([625, 1024])\n",
      "Feature in test_audio at index 3438 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 3439 has shape: torch.Size([501, 1024])\n",
      "Feature in test_audio at index 3440 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 3441 has shape: torch.Size([886, 1024])\n",
      "Feature in test_audio at index 3442 has shape: torch.Size([584, 1024])\n",
      "Feature in test_audio at index 3443 has shape: torch.Size([449, 1024])\n",
      "Feature in test_audio at index 3444 has shape: torch.Size([178, 1024])\n",
      "Feature in test_audio at index 3445 has shape: torch.Size([621, 1024])\n",
      "Feature in test_audio at index 3446 has shape: torch.Size([435, 1024])\n",
      "Feature in test_audio at index 3447 has shape: torch.Size([625, 1024])\n",
      "Feature in test_audio at index 3448 has shape: torch.Size([691, 1024])\n",
      "Feature in test_audio at index 3449 has shape: torch.Size([804, 1024])\n",
      "Feature in test_audio at index 3450 has shape: torch.Size([637, 1024])\n",
      "Feature in test_audio at index 3451 has shape: torch.Size([664, 1024])\n",
      "Feature in test_audio at index 3452 has shape: torch.Size([929, 1024])\n",
      "Feature in test_audio at index 3453 has shape: torch.Size([213, 1024])\n",
      "Feature in test_audio at index 3454 has shape: torch.Size([1006, 1024])\n",
      "Feature in test_audio at index 3455 has shape: torch.Size([1345, 1024])\n",
      "Feature in test_audio at index 3456 has shape: torch.Size([1077, 1024])\n",
      "Feature in test_audio at index 3457 has shape: torch.Size([266, 1024])\n",
      "Feature in test_audio at index 3458 has shape: torch.Size([552, 1024])\n",
      "Feature in test_audio at index 3459 has shape: torch.Size([169, 1024])\n",
      "Feature in test_audio at index 3460 has shape: torch.Size([443, 1024])\n",
      "Feature in test_audio at index 3461 has shape: torch.Size([235, 1024])\n",
      "Feature in test_audio at index 3462 has shape: torch.Size([362, 1024])\n",
      "Feature in test_audio at index 3463 has shape: torch.Size([268, 1024])\n",
      "Feature in test_audio at index 3464 has shape: torch.Size([600, 1024])\n",
      "Feature in test_audio at index 3465 has shape: torch.Size([436, 1024])\n",
      "Feature in test_audio at index 3466 has shape: torch.Size([299, 1024])\n",
      "Feature in test_audio at index 3467 has shape: torch.Size([588, 1024])\n",
      "Feature in test_audio at index 3468 has shape: torch.Size([231, 1024])\n",
      "Feature in test_audio at index 3469 has shape: torch.Size([421, 1024])\n",
      "Feature in test_audio at index 3470 has shape: torch.Size([258, 1024])\n",
      "Feature in test_audio at index 3471 has shape: torch.Size([395, 1024])\n",
      "Feature in test_audio at index 3472 has shape: torch.Size([216, 1024])\n",
      "Feature in test_audio at index 3473 has shape: torch.Size([612, 1024])\n",
      "Feature in test_audio at index 3474 has shape: torch.Size([182, 1024])\n",
      "Feature in test_audio at index 3475 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 3476 has shape: torch.Size([197, 1024])\n",
      "Feature in test_audio at index 3477 has shape: torch.Size([546, 1024])\n",
      "Feature in test_audio at index 3478 has shape: torch.Size([350, 1024])\n",
      "Feature in test_audio at index 3479 has shape: torch.Size([572, 1024])\n",
      "Feature in test_audio at index 3480 has shape: torch.Size([943, 1024])\n",
      "Feature in test_audio at index 3481 has shape: torch.Size([1008, 1024])\n",
      "Feature in test_audio at index 3482 has shape: torch.Size([678, 1024])\n",
      "Feature in test_audio at index 3483 has shape: torch.Size([244, 1024])\n",
      "Feature in test_audio at index 3484 has shape: torch.Size([793, 1024])\n",
      "Feature in test_audio at index 3485 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 3486 has shape: torch.Size([711, 1024])\n",
      "Feature in test_audio at index 3487 has shape: torch.Size([619, 1024])\n",
      "Feature in test_audio at index 3488 has shape: torch.Size([682, 1024])\n",
      "Feature in test_audio at index 3489 has shape: torch.Size([491, 1024])\n",
      "Feature in test_audio at index 3490 has shape: torch.Size([737, 1024])\n",
      "Feature in test_audio at index 3491 has shape: torch.Size([418, 1024])\n",
      "Feature in test_audio at index 3492 has shape: torch.Size([391, 1024])\n",
      "Feature in test_audio at index 3493 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 3494 has shape: torch.Size([406, 1024])\n",
      "Feature in test_audio at index 3495 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 3496 has shape: torch.Size([468, 1024])\n",
      "Feature in test_audio at index 3497 has shape: torch.Size([643, 1024])\n",
      "Feature in test_audio at index 3498 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 3499 has shape: torch.Size([263, 1024])\n",
      "Feature in test_audio at index 3500 has shape: torch.Size([487, 1024])\n",
      "Feature in test_audio at index 3501 has shape: torch.Size([568, 1024])\n",
      "Feature in test_audio at index 3502 has shape: torch.Size([789, 1024])\n",
      "Feature in test_audio at index 3503 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 3504 has shape: torch.Size([576, 1024])\n",
      "Feature in test_audio at index 3505 has shape: torch.Size([626, 1024])\n",
      "Feature in test_audio at index 3506 has shape: torch.Size([369, 1024])\n",
      "Feature in test_audio at index 3507 has shape: torch.Size([483, 1024])\n",
      "Feature in test_audio at index 3508 has shape: torch.Size([201, 1024])\n",
      "Feature in test_audio at index 3509 has shape: torch.Size([314, 1024])\n",
      "Feature in test_audio at index 3510 has shape: torch.Size([664, 1024])\n",
      "Feature in test_audio at index 3511 has shape: torch.Size([183, 1024])\n",
      "Feature in test_audio at index 3512 has shape: torch.Size([465, 1024])\n",
      "Feature in test_audio at index 3513 has shape: torch.Size([477, 1024])\n",
      "Feature in test_audio at index 3514 has shape: torch.Size([354, 1024])\n",
      "Feature in test_audio at index 3515 has shape: torch.Size([220, 1024])\n",
      "Feature in test_audio at index 3516 has shape: torch.Size([752, 1024])\n",
      "Feature in test_audio at index 3517 has shape: torch.Size([493, 1024])\n",
      "Feature in test_audio at index 3518 has shape: torch.Size([566, 1024])\n",
      "Feature in test_audio at index 3519 has shape: torch.Size([540, 1024])\n",
      "Feature in test_audio at index 3520 has shape: torch.Size([654, 1024])\n",
      "Feature in test_audio at index 3521 has shape: torch.Size([633, 1024])\n",
      "Feature in test_audio at index 3522 has shape: torch.Size([346, 1024])\n",
      "Feature in test_audio at index 3523 has shape: torch.Size([831, 1024])\n",
      "Feature in test_audio at index 3524 has shape: torch.Size([1942, 1024])\n",
      "Feature in test_audio at index 3525 has shape: torch.Size([939, 1024])\n",
      "Feature in test_audio at index 3526 has shape: torch.Size([821, 1024])\n",
      "Feature in test_audio at index 3527 has shape: torch.Size([871, 1024])\n",
      "Feature in test_audio at index 3528 has shape: torch.Size([794, 1024])\n",
      "Feature in test_audio at index 3529 has shape: torch.Size([518, 1024])\n",
      "Feature in test_audio at index 3530 has shape: torch.Size([503, 1024])\n",
      "Feature in test_audio at index 3531 has shape: torch.Size([329, 1024])\n",
      "Feature in test_audio at index 3532 has shape: torch.Size([641, 1024])\n",
      "Feature in test_audio at index 3533 has shape: torch.Size([721, 1024])\n",
      "Feature in test_audio at index 3534 has shape: torch.Size([243, 1024])\n",
      "Feature in test_audio at index 3535 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 3536 has shape: torch.Size([662, 1024])\n",
      "Feature in test_audio at index 3537 has shape: torch.Size([521, 1024])\n",
      "Feature in test_audio at index 3538 has shape: torch.Size([250, 1024])\n",
      "Feature in test_audio at index 3539 has shape: torch.Size([558, 1024])\n",
      "Feature in test_audio at index 3540 has shape: torch.Size([539, 1024])\n",
      "Feature in test_audio at index 3541 has shape: torch.Size([559, 1024])\n",
      "Feature in test_audio at index 3542 has shape: torch.Size([814, 1024])\n",
      "Feature in test_audio at index 3543 has shape: torch.Size([488, 1024])\n",
      "Feature in test_audio at index 3544 has shape: torch.Size([1206, 1024])\n",
      "Feature in test_audio at index 3545 has shape: torch.Size([1094, 1024])\n",
      "Feature in test_audio at index 3546 has shape: torch.Size([731, 1024])\n",
      "Feature in test_audio at index 3547 has shape: torch.Size([599, 1024])\n",
      "Feature in test_audio at index 3548 has shape: torch.Size([801, 1024])\n",
      "Feature in test_audio at index 3549 has shape: torch.Size([289, 1024])\n",
      "Feature in test_audio at index 3550 has shape: torch.Size([1353, 1024])\n",
      "Feature in test_audio at index 3551 has shape: torch.Size([679, 1024])\n",
      "Feature in test_audio at index 3552 has shape: torch.Size([1399, 1024])\n",
      "Feature in test_audio at index 3553 has shape: torch.Size([866, 1024])\n",
      "Feature in test_audio at index 3554 has shape: torch.Size([208, 1024])\n",
      "Feature in test_audio at index 3555 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 3556 has shape: torch.Size([636, 1024])\n",
      "Feature in test_audio at index 3557 has shape: torch.Size([198, 1024])\n",
      "Feature in test_audio at index 3558 has shape: torch.Size([476, 1024])\n",
      "Feature in test_audio at index 3559 has shape: torch.Size([1026, 1024])\n",
      "Feature in test_audio at index 3560 has shape: torch.Size([1196, 1024])\n",
      "Feature in test_audio at index 3561 has shape: torch.Size([885, 1024])\n",
      "Feature in test_audio at index 3562 has shape: torch.Size([944, 1024])\n",
      "Feature in test_audio at index 3563 has shape: torch.Size([522, 1024])\n",
      "Feature in test_audio at index 3564 has shape: torch.Size([466, 1024])\n",
      "Feature in test_audio at index 3565 has shape: torch.Size([278, 1024])\n",
      "Feature in test_audio at index 3566 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 3567 has shape: torch.Size([594, 1024])\n",
      "Feature in test_audio at index 3568 has shape: torch.Size([639, 1024])\n",
      "Feature in test_audio at index 3569 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 3570 has shape: torch.Size([513, 1024])\n",
      "Feature in test_audio at index 3571 has shape: torch.Size([779, 1024])\n",
      "Feature in test_audio at index 3572 has shape: torch.Size([1086, 1024])\n",
      "Feature in test_audio at index 3573 has shape: torch.Size([431, 1024])\n",
      "Feature in test_audio at index 3574 has shape: torch.Size([848, 1024])\n",
      "Feature in test_audio at index 3575 has shape: torch.Size([1624, 1024])\n",
      "Feature in test_audio at index 3576 has shape: torch.Size([735, 1024])\n",
      "Feature in test_audio at index 3577 has shape: torch.Size([307, 1024])\n",
      "Feature in test_audio at index 3578 has shape: torch.Size([445, 1024])\n",
      "Feature in test_audio at index 3579 has shape: torch.Size([684, 1024])\n",
      "Feature in test_audio at index 3580 has shape: torch.Size([281, 1024])\n",
      "Feature in test_audio at index 3581 has shape: torch.Size([591, 1024])\n",
      "Feature in test_audio at index 3582 has shape: torch.Size([1193, 1024])\n",
      "Feature in test_audio at index 3583 has shape: torch.Size([549, 1024])\n",
      "Feature in test_audio at index 3584 has shape: torch.Size([698, 1024])\n",
      "Feature in test_audio at index 3585 has shape: torch.Size([644, 1024])\n",
      "Feature in test_audio at index 3586 has shape: torch.Size([889, 1024])\n",
      "Feature in test_audio at index 3587 has shape: torch.Size([453, 1024])\n",
      "Feature in test_audio at index 3588 has shape: torch.Size([858, 1024])\n",
      "Feature in test_audio at index 3589 has shape: torch.Size([868, 1024])\n",
      "Feature in test_audio at index 3590 has shape: torch.Size([561, 1024])\n",
      "Feature in test_audio at index 3591 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 3592 has shape: torch.Size([1109, 1024])\n",
      "Feature in test_audio at index 3593 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 3594 has shape: torch.Size([854, 1024])\n",
      "Feature in test_audio at index 3595 has shape: torch.Size([496, 1024])\n",
      "Feature in test_audio at index 3596 has shape: torch.Size([443, 1024])\n",
      "Feature in test_audio at index 3597 has shape: torch.Size([394, 1024])\n",
      "Feature in test_audio at index 3598 has shape: torch.Size([888, 1024])\n",
      "Feature in test_audio at index 3599 has shape: torch.Size([538, 1024])\n",
      "Feature in test_audio at index 3600 has shape: torch.Size([587, 1024])\n",
      "Feature in test_audio at index 3601 has shape: torch.Size([416, 1024])\n",
      "Feature in test_audio at index 3602 has shape: torch.Size([398, 1024])\n",
      "Feature in test_audio at index 3603 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 3604 has shape: torch.Size([298, 1024])\n",
      "Feature in test_audio at index 3605 has shape: torch.Size([363, 1024])\n",
      "Feature in test_audio at index 3606 has shape: torch.Size([468, 1024])\n",
      "Feature in test_audio at index 3607 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 3608 has shape: torch.Size([580, 1024])\n",
      "Feature in test_audio at index 3609 has shape: torch.Size([448, 1024])\n",
      "Feature in test_audio at index 3610 has shape: torch.Size([234, 1024])\n",
      "Feature in test_audio at index 3611 has shape: torch.Size([353, 1024])\n",
      "Feature in test_audio at index 3612 has shape: torch.Size([184, 1024])\n",
      "Feature in test_audio at index 3613 has shape: torch.Size([286, 1024])\n",
      "Feature in test_audio at index 3614 has shape: torch.Size([612, 1024])\n",
      "Feature in test_audio at index 3615 has shape: torch.Size([303, 1024])\n",
      "Feature in test_audio at index 3616 has shape: torch.Size([423, 1024])\n",
      "Feature in test_audio at index 3617 has shape: torch.Size([608, 1024])\n",
      "Feature in test_audio at index 3618 has shape: torch.Size([498, 1024])\n",
      "Feature in test_audio at index 3619 has shape: torch.Size([514, 1024])\n",
      "Feature in test_audio at index 3620 has shape: torch.Size([624, 1024])\n",
      "Feature in test_audio at index 3621 has shape: torch.Size([393, 1024])\n",
      "Feature in test_audio at index 3622 has shape: torch.Size([510, 1024])\n",
      "Feature in test_audio at index 3623 has shape: torch.Size([413, 1024])\n",
      "Feature in test_audio at index 3624 has shape: torch.Size([464, 1024])\n",
      "Feature in test_audio at index 3625 has shape: torch.Size([754, 1024])\n",
      "Feature in test_audio at index 3626 has shape: torch.Size([156, 1024])\n",
      "Feature in test_audio at index 3627 has shape: torch.Size([253, 1024])\n",
      "Feature in test_audio at index 3628 has shape: torch.Size([743, 1024])\n",
      "Feature in test_audio at index 3629 has shape: torch.Size([313, 1024])\n",
      "Feature in test_audio at index 3630 has shape: torch.Size([389, 1024])\n",
      "Feature in test_audio at index 3631 has shape: torch.Size([460, 1024])\n",
      "Feature in test_audio at index 3632 has shape: torch.Size([651, 1024])\n",
      "Feature in test_audio at index 3633 has shape: torch.Size([618, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 将所有特征数据放入一个字典中\n",
    "text_features = {\n",
    "    'test_audio': test_X_audio\n",
    "}\n",
    "\n",
    "# 遍历字典，转换为tensor并去掉维度，然后打印形状\n",
    "for key, features in text_features.items():\n",
    "    for i, feature in enumerate(features):\n",
    "        tensor_feature = torch.tensor(feature)  # 将特征转换为tensor\n",
    "        tensor_feature = tensor_feature.squeeze(0)  # 去掉大小为1的维度（假设是第一个维度）\n",
    "        text_features[key][i] = tensor_feature  # 更新字典中的值\n",
    "        print(f\"Feature in {key} at index {i} has shape: {tensor_feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature in test_text at index 0 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 4 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 5 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 6 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 7 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 8 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 9 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 10 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 11 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 12 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 13 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 14 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 15 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 16 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 17 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 18 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 19 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 20 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 21 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 22 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 23 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 24 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 25 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 26 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 27 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 28 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 29 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 30 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 31 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 32 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 33 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 34 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 35 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 36 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 37 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 38 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 39 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 40 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 41 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 42 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 43 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 44 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 45 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 46 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 47 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 48 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 49 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 50 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 51 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 52 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 53 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 54 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 55 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 56 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 57 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 58 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 59 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 60 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 61 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 62 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 63 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 64 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 65 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 66 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 67 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 68 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 69 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 70 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 71 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 72 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 73 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 74 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 75 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 76 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 77 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 78 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 79 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 80 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 81 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 82 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 83 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 84 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 85 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 86 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 87 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 88 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 89 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 90 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 91 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 92 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 93 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 94 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 95 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 96 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 97 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 98 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 99 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 100 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 101 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 102 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 103 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 104 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 105 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 106 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 107 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 108 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 109 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 110 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 111 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 112 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 113 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 114 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 115 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 116 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 117 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 118 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 119 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 120 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 121 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 122 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 123 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 124 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 125 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 126 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 127 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 128 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 129 has shape: torch.Size([69, 768])\n",
      "Feature in test_text at index 130 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 131 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 132 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 133 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 134 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 135 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 136 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 137 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 138 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 139 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 140 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 141 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 142 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 143 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 144 has shape: torch.Size([74, 768])\n",
      "Feature in test_text at index 145 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 146 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 147 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 148 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 149 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 150 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 151 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 152 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 153 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 154 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 155 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 156 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 157 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 158 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 159 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 160 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 161 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 162 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 163 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 164 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 165 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 166 has shape: torch.Size([124, 768])\n",
      "Feature in test_text at index 167 has shape: torch.Size([3, 768])\n",
      "Feature in test_text at index 168 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 169 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 170 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 171 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 172 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 173 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 174 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 175 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 176 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 177 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 178 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 179 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 180 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 181 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 182 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 183 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 184 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 185 has shape: torch.Size([72, 768])\n",
      "Feature in test_text at index 186 has shape: torch.Size([4, 768])\n",
      "Feature in test_text at index 187 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 188 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 189 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 190 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 191 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 192 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 193 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 194 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 195 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 196 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 197 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 198 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 199 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 200 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 201 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 202 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 203 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 204 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 205 has shape: torch.Size([71, 768])\n",
      "Feature in test_text at index 206 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 207 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 208 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 209 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 210 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 211 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 212 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 213 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 214 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 215 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 216 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 217 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 218 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 219 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 220 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 221 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 222 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 223 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 224 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 225 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 226 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 227 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 228 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 229 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 230 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 231 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 232 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 233 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 234 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 235 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 236 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 237 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 238 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 239 has shape: torch.Size([83, 768])\n",
      "Feature in test_text at index 240 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 241 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 242 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 243 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 244 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 245 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 246 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 247 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 248 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 249 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 250 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 251 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 252 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 253 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 254 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 255 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 256 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 257 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 258 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 259 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 260 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 261 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 262 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 263 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 264 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 265 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 266 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 267 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 268 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 269 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 270 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 271 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 272 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 273 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 274 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 275 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 276 has shape: torch.Size([73, 768])\n",
      "Feature in test_text at index 277 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 278 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 279 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 280 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 281 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 282 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 283 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 284 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 285 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 286 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 287 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 288 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 289 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 290 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 291 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 292 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 293 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 294 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 295 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 296 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 297 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 298 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 299 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 300 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 301 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 302 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 303 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 304 has shape: torch.Size([128, 768])\n",
      "Feature in test_text at index 305 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 306 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 307 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 308 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 309 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 310 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 311 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 312 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 313 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 314 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 315 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 316 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 317 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 318 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 319 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 320 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 321 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 322 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 323 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 324 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 325 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 326 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 327 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 328 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 329 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 330 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 331 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 332 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 333 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 334 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 335 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 336 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 337 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 338 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 339 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 340 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 341 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 342 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 343 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 344 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 345 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 346 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 347 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 348 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 349 has shape: torch.Size([76, 768])\n",
      "Feature in test_text at index 350 has shape: torch.Size([94, 768])\n",
      "Feature in test_text at index 351 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 352 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 353 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 354 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 355 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 356 has shape: torch.Size([81, 768])\n",
      "Feature in test_text at index 357 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 358 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 359 has shape: torch.Size([68, 768])\n",
      "Feature in test_text at index 360 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 361 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 362 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 363 has shape: torch.Size([111, 768])\n",
      "Feature in test_text at index 364 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 365 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 366 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 367 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 368 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 369 has shape: torch.Size([88, 768])\n",
      "Feature in test_text at index 370 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 371 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 372 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 373 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 374 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 375 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 376 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 377 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 378 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 379 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 380 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 381 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 382 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 383 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 384 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 385 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 386 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 387 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 388 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 389 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 390 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 391 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 392 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 393 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 394 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 395 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 396 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 397 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 398 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 399 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 400 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 401 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 402 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 403 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 404 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 405 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 406 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 407 has shape: torch.Size([99, 768])\n",
      "Feature in test_text at index 408 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 409 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 410 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 411 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 412 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 413 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 414 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 415 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 416 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 417 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 418 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 419 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 420 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 421 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 422 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 423 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 424 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 425 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 426 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 427 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 428 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 429 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 430 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 431 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 432 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 433 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 434 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 435 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 436 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 437 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 438 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 439 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 440 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 441 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 442 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 443 has shape: torch.Size([3, 768])\n",
      "Feature in test_text at index 444 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 445 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 446 has shape: torch.Size([84, 768])\n",
      "Feature in test_text at index 447 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 448 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 449 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 450 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 451 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 452 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 453 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 454 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 455 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 456 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 457 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 458 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 459 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 460 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 461 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 462 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 463 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 464 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 465 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 466 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 467 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 468 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 469 has shape: torch.Size([68, 768])\n",
      "Feature in test_text at index 470 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 471 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 472 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 473 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 474 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 475 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 476 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 477 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 478 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 479 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 480 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 481 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 482 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 483 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 484 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 485 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 486 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 487 has shape: torch.Size([93, 768])\n",
      "Feature in test_text at index 488 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 489 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 490 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 491 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 492 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 493 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 494 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 495 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 496 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 497 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 498 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 499 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 500 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 501 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 502 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 503 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 504 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 505 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 506 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 507 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 508 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 509 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 510 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 511 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 512 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 513 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 514 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 515 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 516 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 517 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 518 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 519 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 520 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 521 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 522 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 523 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 524 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 525 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 526 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 527 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 528 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 529 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 530 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 531 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 532 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 533 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 534 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 535 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 536 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 537 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 538 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 539 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 540 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 541 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 542 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 543 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 544 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 545 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 546 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 547 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 548 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 549 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 550 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 551 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 552 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 553 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 554 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 555 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 556 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 557 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 558 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 559 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 560 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 561 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 562 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 563 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 564 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 565 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 566 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 567 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 568 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 569 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 570 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 571 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 572 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 573 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 574 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 575 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 576 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 577 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 578 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 579 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 580 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 581 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 582 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 583 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 584 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 585 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 586 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 587 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 588 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 589 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 590 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 591 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 592 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 593 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 594 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 595 has shape: torch.Size([77, 768])\n",
      "Feature in test_text at index 596 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 597 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 598 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 599 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 600 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 601 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 602 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 603 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 604 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 605 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 606 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 607 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 608 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 609 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 610 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 611 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 612 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 613 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 614 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 615 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 616 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 617 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 618 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 619 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 620 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 621 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 622 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 623 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 624 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 625 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 626 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 627 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 628 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 629 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 630 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 631 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 632 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 633 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 634 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 635 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 636 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 637 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 638 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 639 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 640 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 641 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 642 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 643 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 644 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 645 has shape: torch.Size([3, 768])\n",
      "Feature in test_text at index 646 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 647 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 648 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 649 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 650 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 651 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 652 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 653 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 654 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 655 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 656 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 657 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 658 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 659 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 660 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 661 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 662 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 663 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 664 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 665 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 666 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 667 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 668 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 669 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 670 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 671 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 672 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 673 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 674 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 675 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 676 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 677 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 678 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 679 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 680 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 681 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 682 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 683 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 684 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 685 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 686 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 687 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 688 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 689 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 690 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 691 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 692 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 693 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 694 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 695 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 696 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 697 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 698 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 699 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 700 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 701 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 702 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 703 has shape: torch.Size([4, 768])\n",
      "Feature in test_text at index 704 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 705 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 706 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 707 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 708 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 709 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 710 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 711 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 712 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 713 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 714 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 715 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 716 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 717 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 718 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 719 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 720 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 721 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 722 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 723 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 724 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 725 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 726 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 727 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 728 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 729 has shape: torch.Size([86, 768])\n",
      "Feature in test_text at index 730 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 731 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 732 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 733 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 734 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 735 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 736 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 737 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 738 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 739 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 740 has shape: torch.Size([293, 768])\n",
      "Feature in test_text at index 741 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 742 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 743 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 744 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 745 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 746 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 747 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 748 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 749 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 750 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 751 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 752 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 753 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 754 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 755 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 756 has shape: torch.Size([72, 768])\n",
      "Feature in test_text at index 757 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 758 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 759 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 760 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 761 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 762 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 763 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 764 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 765 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 766 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 767 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 768 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 769 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 770 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 771 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 772 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 773 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 774 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 775 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 776 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 777 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 778 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 779 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 780 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 781 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 782 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 783 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 784 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 785 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 786 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 787 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 788 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 789 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 790 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 791 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 792 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 793 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 794 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 795 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 796 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 797 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 798 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 799 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 800 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 801 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 802 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 803 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 804 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 805 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 806 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 807 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 808 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 809 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 810 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 811 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 812 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 813 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 814 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 815 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 816 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 817 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 818 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 819 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 820 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 821 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 822 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 823 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 824 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 825 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 826 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 827 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 828 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 829 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 830 has shape: torch.Size([67, 768])\n",
      "Feature in test_text at index 831 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 832 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 833 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 834 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 835 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 836 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 837 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 838 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 839 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 840 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 841 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 842 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 843 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 844 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 845 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 846 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 847 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 848 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 849 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 850 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 851 has shape: torch.Size([70, 768])\n",
      "Feature in test_text at index 852 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 853 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 854 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 855 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 856 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 857 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 858 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 859 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 860 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 861 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 862 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 863 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 864 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 865 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 866 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 867 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 868 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 869 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 870 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 871 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 872 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 873 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 874 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 875 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 876 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 877 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 878 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 879 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 880 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 881 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 882 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 883 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 884 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 885 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 886 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 887 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 888 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 889 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 890 has shape: torch.Size([74, 768])\n",
      "Feature in test_text at index 891 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 892 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 893 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 894 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 895 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 896 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 897 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 898 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 899 has shape: torch.Size([75, 768])\n",
      "Feature in test_text at index 900 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 901 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 902 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 903 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 904 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 905 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 906 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 907 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 908 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 909 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 910 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 911 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 912 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 913 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 914 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 915 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 916 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 917 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 918 has shape: torch.Size([3, 768])\n",
      "Feature in test_text at index 919 has shape: torch.Size([106, 768])\n",
      "Feature in test_text at index 920 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 921 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 922 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 923 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 924 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 925 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 926 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 927 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 928 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 929 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 930 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 931 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 932 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 933 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 934 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 935 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 936 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 937 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 938 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 939 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 940 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 941 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 942 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 943 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 944 has shape: torch.Size([87, 768])\n",
      "Feature in test_text at index 945 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 946 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 947 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 948 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 949 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 950 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 951 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 952 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 953 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 954 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 955 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 956 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 957 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 958 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 959 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 960 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 961 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 962 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 963 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 964 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 965 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 966 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 967 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 968 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 969 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 970 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 971 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 972 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 973 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 974 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 975 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 976 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 977 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 978 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 979 has shape: torch.Size([121, 768])\n",
      "Feature in test_text at index 980 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 981 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 982 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 983 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 984 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 985 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 986 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 987 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 988 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 989 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 990 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 991 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 992 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 993 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 994 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 995 has shape: torch.Size([65, 768])\n",
      "Feature in test_text at index 996 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 997 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 998 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 999 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1000 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1001 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1002 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1003 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1004 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 1005 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1006 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1007 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1008 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 1009 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1010 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1011 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1012 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1013 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1014 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1015 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1016 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1017 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1018 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1019 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1020 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1021 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1022 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1023 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1024 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1025 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1026 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1027 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1028 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 1029 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1030 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1031 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1032 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1033 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1034 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1035 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1036 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1037 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1038 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1039 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 1040 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1041 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1042 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1043 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1044 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1045 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1046 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1047 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1048 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1049 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1050 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1051 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1052 has shape: torch.Size([3, 768])\n",
      "Feature in test_text at index 1053 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1054 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1055 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1056 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1057 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 1058 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1059 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1060 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1061 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1062 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1063 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1064 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1065 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1066 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1067 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1068 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1069 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1070 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1071 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1072 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1073 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1074 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1075 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1076 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1077 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1078 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1079 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1080 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1081 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1082 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1083 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1084 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1085 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1086 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1087 has shape: torch.Size([73, 768])\n",
      "Feature in test_text at index 1088 has shape: torch.Size([89, 768])\n",
      "Feature in test_text at index 1089 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1090 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 1091 has shape: torch.Size([79, 768])\n",
      "Feature in test_text at index 1092 has shape: torch.Size([91, 768])\n",
      "Feature in test_text at index 1093 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 1094 has shape: torch.Size([75, 768])\n",
      "Feature in test_text at index 1095 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1096 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1097 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1098 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1099 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1100 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1101 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1102 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1103 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 1104 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1105 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1106 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1107 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1108 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1109 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1110 has shape: torch.Size([116, 768])\n",
      "Feature in test_text at index 1111 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1112 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1113 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1114 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1115 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1116 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1117 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1118 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1119 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1120 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1121 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1122 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1123 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1124 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 1125 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1126 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1127 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1128 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1129 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1130 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1131 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1132 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1133 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1134 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1135 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1136 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1137 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1138 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1139 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1140 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1141 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1142 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1143 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1144 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1145 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1146 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1147 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1148 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1149 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1150 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1151 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1152 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1153 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1154 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 1155 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1156 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1157 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1158 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1159 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1160 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1161 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1162 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1163 has shape: torch.Size([3, 768])\n",
      "Feature in test_text at index 1164 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1165 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1166 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1167 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1168 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1169 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1170 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1171 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1172 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1173 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1174 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1175 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1176 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1177 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1178 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1179 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1180 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1181 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1182 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1183 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1184 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1185 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1186 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1187 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1188 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1189 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1190 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1191 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1192 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1193 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1194 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1195 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1196 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1197 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1198 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1199 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1200 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1201 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1202 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1203 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1204 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1205 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 1206 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1207 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1208 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1209 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 1210 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1211 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1212 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1213 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1214 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1215 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1216 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1217 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1218 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1219 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1220 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1221 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1222 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1223 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1224 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1225 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1226 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1227 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1228 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1229 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1230 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1231 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1232 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1233 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1234 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1235 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1236 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1237 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1238 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 1239 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1240 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1241 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1242 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1243 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1244 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 1245 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1246 has shape: torch.Size([69, 768])\n",
      "Feature in test_text at index 1247 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1248 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1249 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1250 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1251 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1252 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1253 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1254 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1255 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1256 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1257 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1258 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1259 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1260 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1261 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1262 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 1263 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1264 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1265 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1266 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1267 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1268 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1269 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1270 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1271 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1272 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1273 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1274 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1275 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1276 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1277 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1278 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1279 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 1280 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1281 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1282 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1283 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1284 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1285 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 1286 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1287 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1288 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1289 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1290 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1291 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1292 has shape: torch.Size([75, 768])\n",
      "Feature in test_text at index 1293 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1294 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1295 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1296 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1297 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1298 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1299 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1300 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1301 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1302 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1303 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1304 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1305 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1306 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1307 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1308 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1309 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1310 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1311 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1312 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1313 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1314 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1315 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1316 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1317 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 1318 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1319 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1320 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1321 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1322 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1323 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1324 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1325 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 1326 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1327 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1328 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1329 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 1330 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1331 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1332 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1333 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1334 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1335 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1336 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1337 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1338 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1339 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1340 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1341 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1342 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1343 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1344 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1345 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1346 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1347 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1348 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1349 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1350 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1351 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1352 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1353 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1354 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1355 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1356 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1357 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1358 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1359 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1360 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1361 has shape: torch.Size([5, 768])\n",
      "Feature in test_text at index 1362 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1363 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1364 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1365 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1366 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1367 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1368 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1369 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1370 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1371 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1372 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1373 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1374 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1375 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1376 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1377 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1378 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1379 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1380 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1381 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1382 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1383 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1384 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1385 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1386 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1387 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1388 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1389 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1390 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1391 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1392 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1393 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1394 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1395 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1396 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1397 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1398 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1399 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1400 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1401 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1402 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1403 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1404 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1405 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1406 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1407 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1408 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1409 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1410 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1411 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1412 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1413 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1414 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 1415 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1416 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 1417 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 1418 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1419 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 1420 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1421 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1422 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1423 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1424 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1425 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1426 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1427 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1428 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1429 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1430 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1431 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1432 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1433 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1434 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1435 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1436 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1437 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1438 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1439 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 1440 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1441 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1442 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1443 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1444 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1445 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1446 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1447 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1448 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1449 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1450 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1451 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1452 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1453 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1454 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1455 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1456 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1457 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1458 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1459 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1460 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1461 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 1462 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1463 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1464 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1465 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1466 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1467 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1468 has shape: torch.Size([83, 768])\n",
      "Feature in test_text at index 1469 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1470 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 1471 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 1472 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 1473 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 1474 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1475 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1476 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1477 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1478 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1479 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1480 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1481 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1482 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1483 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1484 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1485 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1486 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1487 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1488 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1489 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1490 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1491 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1492 has shape: torch.Size([70, 768])\n",
      "Feature in test_text at index 1493 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1494 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1495 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1496 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1497 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1498 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1499 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1500 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1501 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1502 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1503 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1504 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1505 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1506 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1507 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1508 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1509 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1510 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1511 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1512 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1513 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1514 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1515 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1516 has shape: torch.Size([73, 768])\n",
      "Feature in test_text at index 1517 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1518 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1519 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1520 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1521 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1522 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1523 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1524 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1525 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1526 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1527 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1528 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1529 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1530 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1531 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1532 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1533 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1534 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1535 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 1536 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1537 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1538 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1539 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1540 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1541 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1542 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1543 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1544 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1545 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1546 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1547 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1548 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1549 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1550 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1551 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1552 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1553 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1554 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1555 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1556 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1557 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1558 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1559 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1560 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1561 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1562 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1563 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1564 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1565 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1566 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1567 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1568 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1569 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1570 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1571 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1572 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1573 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1574 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1575 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1576 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1577 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 1578 has shape: torch.Size([70, 768])\n",
      "Feature in test_text at index 1579 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 1580 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1581 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1582 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1583 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1584 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1585 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1586 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1587 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1588 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1589 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1590 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1591 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1592 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1593 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1594 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1595 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1596 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1597 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1598 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1599 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1600 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1601 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1602 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1603 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1604 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1605 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1606 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1607 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1608 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1609 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1610 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1611 has shape: torch.Size([85, 768])\n",
      "Feature in test_text at index 1612 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1613 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1614 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1615 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1616 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1617 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 1618 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1619 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1620 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1621 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1622 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1623 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1624 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1625 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 1626 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 1627 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1628 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1629 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1630 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1631 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 1632 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1633 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1634 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1635 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1636 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1637 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1638 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1639 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1640 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 1641 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1642 has shape: torch.Size([70, 768])\n",
      "Feature in test_text at index 1643 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1644 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1645 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1646 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 1647 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1648 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1649 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1650 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 1651 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1652 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1653 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1654 has shape: torch.Size([80, 768])\n",
      "Feature in test_text at index 1655 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 1656 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1657 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1658 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1659 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1660 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1661 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1662 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1663 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 1664 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1665 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1666 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1667 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1668 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1669 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1670 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1671 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 1672 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1673 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1674 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1675 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1676 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1677 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1678 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1679 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1680 has shape: torch.Size([65, 768])\n",
      "Feature in test_text at index 1681 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1682 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1683 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 1684 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1685 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 1686 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1687 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1688 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1689 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 1690 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1691 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1692 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1693 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 1694 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1695 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1696 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1697 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1698 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1699 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1700 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1701 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1702 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1703 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1704 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1705 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1706 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 1707 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1708 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1709 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1710 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1711 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1712 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1713 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1714 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 1715 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1716 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1717 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1718 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1719 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1720 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1721 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1722 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1723 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1724 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1725 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1726 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1727 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1728 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1729 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1730 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1731 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1732 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1733 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1734 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1735 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1736 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1737 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1738 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1739 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1740 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1741 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1742 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1743 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1744 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1745 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1746 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1747 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1748 has shape: torch.Size([67, 768])\n",
      "Feature in test_text at index 1749 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 1750 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1751 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1752 has shape: torch.Size([76, 768])\n",
      "Feature in test_text at index 1753 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1754 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1755 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1756 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1757 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1758 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1759 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1760 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1761 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1762 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1763 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1764 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1765 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1766 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1767 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1768 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1769 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1770 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1771 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1772 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1773 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1774 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1775 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 1776 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1777 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1778 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1779 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1780 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1781 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1782 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1783 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1784 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1785 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1786 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1787 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 1788 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1789 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1790 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 1791 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1792 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1793 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1794 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1795 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1796 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1797 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1798 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1799 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1800 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1801 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1802 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1803 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1804 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 1805 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1806 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1807 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1808 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1809 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1810 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1811 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1812 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1813 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1814 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 1815 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1816 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1817 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 1818 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1819 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1820 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1821 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1822 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1823 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1824 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1825 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1826 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 1827 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1828 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1829 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1830 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1831 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1832 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1833 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1834 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 1835 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1836 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1837 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1838 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1839 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1840 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1841 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 1842 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1843 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 1844 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1845 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1846 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1847 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1848 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1849 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1850 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1851 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1852 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1853 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1854 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 1855 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 1856 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1857 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1858 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1859 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1860 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1861 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 1862 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1863 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1864 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1865 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1866 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1867 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1868 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1869 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1870 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 1871 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1872 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 1873 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1874 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1875 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1876 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1877 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1878 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1879 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1880 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1881 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1882 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1883 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1884 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1885 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1886 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1887 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1888 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1889 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1890 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1891 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1892 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1893 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1894 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1895 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1896 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1897 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1898 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 1899 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1900 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1901 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1902 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 1903 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1904 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1905 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1906 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1907 has shape: torch.Size([78, 768])\n",
      "Feature in test_text at index 1908 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1909 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1910 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1911 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1912 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 1913 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1914 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1915 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1916 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1917 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1918 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1919 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1920 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1921 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 1922 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1923 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1924 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1925 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1926 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 1927 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1928 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1929 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 1930 has shape: torch.Size([114, 768])\n",
      "Feature in test_text at index 1931 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 1932 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1933 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1934 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 1935 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1936 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 1937 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1938 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 1939 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 1940 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1941 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1942 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1943 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1944 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 1945 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1946 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1947 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 1948 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1949 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 1950 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1951 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1952 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1953 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 1954 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1955 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 1956 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1957 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1958 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1959 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 1960 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1961 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1962 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1963 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 1964 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1965 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1966 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1967 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 1968 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1969 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 1970 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 1971 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 1972 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1973 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 1974 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1975 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1976 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1977 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 1978 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 1979 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 1980 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 1981 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 1982 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 1983 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1984 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 1985 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 1986 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 1987 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 1988 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 1989 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 1990 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 1991 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 1992 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1993 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 1994 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 1995 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 1996 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 1997 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 1998 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 1999 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2000 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2001 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2002 has shape: torch.Size([65, 768])\n",
      "Feature in test_text at index 2003 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 2004 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2005 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2006 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2007 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2008 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 2009 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2010 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2011 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2012 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2013 has shape: torch.Size([91, 768])\n",
      "Feature in test_text at index 2014 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2015 has shape: torch.Size([88, 768])\n",
      "Feature in test_text at index 2016 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2017 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 2018 has shape: torch.Size([69, 768])\n",
      "Feature in test_text at index 2019 has shape: torch.Size([68, 768])\n",
      "Feature in test_text at index 2020 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2021 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 2022 has shape: torch.Size([94, 768])\n",
      "Feature in test_text at index 2023 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2024 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2025 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2026 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2027 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2028 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2029 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2030 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2031 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2032 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 2033 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 2034 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2035 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2036 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2037 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2038 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2039 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2040 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2041 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2042 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2043 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 2044 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2045 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2046 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2047 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2048 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2049 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2050 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2051 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2052 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2053 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2054 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2055 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2056 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2057 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2058 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 2059 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2060 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 2061 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2062 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2063 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2064 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2065 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2066 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2067 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2068 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2069 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2070 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2071 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2072 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2073 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2074 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2075 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2076 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2077 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2078 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2079 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2080 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2081 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 2082 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2083 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2084 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2085 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2086 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2087 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2088 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2089 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2090 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2091 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2092 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2093 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2094 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2095 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2096 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2097 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2098 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2099 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2100 has shape: torch.Size([70, 768])\n",
      "Feature in test_text at index 2101 has shape: torch.Size([169, 768])\n",
      "Feature in test_text at index 2102 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 2103 has shape: torch.Size([71, 768])\n",
      "Feature in test_text at index 2104 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2105 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2106 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2107 has shape: torch.Size([125, 768])\n",
      "Feature in test_text at index 2108 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2109 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2110 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2111 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2112 has shape: torch.Size([76, 768])\n",
      "Feature in test_text at index 2113 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2114 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2115 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2116 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2117 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2118 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2119 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2120 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2121 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 2122 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2123 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2124 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2125 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2126 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2127 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2128 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2129 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2130 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 2131 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2132 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2133 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2134 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2135 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2136 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 2137 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 2138 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 2139 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2140 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2141 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2142 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2143 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2144 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2145 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2146 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2147 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2148 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2149 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2150 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2151 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2152 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2153 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2154 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2155 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2156 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2157 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2158 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2159 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2160 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2161 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2162 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2163 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2164 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2165 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2166 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2167 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2168 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 2169 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2170 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2171 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2172 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2173 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2174 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2175 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2176 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2177 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2178 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2179 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2180 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2181 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2182 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2183 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2184 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 2185 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2186 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2187 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2188 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2189 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2190 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2191 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2192 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2193 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2194 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2195 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2196 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2197 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2198 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2199 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2200 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2201 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2202 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2203 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2204 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2205 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2206 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2207 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2208 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2209 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2210 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2211 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2212 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2213 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 2214 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2215 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2216 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2217 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 2218 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2219 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2220 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2221 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2222 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2223 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2224 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2225 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2226 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2227 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2228 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2229 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2230 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2231 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2232 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2233 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2234 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2235 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2236 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2237 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2238 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2239 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2240 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2241 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 2242 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2243 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2244 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2245 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2246 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2247 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2248 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2249 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2250 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2251 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2252 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2253 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2254 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2255 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2256 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2257 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2258 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2259 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2260 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2261 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2262 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 2263 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2264 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2265 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2266 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2267 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2268 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2269 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2270 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2271 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2272 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2273 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2274 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 2275 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2276 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2277 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2278 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2279 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2280 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2281 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2282 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2283 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2284 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2285 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2286 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2287 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2288 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2289 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2290 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2291 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2292 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2293 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2294 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2295 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2296 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2297 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2298 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2299 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2300 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2301 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2302 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2303 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2304 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 2305 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 2306 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2307 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2308 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2309 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2310 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2311 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2312 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2313 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2314 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2315 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2316 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2317 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2318 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2319 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2320 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2321 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2322 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2323 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2324 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 2325 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2326 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2327 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2328 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2329 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2330 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2331 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2332 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2333 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2334 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2335 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2336 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2337 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2338 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2339 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2340 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2341 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2342 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2343 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2344 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2345 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2346 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2347 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2348 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2349 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2350 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2351 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2352 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2353 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 2354 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2355 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2356 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2357 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2358 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 2359 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2360 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2361 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2362 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2363 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2364 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 2365 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2366 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2367 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2368 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2369 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2370 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2371 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2372 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2373 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2374 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2375 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2376 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2377 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2378 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2379 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2380 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2381 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2382 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 2383 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2384 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2385 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2386 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2387 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2388 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2389 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2390 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2391 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2392 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2393 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2394 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2395 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2396 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2397 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2398 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2399 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2400 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 2401 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 2402 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 2403 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2404 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2405 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2406 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2407 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2408 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2409 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2410 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2411 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 2412 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2413 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2414 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2415 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2416 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2417 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2418 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2419 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2420 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2421 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2422 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2423 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2424 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2425 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2426 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2427 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2428 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2429 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2430 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2431 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2432 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2433 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2434 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2435 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2436 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2437 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2438 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2439 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2440 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2441 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2442 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2443 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2444 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2445 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2446 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2447 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2448 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2449 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2450 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2451 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2452 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2453 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2454 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2455 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2456 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2457 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2458 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2459 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2460 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2461 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2462 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2463 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2464 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 2465 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2466 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2467 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2468 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2469 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2470 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2471 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2472 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2473 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 2474 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2475 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2476 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 2477 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2478 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2479 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2480 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2481 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2482 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2483 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2484 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2485 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2486 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2487 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2488 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2489 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2490 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2491 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 2492 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2493 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2494 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2495 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2496 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 2497 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 2498 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2499 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2500 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2501 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2502 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2503 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2504 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2505 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2506 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2507 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2508 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2509 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2510 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2511 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2512 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2513 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2514 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2515 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2516 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2517 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2518 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2519 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2520 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2521 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2522 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2523 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2524 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2525 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2526 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2527 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2528 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2529 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 2530 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2531 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2532 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2533 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2534 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2535 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2536 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2537 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2538 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2539 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2540 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 2541 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2542 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 2543 has shape: torch.Size([6, 768])\n",
      "Feature in test_text at index 2544 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2545 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 2546 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2547 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2548 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2549 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 2550 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 2551 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2552 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2553 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2554 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2555 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2556 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2557 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2558 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2559 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2560 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2561 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2562 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2563 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2564 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2565 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2566 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2567 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2568 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2569 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2570 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2571 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2572 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2573 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2574 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2575 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2576 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2577 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2578 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2579 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2580 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2581 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2582 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2583 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2584 has shape: torch.Size([108, 768])\n",
      "Feature in test_text at index 2585 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2586 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2587 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2588 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2589 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2590 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2591 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2592 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2593 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2594 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2595 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2596 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2597 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2598 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2599 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2600 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 2601 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2602 has shape: torch.Size([128, 768])\n",
      "Feature in test_text at index 2603 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2604 has shape: torch.Size([165, 768])\n",
      "Feature in test_text at index 2605 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2606 has shape: torch.Size([79, 768])\n",
      "Feature in test_text at index 2607 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2608 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2609 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2610 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 2611 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2612 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2613 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2614 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 2615 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2616 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2617 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2618 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2619 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2620 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2621 has shape: torch.Size([90, 768])\n",
      "Feature in test_text at index 2622 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2623 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2624 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2625 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2626 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2627 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2628 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 2629 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2630 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2631 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2632 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 2633 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2634 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2635 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2636 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2637 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2638 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2639 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2640 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2641 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2642 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2643 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2644 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2645 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2646 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2647 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2648 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2649 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2650 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2651 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2652 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2653 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2654 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2655 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2656 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2657 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2658 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2659 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2660 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2661 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2662 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2663 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2664 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2665 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2666 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2667 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2668 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2669 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2670 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2671 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2672 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2673 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2674 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2675 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2676 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 2677 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2678 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2679 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2680 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2681 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2682 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2683 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2684 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2685 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2686 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2687 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2688 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2689 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2690 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2691 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2692 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2693 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2694 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2695 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2696 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2697 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2698 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2699 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2700 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2701 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2702 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2703 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2704 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2705 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2706 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2707 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2708 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2709 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2710 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2711 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2712 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 2713 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2714 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2715 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2716 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 2717 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 2718 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2719 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2720 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2721 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2722 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2723 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2724 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2725 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2726 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2727 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2728 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2729 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2730 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2731 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2732 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2733 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2734 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2735 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 2736 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2737 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2738 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2739 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2740 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2741 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2742 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2743 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2744 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2745 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2746 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2747 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2748 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2749 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2750 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2751 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2752 has shape: torch.Size([65, 768])\n",
      "Feature in test_text at index 2753 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2754 has shape: torch.Size([96, 768])\n",
      "Feature in test_text at index 2755 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2756 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 2757 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2758 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2759 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2760 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2761 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2762 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2763 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2764 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2765 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2766 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2767 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2768 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2769 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2770 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2771 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2772 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2773 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 2774 has shape: torch.Size([76, 768])\n",
      "Feature in test_text at index 2775 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2776 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2777 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2778 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2779 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2780 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2781 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2782 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2783 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 2784 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2785 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2786 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2787 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2788 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2789 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 2790 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2791 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2792 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2793 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2794 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2795 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2796 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2797 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2798 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 2799 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2800 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2801 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2802 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2803 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2804 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2805 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2806 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2807 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2808 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2809 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2810 has shape: torch.Size([87, 768])\n",
      "Feature in test_text at index 2811 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2812 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 2813 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2814 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2815 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2816 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2817 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2818 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2819 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2820 has shape: torch.Size([80, 768])\n",
      "Feature in test_text at index 2821 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2822 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2823 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2824 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2825 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2826 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2827 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2828 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2829 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2830 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2831 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2832 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2833 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2834 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2835 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2836 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2837 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2838 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2839 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2840 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2841 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2842 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2843 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2844 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2845 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2846 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2847 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2848 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2849 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2850 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2851 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2852 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2853 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2854 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2855 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2856 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2857 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2858 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2859 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2860 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2861 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2862 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2863 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2864 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2865 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2866 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2867 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2868 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2869 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2870 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2871 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2872 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2873 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2874 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 2875 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2876 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2877 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2878 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2879 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2880 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2881 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2882 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2883 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2884 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2885 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2886 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2887 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2888 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2889 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 2890 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2891 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 2892 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2893 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2894 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2895 has shape: torch.Size([85, 768])\n",
      "Feature in test_text at index 2896 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2897 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2898 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2899 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2900 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 2901 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2902 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2903 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2904 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2905 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 2906 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2907 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2908 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2909 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2910 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2911 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2912 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2913 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2914 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2915 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2916 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2917 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2918 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2919 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2920 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2921 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2922 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 2923 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2924 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2925 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 2926 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2927 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2928 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 2929 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 2930 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 2931 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2932 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2933 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2934 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2935 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 2936 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2937 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2938 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2939 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2940 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2941 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2942 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2943 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2944 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 2945 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2946 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2947 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2948 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2949 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 2950 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2951 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 2952 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2953 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2954 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2955 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 2956 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 2957 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2958 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2959 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2960 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2961 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2962 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2963 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 2964 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2965 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2966 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2967 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 2968 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 2969 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2970 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 2971 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2972 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 2973 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2974 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 2975 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 2976 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 2977 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 2978 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 2979 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 2980 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 2981 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2982 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 2983 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 2984 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 2985 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 2986 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 2987 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 2988 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 2989 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2990 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2991 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 2992 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 2993 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2994 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 2995 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 2996 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2997 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2998 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 2999 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3000 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3001 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3002 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3003 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3004 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3005 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3006 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3007 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 3008 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3009 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3010 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3011 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3012 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3013 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3014 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3015 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 3016 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3017 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3018 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3019 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3020 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3021 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 3022 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 3023 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3024 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3025 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3026 has shape: torch.Size([69, 768])\n",
      "Feature in test_text at index 3027 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 3028 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3029 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3030 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3031 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3032 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3033 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3034 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3035 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3036 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3037 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3038 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 3039 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3040 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 3041 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3042 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3043 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3044 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3045 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3046 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3047 has shape: torch.Size([65, 768])\n",
      "Feature in test_text at index 3048 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3049 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3050 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3051 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3052 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3053 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3054 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3055 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3056 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3057 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3058 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3059 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3060 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3061 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3062 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3063 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3064 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3065 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3066 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 3067 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 3068 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3069 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3070 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 3071 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 3072 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 3073 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3074 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3075 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3076 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3077 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3078 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3079 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3080 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3081 has shape: torch.Size([49, 768])\n",
      "Feature in test_text at index 3082 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3083 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3084 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3085 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3086 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3087 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3088 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 3089 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3090 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3091 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 3092 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 3093 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3094 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3095 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3096 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3097 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3098 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 3099 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3100 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3101 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3102 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3103 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3104 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3105 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3106 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3107 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3108 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3109 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3110 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3111 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3112 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3113 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3114 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3115 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3116 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 3117 has shape: torch.Size([70, 768])\n",
      "Feature in test_text at index 3118 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3119 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3120 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3121 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 3122 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3123 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3124 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3125 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3126 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3127 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3128 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3129 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3130 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3131 has shape: torch.Size([50, 768])\n",
      "Feature in test_text at index 3132 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3133 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3134 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3135 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3136 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3137 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3138 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3139 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3140 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3141 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3142 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3143 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3144 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3145 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3146 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3147 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3148 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3149 has shape: torch.Size([62, 768])\n",
      "Feature in test_text at index 3150 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 3151 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3152 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3153 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 3154 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3155 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 3156 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3157 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3158 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3159 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3160 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3161 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3162 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3163 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3164 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3165 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3166 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3167 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3168 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3169 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3170 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3171 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3172 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3173 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3174 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3175 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3176 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3177 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3178 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3179 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3180 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3181 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3182 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3183 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3184 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3185 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3186 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3187 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3188 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3189 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3190 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3191 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3192 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3193 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3194 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3195 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3196 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3197 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3198 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3199 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3200 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3201 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3202 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3203 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3204 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3205 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3206 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3207 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3208 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3209 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3210 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3211 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 3212 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3213 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3214 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3215 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3216 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3217 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3218 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3219 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3220 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3221 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3222 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3223 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3224 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3225 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3226 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3227 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3228 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3229 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3230 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3231 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3232 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3233 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3234 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3235 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3236 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3237 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3238 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3239 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3240 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3241 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3242 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3243 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3244 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3245 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3246 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3247 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3248 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 3249 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3250 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3251 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3252 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3253 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3254 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3255 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3256 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3257 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3258 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3259 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3260 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3261 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3262 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 3263 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3264 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3265 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3266 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3267 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3268 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3269 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3270 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 3271 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3272 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3273 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3274 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3275 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3276 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3277 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3278 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3279 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 3280 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3281 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3282 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3283 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3284 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3285 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3286 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3287 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3288 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3289 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3290 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3291 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3292 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3293 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3294 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3295 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3296 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3297 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3298 has shape: torch.Size([57, 768])\n",
      "Feature in test_text at index 3299 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3300 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 3301 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3302 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3303 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3304 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3305 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3306 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 3307 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3308 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3309 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 3310 has shape: torch.Size([58, 768])\n",
      "Feature in test_text at index 3311 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3312 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3313 has shape: torch.Size([321, 768])\n",
      "Feature in test_text at index 3314 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3315 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3316 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3317 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3318 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3319 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3320 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3321 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3322 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3323 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3324 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3325 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3326 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3327 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3328 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 3329 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3330 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 3331 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3332 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3333 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3334 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3335 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3336 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3337 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3338 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3339 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3340 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3341 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3342 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3343 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 3344 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3345 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3346 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3347 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3348 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3349 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3350 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3351 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3352 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3353 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3354 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3355 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3356 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3357 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 3358 has shape: torch.Size([36, 768])\n",
      "Feature in test_text at index 3359 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3360 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3361 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3362 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3363 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3364 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3365 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3366 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3367 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3368 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3369 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3370 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3371 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3372 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3373 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3374 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3375 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3376 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3377 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3378 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3379 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3380 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3381 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3382 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3383 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3384 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3385 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3386 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3387 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3388 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 3389 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3390 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3391 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3392 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3393 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3394 has shape: torch.Size([46, 768])\n",
      "Feature in test_text at index 3395 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3396 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3397 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3398 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3399 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3400 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 3401 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 3402 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3403 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3404 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3405 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3406 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3407 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3408 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3409 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3410 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3411 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3412 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3413 has shape: torch.Size([65, 768])\n",
      "Feature in test_text at index 3414 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3415 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3416 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3417 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3418 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 3419 has shape: torch.Size([66, 768])\n",
      "Feature in test_text at index 3420 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3421 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3422 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3423 has shape: torch.Size([59, 768])\n",
      "Feature in test_text at index 3424 has shape: torch.Size([54, 768])\n",
      "Feature in test_text at index 3425 has shape: torch.Size([47, 768])\n",
      "Feature in test_text at index 3426 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3427 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3428 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 3429 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 3430 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3431 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3432 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3433 has shape: torch.Size([42, 768])\n",
      "Feature in test_text at index 3434 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3435 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3436 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3437 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3438 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3439 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3440 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3441 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3442 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3443 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3444 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3445 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3446 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3447 has shape: torch.Size([64, 768])\n",
      "Feature in test_text at index 3448 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3449 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3450 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3451 has shape: torch.Size([44, 768])\n",
      "Feature in test_text at index 3452 has shape: torch.Size([52, 768])\n",
      "Feature in test_text at index 3453 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3454 has shape: torch.Size([60, 768])\n",
      "Feature in test_text at index 3455 has shape: torch.Size([68, 768])\n",
      "Feature in test_text at index 3456 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3457 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3458 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3459 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3460 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3461 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3462 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3463 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3464 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3465 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3466 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3467 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 3468 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3469 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3470 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3471 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3472 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3473 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 3474 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3475 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 3476 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3477 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3478 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3479 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3480 has shape: torch.Size([63, 768])\n",
      "Feature in test_text at index 3481 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 3482 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3483 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3484 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3485 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3486 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3487 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3488 has shape: torch.Size([53, 768])\n",
      "Feature in test_text at index 3489 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3490 has shape: torch.Size([48, 768])\n",
      "Feature in test_text at index 3491 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3492 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3493 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3494 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3495 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3496 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3497 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3498 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3499 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3500 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3501 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3502 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3503 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3504 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3505 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3506 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3507 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3508 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3509 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3510 has shape: torch.Size([51, 768])\n",
      "Feature in test_text at index 3511 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3512 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3513 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3514 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3515 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3516 has shape: torch.Size([21, 768])\n",
      "Feature in test_text at index 3517 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3518 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3519 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3520 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3521 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3522 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3523 has shape: torch.Size([40, 768])\n",
      "Feature in test_text at index 3524 has shape: torch.Size([98, 768])\n",
      "Feature in test_text at index 3525 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3526 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3527 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3528 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3529 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3530 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3531 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3532 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3533 has shape: torch.Size([29, 768])\n",
      "Feature in test_text at index 3534 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3535 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3536 has shape: torch.Size([39, 768])\n",
      "Feature in test_text at index 3537 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3538 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3539 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3540 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3541 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3542 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3543 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3544 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3545 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3546 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3547 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3548 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3549 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3550 has shape: torch.Size([56, 768])\n",
      "Feature in test_text at index 3551 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3552 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 3553 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3554 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3555 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3556 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3557 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3558 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3559 has shape: torch.Size([41, 768])\n",
      "Feature in test_text at index 3560 has shape: torch.Size([61, 768])\n",
      "Feature in test_text at index 3561 has shape: torch.Size([45, 768])\n",
      "Feature in test_text at index 3562 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 3563 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3564 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3565 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3566 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3567 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3568 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3569 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3570 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3571 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3572 has shape: torch.Size([43, 768])\n",
      "Feature in test_text at index 3573 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3574 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3575 has shape: torch.Size([86, 768])\n",
      "Feature in test_text at index 3576 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3577 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3578 has shape: torch.Size([18, 768])\n",
      "Feature in test_text at index 3579 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3580 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3581 has shape: torch.Size([30, 768])\n",
      "Feature in test_text at index 3582 has shape: torch.Size([55, 768])\n",
      "Feature in test_text at index 3583 has shape: torch.Size([33, 768])\n",
      "Feature in test_text at index 3584 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3585 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3586 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3587 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3588 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3589 has shape: torch.Size([35, 768])\n",
      "Feature in test_text at index 3590 has shape: torch.Size([16, 768])\n",
      "Feature in test_text at index 3591 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3592 has shape: torch.Size([37, 768])\n",
      "Feature in test_text at index 3593 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3594 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3595 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3596 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3597 has shape: torch.Size([23, 768])\n",
      "Feature in test_text at index 3598 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3599 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3600 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3601 has shape: torch.Size([25, 768])\n",
      "Feature in test_text at index 3602 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3603 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3604 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 3605 has shape: torch.Size([13, 768])\n",
      "Feature in test_text at index 3606 has shape: torch.Size([34, 768])\n",
      "Feature in test_text at index 3607 has shape: torch.Size([15, 768])\n",
      "Feature in test_text at index 3608 has shape: torch.Size([27, 768])\n",
      "Feature in test_text at index 3609 has shape: torch.Size([26, 768])\n",
      "Feature in test_text at index 3610 has shape: torch.Size([8, 768])\n",
      "Feature in test_text at index 3611 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3612 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3613 has shape: torch.Size([10, 768])\n",
      "Feature in test_text at index 3614 has shape: torch.Size([38, 768])\n",
      "Feature in test_text at index 3615 has shape: torch.Size([19, 768])\n",
      "Feature in test_text at index 3616 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3617 has shape: torch.Size([32, 768])\n",
      "Feature in test_text at index 3618 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3619 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3620 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3621 has shape: torch.Size([22, 768])\n",
      "Feature in test_text at index 3622 has shape: torch.Size([28, 768])\n",
      "Feature in test_text at index 3623 has shape: torch.Size([14, 768])\n",
      "Feature in test_text at index 3624 has shape: torch.Size([12, 768])\n",
      "Feature in test_text at index 3625 has shape: torch.Size([20, 768])\n",
      "Feature in test_text at index 3626 has shape: torch.Size([11, 768])\n",
      "Feature in test_text at index 3627 has shape: torch.Size([7, 768])\n",
      "Feature in test_text at index 3628 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3629 has shape: torch.Size([17, 768])\n",
      "Feature in test_text at index 3630 has shape: torch.Size([9, 768])\n",
      "Feature in test_text at index 3631 has shape: torch.Size([24, 768])\n",
      "Feature in test_text at index 3632 has shape: torch.Size([31, 768])\n",
      "Feature in test_text at index 3633 has shape: torch.Size([19, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 将所有特征数据放入一个字典中\n",
    "text_features = {\n",
    "    'test_text': test_X_text\n",
    "}\n",
    "\n",
    "# 遍历字典，转换为tensor并去掉维度，然后打印形状\n",
    "for key, features in text_features.items():\n",
    "    for i, feature in enumerate(features):\n",
    "        tensor_feature = torch.tensor(feature)  # 将特征转换为tensor\n",
    "        tensor_feature = tensor_feature.squeeze(0)  # 去掉大小为1的维度（假设是第一个维度）\n",
    "        text_features[key][i] = tensor_feature  # 更新字典中的值\n",
    "        print(f\"Feature in {key} at index {i} has shape: {tensor_feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature in test_vision at index 0 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 4 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 5 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 6 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 7 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 8 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 9 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 10 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 11 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 12 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 13 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 14 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 15 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 16 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 17 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 18 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 19 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 20 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 21 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 22 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 23 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 24 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 25 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 26 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 27 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 28 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 29 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 30 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 31 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 32 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 33 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 34 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 35 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 36 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 37 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 38 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 39 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 40 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 41 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 42 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 43 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 44 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 45 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 46 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 47 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 48 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 49 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 50 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 51 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 52 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 53 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 54 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 55 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 56 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 57 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 58 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 59 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 60 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 61 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 62 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 63 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 64 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 65 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 66 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 67 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 68 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 69 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 70 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 71 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 72 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 73 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 74 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 75 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 76 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 77 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 78 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 79 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 80 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 81 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 82 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 83 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 84 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 85 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 86 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 87 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 88 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 89 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 90 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 91 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 92 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 93 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 94 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 95 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 96 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 97 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 98 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 99 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 100 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 101 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 102 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 103 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 104 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 105 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 106 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 107 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 108 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 109 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 110 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 111 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 112 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 113 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 114 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 115 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 116 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 117 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 118 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 119 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 120 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 121 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 122 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 123 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 124 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 125 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 126 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 127 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 128 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 129 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 130 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 131 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 132 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 133 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 134 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 135 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 136 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 137 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 138 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 139 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 140 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 141 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 142 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 143 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 144 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 145 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 146 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 147 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 148 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 149 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 150 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 151 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 152 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 153 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 154 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 155 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 156 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 157 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 158 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 159 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 160 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 161 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 162 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 163 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 164 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 165 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 166 has shape: torch.Size([35, 2048])\n",
      "Feature in test_vision at index 167 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 168 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 169 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 170 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 171 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 172 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 173 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 174 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 175 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 176 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 177 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 178 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 179 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 180 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 181 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 182 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 183 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 184 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 185 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 186 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 187 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 188 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 189 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 190 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 191 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 192 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 193 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 194 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 195 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 196 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 197 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 198 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 199 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 200 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 201 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 202 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 203 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 204 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 205 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 206 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 207 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 208 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 209 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 210 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 211 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 212 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 213 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 214 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 215 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 216 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 217 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 218 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 219 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 220 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 221 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 222 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 223 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 224 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 225 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 226 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 227 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 228 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 229 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 230 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 231 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 232 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 233 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 234 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 235 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 236 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 237 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 238 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 239 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 240 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 241 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 242 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 243 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 244 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 245 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 246 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 247 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 248 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 249 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 250 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 251 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 252 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 253 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 254 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 255 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 256 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 257 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 258 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 259 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 260 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 261 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 262 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 263 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 264 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 265 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 266 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 267 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 268 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 269 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 270 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 271 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 272 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 273 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 274 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 275 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 276 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 277 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 278 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 279 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 280 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 281 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 282 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 283 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 284 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 285 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 286 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 287 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 288 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 289 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 290 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 291 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 292 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 293 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 294 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 295 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 296 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 297 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 298 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 299 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 300 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 301 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 302 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 303 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 304 has shape: torch.Size([31, 2048])\n",
      "Feature in test_vision at index 305 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 306 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 307 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 308 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 309 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 310 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 311 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 312 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 313 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 314 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 315 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 316 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 317 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 318 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 319 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 320 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 321 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 322 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 323 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 324 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 325 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 326 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 327 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 328 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 329 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 330 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 331 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 332 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 333 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 334 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 335 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 336 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 337 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 338 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 339 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 340 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 341 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 342 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 343 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 344 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 345 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 346 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 347 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 348 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 349 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 350 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 351 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 352 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 353 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 354 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 355 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 356 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 357 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 358 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 359 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 360 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 361 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 362 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 363 has shape: torch.Size([35, 2048])\n",
      "Feature in test_vision at index 364 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 365 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 366 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 367 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 368 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 369 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 370 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 371 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 372 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 373 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 374 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 375 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 376 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 377 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 378 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 379 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 380 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 381 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 382 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 383 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 384 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 385 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 386 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 387 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 388 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 389 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 390 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 391 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 392 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 393 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 394 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 395 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 396 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 397 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 398 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 399 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 400 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 401 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 402 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 403 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 404 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 405 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 406 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 407 has shape: torch.Size([30, 2048])\n",
      "Feature in test_vision at index 408 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 409 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 410 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 411 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 412 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 413 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 414 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 415 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 416 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 417 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 418 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 419 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 420 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 421 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 422 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 423 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 424 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 425 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 426 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 427 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 428 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 429 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 430 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 431 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 432 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 433 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 434 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 435 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 436 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 437 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 438 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 439 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 440 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 441 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 442 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 443 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 444 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 445 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 446 has shape: torch.Size([33, 2048])\n",
      "Feature in test_vision at index 447 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 448 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 449 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 450 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 451 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 452 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 453 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 454 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 455 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 456 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 457 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 458 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 459 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 460 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 461 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 462 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 463 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 464 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 465 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 466 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 467 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 468 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 469 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 470 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 471 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 472 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 473 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 474 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 475 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 476 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 477 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 478 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 479 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 480 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 481 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 482 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 483 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 484 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 485 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 486 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 487 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 488 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 489 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 490 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 491 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 492 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 493 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 494 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 495 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 496 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 497 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 498 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 499 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 500 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 501 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 502 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 503 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 504 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 505 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 506 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 507 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 508 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 509 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 510 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 511 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 512 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 513 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 514 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 515 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 516 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 517 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 518 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 519 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 520 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 521 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 522 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 523 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 524 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 525 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 526 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 527 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 528 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 529 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 530 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 531 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 532 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 533 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 534 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 535 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 536 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 537 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 538 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 539 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 540 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 541 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 542 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 543 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 544 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 545 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 546 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 547 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 548 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 549 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 550 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 551 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 552 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 553 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 554 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 555 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 556 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 557 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 558 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 559 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 560 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 561 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 562 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 563 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 564 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 565 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 566 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 567 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 568 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 569 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 570 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 571 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 572 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 573 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 574 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 575 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 576 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 577 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 578 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 579 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 580 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 581 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 582 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 583 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 584 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 585 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 586 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 587 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 588 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 589 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 590 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 591 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 592 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 593 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 594 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 595 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 596 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 597 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 598 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 599 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 600 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 601 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 602 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 603 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 604 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 605 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 606 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 607 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 608 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 609 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 610 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 611 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 612 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 613 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 614 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 615 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 616 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 617 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 618 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 619 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 620 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 621 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 622 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 623 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 624 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 625 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 626 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 627 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 628 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 629 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 630 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 631 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 632 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 633 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 634 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 635 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 636 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 637 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 638 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 639 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 640 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 641 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 642 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 643 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 644 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 645 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 646 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 647 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 648 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 649 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 650 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 651 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 652 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 653 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 654 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 655 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 656 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 657 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 658 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 659 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 660 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 661 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 662 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 663 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 664 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 665 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 666 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 667 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 668 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 669 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 670 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 671 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 672 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 673 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 674 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 675 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 676 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 677 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 678 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 679 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 680 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 681 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 682 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 683 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 684 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 685 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 686 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 687 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 688 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 689 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 690 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 691 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 692 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 693 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 694 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 695 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 696 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 697 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 698 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 699 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 700 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 701 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 702 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 703 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 704 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 705 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 706 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 707 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 708 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 709 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 710 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 711 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 712 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 713 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 714 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 715 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 716 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 717 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 718 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 719 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 720 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 721 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 722 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 723 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 724 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 725 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 726 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 727 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 728 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 729 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 730 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 731 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 732 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 733 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 734 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 735 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 736 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 737 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 738 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 739 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 740 has shape: torch.Size([82, 2048])\n",
      "Feature in test_vision at index 741 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 742 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 743 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 744 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 745 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 746 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 747 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 748 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 749 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 750 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 751 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 752 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 753 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 754 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 755 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 756 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 757 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 758 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 759 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 760 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 761 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 762 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 763 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 764 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 765 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 766 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 767 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 768 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 769 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 770 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 771 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 772 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 773 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 774 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 775 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 776 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 777 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 778 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 779 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 780 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 781 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 782 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 783 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 784 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 785 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 786 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 787 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 788 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 789 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 790 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 791 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 792 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 793 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 794 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 795 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 796 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 797 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 798 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 799 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 800 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 801 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 802 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 803 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 804 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 805 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 806 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 807 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 808 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 809 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 810 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 811 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 812 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 813 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 814 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 815 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 816 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 817 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 818 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 819 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 820 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 821 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 822 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 823 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 824 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 825 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 826 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 827 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 828 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 829 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 830 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 831 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 832 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 833 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 834 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 835 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 836 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 837 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 838 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 839 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 840 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 841 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 842 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 843 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 844 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 845 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 846 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 847 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 848 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 849 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 850 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 851 has shape: torch.Size([34, 2048])\n",
      "Feature in test_vision at index 852 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 853 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 854 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 855 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 856 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 857 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 858 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 859 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 860 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 861 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 862 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 863 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 864 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 865 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 866 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 867 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 868 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 869 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 870 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 871 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 872 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 873 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 874 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 875 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 876 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 877 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 878 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 879 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 880 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 881 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 882 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 883 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 884 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 885 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 886 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 887 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 888 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 889 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 890 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 891 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 892 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 893 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 894 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 895 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 896 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 897 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 898 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 899 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 900 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 901 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 902 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 903 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 904 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 905 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 906 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 907 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 908 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 909 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 910 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 911 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 912 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 913 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 914 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 915 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 916 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 917 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 918 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 919 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 920 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 921 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 922 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 923 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 924 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 925 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 926 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 927 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 928 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 929 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 930 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 931 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 932 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 933 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 934 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 935 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 936 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 937 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 938 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 939 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 940 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 941 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 942 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 943 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 944 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 945 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 946 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 947 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 948 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 949 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 950 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 951 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 952 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 953 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 954 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 955 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 956 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 957 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 958 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 959 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 960 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 961 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 962 has shape: torch.Size([30, 2048])\n",
      "Feature in test_vision at index 963 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 964 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 965 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 966 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 967 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 968 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 969 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 970 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 971 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 972 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 973 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 974 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 975 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 976 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 977 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 978 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 979 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 980 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 981 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 982 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 983 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 984 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 985 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 986 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 987 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 988 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 989 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 990 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 991 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 992 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 993 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 994 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 995 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 996 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 997 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 998 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 999 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1000 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1001 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1002 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1003 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1004 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1005 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1006 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1007 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1008 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1009 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1010 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1011 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1012 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1013 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1014 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1015 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1016 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1017 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1018 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1019 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1020 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1021 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1022 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1023 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1024 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1025 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1026 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1027 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1028 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1029 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1030 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1031 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1032 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1033 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1034 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1035 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1036 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1037 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1038 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1039 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1040 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1041 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1042 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1043 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1044 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1045 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1046 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1047 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1048 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1049 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1050 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1051 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1052 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1053 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1054 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1055 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1056 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1057 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1058 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1059 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1060 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1061 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1062 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1063 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1064 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1065 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1066 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1067 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1068 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1069 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1070 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1071 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1072 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1073 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1074 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1075 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1076 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1077 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1078 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1079 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1080 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1081 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1082 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1083 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1084 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1085 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1086 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1087 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1088 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 1089 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1090 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1091 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1092 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 1093 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1094 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 1095 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1096 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1097 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1098 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1099 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1100 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1101 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1102 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1103 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1104 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1105 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1106 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1107 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1108 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1109 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1110 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 1111 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1112 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1113 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1114 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1115 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1116 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1117 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1118 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1119 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1120 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1121 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1122 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1123 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1124 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1125 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1126 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1127 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1128 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1129 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1130 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1131 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1132 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1133 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1134 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1135 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1136 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1137 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1138 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1139 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1140 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1141 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1142 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1143 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1144 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1145 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1146 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1147 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1148 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1149 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1150 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1151 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1152 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1153 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1154 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1155 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1156 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1157 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1158 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1159 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1160 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1161 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1162 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1163 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 1164 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1165 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1166 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1167 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1168 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1169 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1170 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1171 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1172 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1173 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1174 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1175 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1176 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1177 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1178 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1179 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1180 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1181 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1182 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1183 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1184 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1185 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1186 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1187 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1188 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1189 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1190 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1191 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1192 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1193 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1194 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1195 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1196 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1197 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1198 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1199 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1200 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1201 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1202 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1203 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1204 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1205 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1206 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1207 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1208 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1209 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1210 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1211 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1212 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1213 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1214 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1215 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1216 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1217 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1218 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1219 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1220 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1221 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1222 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1223 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1224 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1225 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1226 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1227 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1228 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1229 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1230 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1231 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1232 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1233 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1234 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1235 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1236 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1237 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1238 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1239 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1240 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1241 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1242 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1243 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1244 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1245 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1246 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1247 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1248 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1249 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1250 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1251 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1252 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1253 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1254 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1255 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1256 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1257 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1258 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1259 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1260 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1261 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1262 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1263 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1264 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1265 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1266 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1267 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1268 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1269 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1270 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1271 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1272 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1273 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1274 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1275 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1276 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1277 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1278 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1279 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1280 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1281 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1282 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1283 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1284 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1285 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1286 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1287 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1288 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1289 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1290 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1291 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1292 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 1293 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1294 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1295 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1296 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1297 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1298 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1299 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 1300 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1301 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1302 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1303 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1304 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1305 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1306 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1307 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1308 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1309 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1310 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1311 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1312 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1313 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 1314 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1315 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1316 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1317 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 1318 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1319 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1320 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1321 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1322 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1323 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1324 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1325 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1326 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1327 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1328 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1329 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1330 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1331 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1332 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1333 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1334 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1335 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 1336 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1337 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1338 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1339 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1340 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1341 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1342 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1343 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1344 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1345 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1346 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1347 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1348 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1349 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1350 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1351 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1352 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1353 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1354 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1355 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1356 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1357 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1358 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1359 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1360 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1361 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1362 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1363 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1364 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1365 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1366 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1367 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1368 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1369 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1370 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1371 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1372 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1373 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1374 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1375 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1376 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1377 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1378 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1379 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1380 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1381 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1382 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1383 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1384 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1385 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1386 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1387 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1388 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1389 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1390 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1391 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1392 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1393 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1394 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1395 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1396 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1397 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1398 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1399 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1400 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1401 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1402 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1403 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1404 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1405 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1406 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1407 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1408 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1409 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1410 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1411 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1412 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1413 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1414 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1415 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1416 has shape: torch.Size([39, 2048])\n",
      "Feature in test_vision at index 1417 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1418 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1419 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 1420 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1421 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1422 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1423 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1424 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1425 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1426 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1427 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1428 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1429 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1430 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1431 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1432 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1433 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1434 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1435 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1436 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1437 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1438 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1439 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1440 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1441 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1442 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1443 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1444 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1445 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1446 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1447 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1448 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1449 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1450 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1451 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1452 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1453 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1454 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1455 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1456 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1457 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1458 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1459 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1460 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1461 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1462 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1463 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1464 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1465 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1466 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1467 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1468 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 1469 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1470 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1471 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1472 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1473 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1474 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1475 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1476 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1477 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1478 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1479 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1480 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1481 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1482 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1483 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1484 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1485 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1486 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1487 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1488 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1489 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1490 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1491 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1492 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1493 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1494 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1495 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1496 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1497 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1498 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1499 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1500 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1501 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1502 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 1503 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1504 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1505 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1506 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1507 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1508 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1509 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1510 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1511 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1512 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1513 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1514 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1515 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1516 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1517 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1518 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1519 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1520 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1521 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1522 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1523 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1524 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1525 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1526 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1527 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1528 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1529 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1530 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1531 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1532 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1533 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1534 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1535 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1536 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1537 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1538 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1539 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1540 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1541 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1542 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1543 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1544 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1545 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1546 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1547 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1548 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1549 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1550 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1551 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1552 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1553 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1554 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1555 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1556 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1557 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1558 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1559 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1560 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1561 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1562 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1563 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1564 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1565 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1566 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1567 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1568 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1569 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1570 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1571 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1572 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1573 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1574 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1575 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1576 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1577 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1578 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1579 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1580 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1581 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1582 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1583 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1584 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1585 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1586 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1587 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1588 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1589 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1590 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1591 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1592 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1593 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1594 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1595 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1596 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1597 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1598 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1599 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1600 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1601 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1602 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1603 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1604 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1605 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1606 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1607 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1608 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1609 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1610 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1611 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1612 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1613 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1614 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1615 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1616 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1617 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 1618 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1619 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1620 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1621 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1622 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1623 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1624 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1625 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1626 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 1627 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1628 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1629 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1630 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1631 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1632 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1633 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1634 has shape: torch.Size([46, 2048])\n",
      "Feature in test_vision at index 1635 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1636 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 1637 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1638 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1639 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1640 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1641 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1642 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1643 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1644 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1645 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1646 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1647 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1648 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1649 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1650 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1651 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1652 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1653 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1654 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1655 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1656 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1657 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1658 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1659 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1660 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1661 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1662 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1663 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1664 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1665 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1666 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1667 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1668 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1669 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1670 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1671 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1672 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1673 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1674 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1675 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1676 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1677 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1678 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1679 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1680 has shape: torch.Size([41, 2048])\n",
      "Feature in test_vision at index 1681 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1682 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1683 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 1684 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1685 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1686 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1687 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1688 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1689 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1690 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1691 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1692 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1693 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1694 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1695 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1696 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1697 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1698 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1699 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1700 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1701 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1702 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1703 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1704 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1705 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1706 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1707 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1708 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1709 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1710 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1711 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1712 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1713 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1714 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 1715 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1716 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1717 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1718 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1719 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1720 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1721 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1722 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1723 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1724 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1725 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1726 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1727 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1728 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1729 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1730 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1731 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1732 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1733 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1734 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1735 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1736 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1737 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1738 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1739 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1740 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1741 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1742 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1743 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1744 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1745 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1746 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1747 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1748 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 1749 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 1750 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1751 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1752 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1753 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1754 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1755 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1756 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1757 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1758 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1759 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1760 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1761 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1762 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1763 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1764 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1765 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1766 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1767 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1768 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1769 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1770 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1771 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1772 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1773 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1774 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1775 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1776 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1777 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1778 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1779 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1780 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1781 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1782 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1783 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1784 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1785 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1786 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1787 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1788 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1789 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1790 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1791 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1792 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1793 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1794 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1795 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1796 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1797 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1798 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1799 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1800 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1801 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1802 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1803 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1804 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1805 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1806 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1807 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1808 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1809 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1810 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1811 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1812 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1813 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1814 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 1815 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1816 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1817 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1818 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1819 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1820 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1821 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1822 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1823 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1824 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1825 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1826 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1827 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1828 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1829 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1830 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1831 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1832 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1833 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1834 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1835 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1836 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1837 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1838 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1839 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1840 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1841 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1842 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1843 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1844 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1845 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1846 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1847 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1848 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1849 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1850 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1851 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1852 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1853 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1854 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1855 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 1856 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1857 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1858 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1859 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1860 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1861 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1862 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1863 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1864 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1865 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1866 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1867 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1868 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1869 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1870 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1871 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1872 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1873 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1874 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1875 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1876 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1877 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1878 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1879 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1880 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1881 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1882 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1883 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1884 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1885 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1886 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1887 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1888 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1889 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1890 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1891 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 1892 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1893 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1894 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1895 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1896 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1897 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1898 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1899 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1900 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1901 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1902 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1903 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1904 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1905 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1906 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1907 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1908 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1909 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1910 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1911 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1912 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1913 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1914 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1915 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1916 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1917 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1918 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1919 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1920 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1921 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1922 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1923 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1924 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1925 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1926 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1927 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1928 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1929 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1930 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 1931 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1932 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1933 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1934 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1935 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1936 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1937 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1938 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1939 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1940 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 1941 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1942 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 1943 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1944 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1945 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1946 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1947 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1948 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1949 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1950 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1951 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1952 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1953 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 1954 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1955 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1956 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1957 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1958 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1959 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1960 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 1961 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1962 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1963 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1964 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1965 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1966 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1967 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1968 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1969 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1970 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1971 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 1972 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 1973 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1974 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1975 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 1976 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 1977 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1978 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1979 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 1980 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1981 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1982 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1983 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1984 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 1985 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1986 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 1987 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 1988 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 1989 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 1990 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1991 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 1992 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1993 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 1994 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 1995 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 1996 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 1997 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 1998 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 1999 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2000 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2001 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2002 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2003 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2004 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2005 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2006 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2007 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2008 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2009 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2010 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2011 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2012 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2013 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 2014 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2015 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 2016 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2017 has shape: torch.Size([31, 2048])\n",
      "Feature in test_vision at index 2018 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2019 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 2020 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2021 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2022 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2023 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2024 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2025 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2026 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2027 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2028 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2029 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2030 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2031 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2032 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2033 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2034 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2035 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2036 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2037 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2038 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2039 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2040 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2041 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2042 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2043 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 2044 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2045 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2046 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2047 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2048 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2049 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2050 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2051 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2052 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2053 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2054 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2055 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2056 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2057 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2058 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2059 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2060 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2061 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2062 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2063 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2064 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2065 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2066 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2067 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2068 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2069 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2070 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2071 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2072 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2073 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2074 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2075 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2076 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2077 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2078 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2079 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2080 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2081 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2082 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2083 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2084 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2085 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2086 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2087 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2088 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2089 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2090 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2091 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2092 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2093 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2094 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2095 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2096 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2097 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2098 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2099 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2100 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2101 has shape: torch.Size([46, 2048])\n",
      "Feature in test_vision at index 2102 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 2103 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 2104 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2105 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2106 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2107 has shape: torch.Size([42, 2048])\n",
      "Feature in test_vision at index 2108 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2109 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2110 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2111 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2112 has shape: torch.Size([35, 2048])\n",
      "Feature in test_vision at index 2113 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2114 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2115 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2116 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2117 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2118 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2119 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2120 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2121 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 2122 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2123 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2124 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2125 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2126 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2127 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2128 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2129 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2130 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2131 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2132 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2133 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2134 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2135 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2136 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2137 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2138 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2139 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2140 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2141 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2142 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2143 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2144 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2145 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2146 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2147 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2148 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2149 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2150 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2151 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2152 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2153 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2154 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2155 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2156 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2157 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2158 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2159 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2160 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2161 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2162 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2163 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2164 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2165 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2166 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2167 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 2168 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2169 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2170 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2171 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2172 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2173 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2174 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2175 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2176 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2177 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2178 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2179 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2180 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2181 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2182 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2183 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2184 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2185 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2186 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2187 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2188 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2189 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2190 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2191 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2192 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2193 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2194 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2195 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2196 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2197 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2198 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2199 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2200 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2201 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2202 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2203 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2204 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2205 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2206 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2207 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2208 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2209 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2210 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2211 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2212 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2213 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2214 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2215 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2216 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2217 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2218 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2219 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2220 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2221 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2222 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2223 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2224 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2225 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2226 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2227 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2228 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2229 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2230 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2231 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2232 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2233 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2234 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2235 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2236 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2237 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2238 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2239 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2240 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2241 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2242 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2243 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2244 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2245 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2246 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2247 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2248 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2249 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2250 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2251 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2252 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2253 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2254 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2255 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2256 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2257 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2258 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2259 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2260 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2261 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2262 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2263 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2264 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2265 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2266 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2267 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2268 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2269 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2270 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2271 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2272 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2273 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2274 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2275 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2276 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2277 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2278 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2279 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2280 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2281 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2282 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2283 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2284 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2285 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2286 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2287 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2288 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2289 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2290 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2291 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2292 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2293 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2294 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2295 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2296 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2297 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2298 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2299 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2300 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2301 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2302 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2303 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2304 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2305 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2306 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2307 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2308 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2309 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2310 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2311 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2312 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2313 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2314 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2315 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2316 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2317 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2318 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2319 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2320 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2321 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2322 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2323 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2324 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2325 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2326 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2327 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2328 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2329 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2330 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2331 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2332 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2333 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2334 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2335 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2336 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2337 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2338 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2339 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2340 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2341 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2342 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2343 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2344 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2345 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 2346 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2347 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2348 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2349 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2350 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2351 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2352 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2353 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2354 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2355 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2356 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2357 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2358 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 2359 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2360 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2361 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2362 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2363 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2364 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2365 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2366 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2367 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2368 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2369 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2370 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2371 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2372 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2373 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2374 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2375 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2376 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2377 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2378 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2379 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2380 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2381 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2382 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2383 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2384 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2385 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2386 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2387 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2388 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2389 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2390 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2391 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2392 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2393 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2394 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2395 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2396 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2397 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2398 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2399 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2400 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2401 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2402 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2403 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2404 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2405 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2406 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2407 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2408 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2409 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2410 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2411 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2412 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2413 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2414 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2415 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2416 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2417 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2418 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2419 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2420 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2421 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2422 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2423 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2424 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2425 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2426 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 2427 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2428 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2429 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2430 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2431 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2432 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2433 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2434 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2435 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2436 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2437 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2438 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2439 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2440 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2441 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2442 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2443 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2444 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2445 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2446 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2447 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2448 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2449 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2450 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2451 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2452 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2453 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2454 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2455 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2456 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2457 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2458 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2459 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2460 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2461 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2462 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2463 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2464 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2465 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2466 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2467 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2468 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2469 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2470 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2471 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2472 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2473 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2474 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2475 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2476 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 2477 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2478 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2479 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2480 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2481 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2482 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2483 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2484 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2485 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2486 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2487 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2488 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2489 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2490 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2491 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2492 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2493 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2494 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2495 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2496 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2497 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2498 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2499 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2500 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2501 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2502 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2503 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2504 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2505 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2506 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2507 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2508 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2509 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2510 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2511 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2512 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2513 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2514 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2515 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2516 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2517 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2518 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2519 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2520 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2521 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2522 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2523 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2524 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2525 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2526 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2527 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2528 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2529 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2530 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2531 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2532 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2533 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2534 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2535 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2536 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2537 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2538 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2539 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2540 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2541 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2542 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2543 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2544 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2545 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2546 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2547 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2548 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2549 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2550 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2551 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2552 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2553 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2554 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2555 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2556 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2557 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2558 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2559 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2560 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2561 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2562 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2563 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2564 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2565 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2566 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2567 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2568 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2569 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2570 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2571 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2572 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2573 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2574 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2575 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2576 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2577 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2578 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2579 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2580 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2581 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2582 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2583 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2584 has shape: torch.Size([44, 2048])\n",
      "Feature in test_vision at index 2585 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2586 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2587 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2588 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2589 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2590 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2591 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2592 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2593 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2594 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2595 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2596 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2597 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2598 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2599 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2600 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 2601 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2602 has shape: torch.Size([45, 2048])\n",
      "Feature in test_vision at index 2603 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2604 has shape: torch.Size([50, 2048])\n",
      "Feature in test_vision at index 2605 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2606 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 2607 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2608 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2609 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2610 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2611 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2612 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2613 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2614 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2615 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2616 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2617 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2618 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2619 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2620 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2621 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 2622 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2623 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2624 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2625 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2626 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2627 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2628 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2629 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2630 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2631 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2632 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2633 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 2634 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2635 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2636 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2637 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2638 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2639 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2640 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2641 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2642 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2643 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2644 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2645 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2646 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2647 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2648 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2649 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2650 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2651 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2652 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2653 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2654 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2655 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2656 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2657 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2658 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2659 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2660 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2661 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2662 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2663 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2664 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2665 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2666 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2667 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2668 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2669 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2670 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2671 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2672 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2673 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2674 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2675 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2676 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2677 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2678 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2679 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2680 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2681 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2682 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2683 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2684 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2685 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2686 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2687 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2688 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2689 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2690 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2691 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2692 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2693 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2694 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2695 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2696 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2697 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2698 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2699 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2700 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2701 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2702 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2703 has shape: torch.Size([1, 2048])\n",
      "Feature in test_vision at index 2704 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2705 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2706 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2707 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2708 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2709 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2710 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2711 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2712 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2713 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2714 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2715 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2716 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2717 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2718 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2719 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2720 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2721 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2722 has shape: torch.Size([103, 2048])\n",
      "Feature in test_vision at index 2723 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2724 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2725 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2726 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2727 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2728 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2729 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2730 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2731 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2732 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2733 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2734 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2735 has shape: torch.Size([29, 2048])\n",
      "Feature in test_vision at index 2736 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2737 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2738 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2739 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2740 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2741 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2742 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2743 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2744 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2745 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2746 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2747 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2748 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2749 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2750 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2751 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2752 has shape: torch.Size([30, 2048])\n",
      "Feature in test_vision at index 2753 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2754 has shape: torch.Size([45, 2048])\n",
      "Feature in test_vision at index 2755 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2756 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2757 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2758 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2759 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2760 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2761 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2762 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2763 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2764 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2765 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2766 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2767 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2768 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2769 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2770 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2771 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2772 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2773 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2774 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2775 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2776 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2777 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2778 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2779 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2780 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2781 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2782 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2783 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2784 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2785 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2786 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2787 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2788 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2789 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2790 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2791 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2792 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2793 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2794 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2795 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2796 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2797 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2798 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2799 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2800 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2801 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2802 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2803 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2804 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2805 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2806 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2807 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2808 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2809 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2810 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 2811 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2812 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 2813 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2814 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2815 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2816 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2817 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2818 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2819 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2820 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 2821 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2822 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2823 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2824 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2825 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2826 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2827 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2828 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2829 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2830 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2831 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2832 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2833 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2834 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2835 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2836 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2837 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2838 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2839 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2840 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2841 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2842 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2843 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2844 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2845 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2846 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2847 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2848 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 2849 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2850 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2851 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 2852 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2853 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2854 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2855 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2856 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2857 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2858 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2859 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2860 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2861 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2862 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2863 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2864 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2865 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2866 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2867 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2868 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2869 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2870 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2871 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2872 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2873 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2874 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2875 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2876 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2877 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2878 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2879 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2880 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2881 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2882 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 2883 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2884 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2885 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2886 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2887 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2888 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 2889 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2890 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2891 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2892 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2893 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2894 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2895 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 2896 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2897 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2898 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2899 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2900 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2901 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2902 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2903 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2904 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2905 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2906 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2907 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2908 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2909 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2910 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2911 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2912 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2913 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2914 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2915 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2916 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2917 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2918 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2919 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2920 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2921 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2922 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2923 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2924 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2925 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2926 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2927 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2928 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2929 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 2930 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2931 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2932 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2933 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2934 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2935 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 2936 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2937 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2938 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2939 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2940 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 2941 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2942 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2943 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2944 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2945 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2946 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2947 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2948 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 2949 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2950 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2951 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2952 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2953 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2954 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2955 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2956 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2957 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2958 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2959 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2960 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2961 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2962 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2963 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 2964 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2965 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2966 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2967 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2968 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2969 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 2970 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 2971 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2972 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2973 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2974 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2975 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2976 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2977 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 2978 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2979 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 2980 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2981 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2982 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2983 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 2984 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2985 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 2986 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2987 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 2988 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2989 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2990 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 2991 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2992 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2993 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2994 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 2995 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 2996 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 2997 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 2998 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 2999 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3000 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3001 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 3002 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3003 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3004 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3005 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3006 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3007 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 3008 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3009 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3010 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3011 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3012 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3013 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3014 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3015 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3016 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3017 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3018 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3019 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3020 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3021 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3022 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3023 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3024 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3025 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3026 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 3027 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3028 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3029 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 3030 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3031 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3032 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3033 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3034 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3035 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3036 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3037 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3038 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 3039 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3040 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3041 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3042 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3043 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3044 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3045 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3046 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3047 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 3048 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3049 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3050 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3051 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3052 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3053 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3054 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3055 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3056 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 3057 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3058 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3059 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3060 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3061 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3062 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3063 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3064 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3065 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3066 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3067 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3068 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3069 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3070 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 3071 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3072 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3073 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3074 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3075 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3076 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3077 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3078 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3079 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3080 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3081 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3082 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3083 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3084 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3085 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3086 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3087 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3088 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3089 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3090 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3091 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3092 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3093 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3094 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3095 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3096 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3097 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3098 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3099 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3100 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3101 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3102 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3103 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3104 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3105 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3106 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3107 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3108 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3109 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3110 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3111 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3112 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3113 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3114 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3115 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3116 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3117 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 3118 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3119 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3120 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3121 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3122 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3123 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3124 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3125 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3126 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3127 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3128 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3129 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3130 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3131 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3132 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3133 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3134 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3135 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3136 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3137 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3138 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3139 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3140 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3141 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3142 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3143 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3144 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3145 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3146 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3147 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3148 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3149 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3150 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3151 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3152 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3153 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3154 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3155 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3156 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3157 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3158 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3159 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3160 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3161 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3162 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3163 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3164 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3165 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3166 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3167 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3168 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3169 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3170 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3171 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3172 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3173 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3174 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3175 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3176 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3177 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3178 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3179 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3180 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3181 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3182 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3183 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3184 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3185 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3186 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3187 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3188 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3189 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3190 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3191 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3192 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3193 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3194 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3195 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3196 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3197 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3198 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3199 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3200 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3201 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3202 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3203 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3204 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3205 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3206 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3207 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3208 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3209 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3210 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3211 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3212 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3213 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3214 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3215 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3216 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3217 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3218 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3219 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3220 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3221 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3222 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3223 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3224 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3225 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3226 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3227 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3228 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3229 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3230 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3231 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3232 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3233 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3234 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3235 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3236 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3237 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3238 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3239 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3240 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3241 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3242 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3243 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3244 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3245 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3246 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3247 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3248 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3249 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3250 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3251 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3252 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3253 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3254 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3255 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3256 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3257 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3258 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3259 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3260 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3261 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3262 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3263 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3264 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3265 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3266 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3267 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3268 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3269 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3270 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3271 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3272 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3273 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3274 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3275 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3276 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3277 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3278 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3279 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3280 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3281 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3282 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3283 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3284 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3285 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3286 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3287 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3288 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3289 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3290 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3291 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3292 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3293 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3294 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3295 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3296 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3297 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3298 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3299 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3300 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3301 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3302 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3303 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3304 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3305 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3306 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3307 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3308 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3309 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3310 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 3311 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 3312 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 3313 has shape: torch.Size([105, 2048])\n",
      "Feature in test_vision at index 3314 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3315 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3316 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3317 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3318 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3319 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3320 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3321 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3322 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3323 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3324 has shape: torch.Size([2, 2048])\n",
      "Feature in test_vision at index 3325 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3326 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3327 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3328 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3329 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3330 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3331 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3332 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3333 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3334 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3335 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3336 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3337 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3338 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3339 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3340 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3341 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3342 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3343 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3344 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3345 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3346 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3347 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3348 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3349 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3350 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3351 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3352 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3353 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3354 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3355 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3356 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3357 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3358 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3359 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3360 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3361 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3362 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3363 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3364 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3365 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3366 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3367 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3368 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3369 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3370 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3371 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3372 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3373 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3374 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3375 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3376 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3377 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3378 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3379 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3380 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3381 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3382 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3383 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3384 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3385 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3386 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3387 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3388 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3389 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3390 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3391 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3392 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3393 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3394 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3395 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3396 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3397 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3398 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3399 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3400 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3401 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3402 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3403 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3404 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3405 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3406 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3407 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3408 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3409 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3410 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3411 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3412 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3413 has shape: torch.Size([25, 2048])\n",
      "Feature in test_vision at index 3414 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3415 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3416 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3417 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3418 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3419 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 3420 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3421 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3422 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3423 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3424 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3425 has shape: torch.Size([19, 2048])\n",
      "Feature in test_vision at index 3426 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3427 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3428 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 3429 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3430 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3431 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3432 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3433 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3434 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3435 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3436 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3437 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3438 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3439 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3440 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3441 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3442 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3443 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3444 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3445 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3446 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3447 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3448 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3449 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3450 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3451 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3452 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3453 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3454 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3455 has shape: torch.Size([26, 2048])\n",
      "Feature in test_vision at index 3456 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 3457 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3458 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3459 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3460 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3461 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3462 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3463 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3464 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3465 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3466 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3467 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3468 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3469 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3470 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3471 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3472 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3473 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3474 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3475 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3476 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3477 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3478 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3479 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3480 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3481 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3482 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3483 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3484 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3485 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3486 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3487 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3488 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3489 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3490 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3491 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3492 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3493 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3494 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3495 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3496 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3497 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3498 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3499 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3500 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3501 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3502 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3503 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3504 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3505 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3506 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3507 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3508 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3509 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3510 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3511 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3512 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3513 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3514 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3515 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3516 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3517 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3518 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3519 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3520 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3521 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3522 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3523 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3524 has shape: torch.Size([38, 2048])\n",
      "Feature in test_vision at index 3525 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3526 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3527 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3528 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3529 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3530 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3531 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3532 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3533 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3534 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3535 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3536 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3537 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3538 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3539 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3540 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3541 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3542 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3543 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3544 has shape: torch.Size([24, 2048])\n",
      "Feature in test_vision at index 3545 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 3546 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3547 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3548 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3549 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3550 has shape: torch.Size([27, 2048])\n",
      "Feature in test_vision at index 3551 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3552 has shape: torch.Size([28, 2048])\n",
      "Feature in test_vision at index 3553 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3554 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3555 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3556 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3557 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3558 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3559 has shape: torch.Size([20, 2048])\n",
      "Feature in test_vision at index 3560 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 3561 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3562 has shape: torch.Size([18, 2048])\n",
      "Feature in test_vision at index 3563 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3564 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3565 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3566 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3567 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3568 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3569 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3570 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3571 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3572 has shape: torch.Size([21, 2048])\n",
      "Feature in test_vision at index 3573 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3574 has shape: torch.Size([16, 2048])\n",
      "Feature in test_vision at index 3575 has shape: torch.Size([32, 2048])\n",
      "Feature in test_vision at index 3576 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3577 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3578 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3579 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3580 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3581 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3582 has shape: torch.Size([23, 2048])\n",
      "Feature in test_vision at index 3583 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3584 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3585 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3586 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3587 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3588 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3589 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3590 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3591 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3592 has shape: torch.Size([22, 2048])\n",
      "Feature in test_vision at index 3593 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3594 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3595 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3596 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3597 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3598 has shape: torch.Size([17, 2048])\n",
      "Feature in test_vision at index 3599 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3600 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3601 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3602 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3603 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3604 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3605 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3606 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3607 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3608 has shape: torch.Size([11, 2048])\n",
      "Feature in test_vision at index 3609 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3610 has shape: torch.Size([4, 2048])\n",
      "Feature in test_vision at index 3611 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3612 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3613 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3614 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3615 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3616 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3617 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3618 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3619 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3620 has shape: torch.Size([12, 2048])\n",
      "Feature in test_vision at index 3621 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3622 has shape: torch.Size([10, 2048])\n",
      "Feature in test_vision at index 3623 has shape: torch.Size([8, 2048])\n",
      "Feature in test_vision at index 3624 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3625 has shape: torch.Size([15, 2048])\n",
      "Feature in test_vision at index 3626 has shape: torch.Size([3, 2048])\n",
      "Feature in test_vision at index 3627 has shape: torch.Size([5, 2048])\n",
      "Feature in test_vision at index 3628 has shape: torch.Size([14, 2048])\n",
      "Feature in test_vision at index 3629 has shape: torch.Size([6, 2048])\n",
      "Feature in test_vision at index 3630 has shape: torch.Size([7, 2048])\n",
      "Feature in test_vision at index 3631 has shape: torch.Size([9, 2048])\n",
      "Feature in test_vision at index 3632 has shape: torch.Size([13, 2048])\n",
      "Feature in test_vision at index 3633 has shape: torch.Size([12, 2048])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 将所有特征数据放入一个字典中\n",
    "vision_features = {\n",
    "    'test_vision': test_X_vision\n",
    "}\n",
    "\n",
    "# 遍历字典，转换为tensor并去掉维度，然后打印形状\n",
    "for key, features in vision_features.items():\n",
    "    for i, feature in enumerate(features):\n",
    "        tensor_feature = torch.tensor(feature)  # 将特征转换为tensor\n",
    "        vision_features[key][i] = tensor_feature  # 更新字典中的值\n",
    "        print(f\"Feature in {key} at index {i} has shape: {tensor_feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class ThreeModal_Dataset(Dataset):\n",
    "    def __init__(self, text_features, audio_features,vision_features, labels):\n",
    "        self.text_features = text_features\n",
    "        self.audio_features = audio_features\n",
    "        self.vision_features = vision_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_features = self.text_features[idx]\n",
    "        audio_features = self.audio_features[idx]\n",
    "        vision_features = self.vision_features[idx]\n",
    "        labels = self.labels[idx]\n",
    "        return text_features, audio_features, vision_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 从批次中分离音频特征、文本特征和标签\n",
    "    text_features, audio_features, vision_features, labels = zip(*batch)\n",
    "    \n",
    "    # 将音频特征和文本特征按照批次中最长的序列进行填充\n",
    "    text_features_padded = pad_sequence(text_features, batch_first=True)    \n",
    "    audio_features_padded = pad_sequence(audio_features, batch_first=True)\n",
    "    vision_features_padded = pad_sequence(vision_features, batch_first=True)    \n",
    "    \n",
    "    \n",
    "    # 转换标签为张量\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return text_features_padded, audio_features_padded, vision_features_padded, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_tensor = torch.tensor(test_Y)\n",
    "test_dataset = ThreeModal_Dataset(test_X_text, test_X_audio, test_X_vision, test_Y_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCrossAttentionClassifier(nn.Module):\n",
    "    def __init__(self, text_dim, audio_dim, vision_dim, hidden_dim, num_heads, dropout_rate=0.1):\n",
    "        super(SimpleCrossAttentionClassifier, self).__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 文本和音频/视觉的线性投影，用于映射到统一的隐层维度\n",
    "        self.text_to_hidden = nn.Linear(text_dim, hidden_dim)\n",
    "        self.audio_to_hidden = nn.Linear(audio_dim, hidden_dim)\n",
    "        self.vision_to_hidden = nn.Linear(vision_dim, hidden_dim)\n",
    "\n",
    "        # Text-Audio 和 Vision-Text 的 Cross-Attention\n",
    "        self.cross_attention_text_audio = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.cross_attention_vision_text = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, 1)  # 两个 Cross-Attention 输出拼接\n",
    "\n",
    "    def forward(self, text_features, audio_features, vision_features):\n",
    "        # 投影到隐层维度\n",
    "        text_hidden = self.text_to_hidden(text_features)  # (batch_size, seq_len, hidden_dim)\n",
    "        audio_hidden = self.audio_to_hidden(audio_features)  # (batch_size, seq_len, hidden_dim)\n",
    "        vision_hidden = self.vision_to_hidden(vision_features)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # 调整形状为 (seq_len, batch_size, hidden_dim) 以适应 MultiheadAttention\n",
    "        text_hidden = text_hidden.permute(1, 0, 2)\n",
    "        audio_hidden = audio_hidden.permute(1, 0, 2)\n",
    "        vision_hidden = vision_hidden.permute(1, 0, 2)\n",
    "\n",
    "        # Text-Audio Cross-Attention\n",
    "        text_audio_output, _ = self.cross_attention_text_audio(query=text_hidden, key=audio_hidden, value=audio_hidden)\n",
    "        text_audio_output = self.dropout(text_audio_output)  # 添加 Dropout\n",
    "        text_audio_output = text_audio_output.permute(1, 0, 2)  # 调整回 (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Vision-Text Cross-Attention\n",
    "        vision_text_output, _ = self.cross_attention_vision_text(query=vision_hidden, key=text_hidden, value=text_hidden)\n",
    "        vision_text_output = self.dropout(vision_text_output)  # 添加 Dropout\n",
    "        vision_text_output = vision_text_output.permute(1, 0, 2)  # 调整回 (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # 对比学习 - 使用 InfoNCE 损失\n",
    "        batch_size = text_audio_output.size(0)\n",
    "\n",
    "        # 对输出进行 L2 归一化以便计算余弦相似度\n",
    "        text_audio_norm = F.normalize(text_audio_output.mean(dim=1), p=2, dim=-1)\n",
    "        vision_text_norm = F.normalize(vision_text_output.mean(dim=1), p=2, dim=-1)\n",
    "\n",
    "        # 计算相似度矩阵\n",
    "        similarity_matrix = torch.matmul(text_audio_norm, vision_text_norm.T)\n",
    "\n",
    "        # 计算正样本的相似度（对角线）\n",
    "        positive_samples = torch.diag(similarity_matrix)\n",
    "\n",
    "        # 计算 InfoNCE 损失\n",
    "        temperature = 0.07  # 温度参数，可调整\n",
    "        similarity_matrix /= temperature\n",
    "        positive_samples /= temperature\n",
    "\n",
    "        # InfoNCE 损失计算\n",
    "        contrastive_loss = -torch.log(\n",
    "            torch.exp(positive_samples) / torch.exp(similarity_matrix).sum(dim=1)\n",
    "        ).mean()\n",
    "\n",
    "        # 池化操作：对序列维度取平均值\n",
    "        text_audio_pooled = text_audio_output.mean(dim=1)  # (batch_size, hidden_dim)\n",
    "        vision_text_pooled = vision_text_output.mean(dim=1)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # 拼接 Text-Audio 和 Vision-Text 的 Cross-Attention 输出\n",
    "        combined_output = torch.cat((text_audio_pooled, vision_text_pooled), dim=1)  # (batch_size, hidden_dim * 2)\n",
    "\n",
    "        # 分类\n",
    "        output = self.classifier(combined_output)\n",
    "        output = torch.sigmoid(output)  # 二分类问题\n",
    "\n",
    "        return output, contrastive_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8638\n",
      "Precision: 0.8689\n",
      "Recall: 0.9225\n",
      "F1 Score: 0.8949\n",
      "Unweighted Average (UA): 0.8435\n",
      "Weighted Average (WA): 0.8638\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.85      0.76      0.81      1350\n",
      "     Class 1       0.87      0.92      0.89      2284\n",
      "\n",
      "    accuracy                           0.86      3634\n",
      "   macro avg       0.86      0.84      0.85      3634\n",
      "weighted avg       0.86      0.86      0.86      3634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCrossAttentionClassifier(\n",
    "    text_dim=768,\n",
    "    audio_dim=1024,\n",
    "    vision_dim=2048,\n",
    "    hidden_dim=256,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.01\n",
    ").to(device)\n",
    "# 载入最好的模型权重\n",
    "best_model_path = '/root/autodl-tmp/best_model_three_modal.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 初始化列表来收集真实标签和预测标签\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# 对测试数据进行评估\n",
    "with torch.no_grad():\n",
    "    for audio_features, text_features, vision_features, labels in test_loader:  # 假设你有 vision_features\n",
    "        # 将音频、文本、视觉特征和标签移到 GPU\n",
    "        audio_features = audio_features.to(device)\n",
    "        text_features = text_features.to(device)\n",
    "        vision_features = vision_features.to(device)  # 包含视觉特征\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs, _ = model(audio_features, text_features, vision_features)  # 如果模型有对比学习部分，我们忽略该损失\n",
    "\n",
    "        # 获取预测结果并转换为 numpy 数组\n",
    "        predicted = torch.sigmoid(outputs.squeeze()).round().cpu().numpy()  # 二分类，预测结果为 0 或 1\n",
    "        predicted_labels.extend(predicted)\n",
    "        \n",
    "        # 将真实标签转换为 numpy 数组\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 将列表转换为 NumPy 数组\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# 计算各项指标\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# 防止除以零的情况，计算 UA (Unweighted Average) 和 WA (Weighted Average)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    per_class_accuracy = np.diag(cm) / np.sum(cm, axis=1)\n",
    "    per_class_accuracy = np.nan_to_num(per_class_accuracy)  # 将 NaN 转换为 0，避免计算错误\n",
    "    ua = np.mean(per_class_accuracy)  # Unweighted Average (UA)\n",
    "\n",
    "wa = accuracy  # Weighted Average (WA)，对于二分类任务，加权平均与总体准确率相同\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Unweighted Average (UA): {ua:.4f}\")\n",
    "print(f\"Weighted Average (WA): {wa:.4f}\")\n",
    "\n",
    "# 打印详细的分类报告\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['Class 0', 'Class 1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
